import{_ as e,c as s,o as i,aN as l}from"./chunks/framework.A-MC8nKA.js";const g=JSON.parse('{"title":"Elasticsearch写入原理","description":"","frontmatter":{},"headers":[],"relativePath":"middleware/es/Elasticsearch写入原理.md","filePath":"middleware/es/Elasticsearch写入原理.md","lastUpdated":1752827238000}'),t={name:"middleware/es/Elasticsearch写入原理.md"};function n(r,a,p,h,o,d){return i(),s("div",null,a[0]||(a[0]=[l(`<h1 id="elasticsearch写入原理" tabindex="-1">Elasticsearch写入原理 <a class="header-anchor" href="#elasticsearch写入原理" aria-label="Permalink to &quot;Elasticsearch写入原理&quot;">​</a></h1><h2 id="基本概念" tabindex="-1">基本概念 <a class="header-anchor" href="#基本概念" aria-label="Permalink to &quot;基本概念&quot;">​</a></h2><h3 id="索引" tabindex="-1">索引 <a class="header-anchor" href="#索引" aria-label="Permalink to &quot;索引&quot;">​</a></h3><p>Elasticsearch的索引是一个逻辑上的概念，指存储了相同类型的文档集合。</p><h3 id="映射" tabindex="-1">映射 <a class="header-anchor" href="#映射" aria-label="Permalink to &quot;映射&quot;">​</a></h3><p>映射（mapping）定义索引中有什么字段、进行字段类型确认。类似于数据库中表结构定义。</p><p>ES 默认动态创建索引和索引类型的 映射（mapping），就像是非关系型数据中的，无需定义表结构，更不用指定字段的数据类型。</p><p>也可以手动指定 mapping 类型，比如通过请求设置索引的映射（mapping）。</p><div class="language-java vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">java</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">curl </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">--</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">location </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">--</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">request POST </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;localhost:9200/course/_mapping&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> \\</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">--</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">header </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Content-Type: application/json&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> \\</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">--</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">data</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">raw </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;{</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;properties&quot;: {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;name&quot;: {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;type&quot;: &quot;text&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        },</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;description&quot;: {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;type&quot;: &quot;text&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        },</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        &quot;studymodel&quot;: {</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">            &quot;type&quot;: &quot;keyword&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        }</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    }</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">}&#39;</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><p><img src="https://s2.loli.net/2025/06/26/XntvjEleyYs4hzw.png" alt="20220531194731.png" loading="lazy"></p><h3 id="动态映射字符串" tabindex="-1">动态映射字符串 <a class="header-anchor" href="#动态映射字符串" aria-label="Permalink to &quot;动态映射字符串&quot;">​</a></h3><p>字符串类型 <code>string</code> 可被分为 <code>text</code> 和 <code>keyword</code> 类型。若不为索引指定映射，6.x 版本的 es 会把字符串定义为 <strong>text</strong> 类型，并增加一个 <strong>keyword</strong> 的类型字段。</p><p>云监控索引模版中，增加了动态映射规则，string 类型指定为 keyword 类型字段。</p><p><img src="https://s2.loli.net/2025/06/26/WCe1LnY9UDoyPi7.png" alt="20220531195748.png" loading="lazy"></p><p>text 字段类型可以被分词查询，而 keyword 字段类型不会被分词。聚合查询的时候需要用到 keyword 类型字段。</p><h3 id="文档" tabindex="-1">文档 <a class="header-anchor" href="#文档" aria-label="Permalink to &quot;文档&quot;">​</a></h3><p>ES 索引中存放的记录就做文档，可以理解为关系型数据库中表的一行数据记录。</p><p><strong>文档数据字段表</strong></p><table tabindex="0"><thead><tr><th>数据字段</th><th>含义</th><th></th></tr></thead><tbody><tr><td>_index</td><td>文档所属索引</td><td></td></tr><tr><td>_type</td><td>文档映射类型（7.x 已废弃），对应关系数据库中表的概念。</td><td></td></tr><tr><td>_id</td><td>文档 ID</td><td></td></tr><tr><td>_source</td><td>表示文档正文的原始 JSON</td><td></td></tr></tbody></table><p><img src="https://s2.loli.net/2025/06/26/sdIWGgN6YhDZi3x.png" alt="20220531195102.png" loading="lazy"></p><h3 id="集群" tabindex="-1">集群 <a class="header-anchor" href="#集群" aria-label="Permalink to &quot;集群&quot;">​</a></h3><p>一个ES集群由多个节点（node）组成， 每个集群都有一个共同的集群名称作为标识。</p><h3 id="节点" tabindex="-1">节点 <a class="header-anchor" href="#节点" aria-label="Permalink to &quot;节点&quot;">​</a></h3><p>一个 es 实例即为一个节点，一台机器可以有多个节点，正常使用下每个实例都应该会部署在不同的机器上。ES的配置文件中可以通过node.master、 node.data 来设置节点类型。</p><ul><li><p>node.master</p><p>指定该节点是否有资格被选举成为 master 节点，默认是true。es 默认集群中的第一台机器为 master，如果这台机挂了就会重新选举 master。</p></li><li><p>node.data</p><p>指定该节点是否存储索引数据，默认为 true。</p></li></ul><p>我们部署的 es 集群未指定节点类型，所以 3 个节点都是 true。</p><h3 id="分片" tabindex="-1">分片 <a class="header-anchor" href="#分片" aria-label="Permalink to &quot;分片&quot;">​</a></h3><p>shard（分片）是物理空间的概念，ES通过将索引数据拆分存储到不同的节点，用来提高ES的处理能力和可用性。</p><p>ES的一个索引可以包含多个分片（shard）</p><ul><li>每一个分片（shard）都是索引最小的工作单元，承载部分数据。</li><li>每个shard 都是一个 lucene 实例，有完整的简历索引和处理请求的能力。</li><li>增减节点时，shard 会自动在 nodes 中负载均衡。</li><li>一个文档只能完整的存放在一个shard上。</li><li>一个索引中含有 shard 的数量，默认值为 5，在索引创建后这个值是不能被更改的。</li><li>每一个shard关联的副本分片（replica shard）的数量，默认值为1，这个设置在任何时候都可以修改。</li></ul><h3 id="副本" tabindex="-1">副本 <a class="header-anchor" href="#副本" aria-label="Permalink to &quot;副本&quot;">​</a></h3><p>shard（分片）的冗余备份。主要作用如下：</p><ol><li>冗余备份，防止数据丢失；</li><li>shard 异常时负责容错和负载均衡；</li></ol><h2 id="es写入原理" tabindex="-1">ES写入原理 <a class="header-anchor" href="#es写入原理" aria-label="Permalink to &quot;ES写入原理&quot;">​</a></h2><h3 id="lucene的介绍" tabindex="-1">Lucene的介绍 <a class="header-anchor" href="#lucene的介绍" aria-label="Permalink to &quot;Lucene的介绍&quot;">​</a></h3><p>Elasticsearch 和 Lucene 的关系很简单：Elasticsearch 是基于 Lucene 实现的。ES 基于底层这些包，然后进行了扩展，提供了更多的更丰富的查询语句，并且通过 RESTful API 可以更方便地与底层交互。类似 ES 还有 Solr 也是基于 Lucene 实现的。</p><h3 id="es整体结构" tabindex="-1">ES整体结构 <a class="header-anchor" href="#es整体结构" aria-label="Permalink to &quot;ES整体结构&quot;">​</a></h3><p><img src="https://pic4.zhimg.com/v2-242903592e715384613486eeb103d3b7_r.jpg" alt="" loading="lazy"></p><p><img src="https://s2.loli.net/2025/06/26/KrUpvkVLuJ3HZfx.png" alt="image-20220605210139749.png" loading="lazy"></p><h3 id="分片结构" tabindex="-1">分片结构 <a class="header-anchor" href="#分片结构" aria-label="Permalink to &quot;分片结构&quot;">​</a></h3><p><img src="https://pic1.zhimg.com/v2-8b1fd96ed82a8edd06ae72de261f4988_b.jpg" alt="" loading="lazy"></p><ol><li><p><strong>Lucene</strong></p><p>Lucene 是 Elasticsearch所基于的 Java 库。</p></li><li><p><strong>Segment</strong></p><p>也叫段，类似于倒排索引，相当于一个数据集。</p></li><li><p><strong>Commit point</strong></p><p>提交点，记录着所有已知的 Segment 信息。</p></li><li><p><strong>del 文件</strong></p><p>记录着删除文档的信息。</p></li></ol><ul><li>文档新写入时，会生成新的 segment。同样会记录到 commit point 里面</li><li>文档查询，会查询所有的 Segment。</li><li>当一个段中的文档被删除或更新时，会将之前文档添加到该文件中。</li></ul><h3 id="分片写入的流程" tabindex="-1">分片写入的流程 <a class="header-anchor" href="#分片写入的流程" aria-label="Permalink to &quot;分片写入的流程&quot;">​</a></h3><p><img src="https://s2.loli.net/2025/06/26/keQHl4vCVjtdUFP.png" alt="image_woi7L9J7Wg..png" loading="lazy"></p><ol><li><p>向 es 的节点发起文档写入请求（每个节点都可以接受请求），接收请求的节点 Node1 作为协调节点（cooridiniate）的角色。</p></li><li><p>根据文档的 <code>_routing</code> 字段（若不指定，默认采用 <code>_id</code> 字段）采用路由算法计算文档存放的分片为分片 3 。</p><div class="language-java vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">java</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">shard </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> hash</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(routing) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">%</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> number_of_primary_shards</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>由于分片 3 的主分片位于 Node3上，此时请求会转发到 Node3。</p><blockquote><p>索引的分片数设置好之后不能修改。原因就在于修改分片数后不能通过路由算法找到原文档。</p></blockquote></li><li><p>在Node3上将数据写入到分片 3 的主分片。写入成功后，会将请求转发给其余副本分片所在的节点，继续副本分片的写入。</p></li><li><p>所有分片写入成功之后，Node3 向协调节点报告写入成功，协调节点向客户端报告写入成功。</p></li></ol><p><img src="https://s2.loli.net/2025/06/26/sdIWGgN6YhDZi3x.png" alt="20220531195102.png" loading="lazy"></p><h3 id="写入分片的流程" tabindex="-1">写入分片的流程 <a class="header-anchor" href="#写入分片的流程" aria-label="Permalink to &quot;写入分片的流程&quot;">​</a></h3><p>ES 写入数据到分片时的步骤：write -&gt; refresh -&gt; flush -&gt; merge。</p><h3 id="_1-write" tabindex="-1">1. write <a class="header-anchor" href="#_1-write" aria-label="Permalink to &quot;1. write&quot;">​</a></h3><p>数据并不直接落磁盘，而是先写入内存缓冲区，同时写入日志文件 Translog。</p><blockquote><p>注意，此时数据不能被查询到。</p></blockquote><p><strong>Translog作用</strong></p><ul><li>保证缓存中的数据不会丢失。</li><li>系统重启时，从 Translog 中恢复数据。</li></ul><p><img src="https://pic2.zhimg.com/v2-4574b8251f39a7cea95cf296c6f64d1d_b.jpg" alt="" loading="lazy"></p><h3 id="_2-refresh" tabindex="-1">2. refresh <a class="header-anchor" href="#_2-refresh" aria-label="Permalink to &quot;2. refresh&quot;">​</a></h3><p><img src="https://pic2.zhimg.com/v2-4574b8251f39a7cea95cf296c6f64d1d_b.jpg" alt="" loading="lazy"></p><p>数据从内存缓冲区写入到新的 Segment 中。但是并不是真正写到磁盘上，而是写到了系统文件的缓存中，避免频繁的磁盘 IO操作。</p><p>写操作完成后，清空 Buffer，但是不会清空 Translog（最终写到磁盘）。</p><blockquote><p>注意，写入 Segment后建立了倒排索引，数据此时可以被查询到。由此 es 并不是可以实时查询到，而是准实时的。</p></blockquote><p>refresh 的时间间隔默认是 1s，可以通过修改配置项 <code>index.refresh_interval</code> 调整该值，减少性能的损耗。</p><blockquote><p>如果对数据实时性，要求不高，可以适当调大该配置。比如 5s。</p></blockquote><p><img src="https://s2.loli.net/2025/06/26/jxo3Z61cynWR4m9.png" alt="image-20220605210054797.png" loading="lazy"></p><hr><h3 id="_3-flush" tabindex="-1">3. flush <a class="header-anchor" href="#_3-flush" aria-label="Permalink to &quot;3. flush&quot;">​</a></h3><p>随着 refresh 操作，Translog 会变得越来越大，当满足以下条件时，会触发 flush 操作。</p><ul><li>达到限定时间，默认30分钟。</li><li>达到 Translog 文件限制大小，默认 512m。</li></ul><p><img src="https://pic3.zhimg.com/v2-ac0ee8ec078c5047c5cc7bd0d572110e_b.jpg" alt="" loading="lazy"></p><ul><li>执行一次 refresh操作，将内存中的数据写到系统文件缓存中的 Segment。</li><li>将 commit point 写入磁盘，标明 所有的 segment。</li><li>文件系统缓存中的 Segment 被 fsync 刷到磁盘中。</li><li>清空并删除 translog，然后创建一个新的 translog。</li></ul><blockquote><p>清空 Translog 的原因是 Segment 也存入磁盘中了，此时 Translog 中的数据没意义了。</p></blockquote><h3 id="_4-merge" tabindex="-1">4. merge <a class="header-anchor" href="#_4-merge" aria-label="Permalink to &quot;4. merge&quot;">​</a></h3><p>每次 refresh 操作都会生成一个 Segment ，导致 Segment 越来越多（搜索分片时会搜索所有的Segment，会导致搜索变得越来越慢）。</p><p><strong>es 后台有个线程会进行 Segment 的合并。</strong></p><p><img src="https://pic1.zhimg.com/v2-e34592cb5381816f4e9c2038d1e2d640_b.jpg" alt="" loading="lazy"></p><blockquote><p>Elasticsearch 中的一个 shard 是一个 Lucene 索引，一个 Lucene 索引被分解成段。段是存储索引数据的索引中的内部存储元素，并且是不可变的。较小的段会定期合并到较大的段中，以保持索引大小并消除删除。</p></blockquote><ul><li>小的 Segment 合并成大的 Segment。</li><li>合并结束删除旧的 Segment。</li><li>更新 commit point 中的 Segment 信息。</li><li>新的 Segment 打开用来搜索。</li></ul><p>在 merge 的过程中，会清理已经删除的数据。Segment 合并时，数据会根据 <code>.del文件</code> 过滤数据，<code>.del</code>文件包含的数据不会写入到新的 Segment中。</p><p><strong>文档数据只有在 merge 这个阶段才被真正的物理删除掉。</strong></p><h3 id="translog-日志文件" tabindex="-1">Translog 日志文件 <a class="header-anchor" href="#translog-日志文件" aria-label="Permalink to &quot;Translog 日志文件&quot;">​</a></h3><p>translog 中的数据仅在 translog 被 <code>fsync</code>编辑和提交时才会持久化到磁盘。如果发生硬件故障或操作系统崩溃或 JVM 崩溃或分片故障，自上次 translog 提交以来写入的任何数据都将丢失。</p><p><img src="https://s2.loli.net/2025/06/26/wGUkQl2JSPXyZxt.png" alt="image-20220605212127139.png" loading="lazy"></p><hr><p>无论写入操作如何，translog 多久被<code>fsync</code>写入磁盘并提交一次。默认为<code>5s</code>. 小于的值<code>100ms</code>是不允许的。</p><hr><p>是否<code>fsync</code>在每次索引、删除、更新或批量请求后提交事务日志。此设置接受以下参数：</p><ul><li><p>request</p><p>（默认）<code>fsync</code>并在每次请求后提交。如果发生硬件故障，所有确认的写入都已经提交到磁盘。</p></li><li><p>async</p><p><code>fsync</code>并在后台提交每个<code>sync_interval</code>. 如果发生故障，自上次自动提交以来所有确认的写入都将被丢弃。</p></li></ul><hr><p><strong><code>index.translog.flush_threshold_size</code></strong></p><p>translog 存储所有尚未安全保存在 Lucene 中的操作（即，不是 Lucene 提交点的一部分）。尽管这些操作可用于读取，但如果分片要关闭并且必须恢复，则需要重新索引它们。此设置控制这些操作的最大总大小，以防止恢复时间过长。一旦达到最大大小，就会发生刷新，生成一个新的 Lucene 提交点。默认为<code>512mb</code>.</p><hr><p><strong><code>index.translog.flush_threshold_period</code></strong></p><p>在指定的时间间隔内如果没有进行flush操作，会进行一次强制flush操作。默认是30m。</p><h2 id="es数据结构" tabindex="-1">ES数据结构 <a class="header-anchor" href="#es数据结构" aria-label="Permalink to &quot;ES数据结构&quot;">​</a></h2><p><a href="https://www.hoyoh.com/fenxiang/60938.html" target="_blank" rel="noreferrer">www.hoyoh.com</a></p><h2 id="参考链接" tabindex="-1">参考链接 <a class="header-anchor" href="#参考链接" aria-label="Permalink to &quot;参考链接&quot;">​</a></h2><ul><li><a href="https://zhuanlan.zhihu.com/p/360990797" target="_blank" rel="noreferrer">https://zhuanlan.zhihu.com/p/360990797</a></li><li><a href="https://zhuanlan.zhihu.com/p/78309627" target="_blank" rel="noreferrer">https://zhuanlan.zhihu.com/p/78309627</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.3/index.html" target="_blank" rel="noreferrer">https://www.elastic.co/guide/en/elasticsearch/reference/7.3/index.html</a></li><li><a href="https://zhuanlan.zhihu.com/p/367703665" target="_blank" rel="noreferrer">https://zhuanlan.zhihu.com/p/367703665</a></li><li><a href="https://zhuanlan.zhihu.com/p/48338447" target="_blank" rel="noreferrer">https://zhuanlan.zhihu.com/p/48338447</a></li><li><a href="https://zhuanlan.zhihu.com/p/342098994" target="_blank" rel="noreferrer">https://zhuanlan.zhihu.com/p/342098994</a></li></ul>`,96)]))}const u=e(t,[["render",n]]);export{g as __pageData,u as default};
