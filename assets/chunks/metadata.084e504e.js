window.__VP_HASH_MAP__=JSON.parse("{\"cloudnative_docker_docker学习总结.md\":\"D7gCzvMj\",\"cloudnative_docker_docker镜像压缩.md\":\"Cds720uT\",\"cloudnative_docker_index.md\":\"gjc7soaD\",\"cloudnative_docker_制作tomcat镜像.md\":\"BZcEO80l\",\"cloudnative_docker_容器新增bash.md\":\"AfPYwlQw\",\"cloudnative_docker_容器软件安装.md\":\"BaaULiV_\",\"cloudnative_k8s_index.md\":\"DdGDVfiD\",\"cloudnative_k8s_k8s常用命令.md\":\"DScall-w\",\"cloudnative_k8s_k8s问题排查流程图.md\":\"JrgQ98vX\",\"cloudnative_prometheus_index.md\":\"B2gcFwg1\",\"cloudnative_prometheus_node_exporter源码.md\":\"Cs8qdSnX\",\"cloudnative_prometheus_tsdb.md\":\"C2Z-ezt1\",\"cloudnative_prometheus_数据模型.md\":\"DNvaUeoF\",\"cloudnative_prometheus_架构.md\":\"iKsAdYJh\",\"database_clickhouse_clickhouse基础.md\":\"B79DB4f6\",\"database_clickhouse_clickhouse安装.md\":\"CU_Qo8CV\",\"database_clickhouse_clickhouse物化列序列化报错.md\":\"BeSB1czW\",\"database_clickhouse_clickhouse高级.md\":\"BbnjY2It\",\"database_clickhouse_index.md\":\"vThCdNoc\",\"database_clickhouse_为什么弃用elasticsearch.md\":\"BwOXDlY4\",\"database_mysql_b树和b_树.md\":\"BWA4bhYc\",\"database_mysql_explain使用总结.md\":\"DjTRZyJW\",\"database_mysql_index.md\":\"qxoc0Rr5\",\"database_mysql_innodb存储引擎.md\":\"CwnKPiN3\",\"database_mysql_mysql基础架构.md\":\"Bs54qqOA\",\"database_mysql_mysql日志系统.md\":\"3et7aJty\",\"database_mysql_mysql根据idb文件恢复数据.md\":\"CuDty_G9\",\"database_mysql_mysql的binlog日志过期删除.md\":\"GXQX4OnS\",\"database_mysql_orderby和limit混用的bug.md\":\"CEDXxHXa\",\"database_mysql_sql语句的抖动问题.md\":\"QYQgq8xy\",\"database_mysql_一条更新sql的执行过程.md\":\"Dw0Ki1kp\",\"database_mysql_事务隔离.md\":\"D-mdlh-4\",\"database_mysql_慢查询日志.md\":\"C_gTcUk8\",\"database_mysql_索引.md\":\"DS8765eP\",\"database_mysql_索引失效的场景.md\":\"CGTjGO_q\",\"database_mysql_行锁.md\":\"B70NRcbV\",\"database_mysql_锁.md\":\"CrkUXMiW\",\"database_redis_index.md\":\"DFrLVQS4\",\"database_redis_lru和lfu算法.md\":\"4xLkoeD0\",\"database_redis_redisson.md\":\"B_XVyuWk\",\"database_redis_redis事务.md\":\"6aCM50aW\",\"database_redis_redis实现分布式锁.md\":\"4Snu8lf3\",\"database_redis_redis数据类型.md\":\"BpIuZMHV\",\"database_redis_redis数据类型原理.md\":\"BxJeCHgW\",\"database_redis_redis的持久化.md\":\"Bz2GSJMG\",\"database_redis_redis集群.md\":\"DYQWIwOl\",\"database_redis_内存淘汰策略.md\":\"iFH9pPoE\",\"database_redis_布隆过滤器.md\":\"DB5Lkn7o\",\"database_redis_缓存问题.md\":\"DdnRDr7Z\",\"database_redis_过期策略.md\":\"DFfuM0lR\",\"frame_mybatis_custom_sql执行器.md\":\"Cw4oNSmU\",\"frame_mybatis_custom_xml解析.md\":\"DbWfMpq3\",\"frame_mybatis_custom_手写mybatis.md\":\"DJ68-P3U\",\"frame_mybatis_custom_数据源.md\":\"DVj-l_5a\",\"frame_mybatis_custom_映射器-mapper.md\":\"BKTndC1z\",\"frame_mybatis_index.md\":\"iS6g4zXq\",\"frame_netty_bytebuf.md\":\"DU-tfEfo\",\"frame_netty_handler的共享和并发安全性.md\":\"B5Jj13fd\",\"frame_netty_http服务和ssl_tls.md\":\"ByoZV-6x\",\"frame_netty_index.md\":\"D_TJCfhk\",\"frame_netty_netty实现文件下载.md\":\"DY53ygwt\",\"frame_netty_netty实现通信框架.md\":\"klEl9EDO\",\"frame_netty_netty常用组件.md\":\"CT-ZAAIb\",\"frame_netty_tcp粘包拆包问题.md\":\"FIk_S-kS\",\"frame_netty_内置通信传输模式.md\":\"DNBWj2C4\",\"frame_netty_写空闲和读空闲.md\":\"Ct2SsFag\",\"frame_netty_基于netty实现rpc.md\":\"BA5vOXcl\",\"frame_netty_序列化问题.md\":\"DPbg2M01\",\"frame_netty_线程模型.md\":\"DR9vhnj-\",\"frame_netty_编解码器.md\":\"C6zom-cD\",\"frame_netty_资源管理和simplechannelinboundhandler.md\":\"DOaWePtv\",\"frame_netty_零拷贝.md\":\"CKc2J9ky\",\"frame_spring_aop.md\":\"DF70AMRN\",\"frame_spring_applicationcontext和beanfactory区别.md\":\"2UR1N5HM\",\"frame_spring_aware接口.md\":\"8GAbsqIh\",\"frame_spring_beanfactory和factorybean总结.md\":\"D94pHWmq\",\"frame_spring_bytebuddy实现动态代理.md\":\"DS_4Ge37\",\"frame_spring_custom_aop.md\":\"SrRGY16h\",\"frame_spring_custom_boot.md\":\"DCXk-8gF\",\"frame_spring_custom_ioc.md\":\"DivTmjFq\",\"frame_spring_custom_jdbc.md\":\"pCGP__-m\",\"frame_spring_custom_mvc.md\":\"DFk1abTL\",\"frame_spring_custom_声明式事务.md\":\"DK-CDy3I\",\"frame_spring_custom_手写spring.md\":\"D-kYvaCr\",\"frame_spring_index.md\":\"DZEmmJUW\",\"frame_spring_spi机制.md\":\"c5Prktrs\",\"frame_spring_spring中bean加载流程.md\":\"D0ehMzyL\",\"frame_spring_spring中bean的作用域.md\":\"D6oCRBTb\",\"frame_spring_spring事务总结.md\":\"CFv-HUIY\",\"frame_spring_spring依赖注入.md\":\"D_PRf5cr\",\"frame_spring_spring如何解决循环依赖.md\":\"BNqYXWxX\",\"frame_spring_spring框架概述.md\":\"D6FlERnx\",\"frame_spring_spring自定义注解扫描.md\":\"Bmy42_5P\",\"frame_spring_spring配置文件加载顺序.md\":\"hj6qFKMj\",\"frame_springboot_index.md\":\"DqP44mh3\",\"frame_springboot_springboot使用apo记录操作日志.md\":\"CzkCL4cx\",\"frame_springboot_springboot能同时处理多少请求.md\":\"4iOxhQxf\",\"frame_springboot_springboot项目自动初始化数据库.md\":\"D6OSqon7\",\"frame_springcloud_feigh远程调用原理.md\":\"Dblzz5zI\",\"frame_springcloud_gateway.md\":\"DJcJbv34\",\"frame_springcloud_index.md\":\"CVLmU41s\",\"frame_springcloud_nacos.md\":\"g5dphIzx\",\"frame_springcloud_seata分布式事务.md\":\"BVGSD_bd\",\"frame_springcloud_sentinel原理.md\":\"CLXu0WFI\",\"frame_springcloud_注册中心的演进.md\":\"BxvR6xKm\",\"index.md\":\"rTclNEau\",\"java_cache_index.md\":\"CQNaJP_1\",\"java_cache_多级缓存.md\":\"UhmBkkbR\",\"java_cache_本地缓存.md\":\"DEShbEHp\",\"java_cache_缓存淘汰算法.md\":\"Bf9xGhZw\",\"java_collection_collection集合概述.md\":\"CSy8LCQO\",\"java_collection_concurrenthashmap1.7.md\":\"CsUms5Z6\",\"java_collection_concurrenthashmap1.8.md\":\"DZlCdjkC\",\"java_collection_hashmap1.7.md\":\"DwH0RSsl\",\"java_collection_hashmap1.8.md\":\"DKSdexe0\",\"java_collection_index.md\":\"BbXbgMnh\",\"java_collection_list集合体系.md\":\"BobptR9E\",\"java_collection_set集合体系.md\":\"CWuGi0iI\",\"java_concurrent_index.md\":\"DEvzjtS6\",\"java_concurrent_java高并发.md\":\"B3V1eLrF\",\"java_concurrent_single_aqs.md\":\"CvQ59pZl\",\"java_concurrent_single_blockqueue阻塞队列.md\":\"BE7vAN5d\",\"java_concurrent_single_cas.md\":\"DCdIxiS7\",\"java_concurrent_single_synchronized原理.md\":\"D0AkUxt6\",\"java_concurrent_single_threadlocal.md\":\"CQ4m4pHJ\",\"java_concurrent_single_transmittable-thread-local.md\":\"DieTp9G5\",\"java_concurrent_single_原子类.md\":\"Br7TAPMu\",\"java_concurrent_single_死锁活锁和饥饿.md\":\"CjNS0ToO\",\"java_concurrent_single_线程池的关闭.md\":\"B-4fKFrG\",\"java_concurrent_single_线程池的执行流程.md\":\"D6MWE6h9\",\"java_concurrent_single_线程的生命周期.md\":\"BJv3N2RN\",\"java_distributed_index.md\":\"UGsbU0n-\",\"java_distributed_分布式id.md\":\"qR2Y-BHE\",\"java_distributed_分布式事务.md\":\"BbjjsRgL\",\"java_distributed_分布式锁.md\":\"BoPPs7yU\",\"java_distributed_幂等性问题.md\":\"BpndSLuf\",\"java_io_bio.md\":\"DidUmPkc\",\"java_io_index.md\":\"CoJxNMQi\",\"java_io_io多路复用.md\":\"C0zZLNF_\",\"java_io_nio.md\":\"2d6160-w\",\"java_io_reactor模式.md\":\"D7lJInBl\",\"java_io_基于bio实现rpc框架.md\":\"DMtluLsy\",\"java_jvm_cpu负载过高排查记录.md\":\"B4NNaitd\",\"java_jvm_g1收集器.md\":\"DaqhYVOK\",\"java_jvm_index.md\":\"BHa0pEcY\",\"java_jvm_java类加载器.md\":\"BhA9bOXV\",\"java_jvm_jdk调优命令.md\":\"DvtThr11\",\"java_jvm_jvm内存模型.md\":\"DCQKY57O\",\"java_jvm_内存问题排查总结.md\":\"C2aar_oB\",\"java_jvm_可视化工具.md\":\"DB-4_az8\",\"java_jvm_垃圾回收器.md\":\"lfdcvcA9\",\"java_jvm_垃圾回收算法.md\":\"BPoGwS3P\",\"java_jvm_对象创建.md\":\"BbMFaPWo\",\"java_jvm_类加载器.md\":\"DlAOtTBl\",\"java_jvm_频繁gc排查.md\":\"MfxtsM5K\",\"middleware_es_bulkprocessor死锁问题.md\":\"CvGafSUu\",\"middleware_es_elasticsearch写入原理.md\":\"013srUlX\",\"middleware_es_elasticsearch基础概念.md\":\"e9E-Gbkt\",\"middleware_es_elasticsearch查询原理.md\":\"BDWF6xXI\",\"middleware_es_elasticsearch检索.md\":\"CdsauQCr\",\"middleware_es_elasticsearch聚合查询.md\":\"DOEW3Rcs\",\"middleware_es_es分片.md\":\"7UlUwqH7\",\"middleware_es_es压测记录和esrally使用.md\":\"Bi70cG1p\",\"middleware_es_es参数调优.md\":\"Dj6VUJqV\",\"middleware_es_es深度分页问题.md\":\"COqW10Wz\",\"middleware_es_es滚动查询-scroll.md\":\"B8yv1ULD\",\"middleware_es_es的log4j2日志自动清理配置.md\":\"BtoITlFA\",\"middleware_es_es聚合查询原理.md\":\"Dij8f8XZ\",\"middleware_es_es集群.md\":\"CthFCLav\",\"middleware_es_index.md\":\"Djo8bRUQ\",\"middleware_es_倒排索引原理.md\":\"DAzIoQjt\",\"middleware_es_并发场景修改文档.md\":\"DY9wRMPY\",\"middleware_es_批量操作bulk和bulkprocessor.md\":\"BFI5HrPN\",\"middleware_es_集群脑裂-参数配置.md\":\"Bqz92Fbw\",\"middleware_kafka___consumer_offsets.md\":\"Bdogv81U\",\"middleware_kafka_index.md\":\"BtTvrHij\",\"middleware_kafka_kafka-ack应答机制.md\":\"BtsPWlAu\",\"middleware_kafka_kafka保证消息不丢失.md\":\"Bnfqd1JX\",\"middleware_kafka_kafka分区机制策略.md\":\"DMY160ej\",\"middleware_kafka_kafka副本机制.md\":\"joN6HrXB\",\"middleware_kafka_kafka总控制器controller.md\":\"CQ6-39Z2\",\"middleware_kafka_kafka手动重新分区.md\":\"DW-UtWo5\",\"middleware_kafka_kafka消费模型.md\":\"CGbvP5Uj\",\"middleware_kafka_kafka消费策略.md\":\"D598dQNY\",\"middleware_kafka_kafka生产者参数.md\":\"Demnuv2s\",\"middleware_kafka_kafka的分区副本规划.md\":\"5I654_CQ\",\"middleware_kafka_kafka解决重复消费.md\":\"DF2owVE_\",\"middleware_kafka_kafka高性能的原因.md\":\"D6o8F1pA\",\"middleware_kafka_producer发布消息机制.md\":\"CjYbOU_k\",\"middleware_kafka_数据日志分段存储.md\":\"D8ahVz7R\",\"middleware_kafka_消费者组.md\":\"CLG3plfR\",\"middleware_kafka_高水位hw和leo.md\":\"DW3bR0Tw\",\"middleware_rocketmq_index.md\":\"CeRiuYUJ\",\"middleware_rocketmq_kakfa和rocketmq的区别.md\":\"D9QV6Xk-\",\"middleware_rocketmq_mq接收消息幂等性.md\":\"rtnUKPT_\",\"middleware_rocketmq_rocketmq基础学习.md\":\"CYW1A07v\",\"middleware_rocketmq_rocketmq集群架构.md\":\"CEUiBD-Q\",\"middleware_rocketmq_事务消息.md\":\"CnAj0eZq\",\"middleware_rocketmq_如何保证发送消息有序.md\":\"_sSogBvb\",\"middleware_rocketmq_如何保证消息不丢失.md\":\"naCqrBq0\",\"middleware_rocketmq_消息样例.md\":\"C-aisTD3\",\"middleware_rocketmq_顺序消息.md\":\"BU3DfP2N\",\"other_algorithm_index.md\":\"C21y0-ds\",\"other_algorithm_动态规划.md\":\"DDrVlPlM\",\"other_algorithm_排序.md\":\"BnYqIfTE\",\"other_algorithm_时间复杂度.md\":\"pDWg81iw\",\"other_algorithm_查找.md\":\"YFgsHFWf\",\"other_datastructure_index.md\":\"5jyEOCDv\",\"other_datastructure_二叉树.md\":\"DcCKemHE\",\"other_datastructure_常用数据结构.md\":\"BkiB-HiB\",\"other_design_index.md\":\"C-pZSXGq\",\"other_design_七大基本原则.md\":\"DbYfqyyp\",\"other_design_创建型.md\":\"B1TtT9us\",\"other_design_结构型.md\":\"DQKB2Lom\",\"other_design_行为型.md\":\"CV8uddWY\",\"other_network_http1x和http2x.md\":\"DRmOLJ4a\",\"other_network_http和https.md\":\"Cosri1Z1\",\"other_network_http常见字段.md\":\"C1lN1u84\",\"other_network_index.md\":\"Dfk-kWJW\",\"other_network_linux如何收发网络包.md\":\"D5Qlqod7\",\"other_network_osi七层网络模型.md\":\"Bvx-gM6o\",\"other_network_rtt和srtt.md\":\"sWwqptF7\",\"other_network_socket.md\":\"CUrhk0j0\",\"other_network_tcpip四层网络模型.md\":\"BpSBZKN5\",\"other_network_tcp分析工具.md\":\"DfqgnKwq\",\"other_network_tcp协议.md\":\"DTuSWiKJ\",\"other_network_tcp粘包拆包.md\":\"DgqfnVKA\",\"other_network_拥塞控制.md\":\"D3vMKyav\",\"other_network_流量控制-滑动窗口.md\":\"CV0FR9CZ\",\"other_network_网址访问页面中间发生了哪些过程.md\":\"CVz1aoO2\",\"other_network_网络包的封装原理.md\":\"TEGSDfhj\",\"other_network_重传机制.md\":\"B416pRUv\",\"other_observability_index.md\":\"ceKCMmhR\",\"other_observability_log_index.md\":\"DqwwoD6-\",\"other_observability_opentelemetry_index.md\":\"jn1v84lh\",\"other_observability_opentelemetry_可观测性.md\":\"C9IUllcD\",\"other_observability_skywalking_index.md\":\"Dnjh_mhJ\",\"other_observability_skywalking_源码学习.md\":\"-ezfreS8\",\"other_observability_skywalking_组件安装.md\":\"CcvC1b_w\",\"personal_index.md\":\"DbyUkNWE\"}");function deserializeFunctions(r){return Array.isArray(r)?r.map(deserializeFunctions):typeof r=="object"&&r!==null?Object.keys(r).reduce((t,n)=>(t[n]=deserializeFunctions(r[n]),t),{}):typeof r=="string"&&r.startsWith("_vp-fn_")?new Function(`return ${r.slice(7)}`)():r};window.__VP_SITE_DATA__=deserializeFunctions(JSON.parse("{\"lang\":\"zh-CN\",\"dir\":\"ltr\",\"title\":\"AlbertYang Blog\",\"description\":\"欢迎来到 Albert Yang 的个人博客\",\"base\":\"/blog/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"pageStyle\":\"segment-nav\",\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"blogger\":{\"avatar\":\"https://s2.loli.net/2025/07/18/gKh3Rix8bMYkQ1y.jpg\",\"shape\":\"circle-rotate\",\"name\":\"Albert Yang\",\"slogan\":\"Learn Fast, Code Better\",\"circleBgImg\":\"/blog/bg14.jpg\",\"color\":\"#ffffff\"},\"articleUpdate\":{\"enabled\":false,\"limit\":3},\"footerInfo\":{\"theme\":{\"name\":\"Theme By Teek@1.4.0\"},\"copyright\":{\"createYear\":2025,\"suffix\":\"Teek\"}},\"codeBlock\":{\"copiedDone\":\"_vp-fn_(TkMessage) => TkMessage.success(\\\"\\\\u590D\\\\u5236\\\\u6210\\\\u529F\\\\uFF01\\\")\"},\"post\":{\"showCapture\":false,\"coverImgMode\":\"full\",\"showMore\":true},\"articleShare\":{\"enabled\":true},\"siteAnalytics\":[],\"logo\":\"/bird.svg\",\"darkModeSwitchLabel\":\"主题\",\"sidebarMenuLabel\":\"菜单\",\"returnToTopLabel\":\"返回顶部\",\"lastUpdatedText\":\"上次更新时间\",\"outline\":{\"level\":[2,4],\"label\":\"本页导航\"},\"docFooter\":{\"prev\":\"上一页\",\"next\":\"下一页\"},\"nav\":[{\"text\":\"首页\",\"link\":\"/\"},{\"text\":\"Java\",\"items\":[{\"text\":\"JVM\",\"link\":\"/java/jvm/\"},{\"text\":\"高并发\",\"link\":\"/java/concurrent/\"},{\"text\":\"IO\",\"link\":\"/java/io/\"},{\"text\":\"缓存\",\"link\":\"/java/cache/\"},{\"text\":\"集合\",\"link\":\"/java/collection/\"},{\"text\":\"分布式\",\"link\":\"/java/distributed/\"}]},{\"text\":\"框架\",\"items\":[{\"text\":\"Spring\",\"link\":\"/frame/spring/\"},{\"text\":\"MyBatis\",\"link\":\"/frame/mybatis/\"},{\"text\":\"SpringBoot\",\"link\":\"/frame/springboot/\"},{\"text\":\"SpringCloud\",\"link\":\"/frame/springcloud/\"},{\"text\":\"Netty\",\"link\":\"/frame/netty/\"}]},{\"text\":\"数据库\",\"items\":[{\"text\":\"MySQL\",\"link\":\"/database/mysql/\"},{\"text\":\"Redis\",\"link\":\"/database/redis/\"},{\"text\":\"ClickHouse\",\"link\":\"/database/clickhouse/\"}]},{\"text\":\"中间件\",\"items\":[{\"text\":\"Elasticsearch\",\"link\":\"/middleware/es/\"},{\"text\":\"Kafka\",\"link\":\"/middleware/kafka/\"},{\"text\":\"RocketMQ\",\"link\":\"/middleware/rocketmq/\"}]},{\"text\":\"其它\",\"items\":[{\"text\":\"云原生\",\"items\":[{\"text\":\"Docker\",\"link\":\"/cloudnative/docker/\"},{\"text\":\"K8s\",\"link\":\"/cloudnative/k8s/\"},{\"text\":\"Prometheus\",\"link\":\"/cloudnative/prometheus/\"}]},{\"text\":\"可观测性\",\"items\":[{\"text\":\"Opentelemetry\",\"link\":\"/other/observability/opentelemetry/\"},{\"text\":\"Skywalking\",\"link\":\"/other/observability/skywalking/\"},{\"text\":\"日志收集\",\"link\":\"/other/observability/log/\"}]},{\"text\":\"设计模式\",\"link\":\"/other/design/\"},{\"text\":\"计算机网络\",\"link\":\"/other/network/\"},{\"text\":\"数据结构\",\"link\":\"/other/datastructure/\"},{\"text\":\"算法\",\"link\":\"/other/algorithm/\"}]}],\"sidebar\":{\"/\":[],\"/cloudnative/\":[{\"text\":\"docker\",\"items\":[{\"text\":\"index\",\"link\":\"/cloudnative/docker/index\"},{\"text\":\"Docker学习总结\",\"link\":\"/cloudnative/docker/Docker学习总结\"},{\"text\":\"docker镜像压缩\",\"link\":\"/cloudnative/docker/docker镜像压缩\"},{\"text\":\"制作Tomcat镜像\",\"link\":\"/cloudnative/docker/制作Tomcat镜像\"},{\"text\":\"容器新增bash\",\"link\":\"/cloudnative/docker/容器新增bash\"},{\"text\":\"容器软件安装\",\"link\":\"/cloudnative/docker/容器软件安装\"}]},{\"text\":\"k8s\",\"items\":[{\"text\":\"index\",\"link\":\"/cloudnative/k8s/index\"},{\"text\":\"k8s常用命令\",\"link\":\"/cloudnative/k8s/k8s常用命令\"},{\"text\":\"k8s问题排查流程图\",\"link\":\"/cloudnative/k8s/k8s问题排查流程图\"}]},{\"text\":\"prometheus\",\"items\":[{\"text\":\"index\",\"link\":\"/cloudnative/prometheus/index\"},{\"text\":\"node_exporter源码\",\"link\":\"/cloudnative/prometheus/node_exporter源码\"},{\"text\":\"TSDB\",\"link\":\"/cloudnative/prometheus/TSDB\"},{\"text\":\"数据模型\",\"link\":\"/cloudnative/prometheus/数据模型\"},{\"text\":\"架构\",\"link\":\"/cloudnative/prometheus/架构\"}]}],\"/database/\":[{\"text\":\"clickhouse\",\"items\":[{\"text\":\"index\",\"link\":\"/database/clickhouse/index\"},{\"text\":\"ClickHouse基础\",\"link\":\"/database/clickhouse/ClickHouse基础\"},{\"text\":\"ClickHouse安装\",\"link\":\"/database/clickhouse/ClickHouse安装\"},{\"text\":\"ClickHouse物化列序列化报错\",\"link\":\"/database/clickhouse/ClickHouse物化列序列化报错\"},{\"text\":\"ClickHouse高级\",\"link\":\"/database/clickhouse/ClickHouse高级\"},{\"text\":\"为什么弃用Elasticsearch\",\"link\":\"/database/clickhouse/为什么弃用Elasticsearch\"}]},{\"text\":\"mysql\",\"items\":[{\"text\":\"index\",\"link\":\"/database/mysql/index\"},{\"text\":\"B树和B+树\",\"link\":\"/database/mysql/B树和B+树\"},{\"text\":\"explain使用总结\",\"link\":\"/database/mysql/explain使用总结\"},{\"text\":\"InnoDB存储引擎\",\"link\":\"/database/mysql/InnoDB存储引擎\"},{\"text\":\"MySQL基础架构\",\"link\":\"/database/mysql/MySQL基础架构\"},{\"text\":\"MySQL日志系统\",\"link\":\"/database/mysql/MySQL日志系统\"},{\"text\":\"MySQL根据idb文件恢复数据\",\"link\":\"/database/mysql/MySQL根据idb文件恢复数据\"},{\"text\":\"MySQL的binlog日志过期删除\",\"link\":\"/database/mysql/MySQL的binlog日志过期删除\"},{\"text\":\"OrderBy和limit混用的bug\",\"link\":\"/database/mysql/OrderBy和limit混用的bug\"},{\"text\":\"SQL语句的抖动问题\",\"link\":\"/database/mysql/SQL语句的抖动问题\"},{\"text\":\"一条更新SQL的执行过程\",\"link\":\"/database/mysql/一条更新SQL的执行过程\"},{\"text\":\"事务隔离\",\"link\":\"/database/mysql/事务隔离\"},{\"text\":\"慢查询日志\",\"link\":\"/database/mysql/慢查询日志\"},{\"text\":\"索引\",\"link\":\"/database/mysql/索引\"},{\"text\":\"索引失效的场景\",\"link\":\"/database/mysql/索引失效的场景\"},{\"text\":\"行锁\",\"link\":\"/database/mysql/行锁\"},{\"text\":\"锁\",\"link\":\"/database/mysql/锁\"}]},{\"text\":\"redis\",\"items\":[{\"text\":\"index\",\"link\":\"/database/redis/index\"},{\"text\":\"LRU和LFU算法\",\"link\":\"/database/redis/LRU和LFU算法\"},{\"text\":\"Redisson\",\"link\":\"/database/redis/Redisson\"},{\"text\":\"redis事务\",\"link\":\"/database/redis/redis事务\"},{\"text\":\"redis实现分布式锁\",\"link\":\"/database/redis/redis实现分布式锁\"},{\"text\":\"redis数据类型\",\"link\":\"/database/redis/redis数据类型\"},{\"text\":\"redis数据类型原理\",\"link\":\"/database/redis/redis数据类型原理\"},{\"text\":\"redis的持久化\",\"link\":\"/database/redis/redis的持久化\"},{\"text\":\"redis集群\",\"link\":\"/database/redis/redis集群\"},{\"text\":\"内存淘汰策略\",\"link\":\"/database/redis/内存淘汰策略\"},{\"text\":\"布隆过滤器\",\"link\":\"/database/redis/布隆过滤器\"},{\"text\":\"缓存问题\",\"link\":\"/database/redis/缓存问题\"},{\"text\":\"过期策略\",\"link\":\"/database/redis/过期策略\"}]}],\"/frame/\":[{\"text\":\"mybatis\",\"items\":[{\"text\":\"index\",\"link\":\"/frame/mybatis/index\"},{\"text\":\"custom\",\"items\":[{\"text\":\"SQL执行器\",\"link\":\"/frame/mybatis/custom/SQL执行器\"},{\"text\":\"xml解析\",\"link\":\"/frame/mybatis/custom/xml解析\"},{\"text\":\"手写MyBatis\",\"link\":\"/frame/mybatis/custom/手写MyBatis\"},{\"text\":\"数据源\",\"link\":\"/frame/mybatis/custom/数据源\"},{\"text\":\"映射器-mapper\",\"link\":\"/frame/mybatis/custom/映射器-mapper\"}]}]},{\"text\":\"netty\",\"items\":[{\"text\":\"index\",\"link\":\"/frame/netty/index\"},{\"text\":\"ByteBuf\",\"link\":\"/frame/netty/ByteBuf\"},{\"text\":\"Handler的共享和并发安全性\",\"link\":\"/frame/netty/Handler的共享和并发安全性\"},{\"text\":\"HTTP服务和SSL&TLS\",\"link\":\"/frame/netty/HTTP服务和SSL&TLS\"},{\"text\":\"Netty实现文件下载\",\"link\":\"/frame/netty/Netty实现文件下载\"},{\"text\":\"Netty实现通信框架\",\"link\":\"/frame/netty/Netty实现通信框架\"},{\"text\":\"Netty常用组件\",\"link\":\"/frame/netty/Netty常用组件\"},{\"text\":\"TCP粘包拆包问题\",\"link\":\"/frame/netty/TCP粘包拆包问题\"},{\"text\":\"内置通信传输模式\",\"link\":\"/frame/netty/内置通信传输模式\"},{\"text\":\"写空闲和读空闲\",\"link\":\"/frame/netty/写空闲和读空闲\"},{\"text\":\"基于Netty实现RPC\",\"link\":\"/frame/netty/基于Netty实现RPC\"},{\"text\":\"序列化问题\",\"link\":\"/frame/netty/序列化问题\"},{\"text\":\"线程模型\",\"link\":\"/frame/netty/线程模型\"},{\"text\":\"编解码器\",\"link\":\"/frame/netty/编解码器\"},{\"text\":\"资源管理和SimpleChannelInboundHandler\",\"link\":\"/frame/netty/资源管理和SimpleChannelInboundHandler\"},{\"text\":\"零拷贝\",\"link\":\"/frame/netty/零拷贝\"}]},{\"text\":\"spring\",\"items\":[{\"text\":\"index\",\"link\":\"/frame/spring/index\"},{\"text\":\"AOP\",\"link\":\"/frame/spring/AOP\"},{\"text\":\"ApplicationContext和BeanFactory区别\",\"link\":\"/frame/spring/ApplicationContext和BeanFactory区别\"},{\"text\":\"Aware接口\",\"link\":\"/frame/spring/Aware接口\"},{\"text\":\"BeanFactory和FactoryBean总结\",\"link\":\"/frame/spring/BeanFactory和FactoryBean总结\"},{\"text\":\"ByteBuddy实现动态代理\",\"link\":\"/frame/spring/ByteBuddy实现动态代理\"},{\"text\":\"custom\",\"items\":[{\"text\":\"AOP\",\"link\":\"/frame/spring/custom/AOP\"},{\"text\":\"Boot\",\"link\":\"/frame/spring/custom/Boot\"},{\"text\":\"IOC\",\"link\":\"/frame/spring/custom/IOC\"},{\"text\":\"JDBC\",\"link\":\"/frame/spring/custom/JDBC\"},{\"text\":\"MVC\",\"link\":\"/frame/spring/custom/MVC\"},{\"text\":\"声明式事务\",\"link\":\"/frame/spring/custom/声明式事务\"},{\"text\":\"手写Spring\",\"link\":\"/frame/spring/custom/手写Spring\"}]},{\"text\":\"Spi机制\",\"link\":\"/frame/spring/Spi机制\"},{\"text\":\"Spring中Bean加载流程\",\"link\":\"/frame/spring/Spring中Bean加载流程\"},{\"text\":\"Spring中Bean的作用域\",\"link\":\"/frame/spring/Spring中Bean的作用域\"},{\"text\":\"Spring事务总结\",\"link\":\"/frame/spring/Spring事务总结\"},{\"text\":\"Spring依赖注入\",\"link\":\"/frame/spring/Spring依赖注入\"},{\"text\":\"Spring如何解决循环依赖\",\"link\":\"/frame/spring/Spring如何解决循环依赖\"},{\"text\":\"Spring框架概述\",\"link\":\"/frame/spring/Spring框架概述\"},{\"text\":\"Spring自定义注解扫描\",\"link\":\"/frame/spring/Spring自定义注解扫描\"},{\"text\":\"Spring配置文件加载顺序\",\"link\":\"/frame/spring/Spring配置文件加载顺序\"}]},{\"text\":\"springboot\",\"items\":[{\"text\":\"index\",\"link\":\"/frame/springboot/index\"},{\"text\":\"SpringBoot使用APO记录操作日志\",\"link\":\"/frame/springboot/SpringBoot使用APO记录操作日志\"},{\"text\":\"SpringBoot能同时处理多少请求\",\"link\":\"/frame/springboot/SpringBoot能同时处理多少请求\"},{\"text\":\"SpringBoot项目自动初始化数据库\",\"link\":\"/frame/springboot/SpringBoot项目自动初始化数据库\"}]},{\"text\":\"springcloud\",\"items\":[{\"text\":\"index\",\"link\":\"/frame/springcloud/index\"},{\"text\":\"Feigh远程调用原理\",\"link\":\"/frame/springcloud/Feigh远程调用原理\"},{\"text\":\"Gateway\",\"link\":\"/frame/springcloud/Gateway\"},{\"text\":\"Nacos\",\"link\":\"/frame/springcloud/Nacos\"},{\"text\":\"Seata分布式事务\",\"link\":\"/frame/springcloud/Seata分布式事务\"},{\"text\":\"Sentinel原理\",\"link\":\"/frame/springcloud/Sentinel原理\"},{\"text\":\"注册中心的演进\",\"link\":\"/frame/springcloud/注册中心的演进\"}]}],\"/java/\":[{\"text\":\"cache\",\"items\":[{\"text\":\"index\",\"link\":\"/java/cache/index\"},{\"text\":\"多级缓存\",\"link\":\"/java/cache/多级缓存\"},{\"text\":\"本地缓存\",\"link\":\"/java/cache/本地缓存\"},{\"text\":\"缓存淘汰算法\",\"link\":\"/java/cache/缓存淘汰算法\"}]},{\"text\":\"collection\",\"items\":[{\"text\":\"index\",\"link\":\"/java/collection/index\"},{\"text\":\"Collection集合概述\",\"link\":\"/java/collection/Collection集合概述\"},{\"text\":\"7\",\"link\":\"/java/collection/ConcurrentHashMap1.7\"},{\"text\":\"8\",\"link\":\"/java/collection/ConcurrentHashMap1.8\"},{\"text\":\"7\",\"link\":\"/java/collection/HashMap1.7\"},{\"text\":\"8\",\"link\":\"/java/collection/HashMap1.8\"},{\"text\":\"List集合体系\",\"link\":\"/java/collection/List集合体系\"},{\"text\":\"Set集合体系\",\"link\":\"/java/collection/Set集合体系\"}]},{\"text\":\"concurrent\",\"items\":[{\"text\":\"index\",\"link\":\"/java/concurrent/index\"},{\"text\":\"Java高并发\",\"link\":\"/java/concurrent/Java高并发\"},{\"text\":\"single\",\"items\":[{\"text\":\"AQS\",\"link\":\"/java/concurrent/single/AQS\"},{\"text\":\"BlockQueue阻塞队列\",\"link\":\"/java/concurrent/single/BlockQueue阻塞队列\"},{\"text\":\"CAS\",\"link\":\"/java/concurrent/single/CAS\"},{\"text\":\"synchronized原理\",\"link\":\"/java/concurrent/single/synchronized原理\"},{\"text\":\"ThreadLocal\",\"link\":\"/java/concurrent/single/ThreadLocal\"},{\"text\":\"transmittable-thread-local\",\"link\":\"/java/concurrent/single/transmittable-thread-local\"},{\"text\":\"原子类\",\"link\":\"/java/concurrent/single/原子类\"},{\"text\":\"死锁活锁和饥饿\",\"link\":\"/java/concurrent/single/死锁活锁和饥饿\"},{\"text\":\"线程池的关闭\",\"link\":\"/java/concurrent/single/线程池的关闭\"},{\"text\":\"线程池的执行流程\",\"link\":\"/java/concurrent/single/线程池的执行流程\"},{\"text\":\"线程的生命周期\",\"link\":\"/java/concurrent/single/线程的生命周期\"}]}]},{\"text\":\"distributed\",\"items\":[{\"text\":\"index\",\"link\":\"/java/distributed/index\"},{\"text\":\"分布式ID\",\"link\":\"/java/distributed/分布式ID\"},{\"text\":\"分布式事务\",\"link\":\"/java/distributed/分布式事务\"},{\"text\":\"分布式锁\",\"link\":\"/java/distributed/分布式锁\"},{\"text\":\"幂等性问题\",\"link\":\"/java/distributed/幂等性问题\"}]},{\"text\":\"io\",\"items\":[{\"text\":\"index\",\"link\":\"/java/io/index\"},{\"text\":\"BIO\",\"link\":\"/java/io/BIO\"},{\"text\":\"IO多路复用\",\"link\":\"/java/io/IO多路复用\"},{\"text\":\"NIO\",\"link\":\"/java/io/NIO\"},{\"text\":\"Reactor模式\",\"link\":\"/java/io/Reactor模式\"},{\"text\":\"基于BIO实现RPC框架\",\"link\":\"/java/io/基于BIO实现RPC框架\"}]},{\"text\":\"jvm\",\"items\":[{\"text\":\"index\",\"link\":\"/java/jvm/index\"},{\"text\":\"CPU负载过高排查记录\",\"link\":\"/java/jvm/CPU负载过高排查记录\"},{\"text\":\"G1收集器\",\"link\":\"/java/jvm/G1收集器\"},{\"text\":\"Java类加载器\",\"link\":\"/java/jvm/Java类加载器\"},{\"text\":\"JDK调优命令\",\"link\":\"/java/jvm/JDK调优命令\"},{\"text\":\"JVM内存模型\",\"link\":\"/java/jvm/JVM内存模型\"},{\"text\":\"内存问题排查总结\",\"link\":\"/java/jvm/内存问题排查总结\"},{\"text\":\"可视化工具\",\"link\":\"/java/jvm/可视化工具\"},{\"text\":\"垃圾回收器\",\"link\":\"/java/jvm/垃圾回收器\"},{\"text\":\"垃圾回收算法\",\"link\":\"/java/jvm/垃圾回收算法\"},{\"text\":\"对象创建\",\"link\":\"/java/jvm/对象创建\"},{\"text\":\"类加载器\",\"link\":\"/java/jvm/类加载器\"},{\"text\":\"频繁GC排查\",\"link\":\"/java/jvm/频繁GC排查\"}]}],\"/middleware/\":[{\"text\":\"es\",\"items\":[{\"text\":\"index\",\"link\":\"/middleware/es/index\"},{\"text\":\"BulkProcessor死锁问题\",\"link\":\"/middleware/es/BulkProcessor死锁问题\"},{\"text\":\"Elasticsearch写入原理\",\"link\":\"/middleware/es/Elasticsearch写入原理\"},{\"text\":\"Elasticsearch基础概念\",\"link\":\"/middleware/es/Elasticsearch基础概念\"},{\"text\":\"Elasticsearch查询原理\",\"link\":\"/middleware/es/Elasticsearch查询原理\"},{\"text\":\"Elasticsearch检索\",\"link\":\"/middleware/es/Elasticsearch检索\"},{\"text\":\"Elasticsearch聚合查询\",\"link\":\"/middleware/es/Elasticsearch聚合查询\"},{\"text\":\"ES分片\",\"link\":\"/middleware/es/ES分片\"},{\"text\":\"ES压测记录和esrally使用\",\"link\":\"/middleware/es/ES压测记录和esrally使用\"},{\"text\":\"ES参数调优\",\"link\":\"/middleware/es/ES参数调优\"},{\"text\":\"ES深度分页问题\",\"link\":\"/middleware/es/ES深度分页问题\"},{\"text\":\"ES滚动查询-Scroll\",\"link\":\"/middleware/es/ES滚动查询-Scroll\"},{\"text\":\"ES的log4j2日志自动清理配置\",\"link\":\"/middleware/es/ES的log4j2日志自动清理配置\"},{\"text\":\"ES聚合查询原理\",\"link\":\"/middleware/es/ES聚合查询原理\"},{\"text\":\"ES集群\",\"link\":\"/middleware/es/ES集群\"},{\"text\":\"倒排索引原理\",\"link\":\"/middleware/es/倒排索引原理\"},{\"text\":\"并发场景修改文档\",\"link\":\"/middleware/es/并发场景修改文档\"},{\"text\":\"批量操作Bulk和BulkProcessor\",\"link\":\"/middleware/es/批量操作Bulk和BulkProcessor\"},{\"text\":\"集群脑裂-参数配置\",\"link\":\"/middleware/es/集群脑裂-参数配置\"}]},{\"text\":\"kafka\",\"items\":[{\"text\":\"index\",\"link\":\"/middleware/kafka/index\"},{\"text\":\"kafka-ACK应答机制\",\"link\":\"/middleware/kafka/kafka-ACK应答机制\"},{\"text\":\"kafka保证消息不丢失\",\"link\":\"/middleware/kafka/kafka保证消息不丢失\"},{\"text\":\"Kafka分区机制策略\",\"link\":\"/middleware/kafka/Kafka分区机制策略\"},{\"text\":\"Kafka副本机制\",\"link\":\"/middleware/kafka/Kafka副本机制\"},{\"text\":\"Kafka总控制器Controller\",\"link\":\"/middleware/kafka/Kafka总控制器Controller\"},{\"text\":\"Kafka手动重新分区\",\"link\":\"/middleware/kafka/Kafka手动重新分区\"},{\"text\":\"kafka消费模型\",\"link\":\"/middleware/kafka/kafka消费模型\"},{\"text\":\"Kafka消费策略\",\"link\":\"/middleware/kafka/Kafka消费策略\"},{\"text\":\"Kafka生产者参数\",\"link\":\"/middleware/kafka/Kafka生产者参数\"},{\"text\":\"kafka的分区副本规划\",\"link\":\"/middleware/kafka/kafka的分区副本规划\"},{\"text\":\"kafka解决重复消费\",\"link\":\"/middleware/kafka/kafka解决重复消费\"},{\"text\":\"Kafka高性能的原因\",\"link\":\"/middleware/kafka/Kafka高性能的原因\"},{\"text\":\"Producer发布消息机制\",\"link\":\"/middleware/kafka/Producer发布消息机制\"},{\"text\":\"__consumer_offsets\",\"link\":\"/middleware/kafka/__consumer_offsets\"},{\"text\":\"数据日志分段存储\",\"link\":\"/middleware/kafka/数据日志分段存储\"},{\"text\":\"消费者组\",\"link\":\"/middleware/kafka/消费者组\"},{\"text\":\"高水位HW和LEO\",\"link\":\"/middleware/kafka/高水位HW和LEO\"}]},{\"text\":\"rocketmq\",\"items\":[{\"text\":\"index\",\"link\":\"/middleware/rocketmq/index\"},{\"text\":\"Kakfa和RocketMQ的区别\",\"link\":\"/middleware/rocketmq/Kakfa和RocketMQ的区别\"},{\"text\":\"MQ接收消息幂等性\",\"link\":\"/middleware/rocketmq/MQ接收消息幂等性\"},{\"text\":\"RocketMQ基础学习\",\"link\":\"/middleware/rocketmq/RocketMQ基础学习\"},{\"text\":\"RocketMQ集群架构\",\"link\":\"/middleware/rocketmq/RocketMQ集群架构\"},{\"text\":\"事务消息\",\"link\":\"/middleware/rocketmq/事务消息\"},{\"text\":\"如何保证发送消息有序\",\"link\":\"/middleware/rocketmq/如何保证发送消息有序\"},{\"text\":\"如何保证消息不丢失\",\"link\":\"/middleware/rocketmq/如何保证消息不丢失\"},{\"text\":\"消息样例\",\"link\":\"/middleware/rocketmq/消息样例\"},{\"text\":\"顺序消息\",\"link\":\"/middleware/rocketmq/顺序消息\"}]}],\"/other/\":[{\"text\":\"algorithm\",\"items\":[{\"text\":\"index\",\"link\":\"/other/algorithm/index\"},{\"text\":\"动态规划\",\"link\":\"/other/algorithm/动态规划\"},{\"text\":\"排序\",\"link\":\"/other/algorithm/排序\"},{\"text\":\"时间复杂度\",\"link\":\"/other/algorithm/时间复杂度\"},{\"text\":\"查找\",\"link\":\"/other/algorithm/查找\"}]},{\"text\":\"datastructure\",\"items\":[{\"text\":\"index\",\"link\":\"/other/datastructure/index\"},{\"text\":\"二叉树\",\"link\":\"/other/datastructure/二叉树\"},{\"text\":\"常用数据结构\",\"link\":\"/other/datastructure/常用数据结构\"}]},{\"text\":\"design\",\"items\":[{\"text\":\"index\",\"link\":\"/other/design/index\"},{\"text\":\"七大基本原则\",\"link\":\"/other/design/七大基本原则\"},{\"text\":\"创建型\",\"link\":\"/other/design/创建型\"},{\"text\":\"结构型\",\"link\":\"/other/design/结构型\"},{\"text\":\"行为型\",\"link\":\"/other/design/行为型\"}]},{\"text\":\"network\",\"items\":[{\"text\":\"index\",\"link\":\"/other/network/index\"},{\"text\":\"HTTP1x和HTTP2x\",\"link\":\"/other/network/HTTP1x和HTTP2x\"},{\"text\":\"HTTP和HTTPS\",\"link\":\"/other/network/HTTP和HTTPS\"},{\"text\":\"HTTP常见字段\",\"link\":\"/other/network/HTTP常见字段\"},{\"text\":\"Linux如何收发网络包\",\"link\":\"/other/network/Linux如何收发网络包\"},{\"text\":\"OSI七层网络模型\",\"link\":\"/other/network/OSI七层网络模型\"},{\"text\":\"RTT和SRTT\",\"link\":\"/other/network/RTT和SRTT\"},{\"text\":\"Socket\",\"link\":\"/other/network/Socket\"},{\"text\":\"TCPIP四层网络模型\",\"link\":\"/other/network/TCPIP四层网络模型\"},{\"text\":\"TCP分析工具\",\"link\":\"/other/network/TCP分析工具\"},{\"text\":\"TCP协议\",\"link\":\"/other/network/TCP协议\"},{\"text\":\"TCP粘包拆包\",\"link\":\"/other/network/TCP粘包拆包\"},{\"text\":\"拥塞控制\",\"link\":\"/other/network/拥塞控制\"},{\"text\":\"流量控制-滑动窗口\",\"link\":\"/other/network/流量控制-滑动窗口\"},{\"text\":\"网址访问页面中间发生了哪些过程\",\"link\":\"/other/network/网址访问页面中间发生了哪些过程\"},{\"text\":\"网络包的封装原理\",\"link\":\"/other/network/网络包的封装原理\"},{\"text\":\"重传机制\",\"link\":\"/other/network/重传机制\"}]},{\"text\":\"observability\",\"items\":[{\"text\":\"index\",\"link\":\"/other/observability/index\"},{\"text\":\"log\",\"items\":[{\"text\":\"index\",\"link\":\"/other/observability/log/index\"}]},{\"text\":\"opentelemetry\",\"items\":[{\"text\":\"index\",\"link\":\"/other/observability/opentelemetry/index\"},{\"text\":\"可观测性\",\"link\":\"/other/observability/opentelemetry/可观测性\"}]},{\"text\":\"skywalking\",\"items\":[{\"text\":\"index\",\"link\":\"/other/observability/skywalking/index\"},{\"text\":\"源码学习\",\"link\":\"/other/observability/skywalking/源码学习\"},{\"text\":\"组件安装\",\"link\":\"/other/observability/skywalking/组件安装\"}]}]}],\"/personal/\":[{\"text\":\"index\",\"link\":\"/personal/index\"}],\"/java/jvm/\":[{\"text\":\"类加载器\",\"collapsed\":false,\"items\":[{\"text\":\"Java类加载器\",\"link\":\"/java/jvm/Java类加载器\"},{\"text\":\"对象创建\",\"link\":\"/java/jvm/对象创建\"}]},{\"text\":\"内存模型\",\"collapsed\":false,\"items\":[{\"text\":\"JVM内存模型\",\"link\":\"/java/jvm/JVM内存模型\"}]},{\"text\":\"垃圾回收\",\"collapsed\":false,\"items\":[{\"text\":\"垃圾回收算法\",\"link\":\"/java/jvm/垃圾回收算法\"},{\"text\":\"垃圾回收器\",\"link\":\"/java/jvm/垃圾回收器\"},{\"text\":\"G1收集器\",\"link\":\"/java/jvm/G1收集器\"}]},{\"text\":\"故障排查\",\"collapsed\":false,\"items\":[{\"text\":\"JDK调优命令\",\"link\":\"/java/jvm/JDK调优命令\"},{\"text\":\"可视化工具\",\"link\":\"/java/jvm/可视化工具\"}]},{\"text\":\"排障记录\",\"collapsed\":false,\"items\":[{\"text\":\"CPU负载过高排查记录\",\"link\":\"/java/jvm/CPU负载过高排查记录\"},{\"text\":\"内存问题排查总结\",\"link\":\"/java/jvm/内存问题排查总结\"},{\"text\":\"频繁GC排查\",\"link\":\"/java/jvm/频繁GC排查\"}]}],\"/java/concurrent/\":[{\"text\":\"Java高并发\",\"collapsed\":false,\"items\":[{\"text\":\"Java高并发\",\"link\":\"/java/concurrent/Java高并发\"}]},{\"text\":\"重点总结\",\"collapsed\":false,\"items\":[{\"text\":\"线程的生命周期\",\"link\":\"/java/concurrent/single/线程的生命周期\"},{\"text\":\"synchronized原理\",\"link\":\"/java/concurrent/single/synchronized原理\"},{\"text\":\"AQS\",\"link\":\"/java/concurrent/single/AQS\"},{\"text\":\"CAS\",\"link\":\"/java/concurrent/single/CAS\"},{\"text\":\"原子类\",\"link\":\"/java/concurrent/single/原子类\"},{\"text\":\"死锁活锁和饥饿\",\"link\":\"/java/concurrent/single/死锁活锁和饥饿\"},{\"text\":\"ThreadLocal\",\"link\":\"/java/concurrent/single/ThreadLocal\"},{\"text\":\"TransmittableThreadLocal\",\"link\":\"/java/concurrent/single/transmittable-thread-local\"},{\"text\":\"线程池的执行流程\",\"link\":\"/java/concurrent/single/线程池的执行流程\"},{\"text\":\"线程池的关闭\",\"link\":\"/java/concurrent/single/线程池的关闭\"},{\"text\":\"BlockQueue阻塞队列\",\"link\":\"/java/concurrent/single/BlockQueue阻塞队列\"}]}],\"/java/io/\":[{\"text\":\"IO\",\"collapsed\":false,\"items\":[{\"text\":\"BIO\",\"link\":\"/java/io/BIO\"},{\"text\":\"基于BIO实现RPC框架\",\"link\":\"/java/io/基于BIO实现RPC框架\"},{\"text\":\"NIO\",\"link\":\"/java/io/NIO\"},{\"text\":\"Reactor模式\",\"link\":\"/java/io/Reactor模式\"},{\"text\":\"IO多路复用\",\"link\":\"/java/io/IO多路复用\"}]}],\"/java/cache/\":[{\"text\":\"缓存\",\"collapsed\":false,\"items\":[{\"text\":\"本地缓存\",\"link\":\"/java/cache/本地缓存.md\"},{\"text\":\"多级缓存\",\"link\":\"/java/cache/多级缓存.md\"},{\"text\":\"缓存淘汰算法\",\"link\":\"/java/cache/缓存淘汰算法.md\"}]}],\"/java/collection/\":[{\"text\":\"Collection集合\",\"collapsed\":false,\"items\":[{\"text\":\"Collection集合概述\",\"link\":\"/java/collection/Collection集合概述\"},{\"text\":\"List集合体系\",\"link\":\"/java/collection/List集合体系\"},{\"text\":\"Set集合体系\",\"link\":\"/java/collection/Set集合体系\"}]},{\"text\":\"Map集合\",\"collapsed\":false,\"items\":[{\"text\":\"HashMap-1.7\",\"link\":\"/java/collection/HashMap1.7\"},{\"text\":\"ConcurrentHashMap-1.7\",\"link\":\"/java/collection/ConcurrentHashMap1.7\"},{\"text\":\"HashMap-1.8\",\"link\":\"/java/collection/HashMap1.8\"},{\"text\":\"ConcurrentHashMap-1.8\",\"link\":\"/java/collection/ConcurrentHashMap1.8\"}]}],\"/java/distributed/\":[{\"text\":\"分布式\",\"collapsed\":false,\"items\":[{\"text\":\"分布式事务\",\"link\":\"/java/distributed/分布式事务\"},{\"text\":\"分布式锁\",\"link\":\"/java/distributed/分布式锁\"},{\"text\":\"分布式ID\",\"link\":\"/java/distributed/分布式ID\"},{\"text\":\"幂等性问题\",\"link\":\"/java/distributed/幂等性问题\"}]}],\"/frame/spring/\":[{\"text\":\"Spring框架\",\"collapsed\":false,\"items\":[{\"text\":\"Spring框架概述\",\"link\":\"/frame/spring/Spring框架概述\"},{\"text\":\"ApplicationContext和BeanFactory区别\",\"link\":\"/frame/spring/ApplicationContext和BeanFactory区别\"},{\"text\":\"BeanFactory和FactoryBean总结\",\"link\":\"/frame/spring/BeanFactory和FactoryBean总结\"},{\"text\":\"Spring中Bean的作用域\",\"link\":\"/frame/spring/Spring中Bean的作用域\"},{\"text\":\"Spring中Bean加载流程\",\"link\":\"/frame/spring/Spring中Bean加载流程\"},{\"text\":\"Spring中Bean加载流程\",\"link\":\"/frame/spring/Spring中Bean加载流程\"},{\"text\":\"Spring依赖注入\",\"link\":\"/frame/spring/Spring依赖注入\"},{\"text\":\"Spring如何解决循环依赖\",\"link\":\"/frame/spring/Spring如何解决循环依赖\"},{\"text\":\"AOP\",\"link\":\"/frame/spring/AOP\"},{\"text\":\"Spring事务总结\",\"link\":\"/frame/spring/Spring事务总结\"},{\"text\":\"Aware接口\",\"link\":\"/frame/spring/Aware接口\"},{\"text\":\"Spi机制\",\"link\":\"/frame/spring/Spi机制\"},{\"text\":\"Spring配置文件加载顺序\",\"link\":\"/frame/spring/Spring配置文件加载顺序\"}]},{\"text\":\"使用总结\",\"collapsed\":false,\"items\":[{\"text\":\"Spring自定义注解扫描\",\"link\":\"/frame/spring/Spring自定义注解扫描\"},{\"text\":\"ByteBuddy实现动态代理\",\"link\":\"/frame/spring/ByteBuddy实现动态代理\"}]},{\"text\":\"手写Spring\",\"collapsed\":false,\"items\":[{\"text\":\"手写Spring\",\"link\":\"/frame/spring/custom/手写Spring\"},{\"text\":\"IOC\",\"link\":\"/frame/spring/custom/IOC\"},{\"text\":\"AOP\",\"link\":\"/frame/spring/custom/AOP\"},{\"text\":\"JDBC\",\"link\":\"/frame/spring/custom/JDBC\"},{\"text\":\"声明式事务\",\"link\":\"/frame/spring/custom/声明式事务\"},{\"text\":\"MVC\",\"link\":\"/frame/spring/custom/MVC\"},{\"text\":\"Boot\",\"link\":\"/frame/spring/custom/Boot\"}]}],\"/frame/springboot/\":[{\"text\":\"SpringBoot\",\"collapsed\":false,\"items\":[{\"text\":\"SpringBoot能同时处理多少请求\",\"link\":\"/frame/springboot/SpringBoot能同时处理多少请求\"},{\"text\":\"SpringBoot使用APO记录操作日志\",\"link\":\"/frame/springboot/SpringBoot使用APO记录操作日志\"},{\"text\":\"SpringBoot项目自动初始化数据库\",\"link\":\"/frame/springboot/SpringBoot项目自动初始化数据库\"}]}],\"/frame/mybatis/\":[{\"text\":\"手写MyBatis\",\"collapsed\":false,\"items\":[{\"text\":\"手写MyBatis\",\"link\":\"/frame/mybatis/custom/手写MyBatis\"},{\"text\":\"映射器-mapper\",\"link\":\"/frame/mybatis/custom/映射器-mapper\"},{\"text\":\"数据源\",\"link\":\"/frame/mybatis/custom/数据源\"},{\"text\":\"SQL执行器\",\"link\":\"/frame/mybatis/custom/SQL执行器\"},{\"text\":\"xml解析\",\"link\":\"/frame/mybatis/custom/xml解析\"}]}],\"/frame/springcloud/\":[{\"text\":\"SpringCloud\",\"collapsed\":false,\"items\":[{\"text\":\"注册中心的演进\",\"link\":\"/frame/springcloud/注册中心的演进\"},{\"text\":\"Nacos\",\"link\":\"/frame/springcloud/Nacos\"},{\"text\":\"Gateway\",\"link\":\"/frame/springcloud/Gateway\"},{\"text\":\"Feigh远程调用原理\",\"link\":\"/frame/springcloud/Feigh远程调用原理\"},{\"text\":\"Sentinel原理\",\"link\":\"/frame/springcloud/Sentinel原理\"},{\"text\":\"Seata分布式事务\",\"link\":\"/frame/springcloud/Seata分布式事务\"}]}],\"/frame/netty/\":[{\"text\":\"基础总结\",\"collapsed\":false,\"items\":[{\"text\":\"Netty常用组件\",\"link\":\"/frame/netty/Netty常用组件.md\"},{\"text\":\"Handler的共享和并发安全性\",\"link\":\"/frame/netty/Handler的共享和并发安全性.md\"},{\"text\":\"资源管理和SimpleChannelInboundHandler\",\"link\":\"/frame/netty/资源管理和SimpleChannelInboundHandler.md\"},{\"text\":\"内置通信传输模式\",\"link\":\"/frame/netty/内置通信传输模式.md\"},{\"text\":\"TCP粘包拆包问题\",\"link\":\"/frame/netty/TCP粘包拆包问题.md\"},{\"text\":\"编解码器\",\"link\":\"/frame/netty/编解码器.md\"},{\"text\":\"HTTP服务和SSL&TLS\",\"link\":\"/frame/netty/HTTP服务和SSL&TLS.md\"},{\"text\":\"序列化问题\",\"link\":\"/frame/netty/序列化问题.md\"},{\"text\":\"写空闲和读空闲\",\"link\":\"/frame/netty/写空闲和读空闲.md\"},{\"text\":\"ByteBuf\",\"link\":\"/frame/netty/ByteBuf.md\"},{\"text\":\"线程模型\",\"link\":\"/frame/netty/线程模型.md\"},{\"text\":\"零拷贝\",\"link\":\"/frame/netty/零拷贝.md\"}]},{\"text\":\"练习总结\",\"collapsed\":false,\"items\":[{\"text\":\"Netty实现通信框架\",\"link\":\"/frame/netty/Netty实现通信框架.md\"},{\"text\":\"基于Netty实现RPC\",\"link\":\"/frame/netty/基于Netty实现RPC.md\"},{\"text\":\"Netty实现文件下载\",\"link\":\"/frame/netty/Netty实现文件下载.md\"}]}],\"/database/mysql/\":[{\"text\":\"MySQL基础\",\"collapsed\":false,\"items\":[{\"text\":\"MySQL基础架构\",\"link\":\"/database/mysql/MySQL基础架构.md\"},{\"text\":\"InnoDB存储引擎\",\"link\":\"/database/mysql/InnoDB存储引擎.md\"},{\"text\":\"MySQL日志系统\",\"link\":\"/database/mysql/MySQL日志系统.md\"},{\"text\":\"一条更新SQL的执行过程\",\"link\":\"/database/mysql/一条更新SQL的执行过程.md\"},{\"text\":\"事务隔离\",\"link\":\"/database/mysql/事务隔离.md\"},{\"text\":\"B树和B+树\",\"link\":\"/database/mysql/B树和B+树.md\"},{\"text\":\"索引\",\"link\":\"/database/mysql/索引.md\"},{\"text\":\"锁\",\"link\":\"/database/mysql/锁.md\"},{\"text\":\"行锁\",\"link\":\"/database/mysql/行锁.md\"}]},{\"text\":\"MySQL总结\",\"collapsed\":false,\"items\":[{\"text\":\"SQL语句的抖动问题\",\"link\":\"/database/mysql/SQL语句的抖动问题.md\"},{\"text\":\"索引失效的场景\",\"link\":\"/database/mysql/索引失效的场景.md\"},{\"text\":\"explain使用总结\",\"link\":\"/database/mysql/explain使用总结.md\"},{\"text\":\"慢查询日志\",\"link\":\"/database/mysql/慢查询日志.md\"}]},{\"text\":\"问题总结\",\"collapsed\":false,\"items\":[{\"text\":\"OrderBy和limit混用的bug\",\"link\":\"/database/mysql/OrderBy和limit混用的bug.md\"},{\"text\":\"MySQL的binlog日志过期删除\",\"link\":\"/database/mysql/MySQL的binlog日志过期删除.md\"},{\"text\":\"MySQL根据idb文件恢复数据\",\"link\":\"/database/mysql/MySQL根据idb文件恢复数据.md\"}]}],\"/database/redis/\":[{\"text\":\"redis\",\"collapsed\":false,\"items\":[{\"text\":\"redis数据类型\",\"link\":\"/database/redis/redis数据类型\"},{\"text\":\"redis数据类型原理\",\"link\":\"/database/redis/redis数据类型原理\"},{\"text\":\"redis的持久化\",\"link\":\"/database/redis/redis的持久化\"},{\"text\":\"过期策略\",\"link\":\"/database/redis/过期策略\"},{\"text\":\"内存淘汰策略\",\"link\":\"/database/redis/内存淘汰策略\"},{\"text\":\"LRU和LFU算法\",\"link\":\"/database/redis/LRU和LFU算法\"},{\"text\":\"redis实现分布式锁\",\"link\":\"/database/redis/redis实现分布式锁\"},{\"text\":\"Redisson\",\"link\":\"/database/redis/Redisson\"},{\"text\":\"redis事务\",\"link\":\"/database/redis/redis事务\"},{\"text\":\"redis集群\",\"link\":\"/database/redis/redis集群\"},{\"text\":\"缓存问题\",\"link\":\"/database/redis/缓存问题\"},{\"text\":\"布隆过滤器\",\"link\":\"/database/redis/布隆过滤器\"}]}],\"/database/clickhouse/\":[{\"text\":\"ClickHouse\",\"collapsed\":false,\"items\":[{\"text\":\"ClickHouse安装\",\"link\":\"/database/clickhouse/ClickHouse安装\"},{\"text\":\"ClickHouse基础\",\"link\":\"/database/clickhouse/ClickHouse基础\"},{\"text\":\"ClickHouse高级\",\"link\":\"/database/clickhouse/ClickHouse高级\"},{\"text\":\"为什么弃用Elasticsearch\",\"link\":\"/database/clickhouse/为什么弃用Elasticsearch\"},{\"text\":\"ClickHouse物化列序列化报错\",\"link\":\"/database/clickhouse/ClickHouse物化列序列化报错\"}]}],\"/middleware/es/\":[{\"text\":\"Elasticsearch基础\",\"collapsed\":false,\"items\":[{\"text\":\"Elasticsearch基础概念\",\"link\":\"/middleware/es/Elasticsearch基础概念.md\"},{\"text\":\"Elasticsearch检索\",\"link\":\"/middleware/es/Elasticsearch检索.md\"},{\"text\":\"Elasticsearch聚合查询\",\"link\":\"/middleware/es/Elasticsearch聚合查询.md\"},{\"text\":\"ES滚动查询-Scroll\",\"link\":\"/middleware/es/ES滚动查询-Scroll.md\"},{\"text\":\"批量操作Bulk和BulkProcessor\",\"link\":\"/middleware/es/批量操作Bulk和BulkProcessor.md\"},{\"text\":\"BulkProcessor死锁问题\",\"link\":\"/middleware/es/BulkProcessor死锁问题.md\"},{\"text\":\"并发场景修改文档\",\"link\":\"/middleware/es/并发场景修改文档.md\"},{\"text\":\"ES深度分页问题\",\"link\":\"/middleware/es/ES深度分页问题.md\"},{\"text\":\"ES集群\",\"link\":\"/middleware/es/ES集群.md\"},{\"text\":\"ES分片\",\"link\":\"/middleware/es/ES分片.md\"}]},{\"text\":\"原理总结\",\"collapsed\":false,\"items\":[{\"text\":\"倒排索引原理\",\"link\":\"/middleware/es/倒排索引原理.md\"},{\"text\":\"Elasticsearch写入原理\",\"link\":\"/middleware/es/Elasticsearch写入原理.md\"},{\"text\":\"Elasticsearch查询原理\",\"link\":\"/middleware/es/Elasticsearch查询原理.md\"},{\"text\":\"ES聚合查询原理\",\"link\":\"/middleware/es/ES聚合查询原理.md\"}]},{\"text\":\"使用问题\",\"collapsed\":false,\"items\":[{\"text\":\"ES参数调优\",\"link\":\"/middleware/es/ES参数调优.md\"},{\"text\":\"集群脑裂-参数配置\",\"link\":\"/middleware/es/集群脑裂-参数配置.md\"},{\"text\":\"ES压测记录和esrally使用\",\"link\":\"/middleware/es/ES压测记录和esrally使用.md\"},{\"text\":\"ES的log4j2日志自动清理配置\",\"link\":\"/middleware/es/ES的log4j2日志自动清理配置.md\"}]}],\"/middleware/kafka/\":[{\"text\":\"Kafka配置\",\"collapsed\":false,\"items\":[{\"text\":\"Kafka消费策略\",\"link\":\"/middleware/kafka/Kafka消费策略.md\"},{\"text\":\"Kafka生产者参数\",\"link\":\"/middleware/kafka/Kafka生产者参数.md\"},{\"text\":\"kafka的分区副本规划\",\"link\":\"/middleware/kafka/kafka的分区副本规划.md\"}]},{\"text\":\"Kafka原理总结\",\"collapsed\":false,\"items\":[{\"text\":\"kafka消费模型\",\"link\":\"/middleware/kafka/kafka消费模型.md\"},{\"text\":\"kafka-ACK应答机制\",\"link\":\"/middleware/kafka/kafka-ACK应答机制.md\"},{\"text\":\"kafka解决重复消费\",\"link\":\"/middleware/kafka/kafka解决重复消费.md\"},{\"text\":\"Kafka分区机制策略\",\"link\":\"/middleware/kafka/Kafka分区机制策略.md\"},{\"text\":\"kafka保证消息不丢失\",\"link\":\"/middleware/kafka/kafka保证消息不丢失.md\"},{\"text\":\"消费者组\",\"link\":\"/middleware/kafka/消费者组.md\"},{\"text\":\"__consumer_offsets\",\"link\":\"/middleware/kafka/__consumer_offsets.md\"},{\"text\":\"Kafka总控制器Controller\",\"link\":\"/middleware/kafka/Kafka总控制器Controller.md\"},{\"text\":\"Kafka副本机制\",\"link\":\"/middleware/kafka/Kafka副本机制.md\"},{\"text\":\"Producer发布消息机制\",\"link\":\"/middleware/kafka/Producer发布消息机制.md\"},{\"text\":\"高水位HW和LEO\",\"link\":\"/middleware/kafka/高水位HW和LEO.md\"},{\"text\":\"数据日志分段存储\",\"link\":\"/middleware/kafka/数据日志分段存储.md\"},{\"text\":\"Kafka高性能的原因\",\"link\":\"/middleware/kafka/Kafka高性能的原因.md\"}]},{\"text\":\"使用问题\",\"collapsed\":false,\"items\":[{\"text\":\"Kafka手动重新分区\",\"link\":\"/middleware/kafka/Kafka手动重新分区.md\"}]}],\"/middleware/rocketmq/\":[{\"text\":\"RocketMQ\",\"collapsed\":false,\"items\":[{\"text\":\"RocketMQ基础学习\",\"link\":\"/middleware/rocketmq/RocketMQ基础学习.md\"},{\"text\":\"RocketMQ集群架构\",\"link\":\"/middleware/rocketmq/RocketMQ集群架构.md\"},{\"text\":\"消息样例\",\"link\":\"/middleware/rocketmq/消息样例.md\"},{\"text\":\"顺序消息\",\"link\":\"/middleware/rocketmq/顺序消息.md\"},{\"text\":\"事务消息\",\"link\":\"/middleware/rocketmq/事务消息.md\"},{\"text\":\"如何保证发送消息有序\",\"link\":\"/middleware/rocketmq/如何保证发送消息有序.md\"},{\"text\":\"如何保证消息不丢失\",\"link\":\"/middleware/rocketmq/如何保证消息不丢失.md\"},{\"text\":\"MQ接收消息幂等性\",\"link\":\"/middleware/rocketmq/MQ接收消息幂等性.md\"},{\"text\":\"Kakfa和RocketMQ的区别\",\"link\":\"/middleware/rocketmq/Kakfa和RocketMQ的区别.md\"}]}],\"/cloudnative/docker/\":[{\"text\":\"Docker学习总结\",\"collapsed\":false,\"items\":[{\"text\":\"Docker学习总结\",\"link\":\"/cloudnative/docker/Docker学习总结\"}]},{\"text\":\"安装总结\",\"collapsed\":false,\"items\":[{\"text\":\"容器软件安装\",\"link\":\"/cloudnative/docker/容器软件安装\"},{\"text\":\"docker镜像压缩\",\"link\":\"/cloudnative/docker/docker镜像压缩\"},{\"text\":\"制作Tomcat镜像\",\"link\":\"/cloudnative/docker/制作Tomcat镜像\"},{\"text\":\"容器新增bash\",\"link\":\"/cloudnative/docker/容器新增bash\"}]}],\"/cloudnative/k8s/\":[{\"text\":\"K8s\",\"collapsed\":false,\"items\":[{\"text\":\"k8s常用命令\",\"link\":\"/cloudnative/k8s/k8s常用命令\"},{\"text\":\"k8s问题排查流程图\",\"link\":\"/cloudnative/k8s/k8s问题排查流程图\"}]}],\"/cloudnative/prometheus/\":[{\"text\":\"Prometheus\",\"collapsed\":false,\"items\":[{\"text\":\"架构\",\"link\":\"/cloudnative/prometheus/架构\"},{\"text\":\"TSDB\",\"link\":\"/cloudnative/prometheus/TSDB\"},{\"text\":\"数据模型\",\"link\":\"/cloudnative/prometheus/数据模型\"},{\"text\":\"node_exporter源码\",\"link\":\"/cloudnative/prometheus/node_exporter源码\"}]}],\"/other/observability/\":[{\"text\":\"可观测性\",\"collapsed\":false,\"items\":[{\"text\":\"可观测性\",\"link\":\"/other/observability/opentelemetry/可观测性.md\"},{\"text\":\"Opentelemetry\",\"link\":\"/other/observability/opentelemetry/\"}]},{\"text\":\"Skywalking\",\"collapsed\":false,\"items\":[{\"text\":\"组件安装\",\"link\":\"/other/observability/skywalking/组件安装\"},{\"text\":\"源码学习\",\"link\":\"/other/observability/skywalking/源码学习\"}]},{\"text\":\"日志收集\",\"collapsed\":false,\"items\":[{\"text\":\"日志收集全链路\",\"link\":\"/other/observability/log/\"}]}],\"/other/design/\":[{\"text\":\"设计模式\",\"collapsed\":false,\"items\":[{\"text\":\"七大基本原则\",\"link\":\"/other/design/七大基本原则\"},{\"text\":\"创建型\",\"link\":\"/other/design/创建型\"},{\"text\":\"结构型\",\"link\":\"/other/design/结构型\"},{\"text\":\"行为型\",\"link\":\"/other/design/行为型\"}]}],\"/other/network/\":[{\"text\":\"网络基础\",\"collapsed\":false,\"items\":[{\"text\":\"TCP/IP四层网络模型\",\"link\":\"/other/network/TCPIP四层网络模型\"},{\"text\":\"OSI七层网络模型\",\"link\":\"/other/network/OSI七层网络模型\"},{\"text\":\"Linux如何收发网络包\",\"link\":\"/other/network/Linux如何收发网络包\"},{\"text\":\"网络包的封装原理\",\"link\":\"/other/network/网络包的封装原理\"},{\"text\":\"Socket\",\"link\":\"/other/network/Socket\"}]},{\"text\":\"TCP\",\"collapsed\":false,\"items\":[{\"text\":\"TCP协议\",\"link\":\"/other/network/TCP协议\"},{\"text\":\"TCP分析工具\",\"link\":\"/other/network/TCP分析工具\"},{\"text\":\"RTT和SRTT\",\"link\":\"/other/network/RTT和SRTT\"},{\"text\":\"流量控制-滑动窗口\",\"link\":\"/other/network/流量控制-滑动窗口\"},{\"text\":\"拥塞控制\",\"link\":\"/other/network/拥塞控制\"},{\"text\":\"重传机制\",\"link\":\"/other/network/重传机制\"},{\"text\":\"TCP粘包拆包\",\"link\":\"/other/network/TCP粘包拆包\"}]},{\"text\":\"HTTP\",\"collapsed\":false,\"items\":[{\"text\":\"HTTP常见字段\",\"link\":\"/other/network/HTTP常见字段\"},{\"text\":\"HTTP和HTTPS\",\"link\":\"/other/network/HTTP和HTTPS\"},{\"text\":\"HTTP1x和HTTP2x\",\"link\":\"/other/network/HTTP1x和HTTP2x\"}]}],\"/other/datastructure/\":[{\"text\":\"设计模式\",\"collapsed\":false,\"items\":[{\"text\":\"七大基本原则\",\"link\":\"/other/design/七大基本原则\"},{\"text\":\"创建型\",\"link\":\"/other/design/创建型\"},{\"text\":\"结构型\",\"link\":\"/other/design/结构型\"},{\"text\":\"行为型\",\"link\":\"/other/design/行为型\"}]}],\"/other/algorithm/\":[{\"text\":\"算法\",\"collapsed\":false,\"items\":[{\"text\":\"时间复杂度\",\"link\":\"/other/algorithm/时间复杂度\"},{\"text\":\"查找\",\"link\":\"/other/algorithm/查找\"},{\"text\":\"排序\",\"link\":\"/other/algorithm/排序\"},{\"text\":\"动态规划\",\"link\":\"/other/algorithm/动态规划\"}]}]},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/AlbertYang0801\"}],\"search\":{\"provider\":\"local\"},\"permalinks\":{\"map\":{},\"inv\":{}},\"docAnalysisInfo\":{\"fileList\":[{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\docker\\\\Docker学习总结.md\",\"relativePath\":\"cloudnative/docker/Docker学习总结.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\docker\\\\docker镜像压缩.md\",\"relativePath\":\"cloudnative/docker/docker镜像压缩.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\docker\\\\index.md\",\"relativePath\":\"cloudnative/docker/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\docker\\\\制作Tomcat镜像.md\",\"relativePath\":\"cloudnative/docker/制作Tomcat镜像.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\docker\\\\容器新增bash.md\",\"relativePath\":\"cloudnative/docker/容器新增bash.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\docker\\\\容器软件安装.md\",\"relativePath\":\"cloudnative/docker/容器软件安装.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\k8s\\\\index.md\",\"relativePath\":\"cloudnative/k8s/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\k8s\\\\k8s常用命令.md\",\"relativePath\":\"cloudnative/k8s/k8s常用命令.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\k8s\\\\k8s问题排查流程图.md\",\"relativePath\":\"cloudnative/k8s/k8s问题排查流程图.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\prometheus\\\\index.md\",\"relativePath\":\"cloudnative/prometheus/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\prometheus\\\\node_exporter源码.md\",\"relativePath\":\"cloudnative/prometheus/node_exporter源码.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\prometheus\\\\TSDB.md\",\"relativePath\":\"cloudnative/prometheus/TSDB.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\prometheus\\\\数据模型.md\",\"relativePath\":\"cloudnative/prometheus/数据模型.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\prometheus\\\\架构.md\",\"relativePath\":\"cloudnative/prometheus/架构.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\clickhouse\\\\ClickHouse基础.md\",\"relativePath\":\"database/clickhouse/ClickHouse基础.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\clickhouse\\\\ClickHouse安装.md\",\"relativePath\":\"database/clickhouse/ClickHouse安装.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\clickhouse\\\\ClickHouse物化列序列化报错.md\",\"relativePath\":\"database/clickhouse/ClickHouse物化列序列化报错.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\clickhouse\\\\ClickHouse高级.md\",\"relativePath\":\"database/clickhouse/ClickHouse高级.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\clickhouse\\\\index.md\",\"relativePath\":\"database/clickhouse/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\clickhouse\\\\为什么弃用Elasticsearch.md\",\"relativePath\":\"database/clickhouse/为什么弃用Elasticsearch.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\B树和B+树.md\",\"relativePath\":\"database/mysql/B树和B+树.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\explain使用总结.md\",\"relativePath\":\"database/mysql/explain使用总结.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\index.md\",\"relativePath\":\"database/mysql/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\InnoDB存储引擎.md\",\"relativePath\":\"database/mysql/InnoDB存储引擎.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\MySQL基础架构.md\",\"relativePath\":\"database/mysql/MySQL基础架构.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\MySQL日志系统.md\",\"relativePath\":\"database/mysql/MySQL日志系统.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\MySQL根据idb文件恢复数据.md\",\"relativePath\":\"database/mysql/MySQL根据idb文件恢复数据.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\MySQL的binlog日志过期删除.md\",\"relativePath\":\"database/mysql/MySQL的binlog日志过期删除.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\OrderBy和limit混用的bug.md\",\"relativePath\":\"database/mysql/OrderBy和limit混用的bug.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\SQL语句的抖动问题.md\",\"relativePath\":\"database/mysql/SQL语句的抖动问题.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\一条更新SQL的执行过程.md\",\"relativePath\":\"database/mysql/一条更新SQL的执行过程.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\事务隔离.md\",\"relativePath\":\"database/mysql/事务隔离.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\慢查询日志.md\",\"relativePath\":\"database/mysql/慢查询日志.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\索引.md\",\"relativePath\":\"database/mysql/索引.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\索引失效的场景.md\",\"relativePath\":\"database/mysql/索引失效的场景.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\行锁.md\",\"relativePath\":\"database/mysql/行锁.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\锁.md\",\"relativePath\":\"database/mysql/锁.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\index.md\",\"relativePath\":\"database/redis/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\LRU和LFU算法.md\",\"relativePath\":\"database/redis/LRU和LFU算法.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\Redisson.md\",\"relativePath\":\"database/redis/Redisson.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\redis事务.md\",\"relativePath\":\"database/redis/redis事务.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\redis实现分布式锁.md\",\"relativePath\":\"database/redis/redis实现分布式锁.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\redis数据类型.md\",\"relativePath\":\"database/redis/redis数据类型.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\redis数据类型原理.md\",\"relativePath\":\"database/redis/redis数据类型原理.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\redis的持久化.md\",\"relativePath\":\"database/redis/redis的持久化.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\redis集群.md\",\"relativePath\":\"database/redis/redis集群.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\内存淘汰策略.md\",\"relativePath\":\"database/redis/内存淘汰策略.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\布隆过滤器.md\",\"relativePath\":\"database/redis/布隆过滤器.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\缓存问题.md\",\"relativePath\":\"database/redis/缓存问题.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\过期策略.md\",\"relativePath\":\"database/redis/过期策略.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\mybatis\\\\custom\\\\SQL执行器.md\",\"relativePath\":\"frame/mybatis/custom/SQL执行器.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\mybatis\\\\custom\\\\xml解析.md\",\"relativePath\":\"frame/mybatis/custom/xml解析.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\mybatis\\\\custom\\\\手写MyBatis.md\",\"relativePath\":\"frame/mybatis/custom/手写MyBatis.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\mybatis\\\\custom\\\\数据源.md\",\"relativePath\":\"frame/mybatis/custom/数据源.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\mybatis\\\\custom\\\\映射器-mapper.md\",\"relativePath\":\"frame/mybatis/custom/映射器-mapper.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\mybatis\\\\index.md\",\"relativePath\":\"frame/mybatis/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\ByteBuf.md\",\"relativePath\":\"frame/netty/ByteBuf.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\Handler的共享和并发安全性.md\",\"relativePath\":\"frame/netty/Handler的共享和并发安全性.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\HTTP服务和SSL&TLS.md\",\"relativePath\":\"frame/netty/HTTP服务和SSL&TLS.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\index.md\",\"relativePath\":\"frame/netty/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\Netty实现文件下载.md\",\"relativePath\":\"frame/netty/Netty实现文件下载.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\Netty实现通信框架.md\",\"relativePath\":\"frame/netty/Netty实现通信框架.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\Netty常用组件.md\",\"relativePath\":\"frame/netty/Netty常用组件.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\TCP粘包拆包问题.md\",\"relativePath\":\"frame/netty/TCP粘包拆包问题.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\内置通信传输模式.md\",\"relativePath\":\"frame/netty/内置通信传输模式.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\写空闲和读空闲.md\",\"relativePath\":\"frame/netty/写空闲和读空闲.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\基于Netty实现RPC.md\",\"relativePath\":\"frame/netty/基于Netty实现RPC.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\序列化问题.md\",\"relativePath\":\"frame/netty/序列化问题.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\线程模型.md\",\"relativePath\":\"frame/netty/线程模型.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\编解码器.md\",\"relativePath\":\"frame/netty/编解码器.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\资源管理和SimpleChannelInboundHandler.md\",\"relativePath\":\"frame/netty/资源管理和SimpleChannelInboundHandler.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\零拷贝.md\",\"relativePath\":\"frame/netty/零拷贝.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\AOP.md\",\"relativePath\":\"frame/spring/AOP.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\ApplicationContext和BeanFactory区别.md\",\"relativePath\":\"frame/spring/ApplicationContext和BeanFactory区别.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Aware接口.md\",\"relativePath\":\"frame/spring/Aware接口.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\BeanFactory和FactoryBean总结.md\",\"relativePath\":\"frame/spring/BeanFactory和FactoryBean总结.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\ByteBuddy实现动态代理.md\",\"relativePath\":\"frame/spring/ByteBuddy实现动态代理.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\custom\\\\AOP.md\",\"relativePath\":\"frame/spring/custom/AOP.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\custom\\\\Boot.md\",\"relativePath\":\"frame/spring/custom/Boot.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\custom\\\\IOC.md\",\"relativePath\":\"frame/spring/custom/IOC.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\custom\\\\JDBC.md\",\"relativePath\":\"frame/spring/custom/JDBC.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\custom\\\\MVC.md\",\"relativePath\":\"frame/spring/custom/MVC.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\custom\\\\声明式事务.md\",\"relativePath\":\"frame/spring/custom/声明式事务.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\custom\\\\手写Spring.md\",\"relativePath\":\"frame/spring/custom/手写Spring.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\index.md\",\"relativePath\":\"frame/spring/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spi机制.md\",\"relativePath\":\"frame/spring/Spi机制.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spring中Bean加载流程.md\",\"relativePath\":\"frame/spring/Spring中Bean加载流程.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spring中Bean的作用域.md\",\"relativePath\":\"frame/spring/Spring中Bean的作用域.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spring事务总结.md\",\"relativePath\":\"frame/spring/Spring事务总结.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spring依赖注入.md\",\"relativePath\":\"frame/spring/Spring依赖注入.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spring如何解决循环依赖.md\",\"relativePath\":\"frame/spring/Spring如何解决循环依赖.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spring框架概述.md\",\"relativePath\":\"frame/spring/Spring框架概述.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spring自定义注解扫描.md\",\"relativePath\":\"frame/spring/Spring自定义注解扫描.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spring配置文件加载顺序.md\",\"relativePath\":\"frame/spring/Spring配置文件加载顺序.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springboot\\\\index.md\",\"relativePath\":\"frame/springboot/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springboot\\\\SpringBoot使用APO记录操作日志.md\",\"relativePath\":\"frame/springboot/SpringBoot使用APO记录操作日志.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springboot\\\\SpringBoot能同时处理多少请求.md\",\"relativePath\":\"frame/springboot/SpringBoot能同时处理多少请求.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springboot\\\\SpringBoot项目自动初始化数据库.md\",\"relativePath\":\"frame/springboot/SpringBoot项目自动初始化数据库.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springcloud\\\\Feigh远程调用原理.md\",\"relativePath\":\"frame/springcloud/Feigh远程调用原理.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springcloud\\\\Gateway.md\",\"relativePath\":\"frame/springcloud/Gateway.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springcloud\\\\index.md\",\"relativePath\":\"frame/springcloud/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springcloud\\\\Nacos.md\",\"relativePath\":\"frame/springcloud/Nacos.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springcloud\\\\Seata分布式事务.md\",\"relativePath\":\"frame/springcloud/Seata分布式事务.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springcloud\\\\Sentinel原理.md\",\"relativePath\":\"frame/springcloud/Sentinel原理.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springcloud\\\\注册中心的演进.md\",\"relativePath\":\"frame/springcloud/注册中心的演进.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\cache\\\\index.md\",\"relativePath\":\"java/cache/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\cache\\\\多级缓存.md\",\"relativePath\":\"java/cache/多级缓存.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\cache\\\\本地缓存.md\",\"relativePath\":\"java/cache/本地缓存.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\cache\\\\缓存淘汰算法.md\",\"relativePath\":\"java/cache/缓存淘汰算法.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\collection\\\\Collection集合概述.md\",\"relativePath\":\"java/collection/Collection集合概述.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\collection\\\\ConcurrentHashMap1.7.md\",\"relativePath\":\"java/collection/ConcurrentHashMap1.7.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\collection\\\\ConcurrentHashMap1.8.md\",\"relativePath\":\"java/collection/ConcurrentHashMap1.8.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\collection\\\\HashMap1.7.md\",\"relativePath\":\"java/collection/HashMap1.7.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\collection\\\\HashMap1.8.md\",\"relativePath\":\"java/collection/HashMap1.8.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\collection\\\\index.md\",\"relativePath\":\"java/collection/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\collection\\\\List集合体系.md\",\"relativePath\":\"java/collection/List集合体系.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\collection\\\\Set集合体系.md\",\"relativePath\":\"java/collection/Set集合体系.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\index.md\",\"relativePath\":\"java/concurrent/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\Java高并发.md\",\"relativePath\":\"java/concurrent/Java高并发.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\AQS.md\",\"relativePath\":\"java/concurrent/single/AQS.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\BlockQueue阻塞队列.md\",\"relativePath\":\"java/concurrent/single/BlockQueue阻塞队列.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\CAS.md\",\"relativePath\":\"java/concurrent/single/CAS.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\synchronized原理.md\",\"relativePath\":\"java/concurrent/single/synchronized原理.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\ThreadLocal.md\",\"relativePath\":\"java/concurrent/single/ThreadLocal.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\transmittable-thread-local.md\",\"relativePath\":\"java/concurrent/single/transmittable-thread-local.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\原子类.md\",\"relativePath\":\"java/concurrent/single/原子类.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\死锁活锁和饥饿.md\",\"relativePath\":\"java/concurrent/single/死锁活锁和饥饿.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\线程池的关闭.md\",\"relativePath\":\"java/concurrent/single/线程池的关闭.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\线程池的执行流程.md\",\"relativePath\":\"java/concurrent/single/线程池的执行流程.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\线程的生命周期.md\",\"relativePath\":\"java/concurrent/single/线程的生命周期.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\distributed\\\\index.md\",\"relativePath\":\"java/distributed/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\distributed\\\\分布式ID.md\",\"relativePath\":\"java/distributed/分布式ID.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\distributed\\\\分布式事务.md\",\"relativePath\":\"java/distributed/分布式事务.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\distributed\\\\分布式锁.md\",\"relativePath\":\"java/distributed/分布式锁.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\distributed\\\\幂等性问题.md\",\"relativePath\":\"java/distributed/幂等性问题.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\io\\\\BIO.md\",\"relativePath\":\"java/io/BIO.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\io\\\\index.md\",\"relativePath\":\"java/io/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\io\\\\IO多路复用.md\",\"relativePath\":\"java/io/IO多路复用.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\io\\\\NIO.md\",\"relativePath\":\"java/io/NIO.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\io\\\\Reactor模式.md\",\"relativePath\":\"java/io/Reactor模式.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\io\\\\基于BIO实现RPC框架.md\",\"relativePath\":\"java/io/基于BIO实现RPC框架.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\CPU负载过高排查记录.md\",\"relativePath\":\"java/jvm/CPU负载过高排查记录.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\G1收集器.md\",\"relativePath\":\"java/jvm/G1收集器.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\index.md\",\"relativePath\":\"java/jvm/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\Java类加载器.md\",\"relativePath\":\"java/jvm/Java类加载器.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\JDK调优命令.md\",\"relativePath\":\"java/jvm/JDK调优命令.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\JVM内存模型.md\",\"relativePath\":\"java/jvm/JVM内存模型.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\内存问题排查总结.md\",\"relativePath\":\"java/jvm/内存问题排查总结.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\可视化工具.md\",\"relativePath\":\"java/jvm/可视化工具.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\垃圾回收器.md\",\"relativePath\":\"java/jvm/垃圾回收器.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\垃圾回收算法.md\",\"relativePath\":\"java/jvm/垃圾回收算法.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\对象创建.md\",\"relativePath\":\"java/jvm/对象创建.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\类加载器.md\",\"relativePath\":\"java/jvm/类加载器.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\频繁GC排查.md\",\"relativePath\":\"java/jvm/频繁GC排查.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\BulkProcessor死锁问题.md\",\"relativePath\":\"middleware/es/BulkProcessor死锁问题.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\Elasticsearch写入原理.md\",\"relativePath\":\"middleware/es/Elasticsearch写入原理.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\Elasticsearch基础概念.md\",\"relativePath\":\"middleware/es/Elasticsearch基础概念.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\Elasticsearch查询原理.md\",\"relativePath\":\"middleware/es/Elasticsearch查询原理.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\Elasticsearch检索.md\",\"relativePath\":\"middleware/es/Elasticsearch检索.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\Elasticsearch聚合查询.md\",\"relativePath\":\"middleware/es/Elasticsearch聚合查询.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\ES分片.md\",\"relativePath\":\"middleware/es/ES分片.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\ES压测记录和esrally使用.md\",\"relativePath\":\"middleware/es/ES压测记录和esrally使用.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\ES参数调优.md\",\"relativePath\":\"middleware/es/ES参数调优.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\ES深度分页问题.md\",\"relativePath\":\"middleware/es/ES深度分页问题.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\ES滚动查询-Scroll.md\",\"relativePath\":\"middleware/es/ES滚动查询-Scroll.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\ES的log4j2日志自动清理配置.md\",\"relativePath\":\"middleware/es/ES的log4j2日志自动清理配置.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\ES聚合查询原理.md\",\"relativePath\":\"middleware/es/ES聚合查询原理.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\ES集群.md\",\"relativePath\":\"middleware/es/ES集群.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\index.md\",\"relativePath\":\"middleware/es/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\倒排索引原理.md\",\"relativePath\":\"middleware/es/倒排索引原理.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\并发场景修改文档.md\",\"relativePath\":\"middleware/es/并发场景修改文档.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\批量操作Bulk和BulkProcessor.md\",\"relativePath\":\"middleware/es/批量操作Bulk和BulkProcessor.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\集群脑裂-参数配置.md\",\"relativePath\":\"middleware/es/集群脑裂-参数配置.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\index.md\",\"relativePath\":\"middleware/kafka/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\kafka-ACK应答机制.md\",\"relativePath\":\"middleware/kafka/kafka-ACK应答机制.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\kafka保证消息不丢失.md\",\"relativePath\":\"middleware/kafka/kafka保证消息不丢失.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\Kafka分区机制策略.md\",\"relativePath\":\"middleware/kafka/Kafka分区机制策略.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\Kafka副本机制.md\",\"relativePath\":\"middleware/kafka/Kafka副本机制.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\Kafka总控制器Controller.md\",\"relativePath\":\"middleware/kafka/Kafka总控制器Controller.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\Kafka手动重新分区.md\",\"relativePath\":\"middleware/kafka/Kafka手动重新分区.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\kafka消费模型.md\",\"relativePath\":\"middleware/kafka/kafka消费模型.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\Kafka消费策略.md\",\"relativePath\":\"middleware/kafka/Kafka消费策略.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\Kafka生产者参数.md\",\"relativePath\":\"middleware/kafka/Kafka生产者参数.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\kafka的分区副本规划.md\",\"relativePath\":\"middleware/kafka/kafka的分区副本规划.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\kafka解决重复消费.md\",\"relativePath\":\"middleware/kafka/kafka解决重复消费.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\Kafka高性能的原因.md\",\"relativePath\":\"middleware/kafka/Kafka高性能的原因.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\Producer发布消息机制.md\",\"relativePath\":\"middleware/kafka/Producer发布消息机制.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\__consumer_offsets.md\",\"relativePath\":\"middleware/kafka/__consumer_offsets.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\数据日志分段存储.md\",\"relativePath\":\"middleware/kafka/数据日志分段存储.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\消费者组.md\",\"relativePath\":\"middleware/kafka/消费者组.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\高水位HW和LEO.md\",\"relativePath\":\"middleware/kafka/高水位HW和LEO.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\index.md\",\"relativePath\":\"middleware/rocketmq/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\Kakfa和RocketMQ的区别.md\",\"relativePath\":\"middleware/rocketmq/Kakfa和RocketMQ的区别.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\MQ接收消息幂等性.md\",\"relativePath\":\"middleware/rocketmq/MQ接收消息幂等性.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\RocketMQ基础学习.md\",\"relativePath\":\"middleware/rocketmq/RocketMQ基础学习.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\RocketMQ集群架构.md\",\"relativePath\":\"middleware/rocketmq/RocketMQ集群架构.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\事务消息.md\",\"relativePath\":\"middleware/rocketmq/事务消息.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\如何保证发送消息有序.md\",\"relativePath\":\"middleware/rocketmq/如何保证发送消息有序.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\如何保证消息不丢失.md\",\"relativePath\":\"middleware/rocketmq/如何保证消息不丢失.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\消息样例.md\",\"relativePath\":\"middleware/rocketmq/消息样例.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\顺序消息.md\",\"relativePath\":\"middleware/rocketmq/顺序消息.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\algorithm\\\\index.md\",\"relativePath\":\"other/algorithm/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\algorithm\\\\动态规划.md\",\"relativePath\":\"other/algorithm/动态规划.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\algorithm\\\\排序.md\",\"relativePath\":\"other/algorithm/排序.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\algorithm\\\\时间复杂度.md\",\"relativePath\":\"other/algorithm/时间复杂度.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\algorithm\\\\查找.md\",\"relativePath\":\"other/algorithm/查找.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\datastructure\\\\index.md\",\"relativePath\":\"other/datastructure/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\datastructure\\\\二叉树.md\",\"relativePath\":\"other/datastructure/二叉树.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\datastructure\\\\常用数据结构.md\",\"relativePath\":\"other/datastructure/常用数据结构.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\design\\\\index.md\",\"relativePath\":\"other/design/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\design\\\\七大基本原则.md\",\"relativePath\":\"other/design/七大基本原则.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\design\\\\创建型.md\",\"relativePath\":\"other/design/创建型.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\design\\\\结构型.md\",\"relativePath\":\"other/design/结构型.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\design\\\\行为型.md\",\"relativePath\":\"other/design/行为型.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\HTTP1x和HTTP2x.md\",\"relativePath\":\"other/network/HTTP1x和HTTP2x.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\HTTP和HTTPS.md\",\"relativePath\":\"other/network/HTTP和HTTPS.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\HTTP常见字段.md\",\"relativePath\":\"other/network/HTTP常见字段.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\index.md\",\"relativePath\":\"other/network/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\Linux如何收发网络包.md\",\"relativePath\":\"other/network/Linux如何收发网络包.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\OSI七层网络模型.md\",\"relativePath\":\"other/network/OSI七层网络模型.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\RTT和SRTT.md\",\"relativePath\":\"other/network/RTT和SRTT.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\Socket.md\",\"relativePath\":\"other/network/Socket.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\TCPIP四层网络模型.md\",\"relativePath\":\"other/network/TCPIP四层网络模型.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\TCP分析工具.md\",\"relativePath\":\"other/network/TCP分析工具.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\TCP协议.md\",\"relativePath\":\"other/network/TCP协议.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\TCP粘包拆包.md\",\"relativePath\":\"other/network/TCP粘包拆包.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\拥塞控制.md\",\"relativePath\":\"other/network/拥塞控制.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\流量控制-滑动窗口.md\",\"relativePath\":\"other/network/流量控制-滑动窗口.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\网址访问页面中间发生了哪些过程.md\",\"relativePath\":\"other/network/网址访问页面中间发生了哪些过程.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\网络包的封装原理.md\",\"relativePath\":\"other/network/网络包的封装原理.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\重传机制.md\",\"relativePath\":\"other/network/重传机制.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\observability\\\\index.md\",\"relativePath\":\"other/observability/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\observability\\\\log\\\\index.md\",\"relativePath\":\"other/observability/log/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\observability\\\\opentelemetry\\\\index.md\",\"relativePath\":\"other/observability/opentelemetry/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\observability\\\\opentelemetry\\\\可观测性.md\",\"relativePath\":\"other/observability/opentelemetry/可观测性.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\observability\\\\skywalking\\\\index.md\",\"relativePath\":\"other/observability/skywalking/index.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\observability\\\\skywalking\\\\源码学习.md\",\"relativePath\":\"other/observability/skywalking/源码学习.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\observability\\\\skywalking\\\\组件安装.md\",\"relativePath\":\"other/observability/skywalking/组件安装.md\"},{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\personal\\\\index.md\",\"relativePath\":\"personal/index.md\"}],\"totalFileWords\":252637,\"eachFileWords\":[{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\docker\\\\Docker学习总结.md\",\"relativePath\":\"cloudnative/docker/Docker学习总结.md\"},\"wordCount\":1976,\"readingTime\":\"8m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\docker\\\\docker镜像压缩.md\",\"relativePath\":\"cloudnative/docker/docker镜像压缩.md\"},\"wordCount\":95,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\docker\\\\index.md\",\"relativePath\":\"cloudnative/docker/index.md\"},\"wordCount\":66,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\docker\\\\制作Tomcat镜像.md\",\"relativePath\":\"cloudnative/docker/制作Tomcat镜像.md\"},\"wordCount\":140,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\docker\\\\容器新增bash.md\",\"relativePath\":\"cloudnative/docker/容器新增bash.md\"},\"wordCount\":224,\"readingTime\":\"1.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\docker\\\\容器软件安装.md\",\"relativePath\":\"cloudnative/docker/容器软件安装.md\"},\"wordCount\":688,\"readingTime\":\"3.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\k8s\\\\index.md\",\"relativePath\":\"cloudnative/k8s/index.md\"},\"wordCount\":29,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\k8s\\\\k8s常用命令.md\",\"relativePath\":\"cloudnative/k8s/k8s常用命令.md\"},\"wordCount\":1471,\"readingTime\":\"7.4m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\k8s\\\\k8s问题排查流程图.md\",\"relativePath\":\"cloudnative/k8s/k8s问题排查流程图.md\"},\"wordCount\":58,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\prometheus\\\\index.md\",\"relativePath\":\"cloudnative/prometheus/index.md\"},\"wordCount\":25,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\prometheus\\\\node_exporter源码.md\",\"relativePath\":\"cloudnative/prometheus/node_exporter源码.md\"},\"wordCount\":805,\"readingTime\":\"4.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\prometheus\\\\TSDB.md\",\"relativePath\":\"cloudnative/prometheus/TSDB.md\"},\"wordCount\":365,\"readingTime\":\"1.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\prometheus\\\\数据模型.md\",\"relativePath\":\"cloudnative/prometheus/数据模型.md\"},\"wordCount\":584,\"readingTime\":\"2.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\cloudnative\\\\prometheus\\\\架构.md\",\"relativePath\":\"cloudnative/prometheus/架构.md\"},\"wordCount\":75,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\clickhouse\\\\ClickHouse基础.md\",\"relativePath\":\"database/clickhouse/ClickHouse基础.md\"},\"wordCount\":794,\"readingTime\":\"3.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\clickhouse\\\\ClickHouse安装.md\",\"relativePath\":\"database/clickhouse/ClickHouse安装.md\"},\"wordCount\":182,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\clickhouse\\\\ClickHouse物化列序列化报错.md\",\"relativePath\":\"database/clickhouse/ClickHouse物化列序列化报错.md\"},\"wordCount\":271,\"readingTime\":\"1.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\clickhouse\\\\ClickHouse高级.md\",\"relativePath\":\"database/clickhouse/ClickHouse高级.md\"},\"wordCount\":1438,\"readingTime\":\"5.5m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\clickhouse\\\\index.md\",\"relativePath\":\"database/clickhouse/index.md\"},\"wordCount\":47,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\clickhouse\\\\为什么弃用Elasticsearch.md\",\"relativePath\":\"database/clickhouse/为什么弃用Elasticsearch.md\"},\"wordCount\":620,\"readingTime\":\"2.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\B树和B+树.md\",\"relativePath\":\"database/mysql/B树和B+树.md\"},\"wordCount\":624,\"readingTime\":\"2.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\explain使用总结.md\",\"relativePath\":\"database/mysql/explain使用总结.md\"},\"wordCount\":1394,\"readingTime\":\"5.8m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\index.md\",\"relativePath\":\"database/mysql/index.md\"},\"wordCount\":184,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\InnoDB存储引擎.md\",\"relativePath\":\"database/mysql/InnoDB存储引擎.md\"},\"wordCount\":311,\"readingTime\":\"1.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\MySQL基础架构.md\",\"relativePath\":\"database/mysql/MySQL基础架构.md\"},\"wordCount\":1670,\"readingTime\":\"6.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\MySQL日志系统.md\",\"relativePath\":\"database/mysql/MySQL日志系统.md\"},\"wordCount\":1650,\"readingTime\":\"6.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\MySQL根据idb文件恢复数据.md\",\"relativePath\":\"database/mysql/MySQL根据idb文件恢复数据.md\"},\"wordCount\":89,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\MySQL的binlog日志过期删除.md\",\"relativePath\":\"database/mysql/MySQL的binlog日志过期删除.md\"},\"wordCount\":183,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\OrderBy和limit混用的bug.md\",\"relativePath\":\"database/mysql/OrderBy和limit混用的bug.md\"},\"wordCount\":79,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\SQL语句的抖动问题.md\",\"relativePath\":\"database/mysql/SQL语句的抖动问题.md\"},\"wordCount\":938,\"readingTime\":\"3.4m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\一条更新SQL的执行过程.md\",\"relativePath\":\"database/mysql/一条更新SQL的执行过程.md\"},\"wordCount\":336,\"readingTime\":\"1.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\事务隔离.md\",\"relativePath\":\"database/mysql/事务隔离.md\"},\"wordCount\":2911,\"readingTime\":\"10.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\慢查询日志.md\",\"relativePath\":\"database/mysql/慢查询日志.md\"},\"wordCount\":446,\"readingTime\":\"1.8m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\索引.md\",\"relativePath\":\"database/mysql/索引.md\"},\"wordCount\":1845,\"readingTime\":\"6.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\索引失效的场景.md\",\"relativePath\":\"database/mysql/索引失效的场景.md\"},\"wordCount\":644,\"readingTime\":\"2.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\行锁.md\",\"relativePath\":\"database/mysql/行锁.md\"},\"wordCount\":618,\"readingTime\":\"2.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\mysql\\\\锁.md\",\"relativePath\":\"database/mysql/锁.md\"},\"wordCount\":1944,\"readingTime\":\"6.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\index.md\",\"relativePath\":\"database/redis/index.md\"},\"wordCount\":111,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\LRU和LFU算法.md\",\"relativePath\":\"database/redis/LRU和LFU算法.md\"},\"wordCount\":2073,\"readingTime\":\"8.7m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\Redisson.md\",\"relativePath\":\"database/redis/Redisson.md\"},\"wordCount\":3912,\"readingTime\":\"17.7m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\redis事务.md\",\"relativePath\":\"database/redis/redis事务.md\"},\"wordCount\":314,\"readingTime\":\"1.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\redis实现分布式锁.md\",\"relativePath\":\"database/redis/redis实现分布式锁.md\"},\"wordCount\":2557,\"readingTime\":\"10.5m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\redis数据类型.md\",\"relativePath\":\"database/redis/redis数据类型.md\"},\"wordCount\":2962,\"readingTime\":\"13.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\redis数据类型原理.md\",\"relativePath\":\"database/redis/redis数据类型原理.md\"},\"wordCount\":1840,\"readingTime\":\"6.7m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\redis的持久化.md\",\"relativePath\":\"database/redis/redis的持久化.md\"},\"wordCount\":1981,\"readingTime\":\"7.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\redis集群.md\",\"relativePath\":\"database/redis/redis集群.md\"},\"wordCount\":1346,\"readingTime\":\"4.8m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\内存淘汰策略.md\",\"relativePath\":\"database/redis/内存淘汰策略.md\"},\"wordCount\":790,\"readingTime\":\"3.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\布隆过滤器.md\",\"relativePath\":\"database/redis/布隆过滤器.md\"},\"wordCount\":2174,\"readingTime\":\"8.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\缓存问题.md\",\"relativePath\":\"database/redis/缓存问题.md\"},\"wordCount\":2744,\"readingTime\":\"9.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\database\\\\redis\\\\过期策略.md\",\"relativePath\":\"database/redis/过期策略.md\"},\"wordCount\":1034,\"readingTime\":\"3.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\mybatis\\\\custom\\\\SQL执行器.md\",\"relativePath\":\"frame/mybatis/custom/SQL执行器.md\"},\"wordCount\":224,\"readingTime\":\"1.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\mybatis\\\\custom\\\\xml解析.md\",\"relativePath\":\"frame/mybatis/custom/xml解析.md\"},\"wordCount\":14,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\mybatis\\\\custom\\\\手写MyBatis.md\",\"relativePath\":\"frame/mybatis/custom/手写MyBatis.md\"},\"wordCount\":273,\"readingTime\":\"1.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\mybatis\\\\custom\\\\数据源.md\",\"relativePath\":\"frame/mybatis/custom/数据源.md\"},\"wordCount\":668,\"readingTime\":\"2.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\mybatis\\\\custom\\\\映射器-mapper.md\",\"relativePath\":\"frame/mybatis/custom/映射器-mapper.md\"},\"wordCount\":617,\"readingTime\":\"2.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\mybatis\\\\index.md\",\"relativePath\":\"frame/mybatis/index.md\"},\"wordCount\":50,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\ByteBuf.md\",\"relativePath\":\"frame/netty/ByteBuf.md\"},\"wordCount\":660,\"readingTime\":\"2.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\Handler的共享和并发安全性.md\",\"relativePath\":\"frame/netty/Handler的共享和并发安全性.md\"},\"wordCount\":331,\"readingTime\":\"1.5m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\HTTP服务和SSL&TLS.md\",\"relativePath\":\"frame/netty/HTTP服务和SSL&TLS.md\"},\"wordCount\":191,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\index.md\",\"relativePath\":\"frame/netty/index.md\"},\"wordCount\":177,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\Netty实现文件下载.md\",\"relativePath\":\"frame/netty/Netty实现文件下载.md\"},\"wordCount\":1666,\"readingTime\":\"8.8m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\Netty实现通信框架.md\",\"relativePath\":\"frame/netty/Netty实现通信框架.md\"},\"wordCount\":401,\"readingTime\":\"1.5m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\Netty常用组件.md\",\"relativePath\":\"frame/netty/Netty常用组件.md\"},\"wordCount\":1654,\"readingTime\":\"6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\TCP粘包拆包问题.md\",\"relativePath\":\"frame/netty/TCP粘包拆包问题.md\"},\"wordCount\":2275,\"readingTime\":\"8.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\内置通信传输模式.md\",\"relativePath\":\"frame/netty/内置通信传输模式.md\"},\"wordCount\":172,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\写空闲和读空闲.md\",\"relativePath\":\"frame/netty/写空闲和读空闲.md\"},\"wordCount\":669,\"readingTime\":\"2.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\基于Netty实现RPC.md\",\"relativePath\":\"frame/netty/基于Netty实现RPC.md\"},\"wordCount\":2157,\"readingTime\":\"10.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\序列化问题.md\",\"relativePath\":\"frame/netty/序列化问题.md\"},\"wordCount\":416,\"readingTime\":\"1.7m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\线程模型.md\",\"relativePath\":\"frame/netty/线程模型.md\"},\"wordCount\":468,\"readingTime\":\"1.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\编解码器.md\",\"relativePath\":\"frame/netty/编解码器.md\"},\"wordCount\":279,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\资源管理和SimpleChannelInboundHandler.md\",\"relativePath\":\"frame/netty/资源管理和SimpleChannelInboundHandler.md\"},\"wordCount\":145,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\netty\\\\零拷贝.md\",\"relativePath\":\"frame/netty/零拷贝.md\"},\"wordCount\":234,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\AOP.md\",\"relativePath\":\"frame/spring/AOP.md\"},\"wordCount\":2135,\"readingTime\":\"8.5m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\ApplicationContext和BeanFactory区别.md\",\"relativePath\":\"frame/spring/ApplicationContext和BeanFactory区别.md\"},\"wordCount\":584,\"readingTime\":\"2.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Aware接口.md\",\"relativePath\":\"frame/spring/Aware接口.md\"},\"wordCount\":297,\"readingTime\":\"1.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\BeanFactory和FactoryBean总结.md\",\"relativePath\":\"frame/spring/BeanFactory和FactoryBean总结.md\"},\"wordCount\":701,\"readingTime\":\"3.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\ByteBuddy实现动态代理.md\",\"relativePath\":\"frame/spring/ByteBuddy实现动态代理.md\"},\"wordCount\":224,\"readingTime\":\"1.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\custom\\\\AOP.md\",\"relativePath\":\"frame/spring/custom/AOP.md\"},\"wordCount\":226,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\custom\\\\Boot.md\",\"relativePath\":\"frame/spring/custom/Boot.md\"},\"wordCount\":434,\"readingTime\":\"2.4m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\custom\\\\IOC.md\",\"relativePath\":\"frame/spring/custom/IOC.md\"},\"wordCount\":3586,\"readingTime\":\"15.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\custom\\\\JDBC.md\",\"relativePath\":\"frame/spring/custom/JDBC.md\"},\"wordCount\":1004,\"readingTime\":\"5.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\custom\\\\MVC.md\",\"relativePath\":\"frame/spring/custom/MVC.md\"},\"wordCount\":535,\"readingTime\":\"2.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\custom\\\\声明式事务.md\",\"relativePath\":\"frame/spring/custom/声明式事务.md\"},\"wordCount\":941,\"readingTime\":\"3.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\custom\\\\手写Spring.md\",\"relativePath\":\"frame/spring/custom/手写Spring.md\"},\"wordCount\":368,\"readingTime\":\"1.5m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\index.md\",\"relativePath\":\"frame/spring/index.md\"},\"wordCount\":254,\"readingTime\":\"1.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spi机制.md\",\"relativePath\":\"frame/spring/Spi机制.md\"},\"wordCount\":950,\"readingTime\":\"4.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spring中Bean加载流程.md\",\"relativePath\":\"frame/spring/Spring中Bean加载流程.md\"},\"wordCount\":1369,\"readingTime\":\"5.7m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spring中Bean的作用域.md\",\"relativePath\":\"frame/spring/Spring中Bean的作用域.md\"},\"wordCount\":1073,\"readingTime\":\"4.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spring事务总结.md\",\"relativePath\":\"frame/spring/Spring事务总结.md\"},\"wordCount\":3709,\"readingTime\":\"14m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spring依赖注入.md\",\"relativePath\":\"frame/spring/Spring依赖注入.md\"},\"wordCount\":92,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spring如何解决循环依赖.md\",\"relativePath\":\"frame/spring/Spring如何解决循环依赖.md\"},\"wordCount\":1371,\"readingTime\":\"5.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spring框架概述.md\",\"relativePath\":\"frame/spring/Spring框架概述.md\"},\"wordCount\":922,\"readingTime\":\"3.5m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spring自定义注解扫描.md\",\"relativePath\":\"frame/spring/Spring自定义注解扫描.md\"},\"wordCount\":853,\"readingTime\":\"4.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\spring\\\\Spring配置文件加载顺序.md\",\"relativePath\":\"frame/spring/Spring配置文件加载顺序.md\"},\"wordCount\":147,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springboot\\\\index.md\",\"relativePath\":\"frame/springboot/index.md\"},\"wordCount\":70,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springboot\\\\SpringBoot使用APO记录操作日志.md\",\"relativePath\":\"frame/springboot/SpringBoot使用APO记录操作日志.md\"},\"wordCount\":738,\"readingTime\":\"3.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springboot\\\\SpringBoot能同时处理多少请求.md\",\"relativePath\":\"frame/springboot/SpringBoot能同时处理多少请求.md\"},\"wordCount\":564,\"readingTime\":\"2.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springboot\\\\SpringBoot项目自动初始化数据库.md\",\"relativePath\":\"frame/springboot/SpringBoot项目自动初始化数据库.md\"},\"wordCount\":635,\"readingTime\":\"3.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springcloud\\\\Feigh远程调用原理.md\",\"relativePath\":\"frame/springcloud/Feigh远程调用原理.md\"},\"wordCount\":721,\"readingTime\":\"4.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springcloud\\\\Gateway.md\",\"relativePath\":\"frame/springcloud/Gateway.md\"},\"wordCount\":250,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springcloud\\\\index.md\",\"relativePath\":\"frame/springcloud/index.md\"},\"wordCount\":85,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springcloud\\\\Nacos.md\",\"relativePath\":\"frame/springcloud/Nacos.md\"},\"wordCount\":1018,\"readingTime\":\"3.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springcloud\\\\Seata分布式事务.md\",\"relativePath\":\"frame/springcloud/Seata分布式事务.md\"},\"wordCount\":2815,\"readingTime\":\"10.7m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springcloud\\\\Sentinel原理.md\",\"relativePath\":\"frame/springcloud/Sentinel原理.md\"},\"wordCount\":1509,\"readingTime\":\"5.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\frame\\\\springcloud\\\\注册中心的演进.md\",\"relativePath\":\"frame/springcloud/注册中心的演进.md\"},\"wordCount\":125,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\cache\\\\index.md\",\"relativePath\":\"java/cache/index.md\"},\"wordCount\":32,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\cache\\\\多级缓存.md\",\"relativePath\":\"java/cache/多级缓存.md\"},\"wordCount\":222,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\cache\\\\本地缓存.md\",\"relativePath\":\"java/cache/本地缓存.md\"},\"wordCount\":552,\"readingTime\":\"2.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\cache\\\\缓存淘汰算法.md\",\"relativePath\":\"java/cache/缓存淘汰算法.md\"},\"wordCount\":530,\"readingTime\":\"1.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\collection\\\\Collection集合概述.md\",\"relativePath\":\"java/collection/Collection集合概述.md\"},\"wordCount\":345,\"readingTime\":\"1.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\collection\\\\ConcurrentHashMap1.7.md\",\"relativePath\":\"java/collection/ConcurrentHashMap1.7.md\"},\"wordCount\":1919,\"readingTime\":\"8.4m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\collection\\\\ConcurrentHashMap1.8.md\",\"relativePath\":\"java/collection/ConcurrentHashMap1.8.md\"},\"wordCount\":92,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\collection\\\\HashMap1.7.md\",\"relativePath\":\"java/collection/HashMap1.7.md\"},\"wordCount\":8627,\"readingTime\":\"35.4m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\collection\\\\HashMap1.8.md\",\"relativePath\":\"java/collection/HashMap1.8.md\"},\"wordCount\":1585,\"readingTime\":\"6.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\collection\\\\index.md\",\"relativePath\":\"java/collection/index.md\"},\"wordCount\":67,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\collection\\\\List集合体系.md\",\"relativePath\":\"java/collection/List集合体系.md\"},\"wordCount\":5174,\"readingTime\":\"21m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\collection\\\\Set集合体系.md\",\"relativePath\":\"java/collection/Set集合体系.md\"},\"wordCount\":506,\"readingTime\":\"2.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\index.md\",\"relativePath\":\"java/concurrent/index.md\"},\"wordCount\":35,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\Java高并发.md\",\"relativePath\":\"java/concurrent/Java高并发.md\"},\"wordCount\":19687,\"readingTime\":\"1h21m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\AQS.md\",\"relativePath\":\"java/concurrent/single/AQS.md\"},\"wordCount\":807,\"readingTime\":\"2.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\BlockQueue阻塞队列.md\",\"relativePath\":\"java/concurrent/single/BlockQueue阻塞队列.md\"},\"wordCount\":1928,\"readingTime\":\"8.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\CAS.md\",\"relativePath\":\"java/concurrent/single/CAS.md\"},\"wordCount\":1271,\"readingTime\":\"4.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\synchronized原理.md\",\"relativePath\":\"java/concurrent/single/synchronized原理.md\"},\"wordCount\":1824,\"readingTime\":\"6.7m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\ThreadLocal.md\",\"relativePath\":\"java/concurrent/single/ThreadLocal.md\"},\"wordCount\":2391,\"readingTime\":\"10.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\transmittable-thread-local.md\",\"relativePath\":\"java/concurrent/single/transmittable-thread-local.md\"},\"wordCount\":783,\"readingTime\":\"3.4m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\原子类.md\",\"relativePath\":\"java/concurrent/single/原子类.md\"},\"wordCount\":983,\"readingTime\":\"4m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\死锁活锁和饥饿.md\",\"relativePath\":\"java/concurrent/single/死锁活锁和饥饿.md\"},\"wordCount\":2160,\"readingTime\":\"8.7m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\线程池的关闭.md\",\"relativePath\":\"java/concurrent/single/线程池的关闭.md\"},\"wordCount\":2128,\"readingTime\":\"9.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\线程池的执行流程.md\",\"relativePath\":\"java/concurrent/single/线程池的执行流程.md\"},\"wordCount\":1790,\"readingTime\":\"7.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\concurrent\\\\single\\\\线程的生命周期.md\",\"relativePath\":\"java/concurrent/single/线程的生命周期.md\"},\"wordCount\":1231,\"readingTime\":\"5.7m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\distributed\\\\index.md\",\"relativePath\":\"java/distributed/index.md\"},\"wordCount\":43,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\distributed\\\\分布式ID.md\",\"relativePath\":\"java/distributed/分布式ID.md\"},\"wordCount\":1034,\"readingTime\":\"4.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\distributed\\\\分布式事务.md\",\"relativePath\":\"java/distributed/分布式事务.md\"},\"wordCount\":1135,\"readingTime\":\"4.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\distributed\\\\分布式锁.md\",\"relativePath\":\"java/distributed/分布式锁.md\"},\"wordCount\":643,\"readingTime\":\"2.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\distributed\\\\幂等性问题.md\",\"relativePath\":\"java/distributed/幂等性问题.md\"},\"wordCount\":268,\"readingTime\":\"1.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\io\\\\BIO.md\",\"relativePath\":\"java/io/BIO.md\"},\"wordCount\":443,\"readingTime\":\"1.5m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\io\\\\index.md\",\"relativePath\":\"java/io/index.md\"},\"wordCount\":40,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\io\\\\IO多路复用.md\",\"relativePath\":\"java/io/IO多路复用.md\"},\"wordCount\":2125,\"readingTime\":\"8.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\io\\\\NIO.md\",\"relativePath\":\"java/io/NIO.md\"},\"wordCount\":1264,\"readingTime\":\"5.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\io\\\\Reactor模式.md\",\"relativePath\":\"java/io/Reactor模式.md\"},\"wordCount\":722,\"readingTime\":\"2.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\io\\\\基于BIO实现RPC框架.md\",\"relativePath\":\"java/io/基于BIO实现RPC框架.md\"},\"wordCount\":842,\"readingTime\":\"3.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\CPU负载过高排查记录.md\",\"relativePath\":\"java/jvm/CPU负载过高排查记录.md\"},\"wordCount\":545,\"readingTime\":\"2.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\G1收集器.md\",\"relativePath\":\"java/jvm/G1收集器.md\"},\"wordCount\":2324,\"readingTime\":\"8.4m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\index.md\",\"relativePath\":\"java/jvm/index.md\"},\"wordCount\":166,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\Java类加载器.md\",\"relativePath\":\"java/jvm/Java类加载器.md\"},\"wordCount\":3641,\"readingTime\":\"15.7m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\JDK调优命令.md\",\"relativePath\":\"java/jvm/JDK调优命令.md\"},\"wordCount\":1164,\"readingTime\":\"5.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\JVM内存模型.md\",\"relativePath\":\"java/jvm/JVM内存模型.md\"},\"wordCount\":4599,\"readingTime\":\"18m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\内存问题排查总结.md\",\"relativePath\":\"java/jvm/内存问题排查总结.md\"},\"wordCount\":324,\"readingTime\":\"1.5m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\可视化工具.md\",\"relativePath\":\"java/jvm/可视化工具.md\"},\"wordCount\":184,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\垃圾回收器.md\",\"relativePath\":\"java/jvm/垃圾回收器.md\"},\"wordCount\":2685,\"readingTime\":\"9.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\垃圾回收算法.md\",\"relativePath\":\"java/jvm/垃圾回收算法.md\"},\"wordCount\":3669,\"readingTime\":\"14.8m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\对象创建.md\",\"relativePath\":\"java/jvm/对象创建.md\"},\"wordCount\":769,\"readingTime\":\"2.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\类加载器.md\",\"relativePath\":\"java/jvm/类加载器.md\"},\"wordCount\":3641,\"readingTime\":\"15.7m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\java\\\\jvm\\\\频繁GC排查.md\",\"relativePath\":\"java/jvm/频繁GC排查.md\"},\"wordCount\":57,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\BulkProcessor死锁问题.md\",\"relativePath\":\"middleware/es/BulkProcessor死锁问题.md\"},\"wordCount\":538,\"readingTime\":\"2.8m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\Elasticsearch写入原理.md\",\"relativePath\":\"middleware/es/Elasticsearch写入原理.md\"},\"wordCount\":2548,\"readingTime\":\"9.8m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\Elasticsearch基础概念.md\",\"relativePath\":\"middleware/es/Elasticsearch基础概念.md\"},\"wordCount\":2601,\"readingTime\":\"10.5m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\Elasticsearch查询原理.md\",\"relativePath\":\"middleware/es/Elasticsearch查询原理.md\"},\"wordCount\":395,\"readingTime\":\"1.5m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\Elasticsearch检索.md\",\"relativePath\":\"middleware/es/Elasticsearch检索.md\"},\"wordCount\":1391,\"readingTime\":\"5.8m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\Elasticsearch聚合查询.md\",\"relativePath\":\"middleware/es/Elasticsearch聚合查询.md\"},\"wordCount\":2914,\"readingTime\":\"14.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\ES分片.md\",\"relativePath\":\"middleware/es/ES分片.md\"},\"wordCount\":414,\"readingTime\":\"1.4m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\ES压测记录和esrally使用.md\",\"relativePath\":\"middleware/es/ES压测记录和esrally使用.md\"},\"wordCount\":910,\"readingTime\":\"4.5m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\ES参数调优.md\",\"relativePath\":\"middleware/es/ES参数调优.md\"},\"wordCount\":220,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\ES深度分页问题.md\",\"relativePath\":\"middleware/es/ES深度分页问题.md\"},\"wordCount\":502,\"readingTime\":\"1.8m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\ES滚动查询-Scroll.md\",\"relativePath\":\"middleware/es/ES滚动查询-Scroll.md\"},\"wordCount\":908,\"readingTime\":\"3.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\ES的log4j2日志自动清理配置.md\",\"relativePath\":\"middleware/es/ES的log4j2日志自动清理配置.md\"},\"wordCount\":275,\"readingTime\":\"1.4m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\ES聚合查询原理.md\",\"relativePath\":\"middleware/es/ES聚合查询原理.md\"},\"wordCount\":52,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\ES集群.md\",\"relativePath\":\"middleware/es/ES集群.md\"},\"wordCount\":2375,\"readingTime\":\"8.7m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\index.md\",\"relativePath\":\"middleware/es/index.md\"},\"wordCount\":370,\"readingTime\":\"1.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\倒排索引原理.md\",\"relativePath\":\"middleware/es/倒排索引原理.md\"},\"wordCount\":1426,\"readingTime\":\"5.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\并发场景修改文档.md\",\"relativePath\":\"middleware/es/并发场景修改文档.md\"},\"wordCount\":99,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\批量操作Bulk和BulkProcessor.md\",\"relativePath\":\"middleware/es/批量操作Bulk和BulkProcessor.md\"},\"wordCount\":502,\"readingTime\":\"2.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\es\\\\集群脑裂-参数配置.md\",\"relativePath\":\"middleware/es/集群脑裂-参数配置.md\"},\"wordCount\":575,\"readingTime\":\"2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\index.md\",\"relativePath\":\"middleware/kafka/index.md\"},\"wordCount\":393,\"readingTime\":\"2.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\kafka-ACK应答机制.md\",\"relativePath\":\"middleware/kafka/kafka-ACK应答机制.md\"},\"wordCount\":590,\"readingTime\":\"2.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\kafka保证消息不丢失.md\",\"relativePath\":\"middleware/kafka/kafka保证消息不丢失.md\"},\"wordCount\":742,\"readingTime\":\"2.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\Kafka分区机制策略.md\",\"relativePath\":\"middleware/kafka/Kafka分区机制策略.md\"},\"wordCount\":424,\"readingTime\":\"1.5m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\Kafka副本机制.md\",\"relativePath\":\"middleware/kafka/Kafka副本机制.md\"},\"wordCount\":861,\"readingTime\":\"3.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\Kafka总控制器Controller.md\",\"relativePath\":\"middleware/kafka/Kafka总控制器Controller.md\"},\"wordCount\":847,\"readingTime\":\"3.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\Kafka手动重新分区.md\",\"relativePath\":\"middleware/kafka/Kafka手动重新分区.md\"},\"wordCount\":433,\"readingTime\":\"2.4m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\kafka消费模型.md\",\"relativePath\":\"middleware/kafka/kafka消费模型.md\"},\"wordCount\":401,\"readingTime\":\"1.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\Kafka消费策略.md\",\"relativePath\":\"middleware/kafka/Kafka消费策略.md\"},\"wordCount\":455,\"readingTime\":\"1.8m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\Kafka生产者参数.md\",\"relativePath\":\"middleware/kafka/Kafka生产者参数.md\"},\"wordCount\":808,\"readingTime\":\"2.8m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\kafka的分区副本规划.md\",\"relativePath\":\"middleware/kafka/kafka的分区副本规划.md\"},\"wordCount\":267,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\kafka解决重复消费.md\",\"relativePath\":\"middleware/kafka/kafka解决重复消费.md\"},\"wordCount\":544,\"readingTime\":\"2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\Kafka高性能的原因.md\",\"relativePath\":\"middleware/kafka/Kafka高性能的原因.md\"},\"wordCount\":319,\"readingTime\":\"1.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\Producer发布消息机制.md\",\"relativePath\":\"middleware/kafka/Producer发布消息机制.md\"},\"wordCount\":297,\"readingTime\":\"1.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\__consumer_offsets.md\",\"relativePath\":\"middleware/kafka/__consumer_offsets.md\"},\"wordCount\":711,\"readingTime\":\"2.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\数据日志分段存储.md\",\"relativePath\":\"middleware/kafka/数据日志分段存储.md\"},\"wordCount\":311,\"readingTime\":\"1.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\消费者组.md\",\"relativePath\":\"middleware/kafka/消费者组.md\"},\"wordCount\":1617,\"readingTime\":\"6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\kafka\\\\高水位HW和LEO.md\",\"relativePath\":\"middleware/kafka/高水位HW和LEO.md\"},\"wordCount\":356,\"readingTime\":\"1.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\index.md\",\"relativePath\":\"middleware/rocketmq/index.md\"},\"wordCount\":218,\"readingTime\":\"1.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\Kakfa和RocketMQ的区别.md\",\"relativePath\":\"middleware/rocketmq/Kakfa和RocketMQ的区别.md\"},\"wordCount\":1128,\"readingTime\":\"4.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\MQ接收消息幂等性.md\",\"relativePath\":\"middleware/rocketmq/MQ接收消息幂等性.md\"},\"wordCount\":144,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\RocketMQ基础学习.md\",\"relativePath\":\"middleware/rocketmq/RocketMQ基础学习.md\"},\"wordCount\":1006,\"readingTime\":\"3.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\RocketMQ集群架构.md\",\"relativePath\":\"middleware/rocketmq/RocketMQ集群架构.md\"},\"wordCount\":257,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\事务消息.md\",\"relativePath\":\"middleware/rocketmq/事务消息.md\"},\"wordCount\":578,\"readingTime\":\"2.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\如何保证发送消息有序.md\",\"relativePath\":\"middleware/rocketmq/如何保证发送消息有序.md\"},\"wordCount\":191,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\如何保证消息不丢失.md\",\"relativePath\":\"middleware/rocketmq/如何保证消息不丢失.md\"},\"wordCount\":955,\"readingTime\":\"3.4m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\消息样例.md\",\"relativePath\":\"middleware/rocketmq/消息样例.md\"},\"wordCount\":935,\"readingTime\":\"4.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\middleware\\\\rocketmq\\\\顺序消息.md\",\"relativePath\":\"middleware/rocketmq/顺序消息.md\"},\"wordCount\":886,\"readingTime\":\"3.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\algorithm\\\\index.md\",\"relativePath\":\"other/algorithm/index.md\"},\"wordCount\":54,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\algorithm\\\\动态规划.md\",\"relativePath\":\"other/algorithm/动态规划.md\"},\"wordCount\":1296,\"readingTime\":\"5.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\algorithm\\\\排序.md\",\"relativePath\":\"other/algorithm/排序.md\"},\"wordCount\":1663,\"readingTime\":\"6.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\algorithm\\\\时间复杂度.md\",\"relativePath\":\"other/algorithm/时间复杂度.md\"},\"wordCount\":278,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\algorithm\\\\查找.md\",\"relativePath\":\"other/algorithm/查找.md\"},\"wordCount\":328,\"readingTime\":\"1.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\datastructure\\\\index.md\",\"relativePath\":\"other/datastructure/index.md\"},\"wordCount\":42,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\datastructure\\\\二叉树.md\",\"relativePath\":\"other/datastructure/二叉树.md\"},\"wordCount\":1287,\"readingTime\":\"5.7m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\datastructure\\\\常用数据结构.md\",\"relativePath\":\"other/datastructure/常用数据结构.md\"},\"wordCount\":1746,\"readingTime\":\"7.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\design\\\\index.md\",\"relativePath\":\"other/design/index.md\"},\"wordCount\":356,\"readingTime\":\"1.3m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\design\\\\七大基本原则.md\",\"relativePath\":\"other/design/七大基本原则.md\"},\"wordCount\":619,\"readingTime\":\"2.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\design\\\\创建型.md\",\"relativePath\":\"other/design/创建型.md\"},\"wordCount\":2136,\"readingTime\":\"8.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\design\\\\结构型.md\",\"relativePath\":\"other/design/结构型.md\"},\"wordCount\":1297,\"readingTime\":\"4.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\design\\\\行为型.md\",\"relativePath\":\"other/design/行为型.md\"},\"wordCount\":3814,\"readingTime\":\"14.5m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\HTTP1x和HTTP2x.md\",\"relativePath\":\"other/network/HTTP1x和HTTP2x.md\"},\"wordCount\":1257,\"readingTime\":\"4.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\HTTP和HTTPS.md\",\"relativePath\":\"other/network/HTTP和HTTPS.md\"},\"wordCount\":450,\"readingTime\":\"1.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\HTTP常见字段.md\",\"relativePath\":\"other/network/HTTP常见字段.md\"},\"wordCount\":406,\"readingTime\":\"1.8m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\index.md\",\"relativePath\":\"other/network/index.md\"},\"wordCount\":377,\"readingTime\":\"2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\Linux如何收发网络包.md\",\"relativePath\":\"other/network/Linux如何收发网络包.md\"},\"wordCount\":157,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\OSI七层网络模型.md\",\"relativePath\":\"other/network/OSI七层网络模型.md\"},\"wordCount\":148,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\RTT和SRTT.md\",\"relativePath\":\"other/network/RTT和SRTT.md\"},\"wordCount\":328,\"readingTime\":\"1.1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\Socket.md\",\"relativePath\":\"other/network/Socket.md\"},\"wordCount\":479,\"readingTime\":\"1.7m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\TCPIP四层网络模型.md\",\"relativePath\":\"other/network/TCPIP四层网络模型.md\"},\"wordCount\":1552,\"readingTime\":\"5.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\TCP分析工具.md\",\"relativePath\":\"other/network/TCP分析工具.md\"},\"wordCount\":413,\"readingTime\":\"1.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\TCP协议.md\",\"relativePath\":\"other/network/TCP协议.md\"},\"wordCount\":3132,\"readingTime\":\"11.4m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\TCP粘包拆包.md\",\"relativePath\":\"other/network/TCP粘包拆包.md\"},\"wordCount\":892,\"readingTime\":\"3.2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\拥塞控制.md\",\"relativePath\":\"other/network/拥塞控制.md\"},\"wordCount\":1056,\"readingTime\":\"3.9m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\流量控制-滑动窗口.md\",\"relativePath\":\"other/network/流量控制-滑动窗口.md\"},\"wordCount\":405,\"readingTime\":\"1.5m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\网址访问页面中间发生了哪些过程.md\",\"relativePath\":\"other/network/网址访问页面中间发生了哪些过程.md\"},\"wordCount\":3975,\"readingTime\":\"14.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\网络包的封装原理.md\",\"relativePath\":\"other/network/网络包的封装原理.md\"},\"wordCount\":249,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\network\\\\重传机制.md\",\"relativePath\":\"other/network/重传机制.md\"},\"wordCount\":707,\"readingTime\":\"2.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\observability\\\\index.md\",\"relativePath\":\"other/observability/index.md\"},\"wordCount\":192,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\observability\\\\log\\\\index.md\",\"relativePath\":\"other/observability/log/index.md\"},\"wordCount\":806,\"readingTime\":\"3.6m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\observability\\\\opentelemetry\\\\index.md\",\"relativePath\":\"other/observability/opentelemetry/index.md\"},\"wordCount\":458,\"readingTime\":\"2m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\observability\\\\opentelemetry\\\\可观测性.md\",\"relativePath\":\"other/observability/opentelemetry/可观测性.md\"},\"wordCount\":188,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\observability\\\\skywalking\\\\index.md\",\"relativePath\":\"other/observability/skywalking/index.md\"},\"wordCount\":49,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\observability\\\\skywalking\\\\源码学习.md\",\"relativePath\":\"other/observability/skywalking/源码学习.md\"},\"wordCount\":835,\"readingTime\":\"4.4m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\other\\\\observability\\\\skywalking\\\\组件安装.md\",\"relativePath\":\"other/observability/skywalking/组件安装.md\"},\"wordCount\":86,\"readingTime\":\"1m\",\"frontmatter\":{}},{\"fileInfo\":{\"filePath\":\"D:\\\\IdeaProjects\\\\vitepress-theme-teek-docs\\\\docs\\\\personal\\\\index.md\",\"relativePath\":\"personal/index.md\"},\"wordCount\":736,\"readingTime\":\"4.1m\",\"frontmatter\":{}}],\"lastCommitTime\":\"2025-08-15 17:44:55\"},\"catalogues\":{\"arr\":[],\"map\":{},\"inv\":{}},\"posts\":{\"allPosts\":[{\"url\":\"/cloudnative/docker/Docker学习总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Docker学习总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本知识\\r\\n\\r\\n 1. Docker 是什么？\\r\\n\\r\\ndocker 是一种容器化虚拟技术，解决了运行环境和配置问题，方便持续集成并有助于项目整体发布。\\r\\n\\r\\n 2. Docker 能干嘛？\\r\\n\\r\\n*一次构建、随处运行。*\\r\\n\\r\\n- 更快速的应用交付和部署。\\r\\n- 更便捷的升级和扩缩容。\\r\\n- 更简单的系统运维。\\r\\n- 更高效的计算源利用。\\r\\n\\r\\n 基本组成\\r\\n\\r\\n 1. 镜像\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 2. 容器\\r\\n\\r\\n&gt; Docker 利用容器（Container）独立运行一个或一组应，容器是用镜像创建的运行实例。\\r\\n&gt; \\r\\n\\r\\n它可以被启动、开始、停止、删除。每个容器都是相\"},{\"url\":\"/cloudnative/docker/docker镜像压缩.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"docker镜像压缩\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"tar包\\r\\n\\r\\n\\r\\n\\r\\n```\\r\\ndocker save tomcat-apm-0915 -o ./tomcat-apm-0915.tar\\r\\n```\\r\\n\\r\\n```\\r\\ndocker load &lt; tomcat-apm-0915.tar\\r\\n```\\r\\n\\r\\nDocker 复制镜像到其他主机 - 彦祚 - 博客园\\r\\n\\r\\n tar.gz包\\r\\n\\r\\n 保存镜像\\r\\n\\r\\n`docker save &lt;myimage\\r\\n\\r\\n```\\r\\ndocker save xxx:xxx| gzip&gt;xxx.tar.gz\\r\\n```\\r\\n\\r\\n 加载镜像\\r\\n\\r\\n`gunzip -c &lt;myimage&gt;_&lt\"},{\"url\":\"/cloudnative/docker/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Docker\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"学习总结\\r\\n- Docker学习总结\\r\\n\\r\\n\\r\\n 使用总结\\r\\n- 容器软件安装\\r\\n- docker镜像压缩\\r\\n- 制作Tomcat镜像\\r\\n- 容器新增bash\"},{\"url\":\"/cloudnative/docker/制作Tomcat镜像.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"制作Tomcat镜像\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"DockerFile文件内容\\r\\n\\r\\n- tomcat 基础镜像\\r\\n  \\r\\n    ```bash\\r\\n    \\r\\n     使用基于 JDK 8 的官方 Tomcat 镜像作为基础镜像\\r\\n    FROM tomcat:8-jdk8\\r\\n    \\r\\n     修改默认的 shell\\r\\n    RUN ln -sf /bin/bash /bin/sh\\r\\n    \\r\\n     暴露 Tomcat 的默认 HTTP 端口\\r\\n    EXPOSE 8080\\r\\n    \\r\\n     设置容器启动时执行的命令\\r\\n    CMD [\\\"catalina.sh\\\", \\\"run\\\"]\\r\\n    ```\\r\\n    \\r\\n- \"},{\"url\":\"/cloudnative/docker/容器新增bash.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"容器新增bash\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"安装方式\\r\\n\\r\\n- wget 下载\\r\\n  \\r\\n    ```bash\\r\\n    from busybox\\r\\n    \\r\\n     下载 bash 二进制文件\\r\\n    RUN wget -O /bin/bash http://ftp.gnu.org/gnu/bash/bash-5.1.tar.gz\\r\\n    \\r\\n     设置可执行权限\\r\\n    RUN chmod +x /bin/bash\\r\\n    \\r\\n     运行命令\\r\\n    CMD [\\\"echo\\\", \\\"Hello, World!\\\"]\\r\\n    ```\\r\\n    \\r\\n- 本地安装\\r\\n  \\r\\n    ```bash\\r\\n    from \"},{\"url\":\"/cloudnative/docker/容器软件安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"容器软件安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"RabbitMQ\\r\\n\\r\\n参考博客\\r\\n\\r\\ndocker安装RabbitMQ\\r\\n\\r\\n---\\r\\n\\r\\n1. 查找镜像\\r\\n   \\r\\n    ```java\\r\\n    docker search rabbitmq\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n2. 拉取镜像\\r\\n   \\r\\n    ```java\\r\\n    docker pull rabbitmq\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 启动镜像\\r\\n   \\r\\n    ```java\\r\\n    docker run -d --hostname my-rabbit --name rabbit -p 15672:15\"},{\"url\":\"/cloudnative/k8s/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"K8s\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- k8s常用命令\\r\\n- k8s问题排查流程图\"},{\"url\":\"/cloudnative/k8s/k8s常用命令.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"k8s常用命令\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"常用命令总结\\r\\n\\r\\n node\\r\\n\\r\\n- 查看所有的node\\r\\n  \\r\\n    ```\\r\\n    kubectl get nodes\\r\\n    ```\\r\\n    \\r\\n- 查看node名与Host文件的相互解析\\r\\n  \\r\\n    ```\\r\\n    cat /etc/hosts\\r\\n    ```\\r\\n    \\r\\n- 查看本机 hostname\\r\\n  \\r\\n    `Plain Text   cat /etc/hostname`\\r\\n    \\r\\n\\r\\n namespace\\r\\n\\r\\n- 查看所有的namespace\\r\\n  \\r\\n    ```\\r\\n    [root@master ~] kubectl  get n\"},{\"url\":\"/cloudnative/k8s/k8s问题排查流程图.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"k8s问题排查流程图\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"深度解密｜基于 eBPF 的 Kubernetes 问题排查全景图发布-阿里云开发者社区\"},{\"url\":\"/cloudnative/prometheus/TSDB.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TSDB\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Prometheus的 TSDB（Time Series Database）作为内置的时序数据库。\\r\\n\\r\\n 存储原理\\r\\n\\r\\nTSDB 既使用内存也使用磁盘进行数据存储。\\r\\n\\r\\n\\r\\n\\r\\n Head\\r\\n\\r\\n在Prometheus中，Head 是数据库的内存部分，用于存储最近写入的数据。\\r\\n\\r\\n当数据在Head中存储2小时后，会被转移到磁盘上的持久块（block）中。这些持久块是不变的，每个块代表一段时间的数据，并且按照时间顺序进行组织和存储。\\r\\n\\r\\n\\r\\n\\r\\n Block块\\r\\n\\r\\nPrometheus中以每2个小时为一个时间窗口，即将2小时内产生的数据存储在一个block中，监控数据会以时间段的形式\"},{\"url\":\"/cloudnative/prometheus/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Prometheus\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 架构\\r\\n- TSDB\\r\\n- 数据模型\\r\\n- node_exporter源码\"},{\"url\":\"/cloudnative/prometheus/node_exporter源码.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"node_exporter源码\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"简单流程\\r\\n\\r\\n1. 定时任务 30s 执行一次\\r\\n    1. 调用采集指标的方法\\r\\n2. 不同 Collector 采集自己的指标\\r\\n    1. 内存\\r\\n        - 读取 `/`@\\r\\n          \\r\\n            `proc/meminfo`文件内容\\r\\n            \\r\\n            ```go\\r\\n            MemTotal:       16267496 kB\\r\\n            MemFree:          803084 kB\\r\\n            MemAvailable:    1507880 kB\\r\\n \"},{\"url\":\"/cloudnative/prometheus/数据模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Prometheus的存储实现上所有的监控样本都是以 time-series 的形式保存在 Prometheus 内置的TSDB（时序数据库）中，而 time-series 所对应的监控指标 (metric) 也是通过 labelset 进行唯一命名的。\\r\\n\\r\\n 样本数据\\r\\n\\r\\n- 指标(metric)：metric name 和描述当前样本特征的 labelsets;\\r\\n- 时间戳(timestamp)：一个精确到毫秒的时间戳;\\r\\n- 样本值(value)： 一个float64的浮点型数据表示当前样本的值。\\r\\n\\r\\n```\\r\\n&lt;--------------- metric -------\"},{\"url\":\"/cloudnative/prometheus/架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Prometheus架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- Promtheus 默认采取主动拉的策略，可以配置各个exporter的拉取间隔。\\r\\n    - Exporter 被动暴露数据，Prometheus 主动拉取。\\r\\n- 但是Promtheus也可以使用 Pushgateway 实现 Push 模型。\\r\\n    - exporter 将数据推给 Pushgateway，Promtheus从Pushgateway拉数据。\"},{\"url\":\"/database/clickhouse/ClickHouse基础.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse基础\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"列式存储\\r\\n\\r\\nclickhouse 是 *列式存储* 数据库\\r\\n\\r\\n在磁盘上按列存储，即按某个字段进行存储。\\r\\n\\r\\n\\r\\n\\r\\n所以列式存储更适合进行查询，比如某一行的聚合、计算、求和等。\\r\\n\\r\\n 列式存储的好处\\r\\n\\r\\n1. 对于某列的聚合、计数、求和等操作要比行式存储更快。\\r\\n   \\r\\n    查询更快。\\r\\n    \\r\\n    - 行式存储，增改删更加方便，因为只需要找到对应的行记录，直接删除即可。但是列式存储对比起来，增改删要更繁琐一点。\\r\\n2. 每一列的数据类型是一样的，这样能更好的进行数据压缩。\\r\\n   \\r\\n    方便数据压缩，节省磁盘\\r\\n    \\r\\n    - 与 es 相比，作为常\"},{\"url\":\"/database/clickhouse/ClickHouse安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"docker下安装clickhouse_docker 安装clickhouse-CSDN博客\\r\\n\\r\\n使用 clickhouse-client 进入 ck\\r\\n\\r\\n mac 安装\\r\\n\\r\\n```java\\r\\ndocker run --rm -d --name=clickhouse \\\\\\r\\n-e CLICKHOUSE_ADMIN_PASSWORD=\\\"123456\\\" \\\\\\r\\n--ulimit nofile=262144:262144 \\\\\\r\\n-p 8123:8123 -p 9009:9009 -p 9090:9000 \\\\\\r\\n-v /Users/yangjunwei/ck/config:/etc/clickhou\"},{\"url\":\"/database/clickhouse/ClickHouse物化列序列化报错.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse物化列序列化报错问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"报错内容\\r\\n\\r\\n```java\\r\\nNo serializer found for column 'date'. Did you forget to register it?\\r\\n\\tat com.clickhouse.client.api.Client.insert(Client.java:1317)\\r\\n\\tat com.clickhouse.client.api.Client.insert(Client.java:1266)\\r\\n```\\r\\n\\r\\n 表结构\\r\\n\\r\\n```java\\r\\nCREATE TABLE IF NOT EXISTS metric_data\\r\\n(\\r\\n    `placeId` UInt3\"},{\"url\":\"/database/clickhouse/ClickHouse高级.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse高级\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MergeTree\\r\\n\\r\\nClickHouse 中最强大的表引擎当属 MergeTree（合并树）引擎及该系列（MergeTree）中的其他引擎，支持索引和分区，地位可以相当于 innodb 之于 Mysql。而且基于 MergeTree，还衍生除了很多小弟，也是非常有特色的引擎。\\r\\n\\r\\n建表语句\\r\\n\\r\\n```sql\\r\\ncreate table t_order_mt(\\r\\n id UInt32,\\r\\n sku_id String,\\r\\n total_amount Decimal(16,2),\\r\\n create_time Datetime\\r\\n) engine = MergeTree\\r\\n partiti\"},{\"url\":\"/database/clickhouse/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- ClickHouse安装\\r\\n- ClickHouse基础\\r\\n- ClickHouse高级\\r\\n- 为什么弃用Elasticsearch\"},{\"url\":\"/database/clickhouse/为什么弃用Elasticsearch.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"对于开发来说：\\r\\n\\r\\n1. 大批量数据查询导致 es 的 CPU 飙升。\\r\\n2. 数据量增大之后，es 的查询效率下降，影响接口性能。\\r\\n3. 聚合效率低。\\r\\n\\r\\n对于运维来说：\\r\\n\\r\\n1. 维护成本很大，在数据量大的情况，es 占用磁盘空间很大，没有很好的压缩手段。\\r\\n2. es 很占内存，内存配置为整体内存的一半。\\r\\n\\r\\n 问题记录\\r\\n\\r\\n- 缓存计算系统评分导致 es 的 cpu 飙升。\\r\\n\\r\\n  系统评分需要查询 es 的流量信息进行计算，实时查询很慢。做了定时任务计算分数信息并作缓存。\\r\\n\\r\\n    - 经常发现 es 的 cpu 会被打满。排查发现随着系统的增多，当定时任务跑的时候\"},{\"url\":\"/database/mysql/B树和B+树.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"B树和B+树\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"B树\\r\\n\\r\\n\\r\\n\\r\\n每个节点是一个磁盘快。每个磁盘快有固定大小，可以存储多个K-V键值对。\\r\\n\\r\\n每个磁盘快包含指向下层节点的指针，方便查找。\\r\\n\\r\\n*由于每个节点存储了更多的键值对数据，可以有效降低查找树的次数，并减少查询磁盘。*\\r\\n\\r\\n- \\r\\n\\r\\n B+树\\r\\n\\r\\n\\r\\n\\r\\n 存储空间\\r\\n\\r\\nB+树是在B树的基础上演进的。\\r\\n\\r\\nB+树的非叶子结点是不保存数据的，仅保存键值。\\r\\n\\r\\n在 InnoDB中页大小是固定的，在只保存键值的情况下，同一个数据页能保存更多的键值。这样就能保证整个树的层级大大降低，减少向下搜索时候的磁盘IO次数，会提高数据的查询效率。\\r\\n\\r\\nInnoDB 中页的默认大小是 \"},{\"url\":\"/database/mysql/InnoDB存储引擎.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"InnoDB存储引擎\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"存储引擎\\r\\n\\r\\n在系统执行 `update` 语句时，经过 `Server层` 的处理，最终要由执行器去调用存储引擎去执行。\\r\\n\\r\\n而 MySQL 存储引擎有很多种，比如 `InnoDB`、`MyISAM`等。\\r\\n\\r\\nMySQL的默认存储引擎已经变更为了 `InnoDB`\\r\\n\\r\\n---\\r\\n\\r\\n`update` 语句操作的数据最终是要写入磁盘中的，但是如果每次都直接操作磁盘，磁盘I/O的开销是很大的。所以需要每次将操作的数据加载到内存中，减少磁盘I/O次数，再在适当时机进行刷盘操作即可。InnoDB 中使用的这块内存叫做 `Buffer Pool`。\\r\\n\\r\\n 缓冲池 - Buffer Pool\\r\"},{\"url\":\"/database/mysql/MySQL基础架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL基础架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL是 `C/S（Client端 / Server端）` 架构。\\r\\n\\r\\n 架构图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nMySQL架构包含 `Server层` 和 `存储引擎层` 。\\r\\n\\r\\n- Server 层包含 `连接器` 、`分析器`、`优化器`、`执行器`。\\r\\n- 存储引擎层包含 `引擎层`、`存储层`。\\r\\n\\r\\n 一、连接器\\r\\n\\r\\n 连接器的作用\\r\\n\\r\\n- 跟客户端建立连接。\\r\\n- 维持和管理连接。\\r\\n- 校验用户和获取用户权限。\\r\\n\\r\\n---\\r\\n\\r\\n 校验用户\\r\\n\\r\\n客户端进行连接MySQL的命令如下：\\r\\n\\r\\n```java\\r\\nmysql -h$ip -P$port -u$user -p\\r\\n`\"},{\"url\":\"/database/mysql/MySQL日志系统.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL日志系统\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"undo.log\\r\\n\\r\\n记录被更新前的数据。\\r\\n\\r\\n\\r\\n\\r\\nInnoDB 支持事务，在事务执行失败回滚时，数据会回到操作前的样子。\\r\\n\\r\\n`undo.log` 就是为了事务回滚，恢复数据的。\\r\\n\\r\\n回滚对应的操作如下：\\r\\n\\r\\n1. insert\\r\\n   \\r\\n    插入一条记录时，将这条记录的主键记录下来，回滚时根据主键删除。\\r\\n    \\r\\n2. update\\r\\n   \\r\\n    更新一条记录时，将更新的列的旧值记录下来，回滚时将这些值更新回去。\\r\\n    \\r\\n3. delete\\r\\n   \\r\\n    删除一条记录时，将这条记录记录下来，回滚时重新插入到表中。\\r\\n    \\r\\n\\r\\n---\\r\\n\\r\\n在\"},{\"url\":\"/database/mysql/MySQL根据idb文件恢复数据.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL根据idb文件恢复数据\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL根据idb文件恢复数据\\r\\n\\r\\n1. MySQl解除表名\\r\\n   \\r\\n    `Plain Text  ALTER TABLE 表名 DISCARD TABLESPACE`\\r\\n    \\r\\n2. 复制 idb 文件到 data目录。\\r\\n   \\r\\n    \\r\\n    \\r\\n3. idb 文件增加权限。\\r\\n   \\r\\n    ```\\r\\n    chown mysql:mysql user_tenant.ibd\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n4. 重新导入表数据文件\\r\\n   \\r\\n    ```\\r\\n    ALTER TABLE 表名 IMPORT TABLESPACE\\r\\n\"},{\"url\":\"/database/mysql/MySQL的binlog日志过期删除.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL的binlog日志过期删除\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"问题\\r\\n\\r\\nmysql的binlog日志过多导致磁盘告警。\\r\\n\\r\\n部署脚本中没有配置 `binlog` 的失效时间，默认是30天。\\r\\n\\r\\n 手动清理\\r\\n\\r\\n1. 查看正在使用的binlog\\r\\n   \\r\\n    ```sql\\r\\n    show master status\\r\\n    ```\\r\\n    \\r\\n2. 删除指定binlog之前的所有binlog\\r\\n   \\r\\n    ```sql\\r\\n    purge binary logs to 'bin.000055'\\r\\n    ```\\r\\n    \\r\\n\\r\\n 配置自动清理\\r\\n\\r\\n 查看日志过期时间\\r\\n\\r\\n```sql\\r\\nshow variables li\"},{\"url\":\"/database/mysql/OrderBy和limit混用的bug.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"OrderBy和limit混用的bug\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"案例\\r\\n\\r\\n```java\\r\\nselect * from table order by month desc limit 0,10\\r\\n```\\r\\n\\r\\nmonth 重复度高的情况下，limt查询会出bug。导致部分数据丢失。可以增加区分度高的字段一起排序，比如id。\\r\\n\\r\\n```java\\r\\nselect * from table order by month desc,id desc limit 0,10\\r\\n```\"},{\"url\":\"/database/mysql/SQL语句的抖动问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SQL语句的抖动问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"有时候在执行 SQL 的时候，突然会变得很慢。这种慢比较随机，看起来像是抖动一样。\\r\\n\\r\\n更新数据流程可以简化一下。\\r\\n\\r\\n1. 内存（buffer pool）中的数据 flush 到磁盘。\\r\\n2. 数据写入到 redo log 中。\\r\\n\\r\\n其中 buffer pool 中的数据页有三种状态：\\r\\n\\r\\n1. 数据页无数据。\\r\\n2. 数据页是干净页。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n3. 数据页是脏页。\\r\\n   \\r\\n    &gt; 脏页指的是内存中的数据被更新，但是没有flush到磁盘。出现内存和磁盘数据不一致的情况，此时该数据页称为脏页面。\\r\\n    &gt; \\r\\n\\r\\n 性能问题\"},{\"url\":\"/database/mysql/explain使用总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"explain使用总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"参数\\r\\n\\r\\n| id | Columns | JSON Name | Meaning |\\r\\n| --- | --- | --- | --- |\\r\\n| 1 | id | select_id | 每个select子句的标识id |\\r\\n| 2 | select_type | None | select语句的类型 |\\r\\n| 3 | table | table_name | 当前表名 |\\r\\n| 4 | partitions | partitions | 匹配的分区 |\\r\\n| 5 | type | access_type | 当前表内访问方式 join type |\\r\\n| 6 | possible_key\"},{\"url\":\"/database/mysql/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL数据库\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL基础\\r\\n\\r\\n- MySQL基础架构\\r\\n- InnoDB存储引擎\\r\\n---\\r\\n- MySQL日志系统\\r\\n---\\r\\n- 一条更新SQL的执行过程\\r\\n---\\r\\n- 事务隔离\\r\\n---\\r\\n- B树和B+树\\r\\n- 索引\\r\\n---\\r\\n- 锁\\r\\n- 行锁\\r\\n\\r\\n\\r\\n\\r\\n MySQL总结\\r\\n\\r\\n- SQL语句的抖动问题\\r\\n- 索引失效的场景\\r\\n- explain使用总结\\r\\n- 慢查询日志\\r\\n\\r\\n\\r\\n 问题总结\\r\\n- OrderBy和limit混用的bug\\r\\n- MySQL的binlog日志过期删除\\r\\n- MySQL根据idb文件恢复数据\"},{\"url\":\"/database/mysql/一条更新SQL的执行过程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"一条更新SQL的执行过程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"juejin.cn\\r\\n\\r\\n```java\\r\\nmysql\\r\\n```\\r\\n\\r\\n 执行流程\\r\\n\\r\\n1. 执行器先找引擎取出 ID=2 这一行记录。\\r\\n    - 如果该行记录在 `Buffer Pool` 中存在，会直接返回数据给执行器。\\r\\n    - 如果该行记录不存在，则会先进行如下操作，再返回数据给执行器。\\r\\n        - 从磁盘中查找数据。\\r\\n        - 将数据写入内存 `Buffer Pool` 中。\\r\\n        - 将数据写入 `undo.log`（记录 insert、update、delete等修改数据的操作）。\\r\\n2. 执行器获取到引擎给的行数据，把这条数据更新 c\"},{\"url\":\"/database/mysql/事务隔离.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"事务隔离\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。\\r\\n\\r\\n在 MySQL 中，事务支持是在`引擎层`实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。\\r\\n\\r\\n比如 MySQL 原生的 `MyISAM 引擎就不支持事务`，这也是 MyISAM 被 InnoDB 取代的重要原因之一。\\r\\n\\r\\n 事务问题\\r\\n\\r\\n 脏读\\r\\n\\r\\n读到了别的事务 修改过 但未提交的数据\\r\\n\\r\\n 不可重复读\\r\\n\\r\\n指的是变没变化的问题。数据被修改了导致前后两次查询结果不一样。\\r\\n\\r\\n原来是 A，现在是 B，就是不可重复读。\\r\\n\\r\\n 幻读\\r\\n\\r\\n指的是存不存在的问题，原来存\"},{\"url\":\"/database/mysql/慢查询日志.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"慢查询日志\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL中，需要查看执行慢的SQL，需要先开启慢查询日志。\\r\\n\\r\\nMySQL的慢查询日志，记录了MySQL中响应时间超过阈值的SQL语句。\\r\\n\\r\\n 参数说明\\r\\n\\r\\n- slow_query_log：是否开启慢查询日志，1表示开启，0表示关闭。\\r\\n- log-slow-queries ：旧版（5.6以下版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name-slow.log\\r\\n- slow-query-log-file：新版（5.6及以上版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name\"},{\"url\":\"/database/mysql/索引.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"索引\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准。\\r\\n\\r\\n InnoDB的索引模型\\r\\n\\r\\n B+树\\r\\n\\r\\n\\r\\n\\r\\nB+树的每个叶子节点存放元素有限，每个叶子节点为一个 page，针对元素的数量会产生页分裂、页合并等现象。\\r\\n\\r\\n什么是B+树？_攻城狮百里的博客-CSDN博客_b+树\\r\\n\\r\\n\\r\\n\\r\\n 聚簇索引和二级索引\\r\\n\\r\\n- 主键索引的叶子结点存的是整行记录。InnoDB 引擎中主键索引又称为聚簇索引。\\r\\n- 非主键索引的叶子结点存的是行记录的ID。在 InnoDB 引擎中非主键索引又称为二级索引。\\r\\n\\r\\n\\r\\n\\r\\n 搜索方式\\r\\n\\r\\n- 根据主键搜索\\r\\n  \\r\\n    `\"},{\"url\":\"/database/mysql/索引失效的场景.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"索引失效的场景\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"查询条件做函数计算\\r\\n\\r\\n```sql\\r\\nselect count(*) from tradelog where month(t_modified)=7;\\r\\n```\\r\\n\\r\\n查询条件做函数计算，在查索引的时候，利用不了索引。因为索引利用的是树的有序性，但是函数计算后的结果在索引的B+树上并不连续。MySQL在查询的时候利用不到树的有序性。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。\\r\\n\\r\\n 隐式类型转换\\r\\n\\r\\n假如 tradeid 字段类型是 varchar ，查询语句\\r\\n\\r\\n```sql\\r\\nexplain   sele\"},{\"url\":\"/database/mysql/行锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"行锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL 中的行锁（row-level locking）并不是单纯指写锁（write lock），而是指锁定机制的粒度。行锁可以是共享锁（也称为读锁，S锁）或排他锁（也称为写锁，X锁），具体取决于事务所使用的隔离级别以及查询类型。\\r\\n\\r\\n- Select for Update：当执行带有 `FOR UPDATE` 子句的 `SELECT` 查询时，InnoDB 会对被选中的行加上排他锁。这确保了在事务提交之前，其他事务不能修改这些行。\\r\\n- Insert Intention Lock：当执行 `INSERT` 操作时，InnoDB 会自动为要插入的行加上意向锁。这是为了避免插入操作与其他事务\"},{\"url\":\"/database/mysql/锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL中加锁是为了处理并发问题，根据锁的粒度可以分为全局锁、表级锁和行锁。\\r\\n\\r\\n 全局锁\\r\\n\\r\\n全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 `Flush tables with read lock` (FTWRL)。\\r\\n\\r\\n加完之后整个数据库处于只读状态。\\r\\n\\r\\n---\\r\\n\\r\\n 应用场景（不推荐）\\r\\n\\r\\n全局锁的经典应用场景 数据库备份。\\r\\n\\r\\n由于加全局锁，会导致整个数据库只读，所以一般不推荐使用。\\r\\n\\r\\n 可重复读进行备份\\r\\n\\r\\n备份数据库一般可以利用可重复读的事务隔离级别来实现，因为可重复读情况开始事务，会生成当前数据库的视图，保证整个事务期间以\"},{\"url\":\"/database/redis/LRU和LFU算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"LRU和LFU算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"LRU算法\\r\\n\\r\\n 简介\\r\\n\\r\\nLRU （Least Recently Used） 算法即最近最久未使用，每次选择最近最久未使用的页面淘汰掉。\\r\\n\\r\\n 实现过程\\r\\n\\r\\n- 新增数据时，元素插入到队列头部。\\r\\n- 访问元素（查询、更新和删除）时，将元素移动到队列头部。\\r\\n- 当超过内存限制，需要淘汰数据时，将已排序队列的最后元素删除。\\r\\n\\r\\n\\r\\n\\r\\n 数据结构\\r\\n\\r\\nLRU 算法内部的数据结构需要根据元素的访问时间排序。还需要查找、插入、删除等效率要高。\\r\\n\\r\\n1. 查找、插入、删除快。\\r\\n2. 支持排序。\\r\\n\\r\\n在常用的集合中，有的是查找更新快或者插入删除快，没有数据结构能同时满足以上条件，所\"},{\"url\":\"/database/redis/Redisson.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Redisson\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还实现了可重入锁（Reentrant Lock）、公平锁（Fair Lock、联锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）等，还提供了许多分布式服务。Redisson提供了使用Redis的最简单和最便捷的方法。Redisson的宗旨是促进使用者对Redis的关注分离（Separation of Concern），从而让使用者能够将精力更集中地放在处理业务逻辑上。\\r\\n\\r\\n Redisson \"},{\"url\":\"/database/redis/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- redis数据类型\\r\\n- redis数据类型原理\\r\\n- redis的持久化\\r\\n\\r\\n\\r\\n- 过期策略\\r\\n- 内存淘汰策略\\r\\n- LRU和LFU算法\\r\\n\\r\\n- redis实现分布式锁\\r\\n- Redisson\\r\\n\\r\\n- redis事务.md\\r\\n- redis集群.md\\r\\n\\r\\n- 缓存问题\\r\\n- 布隆过滤器\"},{\"url\":\"/database/redis/redis事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis的事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis 的事务，可以一次执行多个命令，本质上是一组命令的集合，按照顺序串行化执行而不会被其它命令插入。\\r\\n\\r\\n 常用命令\\r\\n\\r\\n- 开启事务 -`multi`\\r\\n- 执行所有事务 - `exec`\\r\\n- 取消所有事务 - `discard`\\r\\n- 监控一个或多个 key - `watch`\\r\\n- 取消 watch 命令对所有 key 的监控 - `unwatch`\\r\\n  \\r\\n    \\r\\n    \\r\\n\\r\\n watch监控\\r\\n\\r\\nwatch 指令，类似乐观锁，在创建事务之前，使用 watch 指令监控某个值。在事务提交时，如果 key 的值已经被别的客户端改变，那么整个事务队列都不会执行。\\r\\n\"},{\"url\":\"/database/redis/redis实现分布式锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis实现分布式锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"分布式锁简介\\r\\n\\r\\n在分布式环境下，多个系统访问共享资源时会发生线程安全问题，分布式锁就是为了解决分布式环境下访问共享资源的线程安全问题，保证共享资源同一时间只能被一个系统的一个线程访问。\\r\\n\\r\\n 分布式锁具备的条件\\r\\n\\r\\n1. 在分布式环境下，共享资源在同一时间只能被一个系统的一个线程访问。\\r\\n2. 保证设置分布式锁和删除分布式锁操作的原子性。\\r\\n3. 具备可重入特性。\\r\\n4. 防止死锁。\\r\\n5. 具备锁超时失效的机制。\\r\\n6. 具备非阻塞锁特性，不会阻塞等待获取锁。\\r\\n\\r\\n 分布式锁主要实现方式\\r\\n\\r\\n1. zeekeeper 实现分布式锁\\r\\n2. redis 实现分布式锁\\r\\n\\r\\n---\\r\"},{\"url\":\"/database/redis/redis数据类型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis数据类型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis数据类型\\r\\n\\r\\n练习代码地址 redis-practice\\r\\n\\r\\n 键 - key\\r\\n\\r\\n在了解数据类型之前，先了解一下 redis 的键。\\r\\n\\r\\n在 redis 中 命令不区分大小写，但是注意 redis 中的 key 和 value 是区分大小写的。\\r\\n\\r\\n\\r\\n\\r\\n 字符串 - string\\r\\n\\r\\n字符串数据结构是简单的 K-V 模式数据结构。\\r\\n\\r\\n 特点\\r\\n\\r\\n- 单值单 value。\\r\\n- 二进制安全，可以包含任何数据。\\r\\n- 一个键对应 value 值最大能存储数据 512 MB。\\r\\n\\r\\n 常用命令\\r\\n\\r\\n\\r\\n\\r\\n- 设置字符串 - `set test 100`\\r\\n- 查\"},{\"url\":\"/database/redis/redis数据类型原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis数据类型原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. linkedlist (双向链表)\\r\\n    - 当列表元素较多或元素大小超过一定阈值时，Redis 会使用双向链表来存储 `list` 键。\\r\\n    - linkedlist 是一种指针结构，每个节点包含指向前后节点的指针，这使得插入和删除操作非常高效。\\r\\n    - linkedlist 的优点是支持高效的插入和删除操作，但缺点是比 ziplist 更占用内存。\\r\\n\\r\\n 全局哈希表\\r\\n\\r\\n\\r\\n\\r\\nRedis是一个 K-V 数据库，有一个全局的哈希桶存放所有的 key。\\r\\n\\r\\nkey 对应的 entry 包含了实际的 key 和 value。这里的 value 对应着不同的数据类型。\"},{\"url\":\"/database/redis/redis的持久化.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis的持久化\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis 有 RDB 和 AOF 两种持久化方式。\\r\\n\\r\\n RDB\\r\\n\\r\\nRDB 是 *Redis DataBase* 的简称，指的是在指定时间间隔内将内存中的数据集快照写入磁盘文件，也就是 Snapshot 快照，RDB 是默认开启的。\\r\\n\\r\\n RDB的原理\\r\\n\\r\\nRedis 会单独创建 （fork）一个子进程来进行持久化操作，将内存中某一时刻的数据持久化到磁盘文件。这个子进程会先将数据写入到一个临时文件中，等待持久化进程结束后，再用这个临时文件替换掉磁盘文件。\\r\\n\\r\\n\\r\\n\\r\\n在整个过程中，主进程是不进行任何 IO 操作的，这样保证了主进程存取的高性能。\\r\\n\\r\\nRDB 的持久化过程每次都是\"},{\"url\":\"/database/redis/redis集群.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis集群\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Redis集群是一个由多个主从节点群组成的分布式服务集群，它具有复制、高可用和分片特性。\\r\\n\\r\\n 主从模式\\r\\n\\r\\n\\r\\n\\r\\n- 主数据库可以进行读写操作。\\r\\n  \\r\\n    数据会通过主从同步，由主服务器同步给从服务器。\\r\\n    \\r\\n    主服务器将数据\\r\\n    \\r\\n- 从数据库一般是只读的。\\r\\n\\r\\n引入主从复制机制的目的有两个：\\r\\n\\r\\n- 一个是读写分离，分担 “master” 的读写压力\\r\\n- 一个是方便做容灾恢复，避免单点故障。\\r\\n\\r\\n 主从同步的原理\\r\\n\\r\\n\\r\\n\\r\\n- 全量复制\\r\\n  \\r\\n    从数据库在第一次同步的时候会进行全量同步。\\r\\n    \\r\\n    主库执行 bgsav\"},{\"url\":\"/database/redis/内存淘汰策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内存淘汰策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"最大内存设置\\r\\n\\r\\n1. redis 默认内存是多少？\\r\\n   \\r\\n    在 64 位操作系统不限制内存大小，在 32 位操作系统下最多使用 3GB。\\r\\n    \\r\\n2. 查看 redis 最大内存？\\r\\n   \\r\\n    `Plain Text  config get maxmemory`\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 修改 redis 内存大小？\\r\\n    - 修改配置文件\\r\\n      \\r\\n        在 `redis.conf` 第 859 行可以设置最大内存大小（单位是字节）。\\r\\n        \\r\\n        \\r\\n        &gt; \\r\\n        \"},{\"url\":\"/database/redis/布隆过滤器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"布隆过滤器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 什么是布隆过滤器？\\r\\n\\r\\n布隆过滤器（Bloom Filter）是一种数据结构，用来判断一个元素是否在一个集合中。布隆过滤器的本质上使用的是二进制向量和 k 个哈希函数组成。\\r\\n\\r\\n布隆过滤器具有如下优点：\\r\\n\\r\\n- 空间利用率高。\\r\\n  \\r\\n    布隆过滤器底层使用二进制向量保存数据，不需要保存元素本身，只需要在指定 bit 存放标识即可，故空间利用率非常高。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n- 时间效率也较高，插入和查询效率高。\\r\\n  \\r\\n    布隆过滤器的时间复杂度只跟哈希函数的个数 k 有关，插入和查询的时间复杂度均为 O(k)；\\r\\n    \\r\\n    *结合\"},{\"url\":\"/database/redis/缓存问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"缓存问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"前言\\r\\n\\r\\n在使用缓存的时候，简单的缓存处理流程如下。针对如下流程会遇到缓存穿透、缓存击穿、缓存雪崩等问题。\\r\\n\\r\\n\\r\\n\\r\\n 缓存穿透\\r\\n\\r\\n缓存穿透：当用户请求查询某个数据时，先从缓存查询，缓存中没有这个数据。然后向数据库查询数据，数据库中也没有这个数据，导致查询失败。\\r\\n\\r\\n*像一些恶意攻击时，故意查询数据库中不存在的数据，比如查询 id = -1 的数据，会造成数据库压力非常大。*\\r\\n\\r\\n\\r\\n\\r\\n 解决方案\\r\\n\\r\\n1. 对空值做缓存。\\r\\n   \\r\\n    当出现从缓存和数据库都查不到数据的情况时，可以将空值存到缓存中，即 K-V 存为 key-null，缓存过期时间可以设置短点，来防止短\"},{\"url\":\"/database/redis/过期策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"过期策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 Redis 中设置了过期时间的 key，在一定时间后都会被删除。\\r\\n\\r\\n 键的过期时间\\r\\n\\r\\n 配置过期时间\\r\\n\\r\\n1. `setex key seconds value`\\r\\n   \\r\\n    设置 key 时添加过期时间\\r\\n    \\r\\n2. `expire key seconds`\\r\\n   \\r\\n    为某个 key 设置过期时间。\\r\\n    \\r\\n3. 删除 key 的过期时间。\\r\\n   \\r\\n    `persist key`\\r\\n    \\r\\n4. 查看 key 的过期时间\\r\\n   \\r\\n    `ttl key`\\r\\n    \\r\\n\\r\\n redis保存过期时间分析\\r\\n\\r\\n[版权声明：本文为CS\"},{\"url\":\"/frame/mybatis/custom/SQL执行器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SQL执行器-executor\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"将操作数据库的操作从 sqlSession 中解耦，放到 Executor 中。\\r\\n\\r\\n包括事务操作也放到 Executor 中。\\r\\n\\r\\n```java\\r\\npublic interface Executor {\\r\\n\\r\\n    ResultHandler NO_RESULT_HANDLER = null;\\r\\n\\r\\n    &lt;E\\r\\n\\r\\n    Transaction getTransaction();\\r\\n\\r\\n    void commit(boolean required) throws SQLException;\\r\\n\\r\\n    void rollback(boolean required) \"},{\"url\":\"/frame/mybatis/custom/xml解析.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"xml解析\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"\"},{\"url\":\"/frame/mybatis/custom/手写MyBatis.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"手写MyBatis\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"整体流程\\r\\n\\r\\n\\r\\n\\r\\n整个mybatis的功能，就是代理 mapper 然后执行SQL，返回执行结果。\\r\\n\\r\\n\\r\\n\\r\\n1. 解析mybatis配置\\r\\n    - 解析数据源 （Configuration 的 environment）\\r\\n    - 解析mapper文件配置 （路径扫描）\\r\\n2. 解析mapper文件\\r\\n    - 注册mapper到mapperRegistry。（包含mapper的代理类工厂，可以获取代理过的mapper）\\r\\n    - 生成mapper方法对应的mapperStatement。（Configuration 的 mappedStatements）\\r\\n    -\"},{\"url\":\"/frame/mybatis/custom/数据源.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据源\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"数据源解析\\r\\n\\r\\n解析配置文件中的数据源\\r\\n\\r\\n1. 事务模版 - jdbc\\r\\n2. 数据源实现 - druid\\r\\n\\r\\n```xml\\r\\n&lt;configuration\\r\\n\\r\\n    &lt;!--    数据源配置   --&gt;\\r\\n    &lt;environments default=\\\"development\\\"&gt;\\r\\n        &lt;environment id=\\\"development\\\"&gt;\\r\\n            &lt;transactionManager type=\\\"JDBC\\\"/&gt;\\r\\n            &lt;dataSource type=\\\"\"},{\"url\":\"/frame/mybatis/custom/映射器-mapper.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"映射器-mapper\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- SqlSession提供了SqlId。\\r\\n- 而SqlSessionFactroy 提供了开启SqlSession的能力。]\\r\\n- MapperRegistry 包含了所有Mapper的SqlId，包含注册发现Mapper的能力。\\r\\n\\r\\n MapperFactory\\r\\n\\r\\n\\r\\n\\r\\n MapperProxy\\r\\n\\r\\n在mybatis中，调用mapper里面的方法就可以执行SQL。其实是因为mybatis隐藏了实现细节。\\r\\n\\r\\n具体做法是根据mapper里面点的方法生成代理逻辑，在调用该方法时其实是走的代理类的逻辑。\\r\\n\\r\\n而代理类封装了操作数据库的逻辑，代理类即为mapperProxy。\\r\\n\\r\"},{\"url\":\"/frame/mybatis/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MyBatis 框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"手写MyBatis\\r\\n\\r\\n- 手写MyBatis\\r\\n- 映射器-mapper\\r\\n- 数据源\\r\\n- SQL执行器\\r\\n- xml解析\"},{\"url\":\"/frame/netty/ByteBuf.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ByteBuf\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ByteBuf是Netty中用于表示字节序列的数据容器。它是Netty对Java NIO中的ByteBuffer的改进和增强。ByteBuf提供了更灵活、更强大的API，具有许多优势，使得它在网络编程中更加方便和高效。\\r\\n\\r\\n以下是ByteBuf的主要优势：\\r\\n\\r\\n1. 灵活的容量管理： ByteBuf支持动态扩容和收缩，相比Java NIO的ByteBuffer，ByteBuf的容量可以根据实际需求自动调整，无需手动扩容。\\r\\n2. 更丰富的API： ByteBuf提供了丰富的操作API，包括读取、写入、复制、切片、合并等操作。这些API使得对字节数据的操作更加便利，同时提供了更多的功能。\\r\\n\"},{\"url\":\"/frame/netty/HTTP服务和SSL&TLS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP服务和SSL/TLS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"服务端\\r\\n\\r\\n按照 pipline 执行。\\r\\n\\r\\n```java\\r\\n@Override\\r\\n    protected void initChannel(SocketChannel socketChannel) throws Exception {\\r\\n        ChannelPipeline pipeline = socketChannel.pipeline();\\r\\n        //TODO ssl\\r\\n\\r\\n        //服务端\\r\\n        //对请求内容解码\\r\\n        pipeline.addLast(\\\"decoder\\\", new HttpRequestDecode\"},{\"url\":\"/frame/netty/Handler的共享和并发安全性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Handler的共享和并发安全性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"服务端为Channel设置pipeline的时候，可以选择设置共享的还是Channel独有的。\\r\\n\\r\\n```java\\r\\nprivate void start() throws InterruptedException {\\r\\n        final MsgCountHandler msgCountHandler = new MsgCountHandler();\\r\\n        //线程组\\r\\n        EventLoopGroup boss = new NioEventLoopGroup();\\r\\n        EventLoopGroup work = new NioEventLoo\"},{\"url\":\"/frame/netty/Netty实现文件下载.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty实现文件下载\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"实例：如何使用 Netty 下载文件_channelhandlercontext下载文件-CSDN博客\\r\\n\\r\\n ChannelHandler\\r\\n\\r\\n自定义 ChannelHandler ，用来处理 Channel 里面的事件，写数据处理逻辑的。\\r\\n\\r\\n- ChannelInboundHandlerAdapter\\r\\n- SimpleChannelInboundHandler\\r\\n    \\r\\n    是 ChannelInboundHandlerAdapter 的子类，能够指定类型。\\r\\n    \\r\\n\\r\\nNetty 里面预设了很多 ChannelHandler\\r\\n\\r\\n```java\\r\\nch.pipel\"},{\"url\":\"/frame/netty/Netty实现通信框架.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty实现通信框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"功能点\\r\\n\\r\\n1. 基于Netty的NIO通信框架。\\r\\n2. 提供消息的编码解码框架，实现对象的序列化和反序列化。\\r\\n3. 消息内容的放篡改机制。\\r\\n4. 提供基于IP的白名单认证机制。\\r\\n5. 链路的有效性机制（心跳）。\\r\\n6. 链路的断连重连机制。\\r\\n\\r\\n 通信模型\\r\\n\\r\\n\\r\\n\\r\\n 调用链路\\r\\n\\r\\n\\r\\n\\r\\n粘包半包是最前面先要解决的问题。\\r\\n\\r\\n 写空闲检测\\r\\n\\r\\n```java\\r\\npublic class CheckWriteIdleHandler extends IdleStateHandler {\\r\\n\\r\\n    /**\\r\\n     * 0 表示读空闲时间不进行检测，即不对读空闲做任何\"},{\"url\":\"/frame/netty/Netty常用组件.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty常用组件\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Bootstrap\\r\\n\\r\\nNetty的启动类\\r\\n\\r\\n- Bootstrap\\r\\n\\r\\n    客户端启动类\\r\\n\\r\\n- ServerBootstrap\\r\\n\\r\\n    服务端启动类\\r\\n\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n 第一个区别\\r\\n\\r\\n- 客户端需要连接到远程主机和端口即可。\\r\\n\\r\\n- 服务端需要绑定端口。\\r\\n\\r\\n 第二个区别\\r\\n\\r\\n- 服务端需要两个 EventLoopGroup。\\r\\n\\r\\n    原因是使用了多线程主从的Reactor模式。\\r\\n\\r\\n    - 第一个EventLoopGroup，只有一个EventLoop，负责为传入的Accept请求建立连接。一旦建立连接后续，将该 Channel 放到\"},{\"url\":\"/frame/netty/TCP粘包拆包问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP粘包拆包问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"TCP 粘包\\r\\n\\r\\n由于 TCP 协议本身的机制（面向连接的可靠地协议-三次握手机制）客户端与服务器会维持一个连接（Channel），数据在连接不断开的情况下，可以持续不断地将多个数据包发往服务器。\\r\\n\\r\\n但是如果发送的网络数据包太小，那么他本身会启用 Nagle 算法（可配置是否启用）对较小的数据包进行合并（基于此，TCP 的网络延迟要 UDP 的高些）然后再发送（超时或者包大小足够）。\\r\\n\\r\\n那么这样的话，服务器在接收到消息（数据流）的时候就无法区分哪些数据包是客户端自己分开发送的，这样产生了粘包。\\r\\n\\r\\n服务器在接收到数据库后，放到缓冲区中，如果消息没有被及时从缓存区取走，下次在取数据的\"},{\"url\":\"/frame/netty/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础总结\\r\\n\\r\\n- Netty常用组件\\r\\n- Handler的共享和并发安全性\\r\\n- 资源管理和SimpleChannelInboundHandler\\r\\n- 内置通信传输模式\\r\\n- TCP粘包拆包问题\\r\\n- 编解码器\\r\\n\\r\\n\\r\\n- HTTP服务和SSL&TLS\\r\\n- 序列化问题\\r\\n- 写空闲和读空闲\\r\\n\\r\\n\\r\\n- ByteBuf\\r\\n- 线程模型\\r\\n- 零拷贝\\r\\n\\r\\n\\r\\n 练习总结\\r\\n- Netty实现通信框架\\r\\n- 基于Netty实现RPC\\r\\n- Netty实现文件下载\"},{\"url\":\"/frame/netty/内置通信传输模式.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内置通信传输模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```java\\r\\ntry {\\r\\n            //父子EventLoop\\r\\n            serverBootstrap.group(boss,work)\\r\\n                    //指定使用NIO的通信模式\\r\\n                    .channel(NioServerSocketChannel.class)\\r\\n                    .localAddress(new InetSocketAddress(port))\\r\\n                    .childHandler(new ChannelInitia\"},{\"url\":\"/frame/netty/写空闲和读空闲.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"写空闲和读空闲\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在Netty框架中，写空闲（Write Idle） 和 读空闲（Read Idle） 是空闲检测机制中的两个重要概念，它们用于监控网络连接的活跃状态，确保连接的有效性和资源的有效管理。\\r\\n\\r\\n 写空闲（Write Idle）\\r\\n\\r\\n- 定义：写空闲指的是在一段指定时间内，没有数据通过当前的`Channel`被写入到网络中传输给对方。这可能意味着在这段时间内，服务端没有向客户端发送任何数据，或者客户端没有向服务端发送数据。\\r\\n- 应用场景：在某些协议或应用场景中，如果长时间没有数据写入，可能需要触发特定的操作，比如发送心跳包以维持连接活跃，或者是判断连接是否已经失效，进而关闭连接以释放资源。\\r\\n\"},{\"url\":\"/frame/netty/基于Netty实现RPC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"基于netty实现RPC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"源码地址\\r\\n\\r\\nAlbert.Yang/JavaAdvance\\r\\n\\r\\n 服务端\\r\\n\\r\\n ServerBootstrap\\r\\n\\r\\n```java\\r\\n@Service\\r\\n@Slf4j\\r\\npublic class RpcServerFrame implements Runnable {\\r\\n\\r\\n    @Autowired\\r\\n    private ServerInit serverInit;\\r\\n\\r\\n    private EventLoopGroup bossGroup = new NioEventLoopGroup();\\r\\n    private EventLoopGroup workGroup =\"},{\"url\":\"/frame/netty/序列化问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"序列化问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java对象的序列化主要有两个：\\r\\n\\r\\n1. 网络传输\\r\\n   \\r\\n    数据在网络中传输是通过字节流形式的，到服务端需要解码。\\r\\n    \\r\\n2. 对象持久化\\r\\n\\r\\n Java序列化\\r\\n\\r\\nJava序列化机制是基于对象的类结构进行的。\\r\\n\\r\\n当对象需要序列化时，会将对象转换为字节流在网络传输。\\r\\n\\r\\n反序列化时，就是将字节流转换为对象的过程。Java会将字节流转换为对象重新加载到内存中。\\r\\n\\r\\nJava的序列化机制是通过实现`java.io.Serializable`接口来实现的。该接口是一个标记接口，没有任何方法定义。只有实现了`Serializable`接口的类的对象才能被序列化。\\r\\n\"},{\"url\":\"/frame/netty/线程模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Netty的线程模型是什么？为什么它是高效的？\\r\\n\\r\\n1. Netty的线程模型是基于事件驱动的，采用了Reactors设计模式。它的线程模型主要包含以下几个关键组件：\\r\\n2. Boss Group和Worker Group： Netty通过Boss Group和Worker Group来分别管理两类不同的线程。Boss Group负责接收客户端的连接，而Worker Group则负责处理连接后的网络流量。\\r\\n3. Channel： Channel代表了一个网络连接，可以是客户端到服务器的连接，也可以是服务器之间的连接。每个Channel都由一个EventLoop负责处理，而一个EventLo\"},{\"url\":\"/frame/netty/编解码器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"编解码器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在网络传输中，数据是通过字节流传输。\\r\\n\\r\\n对应到客户端和服务端需要进行对应的编码和解码。\\r\\n\\r\\n 解码器\\r\\n\\r\\n- 将字节解码为消息：ByteToMessageDecoder\\r\\n- 将一种消息类型解码为另一种：MessageToMessageDecoder。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 异常处理\\r\\n\\r\\n- TooLongFrameException\\r\\n    \\r\\n    由于 Netty 是一个异步框架，所以需要在字节可以解码之前在内存中缓冲它们。因此，不能让解码器缓冲大量的数据以至于耗尽可用的内存。为了解除这个常见的顾虑，Netty 提供了 TooLongFrameException 类\"},{\"url\":\"/frame/netty/资源管理和SimpleChannelInboundHandler.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"资源管理和SimpleChannelInboundHandler\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NIO中读写Channel数据，都使用了 Buffer，读写数据都是从 Buffer里面读取的。\\r\\n\\r\\n而 Netty在读写网络数据时，同样也需要 Buffer。\\r\\n\\r\\n但是这样就涉及到 Buffer的内存释放，不然会造成内存泄漏。\\r\\n\\r\\n SimpleChannelInboundHandler\\r\\n\\r\\nNetty实现了SimpleChannelInboundHandler类，提供 `channelRead0()` 方法，保证数据被该方法消费后自动释放数据。\\r\\n\\r\\n```java\\r\\n    public void channelRead(ChannelHandlerContext ctx, Ob\"},{\"url\":\"/frame/netty/零拷贝.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"零拷贝\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. ByteBuf 可以直接使用直接内存。\\r\\n    \\r\\n    Socket 通信如果采用堆内存的话，需要将堆里的对象拷贝到堆外，进行一次对象拷贝。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n    \\r\\n    但是 Socket 没有更新对象地址动作，需要的是一个固定的地址。所以堆内存不适合 Socket 使用。只能将对象拷贝到直接内存然后使用。\\r\\n    \\r\\n    而 ByteBuf 直接使用直接内存，减少了对象拷贝。\\r\\n    \\r\\n2. Netty 提供了组合 Buffer，可以将多个 Buffer 合并为一个。\\r\\n    \\r\\n    传统通过内存拷贝的方式将几个小Buffe\"},{\"url\":\"/frame/spring/AOP.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AOP\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"面向切面编程\\r\\n\\r\\n面向切面编程，指的是在运行期间生成代理对象来对类进行增强处理，比如方法执行前和方法执行后进行代码增强。\\r\\n\\r\\n 什么是切面\\r\\n\\r\\n- 切：\\r\\n  \\r\\n    指的是横切逻辑，原有方法代码不动。只能操作横切逻辑代码进行增强。\\r\\n    \\r\\n- 面：\\r\\n  \\r\\n    横切逻辑往往影响很多个方法，每个方法是一个切点，便形成了面。\\r\\n    \\r\\n\\r\\n常用的功能有：\\r\\n\\r\\n- 方法审计日志\\r\\n- 校验权限是否足够\\r\\n\\r\\n\\r\\n\\r\\n AOP体系\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n)连接点 - JoinPoint\\r\\n\\r\\n类里面哪些方法可以被增强，这些方法称为连接点。\\r\\n\\r\\n- 切面\\r\\n\\r\\n    切\"},{\"url\":\"/frame/spring/ApplicationContext和BeanFactory区别.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ApplicationContext和BeanFactory区别\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ApplicationContext 总结\\r\\n\\r\\nApplicationContext 容器上下文，包含了 BeanFactory 的所有功能，还额外提供了以下功能：\\r\\n\\r\\n- MessageSource，提供国际化的消息访问\\r\\n- 资源访问，如 URL 和文件\\r\\n- 事件传播\\r\\n\\r\\n 工具类\\r\\n\\r\\n可以通过实现 `ApplicationContextAware` 接口注入 ApplicationContext\\r\\n\\r\\n```java\\r\\n@Component\\r\\npublic class SpringBeanUtil implements ApplicationContextAware {\\r\\n\\r\\n\"},{\"url\":\"/frame/spring/Aware接口.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Aware接口\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在Spring框架中，`Aware`接口提供了一种机制，允许Bean在初始化过程中获取Spring容器的特定上下文信息或资源。这些接口通常被称作回调接口，因为它们允许Spring容器在特定时刻回调Bean，以便将一些重要的信息注入给Bean。\\r\\n\\r\\n ApplicationContextAware\\r\\n\\r\\n当Spring容器在初始化一个实现了`ApplicationContextAware`接口的Bean时，它会调用`setApplicationContext`方法，将当前的应用上下文传入。\\r\\n\\r\\n```java\\r\\npublic interface ApplicationContextAware\"},{\"url\":\"/frame/spring/BeanFactory和FactoryBean总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BeanFactory和FactoryBean总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"BeanFactory总结\\r\\n\\r\\nBeanFactory 是 Spring 中的一个接口，提供了 IOC 容器最基本的形式，给具体的 IOC 容器实现提供了规范。\\r\\n\\r\\n其本质是一个 IOC 容器或对象工厂，所有的 Bean 都是由 BeanFactory （IOC容器）来进行管理的。Spring 有许多 BeanFactory 的实现类，附件了许多功能。\\r\\n\\r\\n```java\\r\\npublic interface BeanFactory {\\r\\n  \\r\\n  Object getBean(String name) throws BeansException;\\r\\n  \\r\\n\\t&lt;T\\r\\n\\r\\n\\tObj\"},{\"url\":\"/frame/spring/ByteBuddy实现动态代理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ByteBuddy实现动态代理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Byte Buddy - runtime code generation for the Java virtual machine\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n```java\\r\\n&lt;dependency&gt;\\r\\n  &lt;groupId&gt;net.bytebuddy&lt;/groupId&gt;\\r\\n  &lt;artifactId&gt;byte-buddy&lt;/artifactId&gt;\\r\\n  &lt;version&gt;LATEST&lt;/version&gt;\\r\\n&lt;/dependency&gt;\\r\\n```\\r\\n\\r\\n```java\\r\\npublic c\"},{\"url\":\"/frame/spring/Spi机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spi机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SPI机制，全称Service Provider Interface，是Java提供的一种标准的服务发现机制。它允许第三方服务提供者扩展某个接口的实现，而无需修改接口的源代码或重新打包。\\r\\n\\r\\nSpring SPI机制常用于 starter 构建和基础库实现。\\r\\n\\r\\n通过 spi 机制，确保自动配置生效的类包含 FileAutoConfiguration\\r\\n\\r\\n\\r\\n\\r\\n使用 SPI可以可插拔的注入配置，比如 `EnableAutoConfiguration`，如果需要 MinIO的配置类，加在类里面即可开启MinIO的功能。\\r\\n\\r\\nwww.jb51.net\\r\\n\\r\\nSPI机制是什么？_java_\"},{\"url\":\"/frame/spring/Spring中Bean加载流程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring中Bean加载流程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"流程图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 创建流程\\r\\n\\r\\n1. 加载 `ApplicationContext` 上下文环境。\\r\\n2. `ApplicationContext` 通过扫描、读取配置，将 Bean对象封装为 `BeanDefinition` 对象，并注册到 `BeanDefinitionMap` 中。\\r\\n3. 在 `ApplicationContext` 执行完成之后会调用对应的后置处理器 `BeanFactoryProcessor` 和其子类 `BeanDefinitionRegistryPostProcessor` 对应方法，可以修改和注册 `BeanDefinition` 到 \"},{\"url\":\"/frame/spring/Spring中Bean的作用域.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring中Bean的作用域\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"作用域类型\\r\\n\\r\\n- singleton\\r\\n    \\r\\n    单例模式。\\r\\n    \\r\\n    使用 `singleton` 定义的 Bean 在 Spring 容器中只有一个实例，是 Bean 默认的作用域。\\r\\n    \\r\\n- prototype\\r\\n    \\r\\n    原型模式\\r\\n    \\r\\n    每次通过 Spring 容器获取 `prototype` 定义的 Bean 时，容器都将创建一个新的 Bean 实例。\\r\\n    \\r\\n- request\\r\\n    \\r\\n    在一次 HTTP 请求中，容器会返回该 Bean 的同一个实例。而对不同的 HTTP 请求，会返回不同的实例，该作用域\"},{\"url\":\"/frame/spring/Spring事务总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring事务总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"编程式事务\\r\\n\\r\\n在代码中硬编码，不推荐使用。\\r\\n\\r\\n 声明式事务\\r\\n\\r\\n- 基于注解的声明式事务\\r\\n- 基于 XML 的声明式事务\\r\\n\\r\\n @Transactional 注解\\r\\n\\r\\nException 分为运行时异常 RuntimeException 和非运行时异常。事务管理能保证出现异常情况的时候保证数据的一致性。\\r\\n\\r\\n默认 `@Transactional` 注解只会在遇到 RuntimeException 类型异常或者 Error时，才会回滚事务。遇到其它异常，Spring 不会回滚事务。\\r\\n\\r\\n 作用范围\\r\\n\\r\\n当 `@Transactional`注解作用于类上的时，该类的所有方法都\"},{\"url\":\"/frame/spring/Spring依赖注入.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring依赖注入\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"依赖注入就是通过spring将bean所需要的一些参数传递到bean实例对象的过程（将依赖关系注入到对象中，不需要每次都new对象）\\r\\n\\r\\n- set方法注入\\r\\n- 构造方法注入\\r\\n- 注解注入\\r\\n\\r\\n 注解注入的区别\\r\\n\\r\\n- @Resource\\r\\n\\r\\n  byName注入\\r\\n\\r\\n  \\r\\n\\r\\n- Autowired\\r\\n\\r\\n  byType注入\"},{\"url\":\"/frame/spring/Spring如何解决循环依赖.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring如何解决循环依赖\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"依赖注入的四种方法\\r\\n\\r\\n- 构造方法注入\\r\\n  \\r\\n    ```java\\r\\n        public HelloA(@Autowired HelloService helloService) {\\r\\n            this.helloService = helloService;\\r\\n        }\\r\\n    ```\\r\\n    \\r\\n- 工厂方法注入\\r\\n  \\r\\n    ```java\\r\\n        @Bean(initMethod = \\\"init\\\", destroyMethod = \\\"destory\\\")\\r\\n        public HelloB helloB(@Auto\"},{\"url\":\"/frame/spring/Spring框架概述.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring框架概述\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、什么是 Spring 框架？\\r\\n\\r\\nSpring 框架指的是 Spring Framework，是一种轻量级的开发框架，主要核心是控制反转 （IOC）和 面向切面编程（AOP）。\\r\\n\\r\\n 二、Spring 的优点\\r\\n\\r\\n1. 方便解耦，简化开发（高内聚低耦合）\\r\\n    - Spring 是一个容器框架，将所有对象创建和依赖关系的维护交给 Spring 管理。\\r\\n    - Spring 工厂用于生成 Bean。\\r\\n2. AOP编程的支持\\r\\n    - Spring 提供面向切面编程，可以方便的实现权限拦截、运行监控等功能\\r\\n    - 日志打印\\r\\n3. 支持声明式事务\\r\\n    - 只需\"},{\"url\":\"/frame/spring/Spring自定义注解扫描.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring自定义注解扫描\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Spring管理的类\\r\\n\\r\\n以下两种方式都可以实现。\\r\\n\\r\\n 使用@ComponentScan + Bean定义\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\n@ComponentScan(basePackages = {\\\"your.package.to.scan\\\"}) // 指定要扫描的包\\r\\npublic class AppConfig {\\r\\n\\r\\n    @Autowired\\r\\n    private ListableBeanFactory beanFactory;\\r\\n\\r\\n    @PostConstruct\\r\\n    public void processAnnotatedBea\"},{\"url\":\"/frame/spring/Spring配置文件加载顺序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring配置文件加载顺序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot配置文件的加载顺序\\r\\n\\r\\nSpringBoot项目启动会扫描以下位置的application.properties或者application.yml文件作为SpringBoot的默认配置文件，具体的目录位置见下图。\\r\\n\\r\\n1. file:./config/ （ 项目根路径下的config文件夹）\\r\\n2. file:./ （项目根路径）\\r\\n3. classpath:/config/ （类路径下的config文件夹）\\r\\n4. classpath:/ （类路径）\\r\\n\\r\\n\\r\\n\\r\\n按照配置文件的优先级，8001\\r\\n\\r\\n&gt; 注意file层是项目的最外层目录，也就是工作目录。\\r\\n&\"},{\"url\":\"/frame/spring/custom/AOP.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AOP\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ByteBuddy\\r\\n\\r\\nAOP即面向切面编程，本质上是一个 Proxy 模式。核心就是拦截核心 Bean 的方法调用。\\r\\n\\r\\n- JDK动态代理\\r\\n- CGLIB动态生成字节码代理。\\r\\n\\r\\n\\r\\n&gt;\\r\\n\\r\\n AOP实现核心\\r\\n\\r\\n- 找到符合AOP要求的原始Bean\\r\\n- 执行指定的拦截器逻辑\\r\\n\\r\\n AOP流程\\r\\n\\r\\n1. 利用 `BeanPostProcessor` 检测每个Bean。\\r\\n2. 扫描每个 Bean 的 @Around 注解。\\r\\n3. 执行 InvocationHandler 的代理方法。\\r\\n\\r\\n 实现 @Before 和 @After\\r\\n\\r\\n基于@Around的模板就\"},{\"url\":\"/frame/spring/custom/Boot.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Boot\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot 内置了 Tomcat，IOC容器和 WebMVC 模块，所以能直接启动。\\r\\n\\r\\n 启动类\\r\\n\\r\\n```java\\r\\n@Slf4j\\r\\npublic class SummerApplication {\\r\\n\\r\\n    static final String CONFIG_APP_YAML = \\\"/application.yml\\\";\\r\\n    static final String CONFIG_APP_PROP = \\\"/application.properties\\\";\\r\\n\\r\\n    public static void run(String webDir, String base\"},{\"url\":\"/frame/spring/custom/IOC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IOC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"其中构造方法注入和工厂方法注入是强依赖，因为Bean创建和属性注入放到一起了。\\r\\n\\r\\n比如构造方法注入，创建对象的同时进行属性注入，这种属于强依赖。\\r\\n\\r\\n而强依赖是解决不了循环依赖的问题的，因为创建对象和属性注入属于一体不可分的。\\r\\n\\r\\n我们解决循环依赖是先创建对象，然后属性注入的时候利用三级缓存解决的。\\r\\n\\r\\n```java\\r\\n    public BeanTest(@Value(\\\"spring.port\\\") String port, String name) {\\r\\n        System.out.println(port);\\r\\n    }\\r\\n```\\r\\n\\r\\nIOC容器有两类，Bean\"},{\"url\":\"/frame/spring/custom/JDBC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JDBC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"DataSource\\r\\n\\r\\n自动注入DataSource\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\npublic class JdbcConfiguration {\\r\\n\\r\\n    /**\\r\\n     * 自动注入HikariDataSource\\r\\n     *\\r\\n     * @param url\\r\\n     * @param username\\r\\n     * @param password\\r\\n     * @param driver\\r\\n     * @param maximumPoolSize\\r\\n     * @param minimumPoolSize\\r\\n     * @pa\"},{\"url\":\"/frame/spring/custom/MVC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MVC实现逻辑\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 应用程序必须配置一个Summer Framework提供的 Listener；\\r\\n2. Tomcat 完成 Servlet 容器的创建后，立刻根据配置创建Listener；\\r\\n    1. Listener初始化时创建 IOC 容器；\\r\\n    2. Listener继续创建DispatcherServlet实例，并向Servlet容器注册；\\r\\n    3. DispatcherServlet初始化时获取到IOC容器中的Controller实例，因此可以根据URL调用不同Controller实例的不同处理方法。\\r\\n    4. 容器中的Controller实例，因此可以根据URL调用不同\"},{\"url\":\"/frame/spring/custom/声明式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"声明式事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"事务传播模型\\r\\n\\r\\n| 传播行为 | 含义 |\\r\\n| --- | --- |\\r\\n| PROPAGATION_REQUIRED | 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。 |\\r\\n| PROPAGATION_SUPPORTS | 支持当前事务，如果当前没有事务，就以非事务方式执行。 |\\r\\n| PROPAGATION_MANDATORY | 支持当前事务，如果当前没有事务，就抛出异常。 |\\r\\n| PROPAGATION_REQUIRED_NEW | 新建事务，如果当前存在事务，把当前事务挂起。 |\\r\\n| PROPAGATION_NOT_SUPPORTED | 以非事务方式\"},{\"url\":\"/frame/spring/custom/手写Spring.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"手写Spring\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- boot模块：实现一个简化版的 `Spring Boot`，用于打包运行。\\r\\n- web模块：实现Web MVC和REST API。\\r\\n\\r\\n Spring主要模块\\r\\n\\r\\n- context模块：实现ApplicationContext容器与Bean的管理；\\r\\n- aop模块：实现AOP功能；\\r\\n- jdbc模块：实现JdbcTemplate，以及声明式事务管理；\\r\\n\\r\\n IOC\\r\\n\\r\\nIOC\\r\\n\\r\\n AOP\\r\\n\\r\\nAOP\\r\\n\\r\\n JDBC\\r\\n\\r\\nJDBC\\r\\n\\r\\n声明式事务\\r\\n\\r\\n1. 由`JdbcConfiguration`创建的`DataSource`，实现了连接池；\\r\\n2. 由`Jdb\"},{\"url\":\"/frame/spring/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Spring框架\\r\\n\\r\\n 一、Spring框架\\r\\n\\r\\n- Spring框架概述\\r\\n- ApplicationContext 和 BeanFactory 区别\\r\\n- BeanFactory 和 FactoryBean 总结\\r\\n- Spring中Bean的作用域\\r\\n- Spring中Bean加载流程\\r\\n- Spring依赖注入\\r\\n- Spring如何解决循环依赖\\r\\n\\r\\n- AOP\\r\\n- Spring事务总结\\r\\n- Aware接口\\r\\n- Spi机制\\r\\n- Spring配置文件加载顺序\\r\\n\\r\\n 二、使用总结\\r\\n\\r\\n- Spring自定义注解扫描\\r\\n- ByteBuddy实现动态代理\\r\\n\\r\\n 三、手写S\"},{\"url\":\"/frame/springboot/SpringBoot使用APO记录操作日志.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot使用APO记录操作日志\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"通过织入自定义注解 @Log，再进行解析记录操作日志。\\r\\n\\r\\n1. 自定义注解 @Log\\r\\n    \\r\\n    ```java\\r\\n    @Target({ElementType.PARAMETER, ElementType.METHOD})\\r\\n    @Retention(RetentionPolicy.RUNTIME)\\r\\n    @Documented\\r\\n    public @interface Log {\\r\\n    \\r\\n        /**\\r\\n         * 模块\\r\\n         */\\r\\n        String title() default \\\"default\\\";\\r\\n\"},{\"url\":\"/frame/springboot/SpringBoot能同时处理多少请求.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot能同时处理多少请求\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot内置了Tomcat，处理请求是 Web 容器处理的。\\r\\n\\r\\n1. 线程池线程数限制\\r\\n\\r\\n   而 Tomcat 的线程池默认最大线程池是 200，所以默认同时最多能处理 200 个请求。\\r\\n\\r\\n   \\r\\n&gt;\\r\\n2. 连接数限制\\r\\n\\r\\n   达到连接池数时，会限制请求数。此时因连接数限制为准，而不是最大线程数。\\r\\n\\r\\n    ```\\r\\n    tomcat最大连接数限制\\r\\n    server.tomcat.max-connections=12\\r\\n    ```\\r\\n\\r\\n\\r\\n---\\r\\n\\r\\n 限制配置\\r\\n\\r\\n```\\r\\ntomcat最大连接数限制\\r\\nserver.tomca\"},{\"url\":\"/frame/springboot/SpringBoot项目自动初始化数据库.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot项目自动初始化数据库\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"背景\\r\\n\\r\\n在 SpringBoot 启动的时候若配置文件中配置的数据库不存在，则自动创建数据库，并执行初始化SQL。\\r\\n\\r\\n 思路\\r\\n\\r\\n1. 判断数据库是否存在。\\r\\n2. 手动注入Datasource。\\r\\n    \\r\\n    在数据库未创建时，启动会报错\\r\\n    \\r\\n3. 初始化表。\\r\\n\\r\\n 解决方式\\r\\n\\r\\n1. 启动类排除 `DataSourceAutoConfiguration.class` ，采用手动注入的方式。\\r\\n    \\r\\n    如果配置的数据库不存在，SpringBoot启动的时候会提示找不到数据库，所以要排除掉，然后手动注入。\\r\\n    \\r\\n    ```java\\r\\n  \"},{\"url\":\"/frame/springboot/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot 框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot 框架\\r\\n\\r\\n\\r\\n 使用总结\\r\\n- SpringBoot能同时处理多少请求\\r\\n- SpringBoot使用APO记录操作日志\\r\\n- SpringBoot项目自动初始化数据库\"},{\"url\":\"/frame/springcloud/Feigh远程调用原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Feigh远程调用原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"思路\\r\\n\\r\\n根据接口地址和 FeignClient构建http请求。\\r\\n\\r\\n1. 构建 http请求模版，包含 header、body、method等参数信息。\\r\\n2. 设置 options，包含超时时间参数配置。\\r\\n3. 根据 clientName 从 nacos（类似map，保存clientName和访问地址的对应关系）中获取访问地址。\\r\\n4. 根据访问地址和http请求参数发起http请求。\\r\\n\\r\\n 代码入口\\r\\n\\r\\n`io/github/openfeign/feign-core/10.4.0/feign-core-10.4.0.jar!/feign/ReflectiveFeign.cla\"},{\"url\":\"/frame/springcloud/Gateway.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Gateway\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"请求流程\\r\\n\\r\\n&lt;img src=\\\"https://s2.loli.net/2025/06/10/RBVjazHT3NinfQe.png\\\" alt=\\\"image.png\\\" style=\\\"zoom:50%;\\\" /\\r\\n\\r\\n- Gateway Handler（网关处理器）：网关处理器是 Spring Cloud Gateway 的核心组件，负责将请求转发到匹配的路由上。它根据路由配置和断言条件进行路由匹配，选择合适的路由进行请求转发。网关处理器还会依次应用配置的过滤器链，对请求进行处理和转换。\\r\\n- Gateway Filter Chain（网关过滤器链）：网关过滤器链由一系列过滤器组成，按照\"},{\"url\":\"/frame/springcloud/Nacos.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Nacos\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"地址\\r\\n\\r\\n GitHub\\r\\n\\r\\nhttps://github.com/alibaba/nacos\\r\\n\\r\\n 文档\\r\\n\\r\\nNacos 快速开始\\r\\n\\r\\n 启动命令\\r\\n\\r\\n```sql\\r\\nsh startup.sh -m standalone\\r\\n```\\r\\n\\r\\n 可视化页面\\r\\n\\r\\n`http://localhost:8848/nacos`\\r\\n\\r\\n\\r\\n\\r\\n 注册中心原理\\r\\n\\r\\n 服务注册\\r\\n\\r\\nNocas Client 在启动的时候会通过 Rest 的方式将自己的元数据（Ip、端口）等信息发给 Nocas Server。\\r\\n\\r\\nNacos Server 收到 Client 的注册请求后，将元数据信息存到\"},{\"url\":\"/frame/springcloud/Seata分布式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Seata分布式事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在分布式情况下，一次业务请求需要调用多个系统操作多个数据源时，针对多个数据源操作会产生分布式事务问题。每个系统能够保证各自数据源的一致性问题，但是全部系统数据的一致性问题没法保证。\\r\\n\\r\\n 官网地址\\r\\n\\r\\nhttps://seata.io/zh-cn/docs/user/quickstart.html\\r\\n\\r\\n 下载地址\\r\\n\\r\\nhttps://seata.io/zh-cn/blog/download.html\\r\\n\\r\\n 基础概念\\r\\n\\r\\n事务ID + 三组件\\r\\n\\r\\n事务ID\\r\\n\\r\\n- Transaction ID(XID)\\r\\n\\r\\n三组件\\r\\n\\r\\n- TC-事务协调者\\r\\n\\r\\n  维护全局和分支事务的状态\"},{\"url\":\"/frame/springcloud/Sentinel原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Sentinel原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Sentinel工作主流程\\r\\n\\r\\n滑动窗口实现原理 · 吾爱开源 · 看云\\r\\n\\r\\n 限流算法\\r\\n\\r\\n 计数器算法\\r\\n\\r\\n计数器算法统计某个时间段的请求量，判断是否超过阈值。\\r\\n\\r\\n\\r\\n\\r\\n存在的问题：\\r\\n\\r\\n如上图中，在时间段的临界处加起来其实QPS 超过了阈值，但是平均到单个时间段未发生。\\r\\n\\r\\n单纯的计数器算法存在 临界统计不准确 的问题。\\r\\n\\r\\n 滑动窗口计数器算法\\r\\n\\r\\n解决滑动窗口存在的问题，引入了滑动窗口计数器。\\r\\n\\r\\n我们将统计时间细分，比如将 1s 统计时长分为 5个 时间窗口，通过 滚动统计所有时间窗口的QPS 作为系统实际的 QPS 的方式，就能解决上述 临界统计 问题。\\r\"},{\"url\":\"/frame/springcloud/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringCloud\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringCloud\\r\\n\\r\\n 使用总结\\r\\n\\r\\n- 注册中心的演进\\r\\n- Nacos\\r\\n- Gateway\\r\\n- Feigh远程调用原理\\r\\n- Sentinel原理\\r\\n- Seata分布式事务\\r\\n\\r\\n\\r\\n\\r\\n 项目\\r\\n\\r\\nSpringCloud总结练习-Gitee\"},{\"url\":\"/frame/springcloud/注册中心的演进.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"注册中心的演进\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 直接远程调用\\r\\n\\r\\n   \\r\\n\\r\\n2. 维护注册表，维护服务调用地址\\r\\n\\r\\n   \\r\\n\\r\\n3. 接入 nginx，利用 nginx 做负载\\r\\n\\r\\n   \\r\\n\\r\\n4. 引入注册机制，提供注册和服务发现功能\\r\\n\\r\\n   \\r\\n\\r\\n5. 引入心跳机制，解决注册中心宕机或者目标服务不可用\"},{\"url\":\"/\",\"frontmatter\":{\"layout\":\"home\",\"tk\":{\"teekHome\":false},\"hero\":{\"name\":\"技术小站\",\"tagline\":\"✨生活不止眼前的代码，还有迈向田野的步伐\",\"actions\":[{\"theme\":\"brand\",\"text\":\"开始\",\"link\":\"/guide/quickstart\"},{\"theme\":\"alt\",\"text\":\"配置\",\"link\":\"/reference/config\"}],\"image\":{\"src\":\"/bird.svg\",\"alt\":\"Teek\"}},\"features\":[{\"icon\":\"📖\",\"title\":\"结构化 && 体系化\",\"details\":\"自动生成侧边栏、目录页、索引页、面包屑等，轻松构建一个结构化知识库。\"},{\"icon\":\"🎉\",\"title\":\"碎片化 & 个性化\",\"details\":\"提供快速构建知识的碎片化形态，并提供大量个性化的主题配置。\"},{\"icon\":\"🎇\",\"title\":\"文档风 & 博客风\",\"details\":\"支持通过配置随意切换两种模式，支持个人博客、文档站、知识库等场景。\"},{\"icon\":\"📝\",\"title\":\"专注内容\",\"details\":\"只需 Markdown 即可轻松创建美观的文档站点，配合多维索引快速定位每个知识点。\"}]},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"&lt;style\\r\\n\\r\\n/* 彩虹动画 */\\r\\n:root {\\r\\n  animation: rainbow 12s linear infinite;\\r\\n}\\r\\n\\r\\n@media (min-width: 640px) {\\r\\n  :root {\\r\\n    --vp-home-hero-image-filter: blur(56px);\\r\\n  }\\r\\n}\\r\\n\\r\\n@media (min-width: 960px) {\\r\\n  :root {\\r\\n    --vp-home-hero-image-filter: blur(68px);\\r\\n  }\\r\\n}\\r\\n&lt;/style&gt;\\r\\n\\r\\n&lt;script\"},{\"url\":\"/java/cache/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Cache\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 本地缓存\\r\\n- 多级缓存\\r\\n- 缓存淘汰算法\"},{\"url\":\"/java/cache/多级缓存.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"多级缓存\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"二级缓存\\r\\n\\r\\n二级缓存没有网络开销\\r\\n\\r\\n\\r\\n\\r\\n 优点\\r\\n\\r\\n1. 减少网络请求，提高性能。\\r\\n2. 减少远程缓存的读压力。\\r\\n3. 天然分布式缓存，只存在于当前节点服务。\\r\\n\\r\\n 缺点\\r\\n\\r\\n1. 占用本地内存，空间有限，不支持大数据量。\\r\\n\\r\\n   只存储最热的数据到本地缓存，结合热点服务探测。\\r\\n\\r\\n2. 重启数据会丢失。\\r\\n\\r\\n   重启丢失数据无法避免，但是可以在重启项目的时候把最热的数据加到本地缓存。\\r\\n\\r\\n3. 分布式场景，数据可能不一致。\\r\\n4. 和远程缓存可能存在不一致的问题。\\r\\n\\r\\n   只能保证最终一致性，尽可能让本地缓存过期时间短一点，这样就能加载远程缓存，达到最终\"},{\"url\":\"/java/cache/本地缓存.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"本地缓存\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Guava\\r\\n\\r\\n- 支持最大容量限制\\r\\n- 支持两种过期删除策略\\r\\n- 支持简单的统计功能\\r\\n- 插入时间\\r\\n- 访问时间\\r\\n- 基于LRU算法实现\\r\\n\\r\\n```java\\r\\nLoadingCache&lt;Integer, String\\r\\n        //设置并发级别为8，并发级别是指可以同时写缓存的线程数\\r\\n        .concurrencyLevel(8)\\r\\n        //设置缓存的初始容量为10\\r\\n        .initialCapacity(10)\\r\\n        // 设置缓存最大容量为100，超过100之后就会按照LRU最近最少使用算法来移除缓存\\r\\n    \"},{\"url\":\"/java/cache/缓存淘汰算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"缓存淘汰算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"FIFO-先进先出\\r\\n\\r\\n\\r\\n\\r\\n比较简单，不够灵活。\\r\\n\\r\\n没有跟缓存使用频次和时间等维度联系起来。\\r\\n\\r\\n LRU-最近最少使用\\r\\n\\r\\n核心思想是最近使用的时间。比如最近一小时以内使用缓存的时间。\\r\\n\\r\\n\\r\\n\\r\\n根据数据的历史访问记录来淘汰数据，淘汰最久未被使用的数据。\\r\\n\\r\\n基于如果数据最近被访问过，那么将来访问的记录会更高。优先淘汰最久未被使用的冷数据。\\r\\n\\r\\n LFU-最近最不常用\\r\\n\\r\\n核心思想是最近使用的次数。比如最近一小时内使用缓存的次数。\\r\\n\\r\\n\\r\\n\\r\\nLFU能够提高热点数据的命中率。\\r\\n\\r\\n但是当缓存中数据都是热点数据的时候，将失去该特性。\\r\\n\\r\\n单纯的LFU存在缺陷。\\r\\n\"},{\"url\":\"/java/collection/Collection集合概述.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集合概述\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集合概述\\r\\n\\r\\n 为什么使用集合？\\r\\n\\r\\n当我们需要保存一组类型相同的数据的时候，我们应该用一个容器来保存，这个容器就是数组。\\r\\n\\r\\n但是数组的长度是固定的，当添加的元素超过了数组的长度之后，需要对数组重新定义。而且数组存储的数据是`有序的`、`可重复的`，太过于单一，扩展性不够。\\r\\n\\r\\n于是，引入了集合，Java 内部给我们提供了功能完善的集合框架。能`存储任意对象`，长度可以`动态改变`，提高了数据存储的灵活性。\\r\\n\\r\\n 数组和集合的区别\\r\\n\\r\\n1. 存储类型\\r\\n   - 数组可以存储`基本数据类型`，又可以存储`引用数据类型`。\\r\\n   - 集合只能存储`引用数据类型`。（集合中也可以存\"},{\"url\":\"/java/collection/ConcurrentHashMap1.7.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ConcurrentHashMap - 1.7\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、类简介\\r\\n\\r\\nConcurrentHashMap 是一个线程安全的 HashMap，在 JDK 1.7 HashMap的基础上实现了 `分段锁` 来保证线程安全。在 HashMap 的基础上，默认分为 16 个段，每个段都拥有独立的锁，来保证各个段的线程安全。\\r\\n\\r\\n 扩展 - 线程安全的 HashMap\\r\\n\\r\\nMap实现线程安全的三种方式\\r\\n\\r\\n Unsafe方法总结\\r\\n\\r\\n\\r\\n\\r\\n 二、主要参数\\r\\n\\r\\n```java\\r\\npublic class ConcurrentHashMap&lt;K, V\\r\\n        implements ConcurrentMap&lt;K, V&gt;\"},{\"url\":\"/java/collection/ConcurrentHashMap1.8.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ConcurrentHashMap -1.8\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ConcurrentHashMap 源码分析\\r\\n\\r\\n\\r\\n1.8的ConcurrentHashMap，采用对Node加锁机制。\\r\\n\\r\\n 加锁原理\\r\\n\\r\\n采用CAS+Synchronized组合锁的方法。\\r\\n\\r\\n- CAS\\r\\n\\r\\n  操作Node数组的时候以CAS方式操作。\\r\\n\\r\\n- Synchronized\\r\\n\\r\\n  操作Node对应的数据结构，链表或红黑树的时候加Synchronized。保证操作数据的原子性。\"},{\"url\":\"/java/collection/HashMap1.7.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HashMap - 1.7\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类简介\\r\\n\\r\\nHashMap 是一个用来存储 Key - Value 键值对的集合，每一个键值对也叫做 Entry，这些 Entry 保存在底层数组中。\\r\\n\\r\\n 1. 底层数组\\r\\n\\r\\n底层数组包含的每个元素可以称之为 桶，元素实际保存在每个桶上。\\r\\n\\r\\n```java\\r\\n    static final Entry&lt;?,?\\r\\n\\r\\n    /**\\r\\n     * The table, resized as necessary. Length MUST Always be a power of two.\\r\\n     */\\r\\n    transient Entry&lt;K,V&gt;[] t\"},{\"url\":\"/java/collection/HashMap1.8.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HashMap - 1.8\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类简介\\r\\n\\r\\n 默认参数\\r\\n\\r\\n- 默认长度\\r\\n\\r\\n  ```\\r\\n   static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4\\r\\n  ```\\r\\n\\r\\n- 最大容量\\r\\n\\r\\n  ```\\r\\n  static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;\\r\\n  ```\\r\\n\\r\\n- 默认负载因子\\r\\n\\r\\n  ```\\r\\n   static final float DEFAULT_LOAD_FACTOR = 0.75f;\\r\\n  ```\\r\\n\\r\\n- 默认树化临界点\\r\\n\\r\\n  ```\\r\\n  static final in\"},{\"url\":\"/java/collection/List集合体系.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"List集合体系\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ArrayList\\r\\n\\r\\n 特点\\r\\n\\r\\n- 底层基于数组实现。\\r\\n- 有索引，支持快速访问。\\r\\n- 查询修改快，增删慢。\\r\\n- 线程不安全。\\r\\n\\r\\n 构造方法\\r\\n\\r\\n1. 无参构造\\r\\n\\r\\n   - JDK 1.6 之前，以初始容量 10 创建一个长度为10的数组。\\r\\n   - JDK 1.6 之后，创建一个空数组。\\r\\n\\r\\n   ```java\\r\\n       public ArrayList() {\\r\\n           this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;\\r\\n       }\\r\\n   ```\\r\\n\\r\\n2. 有参构造 - 数\"},{\"url\":\"/java/collection/Set集合体系.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Set集合体系\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HashSet\\r\\n\\r\\n 特点\\r\\n\\r\\n- 底层基于哈希算法实现，使用 `HashMap` 保存数据。\\r\\n- 无序（存取顺序不一致）。\\r\\n- 不可以存储重复元素。\\r\\n- 线程不安全。\\r\\n\\r\\n 构造方法\\r\\n\\r\\n1. 无参构造\\r\\n\\r\\n   底层使用 `HashMap` 保存数据。\\r\\n   \\r\\n```java\\r\\n       public HashSet() {\\r\\n           map = new HashMap&lt;\\r\\n       }\\r\\n```\\r\\n\\r\\n3. 有参构造 - Collection 集合\\r\\n\\r\\n   根据传入的 Collection 集合 初始化底层 `HashMap`。\\r\\n\\r\\n\"},{\"url\":\"/java/collection/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集合\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Collection集合\\r\\n\\r\\n- Collection集合概述\\r\\n- List集合体系\\r\\n- Set集合体系\\r\\n\\r\\n Map集合体系\\r\\n\\r\\n- HashMap - 1.7\\r\\n- ConcurrentHashMap - 1.7\\r\\n- HashMap - 1.8\\r\\n- ConcurrentHashMap -1.8\"},{\"url\":\"/java/concurrent/Java高并发.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Java工程师成长计划-高并发\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java工程师成长计划-高并发\\r\\n\\r\\n```\\r\\n         _______________________________________________        \\r\\n        |   _      __        __                         |       \\r\\n________|  | | /| / / ___   / / ____ ___   __ _  ___    |_______\\r\\n\\\\       |  | |/ |/ / / -_) / / / __// _ \\\\ /  ' \\\\/ -_)   |      /\\r\\n \\\\      |  |\"},{\"url\":\"/java/concurrent/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"高并发\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"思维导图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 参考链接\\r\\n\\r\\n- 深入浅出Java多线程\"},{\"url\":\"/java/concurrent/single/AQS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AQS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"从ReentrantLock的实现看AQS的原理及应用\\r\\n\\r\\nAQS是一种提供了原子式管理同步状态、阻塞和唤醒线程功能以及队列模型的简单框架。\\r\\n\\r\\n 组成\\r\\n\\r\\n1. 共享资源状态维护state。\\r\\n\\r\\n   - AQS使用一个`volatile`修饰的 int 成员变量来表示同步状态，这个状态可以反映锁的当前持有情况。\\r\\n\\r\\n     例如，当状态为 0 时表示无锁状态，而当状态为非零时表示有锁被占用。\\r\\n\\r\\n2. FIFO 队列实现线程排队。\\r\\n\\r\\n   AQS维护了一个FIFO（先入先出）的双向队列，用于管理等待获取锁的线程，当一个线程尝试获取锁但失败时，它会进入这个队列并阻塞，直到锁\"},{\"url\":\"/java/concurrent/single/BlockQueue阻塞队列.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"阻塞队列BlockQueue\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"阻塞队列`BlockQueue`比起传统的`Queue`多了阻塞的功能，适合用于多线程之间的数据共享。阻塞主要发生在队列为空和队列满的情况。\\r\\n\\r\\n- 在队列为空的时候，操作元素出队的线程会进行循环等待，直到队列变为非空。\\r\\n- 在队列满的时候，操作元素入队的线程会进行循环等待，直到队列变为非满。\\r\\n\\r\\n 常见方法\\r\\n\\r\\n`BlockQueue入队`的方法有如下几种：\\r\\n\\r\\n- `offer()`方法，如果队列已满，无法存放，直接返回false。\\r\\n- `add()`方法，实际调用了offer()方法，增加了（Queue Full）的异常信息返回。\\r\\n- `put()`方法，若队列已满，会进行\"},{\"url\":\"/java/concurrent/single/CAS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"悲观和乐观策略\\r\\n\\r\\n锁有着悲观锁和乐观锁之分，悲观锁拥有资源的时候，认为随时会有人来篡改拥有的资源，所以在其拥有资源时不允许其他人访问。而乐观锁在拥有资源的时候不认为会有人来篡改其所拥有的资源，所以在其拥有资源的时候允许其他人访问。悲观锁和乐观锁是一种思想，对应的也是一种策略。\\r\\n\\r\\n加锁和使用 synchronized 其实就是一种悲观的策略，因为总是假设临界区的操作会产生冲突，如果有多个线程需要访问临界区资源，加锁和使用 synchronized 会阻塞其它线程。\\r\\n\\r\\n而无锁其实就是一种乐观的策略，它在操作的时候会假设访问资源不会冲突，所有的线程之间不存在阻塞，也就不存在等待，线程会持\"},{\"url\":\"/java/concurrent/single/ThreadLocal.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ThreadLocal总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ThreadLocal 提供了线程的局部变量，只有当前线程可以操作，不会和其它线程的局部变量产生冲突，实现了变量的线程安全。`ThreadLocal&lt;T\\r\\n\\r\\n 简单例子\\r\\n\\r\\n```java\\r\\npublic class ThreadLocalDemo {\\r\\n\\r\\n    private static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;();\\r\\n\\r\\n    public static void main(String[] args) {\\r\\n        //主线程\\r\\n        threadL\"},{\"url\":\"/java/concurrent/single/synchronized原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"synchronized原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"synchronized原理详解（通俗易懂超级好）-CSDN博客\\r\\n\\r\\n 特性\\r\\n\\r\\n- 原子性\\r\\n\\r\\n  synchronized 修饰的对象或类所有操作都是原子性的。线程需要获取锁，保证整个操作过程的原子性。\\r\\n\\r\\n  比如 i++这种赋值操作。\\r\\n\\r\\n- 可见性\\r\\n\\r\\n  一个线程如果要访问该类或对象必须先获得它的锁，而这个锁的状态对于其他任何线程都是可见的，并且在释放锁之前会将对变量的修改刷新到主存当中，保证资源变量的可见性。\\r\\n\\r\\n  如果某个线程占用了该锁，其他线程就必须在锁池中等待锁的释放。\\r\\n\\r\\n- 有序性\\r\\n\\r\\n  保证只有一个线程访问，确保了有序性。\\r\\n\\r\\n- 可重入性\\r\\n\"},{\"url\":\"/java/concurrent/single/transmittable-thread-local.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"transmittable-thread-local\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"线程池中的线程是可以复用的，假如第一个线程对  ThreadLocal 变量进行了操作，如果没有及时清理，下一个线程就会受到影响。因为 ThreadLocal  是在每个线程上维护了一个 ThreadLocalMap ，所以在线程复用的情况下，之后的线程会获取到  ThreadLocal  里之前线程设置的值。\\r\\n\\r\\n ThreadLocal多线程问题\\r\\n\\r\\n在多线程场景下传递ThreadLocal，如果线程池是池化的话，可能会导致复用ThreadLocal里面的值。\\r\\n\\r\\n\\r\\n\\r\\n 需求场景\\r\\n\\r\\n在使用线程池等池化复用线程的情况下，传递ThreadLoca值。\\r\\n\\r\\n1. 分布式跟踪 tr\"},{\"url\":\"/java/concurrent/single/原子类.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"原子类\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本类型-AtomicInteger\\r\\n\\r\\nAtomicInteger 是无锁的线程安全整数类，基于 `CAS` 实现，位于 `java.util.concurrent.atomic` 包下，该包下实现了一系列使用 `CAS` 操作实现线程安全的类型。其它原子类和 AtomicInteger 非常类似，故只分析 AtomicInteger。\\r\\n\\r\\n\\r\\n\\r\\n 比较 Integer\\r\\n\\r\\nAtomicInteger 是一个整数，与 Integer 不同的是，它是可变的并且是线程安全的。\\r\\n\\r\\n比如在多线程不加锁的情况下，操作 Integer 或者 AtomicInteger ，来比较结果是否正确。\"},{\"url\":\"/java/concurrent/single/死锁活锁和饥饿.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"死锁活锁和饥饿\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在使用锁的时候，可能会因为使用不当产生死锁、活锁和饥饿的现象。\\r\\n\\r\\n在单体应用中，加锁是否能解决所有的线程安全问题？\\r\\n\\r\\n*不能，因为加锁使用不当会有死锁、活锁和饥饿等问题。*\\r\\n\\r\\n 死锁\\r\\n\\r\\n什么是死锁？\\r\\n\\r\\n死锁指的是两个或多个线程之间，互相占用着对方请求的资源，而且不会释放已持有的资源，造成了多线程之间无限等待的现象，就叫做死锁。\\r\\n\\r\\n死锁发生后，会浪费大量的系统资源，并且在高并发下存在严重的安全隐患，甚至导致整个系统崩溃。\\r\\n\\r\\n 死锁产生的条件\\r\\n\\r\\n1. 互斥\\r\\n\\r\\n   某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结\"},{\"url\":\"/java/concurrent/single/线程池的关闭.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程池的关闭\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"线程池的关闭\\r\\n\\r\\n线程池的关闭方式有两种，一种是调用 `shutdown()` 方法，另一种是调用 `shutdownNow()` 方法。\\r\\n\\r\\n- shutdown\\r\\n\\r\\n  调用该方法后，线程池拒绝接受新提交的任务，同时等待线程池里和任务队列中的任务执行完毕再关闭线程。\\r\\n\\r\\n- shutdownNow\\r\\n\\r\\n  调用该方法后，线程池拒绝接受新提交的任务，不再执行任务队列的任务，将线程池任务队列里的任务全部返回。\\r\\n\\r\\n shutdown\\r\\n\\r\\n调用该方法后，线程池拒绝接受新提交的任务，同时等待线程池里和任务队列中的任务执行完毕再关闭线程。\\r\\n\\r\\n```java\\r\\n    public \"},{\"url\":\"/java/concurrent/single/线程池的执行流程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程池的执行\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"执行流程\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n1. 根据初始化参数创建线程池，刚创建时，线程池内没有线程。\\r\\n2. 当有新的任务提交到线程池的时候，会立即新增线程执行任务。\\r\\n3. 若运行线程数 = 核心线程数时，这时进来的任务会被添加到任务队列中，而线程会从任务队列中获取任务执行。\\r\\n4. 运行线程数 = 核心线程数 且 任务队列已满，这时候会在线程池中创建新线程来执行任务。\\r\\n5. 运行线程数 = 最大线程数，且任务队列已满，此时会执行线程池对应的拒绝策略。\\r\\n6. 当任务队列中没有任务，且线程等待时间超过空闲时间，则该线程会被回收。最终线程池中的线程数量会保持在核心线程数的大小。\\r\\n\\r\\n 源码分析\\r\\n\"},{\"url\":\"/java/concurrent/single/线程的生命周期.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程的生命周期\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 Java 中线程从新建到关闭会经过不同的状态，将线程从新建到关闭作为一个生命周期，在 Java 中整个线程的生命周期有 6 种状态。\\r\\n\\r\\n 线程状态类型\\r\\n\\r\\n在 JDK 的 Thread 类，存在 `State` 枚举类，包含了线程的 6 种状态。\\r\\n\\r\\n```java\\r\\n    public enum State {\\r\\n        \\r\\n        NEW,\\r\\n        RUNNABLE,\\r\\n        BLOCKED,\\r\\n        WAITING,\\r\\n        TIMED_WAITING,\\r\\n        TERMINATED;\\r\\n    }\\r\\n```\"},{\"url\":\"/java/distributed/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 分布式事务\\r\\n- 分布式锁\\r\\n- 分布式ID\\r\\n- 幂等性问题\"},{\"url\":\"/java/distributed/分布式ID.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式ID\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"要求\\r\\n\\r\\n1. 分布式全局唯一\\r\\n2. 有序递增\\r\\n\\r\\n 方案\\r\\n\\r\\n\\r\\n\\r\\n 数据库主键自增\\r\\n\\r\\n1. 创建一个全局主键自增的表。\\r\\n2.  从该表查询id使用。\\r\\n    - 效率低下，每次插入之前都要查一次自己的id\\r\\n\\r\\n 数据库号段模式\\r\\n\\r\\n批量从全局自增主键表获取一批主键，放到内存里。（减少数据库访问次数）\\r\\n\\r\\n```bash\\r\\nCREATE TABLE `sequence_id_generator` (\\r\\n  `id` int(10) NOT NULL,\\r\\n  `current_max_id` bigint(20) NOT NULL COMMENT '当前最大id',\\r\\n\"},{\"url\":\"/java/distributed/分布式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在分布式情况下，假如存在 A 同时调用 B、C多个微服务。假如 B 服务事务正常执行并提交，但是 C 事务提交失败，此时 B 和 C都需要回滚。\\r\\n\\r\\n而 MySQL 的事务回滚是通过 redo log 机制来实现的，保证事务的持久化和一致性。\\r\\n\\r\\n但是在分布式，使用了分布式事务的情况下，是通过一条更新SQL，还原原本的数据。\\r\\n\\r\\n\\r\\n\\r\\n一文搞明白分布式事务解决方案！真的 so easy！\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n分布式事务，原理简单，写起来全是坑！ - 掘金\\r\\n\\r\\n\\r\\n\\r\\n 分布式事务解决方案\\r\\n\\r\\n 2PC - 两阶段提交\\r\\n\\r\\n1. prepare - 准备阶段\\r\\n\\r\\n    各个参\"},{\"url\":\"/java/distributed/分布式锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- mysql\\r\\n- redis 的 setnx\\r\\n- redission\\r\\n- redLock\\r\\n- zookeeper\\r\\n- curator\\r\\n\\r\\nredis的分布式锁可用性更高，但是分布式不友好。一般单机的redis实现分布式锁性能就够用。\\r\\n\\r\\n如果非要要求可靠性，可以选择zk，只是zk是cp的，性能要差一点。\\r\\n\\r\\n\\r\\n\\r\\n Reids分布式锁\\r\\n\\r\\nredis实现分布式锁\\r\\n\\r\\n\\r\\n\\r\\n 手写 zk 分布式锁\\r\\n\\r\\nzk 实现分布式锁，是依赖 zk 的临时有序节点。\\r\\n\\r\\n多个线程在 rootPath 下面按顺序创建节点。\\r\\n\\r\\n1. 首先有持久节点lock\\r\\n2. 每个请求获取锁\"},{\"url\":\"/java/distributed/幂等性问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"幂等性问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"常见幂等问题\\r\\n\\r\\n解决常见幂等性问题采用 `一锁、二判、三更新` 就可以解决。\\r\\n\\r\\n- 一锁：锁定需要处理的订单\\r\\n- 二判：订单是否支付\\r\\n- 三更新：更新订单状态\\r\\n\\r\\n 数据库锁-悲观锁\\r\\n\\r\\n- for Update\\r\\n  \\r\\n    `FOR UPDATE` 子句告诉数据库管理系统（DBMS）在检索行的同时锁定这些行，直到当前事务结束。\\r\\n    \\r\\n\\r\\n```java\\r\\nBEGIN;\\r\\n\\r\\nSELECT * FROM orders\\r\\nWHERE order_id = 123\\r\\nFOR UPDATE;\\r\\n\\r\\n-- 进行业务逻辑处理，例如更新订单状态\\r\\nUPDATE orders \"},{\"url\":\"/java/io/BIO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BIO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"JDK 网络编程 BIO，意为阻塞的 IO。\\r\\n\\r\\nBIO 的阻塞体现在两个方面：\\r\\n\\r\\n1. 若一个服务端的服务绑定端口启动后，主线程就会一直等待客户端的连接。\\r\\n2. 客户端和服务端 Socket 端口建立连接之后，在读取到 Socket 信息之前，线程一直处于等待，一直处于阻塞状态。\\r\\n\\r\\n典型的 请求 -应答模型\\r\\n\\r\\n由一个独立的 `Acceptor` 模型监听客户端的请求，收到请求后为每一个客户端创建一个线程去处理，处理完成后将结果返回给客户端。\\r\\n\\r\\nJava BIO：传统的网络通讯模型，就是BIO，同步阻塞IO。\\r\\n\\r\\n其实就是服务端创建一个ServerSocket， 然后就是\"},{\"url\":\"/java/io/IO多路复用.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IO多路复用\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"小白也看得懂的 I/O 多路复用解析（超详细案例）_哔哩哔哩_bilibili\\r\\n\\r\\n 基础概念\\r\\n\\r\\n\\r\\n\\r\\n1. Socket\\r\\n\\r\\n   套接字，在网络通信中，就是客户端和服务端的出入口。\\r\\n\\r\\n   \\r\\n&gt;\\r\\n2. fd\\r\\n\\r\\n   文件描述符，是指向资源文件的索引。\\r\\n\\r\\n\\r\\n Socket通讯的过程\\r\\n\\r\\n\\r\\n\\r\\n1. 服务端通过 bind 绑定机器的端口号， 进程 listen 某个端口。\\r\\n2. 客户端和服务端通过 tcp 三次握手建联。\\r\\n3. 进行数据交互，\\r\\n4. 最后通过 close 断开连接。\\r\\n\\r\\n IO模型\\r\\n\\r\\n\\r\\n\\r\\n 同步阻塞IO - BIO\\r\\n\\r\\n-\"},{\"url\":\"/java/io/NIO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"NIO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NIO 是 JDK1.4 引入，为了解决 BIO 阻塞的问题，又称 `no-blocking io`。\\r\\n\\r\\n同步非阻塞\\r\\n\\r\\n NIO特点\\r\\n\\r\\n- 面向缓冲区\\r\\n  \\r\\n    BIO 是面向流的，NIO 是面向缓冲区的。\\r\\n    \\r\\n    \\r\\n\\r\\n- 非阻塞模式\\r\\n  \\r\\n    NIO 的非阻塞模式，使其线程从 Channel 获取数据时，即使获取不到数据也不会阻塞线程。\\r\\n    \\r\\n\\r\\n NIO 核心组件\\r\\n\\r\\n\\r\\n\\r\\n Selector-轮询选择器\\r\\n\\r\\nJava NIO 的选择器允许一个单独的线程来监视多个输入通道（Channel）。\\r\\n\\r\\n选择器用于检测一个或多个通道的状\"},{\"url\":\"/java/io/Reactor模式.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Reactor模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Reactor模式详解＋源码实现\\r\\n\\r\\n整个 reactor 模式解决的主要问题就是在接收到任务后根据分发器快速进行分发给相应的事件处理器，不需要从开始状态就阻塞。\\r\\n\\r\\n基于事件驱动模型，当接收到请求后会将请求封装成事件，并将事件分发给相应处理事件的Handler，handler处理完成后将事件状态修改为下一个状态，再由Reactor将事件分发给能够处理下一个状态的handler进行处理。\\r\\n\\r\\n\\r\\n\\r\\n1. EventHandler：事件处理器，可以根据事件的不同状态创建处理不同状态的处理器；\\r\\n   \\r\\n    ```java\\r\\n    public abstract class Eve\"},{\"url\":\"/java/io/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- BIO\\r\\n- 基于BIO实现RPC框架\\r\\n- NIO\\r\\n- Reactor模式\\r\\n- IO多路复用\"},{\"url\":\"/java/io/基于BIO实现RPC框架.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"基于BIO实现RPC框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基于bio手写实现简单的rpc_java 手写一个bio-CSDN博客\\r\\n\\r\\n RPC\\r\\n\\r\\n\\r\\n\\r\\n RPC设计\\r\\n\\r\\n\\r\\n\\r\\nRPC 的核心就是让客户端调用远程服务方法，就像调用本地方法一样。\\r\\n\\r\\n- 服务端将自己的类注册到远程服务。\\r\\n- 客户端通过注册中心获取到服务端地址。\\r\\n    - 客户端调用服务端地址，传入类名，调用方法、入参\\r\\n    - 服务端收到方法信息后，本地通过反射执行方法，获取结果返回给客户端。\\r\\n- 客户端需要写一个需要调用的类，和服务端的类保持一致（方法名、入参类型、入参）。\\r\\n    - 客户端需要对这个类进行动态代理，实际访问的是该类的代理对象。\\r\\n   \"},{\"url\":\"/java/jvm/CPU负载过高排查记录.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"CPU负载过高排查记录\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"解决线上微服务容器cpu占用100%问题（java进程占用100%问题）_容器cpu占用高_上树的蜗牛儿的博客-CSDN博客\\r\\n\\r\\n 平台发现问题\\r\\n\\r\\n平台发现集群节点 node219 CPU利用率过高。\\r\\n\\r\\n\\r\\n\\r\\n通过查看该节点下的 pod 发现，bookdemo 使用 CPU 过高。\\r\\n\\r\\n\\r\\n\\r\\n 主机排查\\r\\n\\r\\n top 查看进程情况\\r\\n\\r\\n使用 top 确认占用cpu过高的进程。\\r\\n\\r\\nPID=17177 占用 CPU 最高。\\r\\n\\r\\n\\r\\n\\r\\n 查看进程 PID 对应的容器\\r\\n\\r\\n由于该进程是个POD，需要找到对应容器，进入容器内部排查线程情况。\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 容器内部\"},{\"url\":\"/java/jvm/G1收集器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"G1收集器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- XX:+UseG1GC\\r\\n\\r\\nG1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对 配备多颗处理器及大容量内存的机器，以极高概率满足GC停顿时间要求的同时，还具备高吞吐量性能特征。\\r\\n\\r\\nG1 收集器 在 JDK1.7 正式启用，是 JDK 9以后的默认垃圾收集器，取代了 CMS 以及 Parallel+Parallel Old 的组合，被 Oracle 官方称为“全功能的垃圾收集器”。\\r\\n\\r\\n- 适合大内存机器，具备高吞吐量。\\r\\n- 低 GC 停顿时间。\\r\\n\\r\\n 堆分布\\r\\n\\r\\n 区域分布\\r\\n\\r\\n\\r\\n\\r\\n区分于传统的堆内存分布，G1 是将 JVM 堆内存划分为了多个 \"},{\"url\":\"/java/jvm/JDK调优命令.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JDK调优命令\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"jstack\\r\\n\\r\\n 死锁检测\\r\\n\\r\\n1. 使用 jps 命令查看运行中的 java 进程 Id。\\r\\n   \\r\\n    \\r\\n    \\r\\n2. 使用 jstack 分析线程状态。\\r\\n   \\r\\n    ```\\r\\n    jstack 进程Id\\r\\n    ```\\r\\n    \\r\\n    - 线程状态\\r\\n      \\r\\n        通过分析进程可以得到，`DeadLockTest` 进程的两个线程分别为 `pool-1-thread-2` （简称2）和 `pool-1-thread-1`（简称1）。\\r\\n        \\r\\n        通过打印的线程信息可以发现，线程 2 和 1 的线程状态都是 \"},{\"url\":\"/java/jvm/JVM内存模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JVM内存模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java 内存模型在 JDK1.7 主要包含以下区域。\\r\\n\\r\\n- 程序计数器\\r\\n- 虚拟机栈\\r\\n- 本地方法栈\\r\\n- 方法区\\r\\n- 堆\\r\\n\\r\\n而在 JDK1.8中将运行时数据区中的方法区给取消了，换成了本地内存中的元数据区。\\r\\n\\r\\n- 程序计数器\\r\\n- 虚拟机栈\\r\\n- 本地方法栈\\r\\n- 堆\\r\\n- 元数据区\\r\\n\\r\\n 内存模型图\\r\\n\\r\\n1. JDK 1.7 内存模型图\\r\\n   \\r\\n    \\r\\n    \\r\\n2. JDK 1.8 内存模型图\\r\\n   \\r\\n    JDK1.8中取消了运行时数据区中的方法区，换成了元数据区放到了本地内存里。\\r\\n    \\r\\n    \\r\\n    \\r\\n\\r\\n 运行时数据区\\r\\n\\r\\n\"},{\"url\":\"/java/jvm/Java类加载器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"类加载器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"什么是类加载器\\r\\n\\r\\n类加载器（ClassLoader）就是在系统运行过程中动态的将编译后的.class字节码文件加载到JVM中的工具。在IDE中编写的源代码文件都是`.java`文件，通过编译对应生成`.class`文件。而类加载器就是用来将`.class`文件加载到JVM中的工具。\\r\\n\\r\\n 类加载器类型\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nJava默认提供了三个类加载器，分别是 AppClassLoader、ExtClassLoader、BootstrapClassLoader，除此之外还可以自定义类加载器。类加载器之间是父级的关系，但不是通过继承实现父级关系的，而是通过组合的形式来实现的，在`Clas\"},{\"url\":\"/java/jvm/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JVM\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、类加载器\\r\\n\\r\\n- 类加载器\\r\\n- 对象创建\\r\\n\\r\\n 二、内存模型\\r\\n\\r\\n- JVM内存模型\\r\\n\\r\\n 三、垃圾回收\\r\\n\\r\\n- 垃圾回收算法\\r\\n- 垃圾回收器\\r\\n- G1收集器\\r\\n\\r\\n 四、命令工具\\r\\n\\r\\n- JDK调优命令\\r\\n- 可视化工具\\r\\n\\r\\n 五、排障记录\\r\\n\\r\\n- CPU负载过高排查记录\\r\\n- 内存问题排查总结\\r\\n- 频繁GC排查\\r\\n\\r\\n---\"},{\"url\":\"/java/jvm/内存问题排查总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内存问题排查总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"堆内存dump\\r\\n\\r\\n```\\r\\n1 jmap ‐dump:format=b,file=eureka.hprof 14660\\r\\n```\\r\\n\\r\\n可以配置自动 dump 文件，在内存溢出的时候会自动 dump 文件。\\r\\n\\r\\n```\\r\\n-XX:+HeapDumpOnOutOfMemoryError\\r\\n```\\r\\n\\r\\n比如应用的启动脚本，开启自动 dump 文件。\\r\\n\\r\\n```\\r\\nexec java -classpath $CLASSPATH -Xms1024m -Xmx2048m\\r\\n-XX:+HeapDumpOnOutOfMemoryError\\r\\n-Dquery.type=es\\r\\n-Dfile.enco\"},{\"url\":\"/java/jvm/可视化工具.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可视化工具\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"jconsole\\r\\n\\r\\njconsole是JDK 提供的可视化工具。可以查看内存、线程数量、CPU等资源信息。\\r\\n\\r\\n 使用方式\\r\\n\\r\\n 本地进程\\r\\n\\r\\n直接执行命令\\r\\n\\r\\n```java\\r\\njconsole\\r\\n```\\r\\n\\r\\n 远程进程\\r\\n\\r\\n```java\\r\\n-Djava.rmi.server.hostname=10.10.102.81-Dcom.sun.management.jmxremote.port=9999-Dcom.sun.management.jmxremote-Dcom.sun.management.jmxremote.authenticate=false\\r\\n-Dcom.sun\"},{\"url\":\"/java/jvm/垃圾回收器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"垃圾回收器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"垃圾回收类型\\r\\n\\r\\n1. 串行\\r\\n    - 单线程\\r\\n    - 适合堆内存小的时候。\\r\\n    - STW\\r\\n      \\r\\n        Stop The World 的简称。这是因为串行的机制，在垃圾回收的线程运行的时候，其它工作线程都要阻塞。\\r\\n        \\r\\n        *在垃圾回收过程中，对象的地址会发生改变。如果其它线程不阻塞，则可能会发生对象引用错误的问题。*\\r\\n    \\r\\n2. 吞吐量优先\\r\\n    - 多线程\\r\\n    - 适合堆内存较大，且多核CPU的情况。\\r\\n    - 在单位时间内，STW时间最短。\\r\\n3. 响应时间优先\\r\\n    - 多线程\\r\\n    -\"},{\"url\":\"/java/jvm/垃圾回收算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"垃圾回收算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"如何判断对象可以回收\\r\\n\\r\\n 引用计数法\\r\\n\\r\\n为对象添加引用计数器，如果对象被其它对象引用一次，计数器 +1；对应引用释放，则计数器 -1；只有当计数器为 0 时该对象才会被垃圾回收。\\r\\n\\r\\n- 引用计数法造成的内存泄漏\\r\\n  \\r\\n    像下面这种即使对象不被其它对象引用，这两个对象也一直不会被回收，因为对象A和B之间存在引用关系，引用计数器一直为 1，这样就导致了内存泄露。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n\\r\\n\\r\\n\\r\\n 可达性分析算法\\r\\n\\r\\n&gt; 如果某个对象到GC Roots间没有任何引用链相连， 或者用图论的话来说就是从GC Roots到这个对象不可达时，则证明此\"},{\"url\":\"/java/jvm/对象创建.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"对象创建\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"对象的创建流程\\r\\n\\r\\n\\r\\n\\r\\n 类加载检查\\r\\n\\r\\n判断有无加载过该类，有则直接进入下一步、没有则加载类对象。\\r\\n\\r\\n 分配内存\\r\\n\\r\\n虚拟机为新生对象分配内存。\\r\\n\\r\\n对象所需内存大小在类检查阶段便可确定，为对象分配空间就是将一块确定大小内存从 Java 堆中划分出来。\\r\\n\\r\\n 1. 划分内存的方法\\r\\n\\r\\n- 指针碰撞法\\r\\n  \\r\\n    该方法是JVM中的默认方法。\\r\\n    \\r\\n    它主要就是假设JVM中的内存是绝对规整的，使用过的内存和未使用过的内存分别放在两边，用一个指针来给他们做区分。如果要分配内存，只需要将指针向空闲的那一端移动对象大小的位置就好了。\\r\\n    \\r\\n- 空闲列表\"},{\"url\":\"/java/jvm/类加载器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"类加载器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"什么是类加载器\\r\\n\\r\\n类加载器（ClassLoader）就是在系统运行过程中动态的将编译后的.class字节码文件加载到JVM中的工具。在IDE中编写的源代码文件都是`.java`文件，通过编译对应生成`.class`文件。而类加载器就是用来将`.class`文件加载到JVM中的工具。\\r\\n\\r\\n 类加载器类型\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nJava默认提供了三个类加载器，分别是 AppClassLoader、ExtClassLoader、BootstrapClassLoader，除此之外还可以自定义类加载器。类加载器之间是父级的关系，但不是通过继承实现父级关系的，而是通过组合的形式来实现的，在`Clas\"},{\"url\":\"/java/jvm/频繁GC排查.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"频繁GC排查\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```\\r\\njstat -gcutil 1000\\r\\n```\\r\\n\\r\\n\\r\\n\\r\\n```\\r\\njmap -dump:format=b,file=dumpfile 1000\\r\\n```\\r\\n\\r\\n使用 MAT 工具分析代码\\r\\n\\r\\n---\\r\\n\\r\\n组件消费数据的线程池配置有问题。\"},{\"url\":\"/middleware/es/BulkProcessor死锁问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BulkProcessor死锁问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"问题原因\\r\\n\\r\\n- 定时flush\\r\\n- bulk操作\\r\\n- retryHandler：失败重试\\r\\n1. 定时 flush 和 retryHandler 用的是一个定时线程池，而该线程池只有一个线程。\\r\\n2. 定时 flush 的方法用的锁和 bulk 操作时的锁是同一把锁。都是类对象级别的锁。\\r\\n   \\r\\n    \\r\\n    \\r\\n    \\r\\n    \\r\\n3. 当bluk失败后，会触发默认的重试逻辑。\\r\\n4. 如果重试时候 flush 刚好运行，就会出现这种死锁情况。\\r\\n    1. bulk持有对象锁`BulkProcessor.class`，进行重试逻辑。\\r\\n    2. flush占有线\"},{\"url\":\"/middleware/es/ES分片.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES分片\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"同一个索引会划分为多个分片。分片可以设置副本数量，分为主分片和副本分片。\\r\\n\\r\\n```java\\r\\n 指定索引的主分片和副本分片数\\r\\nPUT /blogs\\r\\n{\\r\\n  \\\"settings\\\": {\\r\\n    \\\"number_of_shards\\\": 3,\\r\\n    \\\"number_of_replicas\\\": 1\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n 主分片\\r\\n\\r\\n- 解决数据水平扩展的问题。同一个索引可以按照分片分配数据，将数据平均分配到所有节点之上。\\r\\n- 主分片数创建好后就不能修改。\\r\\n- 一个分片就是一个运行的 Lucene 实例。\\r\\n\\r\\n 主分片过少\\r\\n\\r\\n- 单个分片数据量过大。查询较慢，利用\"},{\"url\":\"/middleware/es/ES压测记录和esrally使用.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES压测记录和esrally使用\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"环境信息\\r\\n\\r\\n- 压测环境\\r\\n  \\r\\n    ```\\r\\n    http://10.1.11.200:39200/\\r\\n    ```\\r\\n    \\r\\n- 开发环境\\r\\n  \\r\\n    ```java\\r\\n    http://10.10.101.69:39200\\r\\n    ```\\r\\n    \\r\\n- 测试环境\\r\\n  \\r\\n    ```java\\r\\n    http://10.10.103.218:39200/\\r\\n    ```\\r\\n    \\r\\n\\r\\n esrally安装\\r\\n\\r\\n docker安装\\r\\n\\r\\n1. 拉取镜像\\r\\n   \\r\\n    ```\\r\\n    docker pull elastic/rally\"},{\"url\":\"/middleware/es/ES参数调优.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES参数调优\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"预防脑裂\\r\\n\\r\\n\\r\\n\\r\\n重要配置的修改 | Elasticsearch: 权威指南 | Elastic\\r\\n\\r\\n 堆内存设置\\r\\n\\r\\n```\\r\\n -Xms2730m -Xmx2730m -Duser.timezone=Asia/Shanghai\\r\\n```\\r\\n\\r\\nxms和xmx设置一样大小，并设置为略小于pod分配内存的一半。\\r\\n\\r\\n 分片设置\\r\\n\\r\\n分片过小或过多都会影响es的查询速率。\\r\\n\\r\\n一经设置无法修改。\\r\\n\\r\\n目前是10个分片，数据量不大的情况下，设置为5个分片进行测试一下。1个、和node数量一致分片测试。\\r\\n\\r\\n1GB 20个分片\\r\\n\\r\\n1个 20G～40GB\\r\\n\\r\\n 副本数量\\r\\n\\r\"},{\"url\":\"/middleware/es/ES深度分页问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES深度分页问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"from+to分页\\r\\n\\r\\nes在查询时候默认使用的是分页查询，单次只会返回10条数据。\\r\\n\\r\\n可以指定size。\\r\\n\\r\\n\\r\\n\\r\\n- 查询要求默认 from+size 的结果必须不超过10000。\\r\\n  \\r\\n    可以通过修改配置\\r\\n    \\r\\n    ```java\\r\\n    \\\"index.max_result_window\\\":\\\"20000\\\"\\r\\n    ```\\r\\n    \\r\\n    限制单词查询满足条件的结果窗口的大小，由from+size共同决定。\\r\\n    \\r\\n    因为es是先将数据全查出来再做分页，这样做是为了限制内存的消耗。\\r\\n    \\r\\n    ---\\r\\n    \\r\\n    因\"},{\"url\":\"/middleware/es/ES滚动查询-Scroll.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES滚动查询-Scroll\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"原理\\r\\n\\r\\nElasticsearch中的滚动查询是基于 固定的排序规则 来加载一部分数据。\\r\\n\\r\\n当用户刷新时，将从上次加载的最后一条数据的位置再加载同样数量的数据。\\r\\n\\r\\n滚动查询的原理类似于分页查询，但是滚动查询不需要重新执行搜索，只需要继续检索下一批结果。在滚动查询中，每次只加载当前页的数据，而不是一次性加载所有数据。这使得滚动查询比分页查询更高效，因为滚动查询不需要将所有数据都存储在内存中。同时，滚动查询也适用于大量数据的处理，因为它可以分批次地处理数据，而不是一次性处理所有数据。\\r\\n\\r\\n 滚动查询的排序规则\\r\\n\\r\\n滚动查询的排序规则不一定是时间。在Elasticsearch中，滚动\"},{\"url\":\"/middleware/es/ES的log4j2日志自动清理配置.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES的log4j2日志自动清理配置\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"配置\\r\\n\\r\\n```xml\\r\\nappender.rolling.strategy.type = DefaultRolloverStrategy\\r\\nappender.rolling.strategy.fileIndex = nomax\\r\\nappender.rolling.strategy.action.type = Delete\\r\\nappender.rolling.strategy.action.basepath = ${sys:es.logs.base_path}\\r\\nappender.rolling.strategy.action.condition.type = IfFileName\\r\\napp\"},{\"url\":\"/middleware/es/ES聚合查询原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES聚合查询原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES在对海量数据进行聚合分析的时候会损失搜索的精准度来满足实时性的需求。\"},{\"url\":\"/middleware/es/ES集群.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES集群\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集群节点类型\\r\\n\\r\\n1. Master Node - 主节点\\r\\n2. DataNode - 数据节点\\r\\n3. Coordinating Node - 协调节点\\r\\n\\r\\n Master Node\\r\\n\\r\\n- 处理创建，删除索引等请求。\\r\\n- 决定分片被分配到哪个节点。\\r\\n- 维护并更新集群 state。\\r\\n\\r\\n Master Node节点最佳实践\\r\\n\\r\\n- Master节点非常重要，在部署上需要解决单点问题。\\r\\n- 为一个集群设置多个Master节点，而且节点只承担 Master 角色。\\r\\n\\r\\n Data Node\\r\\n\\r\\n保存数据的节点，负责保存分片数据。\\r\\n\\r\\n通过增加数据节点可以解决数据水平扩展\"},{\"url\":\"/middleware/es/Elasticsearch写入原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch写入原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本概念\\r\\n\\r\\n 索引\\r\\n\\r\\nElasticsearch的索引是一个逻辑上的概念，指存储了相同类型的文档集合。\\r\\n\\r\\n 映射\\r\\n\\r\\n映射（mapping）定义索引中有什么字段、进行字段类型确认。类似于数据库中表结构定义。\\r\\n\\r\\nES 默认动态创建索引和索引类型的 映射（mapping），就像是非关系型数据中的，无需定义表结构，更不用指定字段的数据类型。\\r\\n\\r\\n也可以手动指定 mapping 类型，比如通过请求设置索引的映射（mapping）。\\r\\n\\r\\n```java\\r\\ncurl --location --request POST 'localhost:9200/course/_mapping' \"},{\"url\":\"/middleware/es/Elasticsearch基础概念.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch基础概念\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础概念\\r\\n\\r\\n 一、索引库（index）\\r\\n\\r\\nElasticsearch的索引库是一个逻辑上的概念，存储了相同类型的文档内容。类似于 MySQL 数据表，MongoDB 中的集合。\\r\\n\\r\\n1. 新建索引库\\r\\n    - number_of_shards\\r\\n      \\r\\n        设置分片的数量，在集群中通常设置多个分片，表示一个索引库将拆分成多片分别存储不同 的结点，提高了ES的处理能力和高可用性，入门程序使用单机环境，这里设置为 1。\\r\\n        \\r\\n    - number_of_replicas\\r\\n      \\r\\n        设置副本的数量，设置副本是为了提高ES的\"},{\"url\":\"/middleware/es/Elasticsearch查询原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch查询原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES查询原理\\r\\n\\r\\n 查询方式\\r\\n\\r\\n- 根据 doc_id 查询。\\r\\n\\r\\n\\r\\n\\r\\n- 根据条件查询\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引\\r\\n\\r\\n根据文档中的每个字段建立倒排索引。\\r\\n\\r\\n 倒排索引的查询流程\\r\\n\\r\\n\\r\\n\\r\\n1. 查询条件分词。\\r\\n2. 查询单词词典 （term dictionary）。\\r\\n3. 获取对应分词的 doc_id 列表。\\r\\n4. 将查询结果返回。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 倒排索引的组成\\r\\n\\r\\n- postings list\\r\\n  \\r\\n    文档列表。\\r\\n    \\r\\n- term dictionary\\r\\n  \\r\\n    单词字典表。包含文档中所有的单词，es 会将单词排序\"},{\"url\":\"/middleware/es/Elasticsearch检索.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch检索\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"检索方式\\r\\n\\r\\nElasticsearch提供两种检索方式。\\r\\n\\r\\n1. RestAPI 形式通过 URL 参数进行检索。\\r\\n2. 通过 DSL 语句进行查询，通过传递 JSON 为请求体与 Elasticsearch 进行交互，这种方式更强大简洁。\\r\\n\\r\\n URL检索\\r\\n\\r\\n`GET /{index}/{type}/_search?q=*&sort=age:desc&size=5&from=0&_source=name,age,bir`\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\nq=* ：匹配所有文档\\r\\n\\r\\nsort=age：按照指定字段进行排序，默认为升序，:desc 降序排列\\r\\n\\r\\nsize：展示多少\"},{\"url\":\"/middleware/es/Elasticsearch聚合查询.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch聚合查询\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES在对海量数据进行聚合分析的时候会损失搜索的精准度来满足实时性的需求。\\r\\n\\r\\n Elasticsearch聚合查询总结\\r\\n\\r\\n 1. 求和、最大值、最小值、平均值\\r\\n\\r\\n- 求和 - sum\\r\\n- 最大值 - max\\r\\n- 最小值 - min\\r\\n- 平均值 - avg\\r\\n\\r\\n---\\r\\n\\r\\nDSL查询语句\\r\\n\\r\\n```java\\r\\n{\\r\\n    \\\"size\\\": 0,\\r\\n    \\\"query\\\": {\\r\\n        \\\"bool\\\": {\\r\\n            \\\"filter\\\": [\\r\\n                {\\r\\n                    \\\"range\\\": {\\r\\n    \"},{\"url\":\"/middleware/es/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础总结\\r\\n\\r\\n- Elasticsearch基础概念\\r\\n- Elasticsearch检索\\r\\n- Elasticsearch聚合查询\\r\\n\\r\\n\\r\\n- ES滚动查询-Scroll\\r\\n- 批量操作Bulk和BulkProcessor\\r\\n- BulkProcessor死锁问题\\r\\n\\r\\n\\r\\n- 并发场景修改文档\\r\\n- ES深度分页问题\\r\\n\\r\\n\\r\\n- ES集群\\r\\n- ES分片\\r\\n\\r\\n 原理总结\\r\\n\\r\\n- 倒排索引原理\\r\\n- Elasticsearch写入原理\\r\\n- Elasticsearch查询原理\\r\\n- ES聚合查询原理\\r\\n\\r\\n 使用问题\\r\\n- ES参数调优\\r\\n- 集群脑裂-参数配置\\r\\n\\r\\n\\r\\n- ES\"},{\"url\":\"/middleware/es/倒排索引原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"倒排索引图解\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"原理图\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引的搜索过程\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引原理\\r\\n\\r\\nElasticsearch 主要功能就是搜索，为了提高搜索效率，其内部使用了倒排索引。\\r\\n\\r\\n 正排索引\\r\\n\\r\\n在搜索引擎中，每个文件对应一个文件 ID （doc_id），文件内容是关键词的集合。\\r\\n\\r\\n\\r\\n\\r\\n根据 `doc_id` 可以查找到文档详情。\\r\\n\\r\\n*这种方式本质上就是通过文档的 key 查找 value 值。*\\r\\n\\r\\n比如查找 `name=jetty wan` 的文档，只能按照顺序从前向后匹配每个文档的 name 字段。\\r\\n\\r\\n这种查找方式的效率非常低下。\\r\\n\\r\\n 倒排索引\\r\\n\\r\\n倒排索引和正向索引\"},{\"url\":\"/middleware/es/并发场景修改文档.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"并发场景修改文档\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES从7.X版本默认使用的是乐观锁机制修改文档。\\r\\n\\r\\n当在高并发环境下使用乐观锁机制修改文档时，要带上当前文档的_seq_no和_primary_term进行更新：\\r\\n\\r\\n```java\\r\\nPOST /es_db/_doc/2?if_seq_no=21&if_primary_term=6{  \\\"name\\\": \\\"李四xxx\\\"}\\r\\n```\\r\\n\\r\\n如果冲突会提示版本冲突异常。\"},{\"url\":\"/middleware/es/批量操作Bulk和BulkProcessor.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"批量操作Bulk和BulkProcessor\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"es的批量操作，6.x版本的es中high-rest-client中可以用到以下三种。\\r\\n\\r\\n- bulk\\r\\n- bulkAsync\\r\\n- bulkProcessor\\r\\n\\r\\n Bulk\\r\\n\\r\\nbulk api 以此按顺序执行所有的 action（动作）。如果一个单个的动作因任何原因失败，它将继续处理它后面剩余的动作。当 bulk api 返回时，它将提供每个动作的状态（与发送的顺序相同），所以您可以检查是否一个指定的动作是否失败了。\\r\\n\\r\\nes可以通过 _bulk 的API实现批量操作。\\r\\n\\r\\n```java\\r\\nPOST _bulk\\r\\n{\\\"create\\\":{\\\"_index\\\":\\\"article\\\"\"},{\"url\":\"/middleware/es/集群脑裂-参数配置.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集群脑裂-参数配置\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集群脑裂的问题\\r\\n\\r\\n 什么是集群脑裂\\r\\n\\r\\nes 在主节点上产生分歧，产生多个master 节点，从而使集群分裂成多个同名集群，使得集群处于异常状态。\\r\\n\\r\\n当出现多个master节点的时候，可能发生写入请求分配到不同的master节点，而数据只保存在对应的master节点的分片上，不会复制到其它节点。此时若访问不同的节点，会发现查询的结果是不一样的。\\r\\n\\r\\n 举例说明脑裂\\r\\n\\r\\n`discovery.zen.minimum_master_nodes` 参数之前设置为 1（默认值）。\\r\\n\\r\\n这个参数的含义是限制选举master节点的数量。\\r\\n\\r\\n- 当master节点不存在时，至少有几个ma\"},{\"url\":\"/middleware/kafka/Kafka分区机制策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka分区机制策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"分区策略\\r\\n\\r\\n分区策略是决定生产者将消息发送到哪个分区的算法。\\r\\n\\r\\n 轮询策略\\r\\n\\r\\n是 Java 生产者 API 默认提供的分区策略。\\r\\n\\r\\n- 轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。\\r\\n\\r\\n\\r\\n\\r\\n 随机策略\\r\\n\\r\\n将消息随机写入分区\\r\\n\\r\\n key 指定分区\\r\\n\\r\\n当发送消息时指定了key，Kafka会根据key的hash值与分区数取模来决定将数据写入哪个分区。\\r\\n\\r\\n项目中 dr 就是生产这种方式，根据消息类型指定 key，比如 transactionId。这样能保证同一t\"},{\"url\":\"/middleware/kafka/Kafka副本机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka副本机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka 的副本是针对分区来说的，为分区创建副本。\\r\\n\\r\\n副本的作用就是提供数据冗余，在 Leader 副本挂掉之后，转换为 Leader 副本继续工作。\\r\\n\\r\\n不然当 Leader 副本挂掉之后，该分区就会停止对外提供服务。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 副本同步\\r\\n\\r\\n\\r\\n\\r\\n生产者只会往分区的 Leader 发消息，而其它 Follower 会从 Leader 拉取数据进行同步。\\r\\n\\r\\n Follower追随者副本\\r\\n\\r\\nFollower 副本是不对外提供服务的，只是定期地异步拉取领导者副本中的数据而已。\\r\\n\\r\\n LSR副本集合\\r\\n\\r\\nLSR集合里面保存的副本都是与 Leader 副本\"},{\"url\":\"/middleware/kafka/Kafka总控制器Controller.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka总控制器 Controller\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 kafka中会有多个 Broker，其中一个 Broker 会被选举为 Controller，负责管理整个集群中分区和副本的状态。\\r\\n\\r\\n Zookeeper\\r\\n\\r\\nzk 使用的数据模型类似于文件系统的树形结构，根目录也是以“/”开始。该结构上的每个节点被称为 znode，用来保存一些元数据协调信息。\\r\\n\\r\\nZooKeeper 常被用来实现集群成员管理、分布式锁、领导者选举等功能。\\r\\n\\r\\nznode 用来保存元数据信息。\\r\\n\\r\\n- 永久性 znode\\r\\n  \\r\\n    持久性 znode 不会因为 ZooKeeper 集群重启而消失。\\r\\n    \\r\\n- 临时性 znode\\r\\n  \\r\\n   \"},{\"url\":\"/middleware/kafka/Kafka手动重新分区.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka手动重新分区\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka重分配分区_kafka重新分配分区-CSDN博客\\r\\n\\r\\n1. 确定需要重新分区的 topic\\r\\n   \\r\\n    vi topics-to-move.json\\r\\n    \\r\\n    ```java\\r\\n    \\r\\n    {\\r\\n      \\\"topics\\\": [{\\r\\n         \\\"topic\\\": \\\"test-topic\\\"\\r\\n       }],\\r\\n       \\\"version\\\": 1\\r\\n    }\\r\\n    ```\\r\\n    \\r\\n    - topic 可以批量设置\\r\\n2. 根据 topic 生成执行计划\\r\\n   \\r\\n    ```java\\r\\n    bin/kafka-rea\"},{\"url\":\"/middleware/kafka/Kafka消费策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka消费策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka消费者-主动批量拉取\\r\\n\\r\\n\\r\\n&gt; \\r\\n1. kafka配置类\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\n@Slf4j\\r\\npublic class KafkaConfig {\\r\\n\\r\\n    @Bean\\r\\n    public KafkaListenerContainerFactory&lt;?&gt; batchFactory(ConsumerFactory consumerFactory){\\r\\n        ConcurrentKafkaListenerContainerFactory&lt;Integer,String&gt; factory =\\r\\n    \"},{\"url\":\"/middleware/kafka/Kafka生产者参数.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka生产者参数\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- bootstrap.servers： broker的地址\\r\\n- key.serializer：关键字的序列化方式\\r\\n- value.serializer：消息值的序列化方式\\r\\n- acks：指定必须要有多少个分区的副本接收到该消息，服务端才会向生产者发送响应，可选值为：0,1,2，…，all\\r\\n- buffer.memory：生产者的内存缓冲区大小。如果生产者发送消息的速度 \\r\\n- max.block.ms：表示send()方法在抛出异常之前可以阻塞多久的时间，默认是60s\\r\\n- compression.type：消息在发往kafka之前可以进行压缩处理，以此来降低存储开销和网络带宽。默认\"},{\"url\":\"/middleware/kafka/Kafka高性能的原因.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka高性能的原因\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 写数据是按照磁盘顺序读写。\\r\\n   \\r\\n    保证顺序读写，比随机写性能要高很多。\\r\\n    \\r\\n    数据保存在 log 中，并对 log 进行了分段（logSegment）技术，对 logSegment 还增加了日志索引。\\r\\n    \\r\\n2. 数据传输的零拷贝，使的数据在内核空间中就完成了读写操作。\\r\\n   \\r\\n    零拷贝原理：\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 读写数据的批量处理以及压缩传输。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n\\r\\n 零拷贝\\r\\n\\r\\n- 传统数据文件拷贝过程\\r\\n  \\r\\n    整个过程需要在内核空间和应用空间之间拷贝 2 次。\\r\\n    \"},{\"url\":\"/middleware/kafka/Producer发布消息机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Producer发布消息机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"写入机制\\r\\n\\r\\nProducer 通过push模式将消息发给 Broker，每条消息都被追加到对应的 Partition。而且是采用顺序写磁盘的方式（顺序写比随机写效率高，保障 Kafka 高吞吐量）。\\r\\n\\r\\n 消息路由模式\\r\\n\\r\\nProducer 如何确认消息发到哪个 Partition 上？\\r\\n\\r\\n1. 指定了 Partition，直接使用。\\r\\n2. 如果未指定 Partition，指定了 Key。根据 Key 的 Hash 值计算 Partition。\\r\\n   \\r\\n    Hash(key) % num(Partition)\\r\\n    \\r\\n3. 如果未指定 Partition，也未指定 \"},{\"url\":\"/middleware/kafka/__consumer_offsets.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"__consumer_offsets\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"将 Consumer 的位移数据作为一条条普通的 Kafka 消息，提交到 consumer*offsets 中。可以这么说，consumer*offsets 的主要作用是保存 Kafka 消费者的位移信息。\\r\\n\\r\\n_*consumer*offsets也是一个 topic，也有分区。和 kafka 的 topic 基本一致支持自定义写入。但是它是内部的 topic，一般最好不要自动修改。\\r\\n\\r\\n 消息格式\\r\\n\\r\\n1. 分区消费的 offset\\r\\n    \\r\\n    位移主题的 Key 中应该保存 3 部分内容：\\r\\n    \\r\\n    标识某个消费者组里面某个 topic 的某个分区，已经被消费\"},{\"url\":\"/middleware/kafka/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka配置\\r\\n\\r\\n- Kafka消费策略\\r\\n- Kafka生产者参数\\r\\n- kafka的分区副本规划\\r\\n\\r\\n\\r\\n Kafka原理总结\\r\\n- kafka消费模型\\r\\n- kafka-ACK应答机制\\r\\n- kafka解决重复消费\\r\\n\\r\\n\\r\\n- Kafka分区机制策略\\r\\n- kafka保证消息不丢失\\r\\n- 消费者组\\r\\n- __consumer_offsets\\r\\n- Kafka总控制器Controller\\r\\n- Kafka副本机制\\r\\n\\r\\n\\r\\n- Producer发布消息机制\\r\\n- 高水位HW和LEO\\r\\n- 数据日志分段存储\\r\\n\\r\\n\\r\\n- Kafka高性能的原因\\r\\n\\r\\n 使用总结\\r\\n- Kafka手动\"},{\"url\":\"/middleware/kafka/kafka-ACK应答机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka生产者保证消息不丢失-ACK应答机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka 生产者写入数据的时候，引入了 ACK 应答机制。\\r\\n\\r\\n```java\\r\\n            Properties props = new Properties();\\r\\n            props.put(\\\"bootstrap.servers\\\", Configuration.KAFKA_ADDRESS);\\r\\n\\t\\t\\t\\t\\t\\t//1:leader应答就可以发送下一条，确保发送成功。\\r\\n            props.put(\\\"acks\\\", \\\"1\\\");\\r\\n\\t\\t\\t\\t\\t\\t......\\r\\n            props.put(\\\"key.serializer\\\", \\\"org.a\"},{\"url\":\"/middleware/kafka/kafka保证消息不丢失.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka保证消息不丢失\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。\\r\\n\\r\\n 生产者端消息丢失\\r\\n\\r\\n生产者发送消息的时候，如果没有发到 kafka 导致消息丢失（网络抖动），其实这并不是 kafka 的原因。\\r\\n\\r\\nkafka 能保证已经提交到 borker 的数据，不会丢失。\\r\\n\\r\\n默认生产者发数据，采用 `send(msg)`发数据，这样发数据之后生产者并不知道是否发送成功。\\r\\n\\r\\n最好使用 `producer.send(msg, callback)` 发数据，这样通过`callback`能够清楚的知道消息是否发送成功。\\r\\n\\r\\n 消费者端消息丢失\\r\\n\\r\\nConsu\"},{\"url\":\"/middleware/kafka/kafka消费模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka消费模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka消费模型分为两种。\\r\\n\\r\\n1. 消费组消费\\r\\n   \\r\\n    消费组里面的单个消费者消费一个分区的数据。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n    \\r\\n    \\r\\n    \\r\\n2. 消费者-worker进程消费。\\r\\n\\r\\n\\r\\n\\r\\n&gt; 第一种消费模型，每个分区对应一个 consumer。\\r\\n&gt; \\r\\n\\r\\n第二种消费模型，只消费数据不处理，处理的工作单独交给 worker线程池，这样可以避免很多 consumer产生的问题。不要把很重的处理逻辑放到消费者中。\\r\\n\\r\\n&gt; 难以保证 offset 的语义正确性，可能导致重复消费。\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n--\"},{\"url\":\"/middleware/kafka/kafka的分区副本规划.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka的分区副本规划\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. topic划分\\r\\n\\r\\n每个日志对应一个topic。\\r\\n\\r\\ntopic 有自己的分区数量和副本数量。一般根据kafka指定的默认数量自动生成。\\r\\n\\r\\n---\\r\\n\\r\\n 2. 分区数量\\r\\n\\r\\n当生产者发给kafka一条消息时，根据规则分到 topic 的指定分区（partition），所以每个分区的数据是不一样的。\\r\\n\\r\\n 规划分区数量\\r\\n\\r\\n消费者在消费数据的时候，也是从分区中消费的，同一个分区只能被消费组里的一个消费者去消费。\\r\\n\\r\\n比如kafka有3个borker时，假如配置topic有5个分区，分配到3个borker就会出现 2 2 1 的情况。\\r\\n\\r\\n所以在指定topic的分区数量时\"},{\"url\":\"/middleware/kafka/kafka解决重复消费.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka解决重复消费\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"技术干货分享 | Kafka重复消费场景及解决方案\\r\\n\\r\\n 导致重复消费的原因\\r\\n\\r\\n- enable.auto.commit 默认值true，表示消费者会周期性自动提交消费的offset\\r\\n- auto.commit.interval.ms 在enable.auto.commit 为true的情况下， 自动提交的间隔，默认值5000ms\\r\\n- max.poll.records 单次消费者拉取的最大数据条数，默认值 500\\r\\n- max.poll.interval.ms 默认值5分钟，表示若5分钟之内消费者没有消费完上一次poll的消息，那么consumer会主动发起离开group的请求\\r\\n1\"},{\"url\":\"/middleware/kafka/数据日志分段存储.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据日志分段存储\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"数据保存机制\\r\\n\\r\\n\\r\\n\\r\\nKafka 的数据是按照分区存储的，以 topic-partition 为目录保存数据。\\r\\n\\r\\n数据是存到 log 中，而 log 又引入了LogSegment机制。\\r\\n\\r\\n`log.segment.bytes`，默认 1G。当超过1G 之后，日志就会开始分割。\\r\\n\\r\\n而日志分段文件以及索引文件都是以基准偏移量（offset）命名的。\\r\\n\\r\\n基本每段的日志文件包含一个数据文件和两个索引文件。\\r\\n\\r\\n- 以offset 为索引的 `.index`。\\r\\n- 以时间戳为索引的 `.timeindex`。\\r\\n\\r\\n索引里面并不是保留全量的数据索引，而是以稀疏索引的方式保存（方\"},{\"url\":\"/middleware/kafka/消费者组.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"消费者组\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。\\r\\n\\r\\n- 组内的所有消费者协调在一起来消费订阅主题（Subscribed Topics）的所有分区（Partition）。\\r\\n- 每个分区只能由同一个消费者组内的一个 Consumer 实例来消费。\\r\\n\\r\\n比如 topic 有 6 个分区，消费者组里面的消费者数量最理想状态是 6 个，每个消费者消费一个分区。也可以是 3 个或者两个，这样分区能够平均分配。\\r\\n\\r\\n但是最好不要超过 6 个消费者，这样的话会有消费者分不到分区。\\r\\n\\r\\n而 topic 的分区设计时，最好和 broker 的数量成比例。比如 3 个\"},{\"url\":\"/middleware/kafka/高水位HW和LEO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"高水位HW和LEO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"LEO（log_end_offset) 指的是当前分区日志末端的 offset。\\r\\n\\r\\n而 HW 指的是整个 LSR 集合副本中，LEO 最小的。保障 Consumer 只能消费到 HW 的位置。\\r\\n\\r\\n首先Leader 和 Followers 都有自己的 HW和 LEO，当有新消息写入 Leader 时，Consumer 并不能立即消费。\\r\\n\\r\\nFollowers 会 pull leader 最新的消息，同步完之后，发送 ACK 给 Leader。然后 Leader会增加 HW。增加之后，新产生的消息才能被 Consumer 消费掉。\\r\\n\\r\\n这样的目的是为了保证当 Leader 挂掉之后，重\"},{\"url\":\"/middleware/rocketmq/Kakfa和RocketMQ的区别.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kakfa和RocketMQ的区别\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"消费者组\\r\\n\\r\\nRocketMQ和Kafka虽然都使用了Consumer Group的概念来实现消息的分发和负载均衡，但两者在具体实现和一些特性上存在一些差异：\\r\\n\\r\\n1. Rebalance机制：\\r\\n    - RocketMQ：RocketMQ的Consumer Group在成员增减或Topic队列发生变化时会触发Rebalance，旨在重新分配队列到各个消费者实例，确保消息的公平消费。RocketMQ的Rebalance更加灵活，支持多种分配策略，例如平均分配、广播消费等，可以根据业务需求进行配置。\\r\\n    - Kafka：Kafka同样在Consumer Group中进行Rebala\"},{\"url\":\"/middleware/rocketmq/MQ接收消息幂等性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MQ接收消息幂等性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"幂等性\\r\\n\\r\\nMQ的消息幂性，指的是MQ接收消息时候的幂等性。\\r\\n\\r\\n- 最多一次\\r\\n    \\r\\n    消息最多只会被消费一次。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n- 最少一次\\r\\n    \\r\\n    消息最少被消费一次。\\r\\n    \\r\\n    &gt; 同步发送、事务消息。\\r\\n    &gt; \\r\\n- 准确消费一次\\r\\n    \\r\\n    默认RocketMQ保证不了准确消费一次。但是商业版本有。\\r\\n    \\r\\n\\r\\n 消息幂等的必要性\\r\\n\\r\\n- 生产者发送消息时，MQ收到消息，但是网络波动导致ACK没有给到生产者。可能会导致重推消息。\"},{\"url\":\"/middleware/rocketmq/RocketMQ基础学习.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ基础学习\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础架构\\r\\n\\r\\n\\r\\n\\r\\n 生产者\\r\\n\\r\\nRocketMQ提供多种发送方式，同步发送、异步发送、顺序发送、单向发送。\\r\\n\\r\\n同步和异步方式均需要 Broker 返回确认信息，单向发送不需要。\\r\\n\\r\\n生产者中，会把同一类 Producer 组成一个集合，叫做生产者组。同一组的 Producer 被认为是发送同一类消息且发送逻辑一致。\\r\\n\\r\\n 消费者\\r\\n\\r\\n 消费者组\\r\\n\\r\\n消费者组消费同一组数据，消费相同topic，并且消费逻辑一致。消费者组的消费者实例必须订阅完全相同的Topic。\\r\\n\\r\\n 消费模式\\r\\n\\r\\nRocketMQ 支持两种消息模式：集群消费（Clustering）和广播消费（Broad\"},{\"url\":\"/middleware/rocketmq/RocketMQ集群架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ集群架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NameServer：提供Broker的路由服务\\r\\n\\r\\nBroker：负责接收Producer的消息，存储消息，将消息投递给Consumer。\\r\\n\\r\\n- Broker需要管理数据，频繁处理数据，所以需要G1、ZGC这种更先进的垃圾回收器。\\r\\n- 而NameServer类似于Broker的注册中心，提供路由功能，只需要简单的垃圾回收算法就可以，比如CMS。\\r\\n\\r\\nProducer：生产者\\r\\n\\r\\nConsumer：消费者\\r\\n\\r\\n 集群架构说明\\r\\n\\r\\n整个RocketMQ集群里面主要分为两部分，Broker和NameServer。\\r\\n\\r\\n整个RocketMQ遵循的是AP架构，追求可用性。\\r\\n\\r\\n N\"},{\"url\":\"/middleware/rocketmq/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- RocketMQ基础学习\\r\\n- RocketMQ集群架构\\r\\n\\r\\n\\r\\n- 消息样例\\r\\n- 顺序消息\\r\\n- 事务消息\\r\\n\\r\\n\\r\\n- 如何保证发送消息有序\\r\\n- 如何保证消息不丢失\\r\\n- MQ接收消息幂等性\\r\\n\\r\\n\\r\\n- Kakfa和RocketMQ的区别\"},{\"url\":\"/middleware/rocketmq/事务消息.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"事务消息\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"事务消息的流程\\r\\n\\r\\n- 先写half消息到RocketMQ\\r\\n- 再执行本地事务\\r\\n  \\r\\n    本地事务有两个方法，一个是回调执行本地事务，另一个是检查本地事务。\\r\\n    \\r\\n    ```java\\r\\n    /**\\r\\n     * 事务监听器，用来处理本地事务\\r\\n     * @author yangjunwei\\r\\n     * @date 2024/7/4\\r\\n     */\\r\\n    public class TransactionListenerImpl implements TransactionListener {\\r\\n        private AtomicInteger\"},{\"url\":\"/middleware/rocketmq/如何保证发送消息有序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"如何保证发送消息有序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类比Kafka的ParitationKey，RocketMQ是messageQueue。\\r\\n\\r\\n将需要保证顺序的消息发给RocketMQ的messageQueue，被同一个消费者消费，即可保证有序。\\r\\n\\r\\n1. 消费者在发送的时候可以指定selector，指定消息发给哪个messageQueue。\\r\\n2. messageQueue是一个FIFO的队列，能够保证消费时按照写入消息的顺序去消费。\\r\\n\\r\\n所以需要保证有顺序的消息，比如相同产品的订单，可以按照产品 code 设置 selector，保证消息发到同一个 messageQueue，这样就能被同一个消费者消费。\\r\\n\\r\\n```java\\r\\nSe\"},{\"url\":\"/middleware/rocketmq/如何保证消息不丢失.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"如何保证消息不丢失\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"消息丢失场景\\r\\n\\r\\n数据丢失在MQ中比较常见，一般丢失数据都是在跨网络的部分，比如1、2、4。\\r\\n\\r\\n- 生产者发数据\\r\\n- 消费者消费数据\\r\\n- MQ内部主从同步\\r\\n\\r\\n而MQ写数据到磁盘过程也是有丢失数据的可能的。\\r\\n\\r\\n一般写数据到磁盘不会直接去写，而是利用操作系统的缓存，先写数据到缓存中，等待操作系统异步刷进磁盘。\\r\\n\\r\\n比如 Prometheus 的 WAL 机制。\\r\\n\\r\\n\\r\\n\\r\\n 事务消息-生产者\\r\\n\\r\\n使用事务消息能保证本地事务和写入MQ的事务一致性。\\r\\n\\r\\n比如订单场景，只保证本地下订单和向MQ发消息的事务一致性。不会像MySQL一样保证数据库事务。\\r\\n\\r\\n只是保证了业务的分布\"},{\"url\":\"/middleware/rocketmq/消息样例.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"消息样例\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"顺序消息\\r\\n\\r\\nkafka的顺序消息可以指定paritationKey实现，相同paritationKey的消息会被发给同一个paritation。\\r\\n\\r\\nRocketMQ可以通过实现 `MessageQueueSelector` 的 `select` 方法自定义实现消息所发给 MessageQueue的逻辑。\\r\\n\\r\\n```java\\r\\n    @SneakyThrows\\r\\n    @Test\\r\\n    public void orderSend() {\\r\\n        try {\\r\\n            DefaultMQProducer producer = new DefaultMQP\"},{\"url\":\"/middleware/rocketmq/顺序消息.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"顺序消息\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"生产者\\r\\n\\r\\n生产者发送消息到MQ的过程，如果要保证顺序消费。\\r\\n\\r\\n只能采用单线程去生产消息，因为多线程无法控制消息生产顺序。\\r\\n\\r\\n还需要保证 sharding key 相同，保证同一类消息发到同一个 ConsumerQueue。\\r\\n\\r\\n\\r\\n&gt; \\r\\n- 单线程生产消息\\r\\n- 发送到同一个ConsumerQueue\\r\\n\\r\\n 存储\\r\\n\\r\\nRocketMQ的存储是按照时间顺序 append write 到 commitlog 中的，同时它会被分发到 ConsumeQueue中。\\r\\n\\r\\n所以只需要生产时候保证消息采用单线程发送到同一个ConsumerQueue，存储时候就能够顺序存储。\\r\\n\\r\"},{\"url\":\"/other/algorithm/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 时间复杂度\\r\\n- 查找\\r\\n- 排序\\r\\n- 动态规划\"},{\"url\":\"/other/algorithm/动态规划.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"动态规划\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"动态规划重要特性\\r\\n\\r\\n动态规划的核心问题是穷举，因为要求最值，要把所有可行答案找出来，找最值。但是穷举的过程中，会存在【重叠子问题】。\\r\\n\\r\\n 重叠子问题\\r\\n\\r\\n在求解的过程中，存在重复的子问题，若是重复解决这些子问题，存在效率低下的问题。\\r\\n\\r\\n而解决重叠子问题，可以使用【备忘录】或者【DP table】方法来解决。\\r\\n\\r\\n- 备忘录\\r\\n  \\r\\n    备忘录的思想就是将已经解决的子问题结果记录在备忘录中（可以是数组等数据结构）。\\r\\n    \\r\\n\\r\\n\\r\\n&gt; \\r\\n- DP table\\r\\n  \\r\\n    使用 DP table 保存每个子问题的结果，自下向上推算结果。\\r\\n    \\r\\n\\r\\n\"},{\"url\":\"/other/algorithm/排序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"排序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"概念\\r\\n\\r\\n 稳定性\\r\\n\\r\\n稳定性指的是相同的数据所在的位置经过排序后是否发生变化。若是排序后，次序不变，则是稳定的。\\r\\n\\r\\n 内部排序\\r\\n\\r\\n排序记录全部存放在内存中进行排序的过程。\\r\\n\\r\\n 外部排序\\r\\n\\r\\n待排序记录的数量很大，以至于内存不能容纳全部记录，在排序过程中尚需对外存进行访问的排序过程。\\r\\n\\r\\n\\r\\n\\r\\n 选择排序-不稳定\\r\\n\\r\\n每次选择剩余待排序元素中的最小值，放到已排序元素的末尾。\\r\\n\\r\\n原理：每次排序选出最小的元素，替换到对应顺序末尾的位置。\\r\\n思路：第一次排序选出最小的元素，和待排序数组第一位的元素进行交换。\\r\\n\\r\\n```json\\r\\n/**\\r\\n     * 选择排序的思路：\"},{\"url\":\"/other/algorithm/时间复杂度.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"时间复杂度\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"O(1)\\r\\n\\r\\n- 数组下表查询\\r\\n\\r\\n O(n)\\r\\n\\r\\n- 链表元素查询，最坏情况是要查n次。\\r\\n\\r\\n O(logn)\\r\\n\\r\\n- 平衡二叉树\\r\\n- 数组二分法查找指定元素\\r\\n\\r\\n开根号\\r\\n\\r\\n- 比如16长度的数组，想要找到指定元素最多需要4次、\\r\\n  \\r\\n    16→8→4→2→1\\r\\n    \\r\\n- 红黑树（平衡二叉树、完全二叉树）\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n O(log n) \\r\\n\\r\\n复杂度解释：\\r\\n\\r\\n- 在一个理想平衡的二叉搜索树中，每次查找操作从根节点开始，通过比较目标值与当前节点的值来决定是向左还是向右子树进行下一步查找。\\r\\n- 每次比较后，查找范围大致减半，这类似于\"},{\"url\":\"/other/algorithm/查找.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"查找\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"静态查找表\\r\\n\\r\\n 顺序查找\\r\\n\\r\\n线性表查询，查找效率（n+1)/2\\r\\n\\r\\n\\r\\n\\r\\n 折半查找\\r\\n\\r\\n\\r\\n\\r\\n二分查找，仅适用于有序的线性表。\\r\\n\\r\\n折半查找比较次数最多为 [log2n]+1 次。n=2^x，比如8个元素最多需要3次，对应 8=2^3。\\r\\n\\r\\n所以时间复杂度为 O(log2n) 。\\r\\n\\r\\n 分块查找\\r\\n\\r\\n特点是块内无序，但是块间有序。\\r\\n\\r\\n- 先在索引表确定目标所在块。\\r\\n- 在块内顺序查找。\\r\\n\\r\\n\\r\\n\\r\\n比如索引表或者索引文件。\\r\\n\\r\\n 哈希表\\r\\n\\r\\n\\r\\n\\r\\n按照哈希存储元素到哈希表里。\\r\\n\\r\\n 哈希冲突解决方式\\r\\n\\r\\n按照值的哈希值存储会出现哈希冲突的问题，可以通\"},{\"url\":\"/other/datastructure/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据结构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 常用数据结构\\r\\n- 二叉树\"},{\"url\":\"/other/datastructure/二叉树.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"二叉树\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"推荐一个练习数据结构的网站\\r\\n\\r\\nData Structure Visualization\\r\\n\\r\\n 二叉树的遍历（重要）\\r\\n\\r\\n以图示二叉树为例。\\r\\n\\r\\n\\r\\n\\r\\n 中序遍历\\r\\n\\r\\n简化为每个树，都是左中右即可。\\r\\n\\r\\n中序遍历（LDR）是二叉树遍历的一种，也叫做中根遍历、中序周游。在二叉树中，中序遍历首先遍历左子树，然后访问根结点，最后遍历右子树。\\r\\n\\r\\n*左子树 → 根节点 → 右子树*\\r\\n\\r\\n图示二叉树中序遍历结果为：`3、5、6、10、14、15、17、20`；\\r\\n\\r\\n参考代码：Java实现中序遍历\\r\\n\\r\\n 前序遍历\\r\\n\\r\\n前序遍历（VLR）， 1] 是[二叉树遍历的一种，也叫做先根遍历\"},{\"url\":\"/other/datastructure/常用数据结构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"常用数据结构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"存储结构\\r\\n\\r\\n\\r\\n\\r\\n 复杂度\\r\\n\\r\\n时间复杂度\\r\\n\\r\\n空间复杂度\\r\\n\\r\\n 线性表\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 串\\r\\n\\r\\n比如字符串。\\r\\n\\r\\n\\r\\n\\r\\n 数组\\r\\n\\r\\n\\r\\n\\r\\n 矩阵\\r\\n\\r\\n\\r\\n\\r\\n求矩阵元素下标，直接代入即可。\\r\\n\\r\\n\\r\\n\\r\\n代入 A(0,0) 和 A(0,1)，分别对应 M(1) 和 M(2)。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 广义表\\r\\n\\r\\n\\r\\n\\r\\n例1：长度为3，深度为2\\r\\n\\r\\n例2: 先取表尾，再取表头，再取表头。\\r\\n\\r\\nhead (head ( tail(LS1) ) )\\r\\n\\r\\n 广义表的基本运算\\r\\n\\r\\n1. 取表头\\r\\n2. 取表尾\\r\\n\\r\\n 二叉树\\r\\n\\r\\n\\r\\n\\r\\n- 满二叉树\"},{\"url\":\"/other/design/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"设计模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"设计模式的目的\\r\\n\\r\\n* 代码重用性（提取重复代码）\\r\\n* 可读性（代码规范，便于阅读）\\r\\n* 可扩展性（方便增加新功能）\\r\\n* 可靠性（增加新功能，对以前的功能没有影响）\\r\\n* 使程序呈现高内聚、低耦合的特性\\r\\n\\r\\n 设计模式的七大基本原则\\r\\n\\r\\ndesign-principle\\r\\n\\r\\n* 单一职责原则\\r\\n\\r\\n* 接口隔离原则\\r\\n\\r\\n* 依赖倒置原则\\r\\n\\r\\n* 里氏替换原则\\r\\n\\r\\n* 开闭原则\\r\\n\\r\\n* 迪米特法则\\r\\n\\r\\n* 合成复用法则\\r\\n\\r\\n 设计模式三大类型\\r\\n\\r\\n 1. 创建型模式\\r\\n\\r\\ndesign-create\\r\\n\\r\\n* 单例模式\\r\\n\\r\\n    * 序列化和反序列化\\r\\n\\r\\n* 工\"},{\"url\":\"/other/design/七大基本原则.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"七大基本原则\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-principle\\r\\n\\r\\n 单一职责原则\\r\\n\\r\\n1. 一种类只能具有一种职责，降低类的复杂度。\\r\\n2. 提高类的可读性，可维护性。\\r\\n3. 降低变更引起的风险。\\r\\n4. 在类中的方法比较少的时候，可以在方法级别保持单一职责原则。其他情况下，都要保持类的类单一职责原则。\\r\\n\\r\\n 接口隔离原则\\r\\n\\r\\n1. 客户端不应该依赖它不需要的接口。\\r\\n2. 一个类对另一个类的依赖应该建立在最小的接口上。\\r\\n\\r\\n 依赖倒置原则\\r\\n\\r\\n1. 依赖倒置原则的中心思想是面向接口编程。\\r\\n2. 抽象不应该依赖细节，细节应该依赖抽象。抽象是接口或者抽象类，细节即为实现类。\\r\\n3. 对于细节的多变性，抽象的\"},{\"url\":\"/other/design/创建型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"创建型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-create\\r\\n\\r\\n 单例模式\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 饿汉式\\r\\n\\r\\n特点：类创建时创建对象，节省时间，占用内存，`以空间换时间`。\\r\\n\\r\\n1. 静态变量实现\\r\\n    \\r\\n    类加载时创建对象，节省时间，占用内存，`以空间换时间`。`推荐使用`，但是比较浪费空间。\\r\\n    \\r\\n    ```java\\r\\n    \\t\\t/**\\r\\n         * 类加载时创建对象，节省时间，占用内存，以空间换时间\\r\\n         */\\r\\n        private final static SingletonHungryOne INSTANCE = new Singleton\"},{\"url\":\"/other/design/结构型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"结构型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-structural\\r\\n\\r\\n 代理模式\\r\\n\\r\\n代理模式是属于结构型的设计模式,指客户端的请求到达真正的对象之前，做一些额外的操作。\\r\\n\\r\\n 静态代理模式\\r\\n\\r\\n\\r\\n以 AspectJ 为代表。指代理类在编译期生成的，与动态代理相比，效率会很高，但是会生成大量代理类。\\r\\n\\r\\n 动态代理模式\\r\\n\\r\\n以 SpringAOP 为代表为代表，代理类是动态生成的。虽然会效率会低一点，但是大大简化了代码和开发量。\\r\\n\\r\\n- JDK 动态代理\\r\\n- CGlib 动态代理\\r\\n\\r\\n 桥接模式\\r\\n\\r\\n抽象类：定义一个抽象类，作为系统的一部分。\\r\\n\\r\\n实现类：定义一个或多个实现类，与抽象类通过聚合（而非\"},{\"url\":\"/other/design/行为型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"行为型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-behavioral\\r\\n\\r\\n 责任链模式\\r\\n\\r\\n责任链模式——某个请求需要多个对象进行处理，从而避免请求的发送者和接收之间的耦合关系。将这些对象连成一条链子，并沿着这条链子传递该请求，直到有对象处理它为止。主要涉及两个角色：\\r\\n\\r\\n\\r\\n- 抽象处理者角色（Handler）：定义出一个处理请求的接口。这个接口通常由接口或抽象类来实现。\\r\\n- 具体处理者角色（ConcreteHandler）：具体处理者接受到请求后，可以选择将该请求处理掉，或者将请求传给下一个处理者。因此，每个具体处理者需要保存下一个处理者的引用，以便把请求传递下去。\\r\\n\\r\\n 优缺点比较\\r\\n\\r\\n优点\\r\\n\\r\\n- 降低耦\"},{\"url\":\"/other/network/HTTP1x和HTTP2x.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP1x和HTTP2.x\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HTTP1.x\\r\\n\\r\\n 数据格式\\r\\n\\r\\nHTTP1.x基于文本传输。\\r\\n\\r\\n- 请求行\\r\\n- 请求头\\r\\n- 请求体\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 缺点\\r\\n\\r\\n1. 占用字节：在HTTP请求中，包含很多空格和换行符。\\r\\n2. 头部不能压缩：在HTTP1.x中，请求头不能压缩。所以存在请求头比较大的问题，出现大头儿子。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n3. 传输效率低：同一个链接（`Keep-Alive`的情况）同时只能处理一个请求，收到响应才会开始发送下一个请求。\\r\\n    - 如果不设置 `Keep-Alive`，则每一次HTTP请求都会新建一个TCP链接。\\r\\n    \\r\\n    &g\"},{\"url\":\"/other/network/HTTP和HTTPS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP和HTTPS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HTTP 和 HTTPS 的区别\\r\\n\\r\\n- 传输问题。\\r\\n    - HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。\\r\\n    - HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。\\r\\n- 建立连接过程。\\r\\n    - HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。\\r\\n    - HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。\\r\\n- 两者的默认端口不一样。\\r\\n    - HTTP 默认端口号是 80。\\r\\n\"},{\"url\":\"/other/network/HTTP常见字段.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP常见字段\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```json\\r\\nPOST /apmServer-sl/sys-user/login HTTP/1.1\\r\\nAccept: application/json, text/plain, */*\\r\\nAccept-Encoding: gzip, deflate\\r\\nAccept-Language: zh-CN,zh;q=0.9\\r\\nAuthorization: clusterid34\\r\\nConnection: keep-alive\\r\\nContent-Length: 101\\r\\nContent-Type: application/json\\r\\nCookie: apm.name=admin\\r\\nHost: 10.1\"},{\"url\":\"/other/network/Linux如何收发网络包.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Linux如何收发网络包\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"2.3 Linux 系统是如何收发网络包的？\\r\\n\\r\\n 网络协议栈\\r\\n\\r\\n\\r\\n\\r\\n1. 应用程序需要通过系统调用，来和 Socket 进程数据交互。\\r\\n2. Socket 层是介于应用层和传输层之间的抽象层。\\r\\n3. 最下面的一层，则是网卡驱动程序和硬件网卡设备。\\r\\n\\r\\n Linux 接收和发送网络包的流程\"},{\"url\":\"/other/network/OSI七层网络模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"OSI七层网络模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 应用层，负责给应用程序提供统一的接口；\\r\\n- 表示层，负责把数据转换成兼容另一个系统能识别的格式；\\r\\n- 会话层，负责建立、管理和终止表示层实体之间的通信会话；\\r\\n- 传输层，负责端到端的数据传输；\\r\\n- 网络层，负责数据的路由、转发、分片；\\r\\n- 数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址；\\r\\n- 物理层，负责在物理网络中传输数据帧；\"},{\"url\":\"/other/network/RTT和SRTT.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RTT和SRTT\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"RTT\\r\\n\\r\\nRTT 指的是客户端发出数据 → 客户端收到服务端发送的确认数据的时间。\\r\\n\\r\\nRTT 称为往返时延。\\r\\n\\r\\n SRTT\\r\\n\\r\\nSRTT（Smoothed Round Trip Time）是一种用于衡量网络延迟的指标，通常用于评估网络连接的质量和性能。SRTT表示在一系列网络往返（Round Trip）中的平滑往返时间。\\r\\n\\r\\nSRTT是通过在每次往返时间（RTT）的基础上应用加权平均算法来计算得出的。加权平均算法会给最近的RTT值更高的权重，以反映出网络延迟的实时变化。\\r\\n\\r\\nSRTT的值越小，表示网络延迟越低，网络连接的质量越好。较低的SRTT值通常意味着网络响应更快，数据传\"},{\"url\":\"/other/network/Socket.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Socket\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Socket 位于应用层和传输层之前的抽象层，是一组调用接口，TCP/IP网络的API函数。\\r\\n\\r\\n实际上是对 TCP/IP协议的封装，只是为了更方便使用 TCP/IP 协议。\\r\\n\\r\\n\\r\\n这个就像操作系统会提供标准的编程接口，比如win32编程接口一样。\\r\\nTCP/IP也要提供可供程序员做网络开发所用的接口，这就是Socket编程接口。\\r\\n&gt; \\r\\n\\r\\n Socket 通信流程\\r\\n\\r\\n\\r\\n\\r\\nSocket按照四元组来标识不同客户端与服务端之间的连接。\\r\\n\\r\\n四元组「源 IP、源端口、目的 IP、目的端口」\\r\\n\\r\\n- `accept()`\\r\\n  \\r\\n    服务端绑定端口之后，进入 `acc\"},{\"url\":\"/other/network/TCPIP四层网络模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP/IP四层网络模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"为什么要有网络模型\\r\\n\\r\\n进程通信的方式\\r\\n\\r\\n- 本机\\r\\n    - 消息队列\\r\\n    - 共享内存\\r\\n    - 管道（程序用来交换数据的地方）\\r\\n- 不同主机\\r\\n    - 网络通信\\r\\n\\r\\n需要网络通信的设备是多种多样的，所以要兼容，就要设定网络通信之间的网络协议。\\r\\n\\r\\n 应用层\\r\\n\\r\\n应用层定义了应用进程之间通信和交互的规则，应用层交互数据单元为报文。\\r\\n\\r\\n不关心数据如何传输，将报文传给传输层做传输。\\r\\n\\r\\n在这一层有很多熟悉的协议，比如 HTTP、HTTPS、DNS等。\\r\\n\\r\\n【计算机网络】TCP / IP 四层协议_tcp/ip协议包含哪几层_L Jiawen的博客-CSDN\"},{\"url\":\"/other/network/TCP分析工具.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP分析工具\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Wireshark · Go Deep\\r\\n\\r\\n\\r\\n\\r\\n 三次握手\\r\\n\\r\\n\\r\\n\\r\\n 第1次握手\\r\\n\\r\\n\\r\\n\\r\\nsyn设置为1，表明这是一个 SYN包\\r\\n\\r\\n\\r\\n\\r\\nseq = 1390201126\\r\\n\\r\\n\\r\\n\\r\\n 第2次握手\\r\\n\\r\\nsyn=1 同时 ACK=1，表明这是一个 SYN/ACK包\\r\\n\\r\\n\\r\\n\\r\\n服务端返回的 ACK = 客户端第一次发送的 seq+1 = 1390201126+1\\r\\n\\r\\n同时服务端向客户端返回了自己的 seq（如果第三次握手客户端返回的ack=seq+1，代表客户端收到了自己发的seq）\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n 第3次握手\\r\\n\\r\\n可以看到第 3 次握手的\"},{\"url\":\"/other/network/TCP协议.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP协议\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"TCP 协议灵魂 12 问，巩固你的网路底层基础！-腾讯云开发者社区-腾讯云\\r\\n\\r\\n\\r\\n\\r\\n TCP和UDP的区别\\r\\n\\r\\n- 面向连接\\r\\n    - TCP 需要客户端与服务端之间通过三次握手建联，之后才可以发送数据。\\r\\n    - UDP直接向服务端发数据包。\\r\\n- 可靠性\\r\\n    - 有状态\\r\\n        - TCP发数据包时，保证数据包按顺序到达。\\r\\n    - 可控制\\r\\n        - 当TCP协议丢包时，可以控制重发和自己的发送速度，保证数据包完整和有序。\\r\\n    - UDP 是无状态并且不可控的。\\r\\n- 基于字节流\\r\\n    - TCP将数据包通过字节流发送。\\r\\n   \"},{\"url\":\"/other/network/TCP粘包拆包.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP粘包拆包\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"发生粘包的原因\\r\\n\\r\\n- 要发送的数据小于 TCP 发送缓冲区的大小，TCP 将多次写入缓冲区的数据一次发送出去，将会发生粘包；\\r\\n- 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包；\\r\\n- 要发送的数据大于 TCP 发送缓冲区剩余空间大小，将会发生拆包；\\r\\n- 待发送数据大于 MSS（最大报文长度），TCP 在传输前将进行拆包。即 TCP 报文长度 - TCP 头部长度 \\r\\n\\r\\n 解决粘包拆包问题\\r\\n\\r\\n- 定长消息：发送端将每个数据包封装为固定长度\\r\\n- 特殊分隔符：在数据尾部增加特殊字符进行分割\\r\\n- 消息头：将数据分为两部分，一部分是头部，一部分是内容体；其中头部结构大小\"},{\"url\":\"/other/network/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"计算机网络\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础\\r\\n\\r\\n- TCP/IP四层网络模型\\r\\n- OSI七层网络模型\\r\\n- 网址访问页面中间发生了哪些过程\\r\\n- Linux如何收发网络包\\r\\n- 网络包的封装原理\\r\\n- Socket\\r\\n\\r\\n TCP\\r\\n\\r\\n- TCP协议\\r\\n- TCP分析工具\\r\\n\\r\\n\\r\\n- RTT和SRTT\\r\\n- 流量控制-滑动窗口\\r\\n\\r\\n- 拥塞控制\\r\\n- 重传机制\\r\\n- TCP粘包拆包\\r\\n\\r\\n\\r\\n UDP\\r\\n\\r\\nUDP不需要连接，可以单播和广播。\\r\\n\\r\\n HTTP\\r\\n- HTTP常见字段\\r\\n- HTTP和HTTPS\\r\\n- HTTP1x和HTTP2x\\r\\n\\r\\n 参考链接\\r\\n\\r\\n图解网络介绍\"},{\"url\":\"/other/network/拥塞控制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"拥塞控制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"流量控制是避免数据填满发送方的缓冲区。\\r\\n\\r\\n而拥塞控制是避免发送方的数据填满整个网络。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n在⽹络出现拥堵时，如果继续发送⼤量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是⼀重传就会导致⽹络的负担更重，于是会导致更⼤的延迟以及更多的丢包，这个情况就会进⼊恶性循环被不断地放⼤….\\r\\n\\r\\n所以，TCP 不能忽略整个网络中发⽣的事，它被设计成⼀个⽆私的协议，当⽹络发送拥塞时，TCP 会⾃我牺牲，降低发送的数据流。\\r\\n\\r\\n 拥塞窗口\\r\\n\\r\\n拥塞窗⼝ cwnd是发送⽅维护的⼀个的状态变量，它会根据⽹络的拥塞程度动态变化的。\\r\\n\\r\\n发送窗⼝ swnd 和接\"},{\"url\":\"/other/network/流量控制-滑动窗口.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"流量控制-滑动窗口\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在TCP中，滑动窗口用来流量控制。确保发送方不会过快的发送数据导致接收方无法处理数据。\\r\\n\\r\\nTCP拥塞控制是为了解决发送方以过高的速率发送导致网络中出现阻塞，其核心思想就是发生重传时控制发送方滑动窗口（通过控制拥塞窗口cwnd）的大小，从而控制其发送速率。\\r\\n\\r\\n 滑动窗口\\r\\n\\r\\nTCP窗口包括发送窗口和接收窗口，用来限制不同端所能容纳数据的上限，达到控制发送数据的速率。\\r\\n\\r\\n\\r\\n\\r\\nTCP报文里面的窗口大小，作用是告诉对方本端的接受缓冲区还能容纳多少字节的数据。\\r\\n\\r\\n\\r\\n\\r\\n在通信过程中，接收方每次收到数据包，在发送确认报文的时候，还需要告诉发送方自己的缓冲区剩余大小。缓冲区剩余大小，\"},{\"url\":\"/other/network/网址访问页面中间发生了哪些过程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"网址访问页面中间发生了哪些过程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"2.2 键入网址到网页显示，期间发生了什么？\\r\\n\\r\\n URL解析\\r\\n\\r\\n URL组成信息\\r\\n\\r\\nURL实际上就是访问 Web服务器里面的文件资源。\\r\\n\\r\\n\\r\\n\\r\\n 组装HTTP报文\\r\\n\\r\\n根据 URL 解析得到的内容，进行报文组装。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n DNS域名解析\\r\\n\\r\\n解析URL时，如果web服务器是域名，需要走DNS服务器进行域名解析，得到真实访问的IP地址。\\r\\n\\r\\n 域名组成\\r\\n\\r\\n`www.server.com.` 类似树状结构，越右等级越高。\\r\\n\\r\\n域名组成都代表了DNS服务器，里面保存了域名和IP的对应关系。\\r\\n\\r\\n域名服务器就像是一个树状结构。\\r\\n\\r\\n- 根\"},{\"url\":\"/other/network/网络包的封装原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"网络包的封装原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 TCP/IP 四层网络模型中，网络包每层的包装如下：\\r\\n\\r\\n- 传输层，给应用数据前面增加了 TCP 头；\\r\\n- 网络层，给 TCP 数据包前面增加了 IP 头；\\r\\n- 网络接口层，给 IP 数据包前后分别增加了帧头和帧尾；\\r\\n\\r\\n每层增加的头部和尾部，都有每层独特的作用，按照各自的协议填充。\\r\\n\\r\\n在物理链路上并不能传输任意大小的数据包，在以太网中，规定了最大传输单元（MTU）为 1500 字节，规定了单次传输的最大 IP 包的大小。\\r\\n\\r\\n当网络包超过 MTU 时，就会在网络层分片，确保分片后的包不会超过 MTU 大小。\\r\\n\\r\\n- 如果 MTU 越小，网络包分片数越多，那么网络吞吐能力\"},{\"url\":\"/other/network/重传机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"重传机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"超时重传\\r\\n\\r\\n原理是在发送某一个数据以后就开启一个计时器，在一定时间内如果没有得到发送的数据报的 ACK 报文，那么就重新发送数据，直到发送成功为止。\\r\\n\\r\\n RTT\\r\\n\\r\\nRTT（Round-Trip Time，往返时间）。数据包一次的往返时间。\\r\\n\\r\\n\\r\\n\\r\\nSRTT：平均的RTT\\r\\n\\r\\n 缺点\\r\\n\\r\\n- 当一个报文丢失时，会等待一定的超时周期，才重传分组，增加了端到端的时延。\\r\\n- 当一个报文丢失时，在其等待超时的过程中，可能会出现这种情况：其后的报文段已经被接收端接收但却迟迟得不到确认，发送端会认为也丢失了，从而引起不必要的重传，既浪费资源也浪费时间。\\r\\n- 并且，对于 TCP，如果\"},{\"url\":\"/other/observability/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可观测性常见维度\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"可观测性指的是对于系统内部运行状态的全面洞察和理解能力。\\r\\n\\r\\n可观测性项⽬旨在提供⼯具和解决⽅案，帮助开发⼈员和运维团队更好地监视、调试和理解其应⽤程序的行为。\\r\\n\\r\\n 维度\\r\\n\\r\\n- 日志采集 （log）\\r\\n- 指标采集 （Metric）\\r\\n- 链路追踪（Trace）\\r\\n- 告警管理（AlertManager）\\r\\n- 可视化（Visualization）\\r\\n\\r\\n整个可观测项目，维度除了常见的 log、metric、trace之外。还包括告警和可视化。\\r\\n\\r\\n 指标\\r\\n\\r\\n指标又可以分为：\\r\\n\\r\\n- 基础设施\\r\\n\\r\\n  服务器、数据库、MQ的指标。\\r\\n\\r\\n- 应用维度\\r\\n\\r\\n  应用包含模块\"},{\"url\":\"/other/observability/log/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"日志收集全链路\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ELFK\\r\\n\\r\\nELFK 指的是 elasticsearch+logstash+filebeat+kibana\\r\\n\\r\\n 日志管理\\r\\n\\r\\n日志收集→格式化分析→检索和可视化→日志告警\\r\\n\\r\\n\\r\\n\\r\\n 日志架构\\r\\n\\r\\n 小规模环境\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 大规模生产环境\\r\\n\\r\\nELFK + Kafka\\r\\n\\r\\n Logstash\\r\\n\\r\\n从多个来源采集数据，转换数据，然后将数据放到不同的数据库中。\\r\\n\\r\\nda 就很像 logstash 的功能设计。\\r\\n\\r\\n 架构\\r\\n\\r\\n\\r\\n\\r\\nLogstash 接入数据源数据，经过内部 Pipeline，将数据可以写到不同的存储（ES、Kafka）里面。\\r\\n\\r\\nLog\"},{\"url\":\"/other/observability/opentelemetry/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Opentelemetry\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"docs-cn/OT.md at main · open-telemetry/docs-cn\\r\\n\\r\\n OpenTracing&OpenCensus\\r\\n\\r\\n- OpenTracing 制定了一套平台无关、厂商无关的协议标准，使得开发人员能够方便的添加或更换底层 APM 的实现。\\r\\n- OpenCensus支持Metrics、分布式跟踪。\\r\\n\\r\\n OpenTelemetry\\r\\n\\r\\nOpenTelemetry 的核心工作目前主要集中在 3 个部分：\\r\\n\\r\\n1. 规范的制定和协议的统一，规范包含数据传输、API的规范。协议的统一包含：HTTP W3C的标准支持及GRPC 等框架的协议标准。\\r\\n2. 多\"},{\"url\":\"/other/observability/opentelemetry/可观测性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可观测性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"可观测性指的是对于系统内部运行状态的全面洞察和理解能力。\\r\\n\\r\\n可观测性项⽬旨在提供⼯具和解决⽅案，帮助开发⼈员和运维团队更好地监视、调试和理解其应⽤程序的行为。\\r\\n\\r\\n 维度\\r\\n\\r\\n- 日志采集 （log）\\r\\n- 指标采集 （Metric）\\r\\n- 链路追踪（Trace）\\r\\n- 告警管理（AlertManager）\\r\\n- 可视化（Visualization）\\r\\n\\r\\n整个可观测项目，维度除了常见的 log、metric、trace之外。还包括告警和可视化。\\r\\n\\r\\n 指标\\r\\n\\r\\n指标又可以分为：\\r\\n\\r\\n- 基础设施\\r\\n\\r\\n  服务器、数据库、MQ的指标。\\r\\n\\r\\n- 应用维度\\r\\n\\r\\n  应用包含模块\"},{\"url\":\"/other/observability/skywalking/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Skywalking\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Skywalking\\r\\n\\r\\n- 组件安装\\r\\n- 源码学习\"},{\"url\":\"/other/observability/skywalking/源码学习.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"源码学习\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Category: SkyWalking | 芋道源码 —— 纯源码解析博客\\r\\n\\r\\nSkyWalking8.7源码解析\\r\\n\\r\\n 告警组件\\r\\n\\r\\n 初始化Kafka消费者\\r\\n\\r\\n```java\\r\\n@Slf4j\\r\\npublic class KafkaFetcherProvider extends ModuleProvider {\\r\\n    private KafkaFetcherHandlerRegister handlerRegister;\\r\\n    private KafkaFetcherConfig config;\\r\\n\\r\\n    @Override\\r\\n    public String na\"},{\"url\":\"/other/observability/skywalking/组件安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"组件安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"OAP\\r\\n\\r\\n- 配置文件\\r\\n  \\r\\n    ```java\\r\\n    apache-skywalking-apm-bin/config/application.yml\\r\\n    ```\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n- 启动脚本\\r\\n  \\r\\n    ```java\\r\\n    sh bin/oapService.sh\\r\\n    ```\\r\\n    \\r\\n\\r\\n UI\\r\\n\\r\\n- 配置\\r\\n  \\r\\n    ```java\\r\\n    apache-skywalking-apm-bin/webapp/webapp.yml\\r\\n    ```\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n- 启动脚本\\r\\n  \\r\\n    ```java\\r\\n\"},{\"url\":\"/personal/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"personal\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"&lt;div align=\\\"center\\\"\\r\\n  &lt;img src=\\\"https://capsule-render.vercel.app/api?type=waving&color=gradient&height=300&section=header&text=Albert%20Yang&fontSize=90&animation=fadeIn&fontAlignY=38&desc=热爱编程%20|%20追求卓越%20|%20创新思维&descAlignY=55&descAlign=62\\\" /&gt;\\r\\n&lt;/div&gt;\\r\\n&lt;p align=\\\"center\\\" style=\"}],\"originPosts\":[{\"url\":\"/cloudnative/docker/Docker学习总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Docker学习总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本知识\\r\\n\\r\\n 1. Docker 是什么？\\r\\n\\r\\ndocker 是一种容器化虚拟技术，解决了运行环境和配置问题，方便持续集成并有助于项目整体发布。\\r\\n\\r\\n 2. Docker 能干嘛？\\r\\n\\r\\n*一次构建、随处运行。*\\r\\n\\r\\n- 更快速的应用交付和部署。\\r\\n- 更便捷的升级和扩缩容。\\r\\n- 更简单的系统运维。\\r\\n- 更高效的计算源利用。\\r\\n\\r\\n 基本组成\\r\\n\\r\\n 1. 镜像\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 2. 容器\\r\\n\\r\\n&gt; Docker 利用容器（Container）独立运行一个或一组应，容器是用镜像创建的运行实例。\\r\\n&gt; \\r\\n\\r\\n它可以被启动、开始、停止、删除。每个容器都是相\"},{\"url\":\"/cloudnative/docker/docker镜像压缩.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"docker镜像压缩\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"tar包\\r\\n\\r\\n\\r\\n\\r\\n```\\r\\ndocker save tomcat-apm-0915 -o ./tomcat-apm-0915.tar\\r\\n```\\r\\n\\r\\n```\\r\\ndocker load &lt; tomcat-apm-0915.tar\\r\\n```\\r\\n\\r\\nDocker 复制镜像到其他主机 - 彦祚 - 博客园\\r\\n\\r\\n tar.gz包\\r\\n\\r\\n 保存镜像\\r\\n\\r\\n`docker save &lt;myimage\\r\\n\\r\\n```\\r\\ndocker save xxx:xxx| gzip&gt;xxx.tar.gz\\r\\n```\\r\\n\\r\\n 加载镜像\\r\\n\\r\\n`gunzip -c &lt;myimage&gt;_&lt\"},{\"url\":\"/cloudnative/docker/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Docker\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"学习总结\\r\\n- Docker学习总结\\r\\n\\r\\n\\r\\n 使用总结\\r\\n- 容器软件安装\\r\\n- docker镜像压缩\\r\\n- 制作Tomcat镜像\\r\\n- 容器新增bash\"},{\"url\":\"/cloudnative/docker/制作Tomcat镜像.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"制作Tomcat镜像\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"DockerFile文件内容\\r\\n\\r\\n- tomcat 基础镜像\\r\\n  \\r\\n    ```bash\\r\\n    \\r\\n     使用基于 JDK 8 的官方 Tomcat 镜像作为基础镜像\\r\\n    FROM tomcat:8-jdk8\\r\\n    \\r\\n     修改默认的 shell\\r\\n    RUN ln -sf /bin/bash /bin/sh\\r\\n    \\r\\n     暴露 Tomcat 的默认 HTTP 端口\\r\\n    EXPOSE 8080\\r\\n    \\r\\n     设置容器启动时执行的命令\\r\\n    CMD [\\\"catalina.sh\\\", \\\"run\\\"]\\r\\n    ```\\r\\n    \\r\\n- \"},{\"url\":\"/cloudnative/docker/容器新增bash.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"容器新增bash\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"安装方式\\r\\n\\r\\n- wget 下载\\r\\n  \\r\\n    ```bash\\r\\n    from busybox\\r\\n    \\r\\n     下载 bash 二进制文件\\r\\n    RUN wget -O /bin/bash http://ftp.gnu.org/gnu/bash/bash-5.1.tar.gz\\r\\n    \\r\\n     设置可执行权限\\r\\n    RUN chmod +x /bin/bash\\r\\n    \\r\\n     运行命令\\r\\n    CMD [\\\"echo\\\", \\\"Hello, World!\\\"]\\r\\n    ```\\r\\n    \\r\\n- 本地安装\\r\\n  \\r\\n    ```bash\\r\\n    from \"},{\"url\":\"/cloudnative/docker/容器软件安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"容器软件安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"RabbitMQ\\r\\n\\r\\n参考博客\\r\\n\\r\\ndocker安装RabbitMQ\\r\\n\\r\\n---\\r\\n\\r\\n1. 查找镜像\\r\\n   \\r\\n    ```java\\r\\n    docker search rabbitmq\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n2. 拉取镜像\\r\\n   \\r\\n    ```java\\r\\n    docker pull rabbitmq\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 启动镜像\\r\\n   \\r\\n    ```java\\r\\n    docker run -d --hostname my-rabbit --name rabbit -p 15672:15\"},{\"url\":\"/cloudnative/k8s/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"K8s\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- k8s常用命令\\r\\n- k8s问题排查流程图\"},{\"url\":\"/cloudnative/k8s/k8s常用命令.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"k8s常用命令\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"常用命令总结\\r\\n\\r\\n node\\r\\n\\r\\n- 查看所有的node\\r\\n  \\r\\n    ```\\r\\n    kubectl get nodes\\r\\n    ```\\r\\n    \\r\\n- 查看node名与Host文件的相互解析\\r\\n  \\r\\n    ```\\r\\n    cat /etc/hosts\\r\\n    ```\\r\\n    \\r\\n- 查看本机 hostname\\r\\n  \\r\\n    `Plain Text   cat /etc/hostname`\\r\\n    \\r\\n\\r\\n namespace\\r\\n\\r\\n- 查看所有的namespace\\r\\n  \\r\\n    ```\\r\\n    [root@master ~] kubectl  get n\"},{\"url\":\"/cloudnative/k8s/k8s问题排查流程图.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"k8s问题排查流程图\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"深度解密｜基于 eBPF 的 Kubernetes 问题排查全景图发布-阿里云开发者社区\"},{\"url\":\"/cloudnative/prometheus/TSDB.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TSDB\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Prometheus的 TSDB（Time Series Database）作为内置的时序数据库。\\r\\n\\r\\n 存储原理\\r\\n\\r\\nTSDB 既使用内存也使用磁盘进行数据存储。\\r\\n\\r\\n\\r\\n\\r\\n Head\\r\\n\\r\\n在Prometheus中，Head 是数据库的内存部分，用于存储最近写入的数据。\\r\\n\\r\\n当数据在Head中存储2小时后，会被转移到磁盘上的持久块（block）中。这些持久块是不变的，每个块代表一段时间的数据，并且按照时间顺序进行组织和存储。\\r\\n\\r\\n\\r\\n\\r\\n Block块\\r\\n\\r\\nPrometheus中以每2个小时为一个时间窗口，即将2小时内产生的数据存储在一个block中，监控数据会以时间段的形式\"},{\"url\":\"/cloudnative/prometheus/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Prometheus\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 架构\\r\\n- TSDB\\r\\n- 数据模型\\r\\n- node_exporter源码\"},{\"url\":\"/cloudnative/prometheus/node_exporter源码.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"node_exporter源码\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"简单流程\\r\\n\\r\\n1. 定时任务 30s 执行一次\\r\\n    1. 调用采集指标的方法\\r\\n2. 不同 Collector 采集自己的指标\\r\\n    1. 内存\\r\\n        - 读取 `/`@\\r\\n          \\r\\n            `proc/meminfo`文件内容\\r\\n            \\r\\n            ```go\\r\\n            MemTotal:       16267496 kB\\r\\n            MemFree:          803084 kB\\r\\n            MemAvailable:    1507880 kB\\r\\n \"},{\"url\":\"/cloudnative/prometheus/数据模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Prometheus的存储实现上所有的监控样本都是以 time-series 的形式保存在 Prometheus 内置的TSDB（时序数据库）中，而 time-series 所对应的监控指标 (metric) 也是通过 labelset 进行唯一命名的。\\r\\n\\r\\n 样本数据\\r\\n\\r\\n- 指标(metric)：metric name 和描述当前样本特征的 labelsets;\\r\\n- 时间戳(timestamp)：一个精确到毫秒的时间戳;\\r\\n- 样本值(value)： 一个float64的浮点型数据表示当前样本的值。\\r\\n\\r\\n```\\r\\n&lt;--------------- metric -------\"},{\"url\":\"/cloudnative/prometheus/架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Prometheus架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- Promtheus 默认采取主动拉的策略，可以配置各个exporter的拉取间隔。\\r\\n    - Exporter 被动暴露数据，Prometheus 主动拉取。\\r\\n- 但是Promtheus也可以使用 Pushgateway 实现 Push 模型。\\r\\n    - exporter 将数据推给 Pushgateway，Promtheus从Pushgateway拉数据。\"},{\"url\":\"/database/clickhouse/ClickHouse基础.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse基础\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"列式存储\\r\\n\\r\\nclickhouse 是 *列式存储* 数据库\\r\\n\\r\\n在磁盘上按列存储，即按某个字段进行存储。\\r\\n\\r\\n\\r\\n\\r\\n所以列式存储更适合进行查询，比如某一行的聚合、计算、求和等。\\r\\n\\r\\n 列式存储的好处\\r\\n\\r\\n1. 对于某列的聚合、计数、求和等操作要比行式存储更快。\\r\\n   \\r\\n    查询更快。\\r\\n    \\r\\n    - 行式存储，增改删更加方便，因为只需要找到对应的行记录，直接删除即可。但是列式存储对比起来，增改删要更繁琐一点。\\r\\n2. 每一列的数据类型是一样的，这样能更好的进行数据压缩。\\r\\n   \\r\\n    方便数据压缩，节省磁盘\\r\\n    \\r\\n    - 与 es 相比，作为常\"},{\"url\":\"/database/clickhouse/ClickHouse安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"docker下安装clickhouse_docker 安装clickhouse-CSDN博客\\r\\n\\r\\n使用 clickhouse-client 进入 ck\\r\\n\\r\\n mac 安装\\r\\n\\r\\n```java\\r\\ndocker run --rm -d --name=clickhouse \\\\\\r\\n-e CLICKHOUSE_ADMIN_PASSWORD=\\\"123456\\\" \\\\\\r\\n--ulimit nofile=262144:262144 \\\\\\r\\n-p 8123:8123 -p 9009:9009 -p 9090:9000 \\\\\\r\\n-v /Users/yangjunwei/ck/config:/etc/clickhou\"},{\"url\":\"/database/clickhouse/ClickHouse物化列序列化报错.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse物化列序列化报错问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"报错内容\\r\\n\\r\\n```java\\r\\nNo serializer found for column 'date'. Did you forget to register it?\\r\\n\\tat com.clickhouse.client.api.Client.insert(Client.java:1317)\\r\\n\\tat com.clickhouse.client.api.Client.insert(Client.java:1266)\\r\\n```\\r\\n\\r\\n 表结构\\r\\n\\r\\n```java\\r\\nCREATE TABLE IF NOT EXISTS metric_data\\r\\n(\\r\\n    `placeId` UInt3\"},{\"url\":\"/database/clickhouse/ClickHouse高级.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse高级\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MergeTree\\r\\n\\r\\nClickHouse 中最强大的表引擎当属 MergeTree（合并树）引擎及该系列（MergeTree）中的其他引擎，支持索引和分区，地位可以相当于 innodb 之于 Mysql。而且基于 MergeTree，还衍生除了很多小弟，也是非常有特色的引擎。\\r\\n\\r\\n建表语句\\r\\n\\r\\n```sql\\r\\ncreate table t_order_mt(\\r\\n id UInt32,\\r\\n sku_id String,\\r\\n total_amount Decimal(16,2),\\r\\n create_time Datetime\\r\\n) engine = MergeTree\\r\\n partiti\"},{\"url\":\"/database/clickhouse/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- ClickHouse安装\\r\\n- ClickHouse基础\\r\\n- ClickHouse高级\\r\\n- 为什么弃用Elasticsearch\"},{\"url\":\"/database/clickhouse/为什么弃用Elasticsearch.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"对于开发来说：\\r\\n\\r\\n1. 大批量数据查询导致 es 的 CPU 飙升。\\r\\n2. 数据量增大之后，es 的查询效率下降，影响接口性能。\\r\\n3. 聚合效率低。\\r\\n\\r\\n对于运维来说：\\r\\n\\r\\n1. 维护成本很大，在数据量大的情况，es 占用磁盘空间很大，没有很好的压缩手段。\\r\\n2. es 很占内存，内存配置为整体内存的一半。\\r\\n\\r\\n 问题记录\\r\\n\\r\\n- 缓存计算系统评分导致 es 的 cpu 飙升。\\r\\n\\r\\n  系统评分需要查询 es 的流量信息进行计算，实时查询很慢。做了定时任务计算分数信息并作缓存。\\r\\n\\r\\n    - 经常发现 es 的 cpu 会被打满。排查发现随着系统的增多，当定时任务跑的时候\"},{\"url\":\"/database/mysql/B树和B+树.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"B树和B+树\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"B树\\r\\n\\r\\n\\r\\n\\r\\n每个节点是一个磁盘快。每个磁盘快有固定大小，可以存储多个K-V键值对。\\r\\n\\r\\n每个磁盘快包含指向下层节点的指针，方便查找。\\r\\n\\r\\n*由于每个节点存储了更多的键值对数据，可以有效降低查找树的次数，并减少查询磁盘。*\\r\\n\\r\\n- \\r\\n\\r\\n B+树\\r\\n\\r\\n\\r\\n\\r\\n 存储空间\\r\\n\\r\\nB+树是在B树的基础上演进的。\\r\\n\\r\\nB+树的非叶子结点是不保存数据的，仅保存键值。\\r\\n\\r\\n在 InnoDB中页大小是固定的，在只保存键值的情况下，同一个数据页能保存更多的键值。这样就能保证整个树的层级大大降低，减少向下搜索时候的磁盘IO次数，会提高数据的查询效率。\\r\\n\\r\\nInnoDB 中页的默认大小是 \"},{\"url\":\"/database/mysql/InnoDB存储引擎.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"InnoDB存储引擎\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"存储引擎\\r\\n\\r\\n在系统执行 `update` 语句时，经过 `Server层` 的处理，最终要由执行器去调用存储引擎去执行。\\r\\n\\r\\n而 MySQL 存储引擎有很多种，比如 `InnoDB`、`MyISAM`等。\\r\\n\\r\\nMySQL的默认存储引擎已经变更为了 `InnoDB`\\r\\n\\r\\n---\\r\\n\\r\\n`update` 语句操作的数据最终是要写入磁盘中的，但是如果每次都直接操作磁盘，磁盘I/O的开销是很大的。所以需要每次将操作的数据加载到内存中，减少磁盘I/O次数，再在适当时机进行刷盘操作即可。InnoDB 中使用的这块内存叫做 `Buffer Pool`。\\r\\n\\r\\n 缓冲池 - Buffer Pool\\r\"},{\"url\":\"/database/mysql/MySQL基础架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL基础架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL是 `C/S（Client端 / Server端）` 架构。\\r\\n\\r\\n 架构图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nMySQL架构包含 `Server层` 和 `存储引擎层` 。\\r\\n\\r\\n- Server 层包含 `连接器` 、`分析器`、`优化器`、`执行器`。\\r\\n- 存储引擎层包含 `引擎层`、`存储层`。\\r\\n\\r\\n 一、连接器\\r\\n\\r\\n 连接器的作用\\r\\n\\r\\n- 跟客户端建立连接。\\r\\n- 维持和管理连接。\\r\\n- 校验用户和获取用户权限。\\r\\n\\r\\n---\\r\\n\\r\\n 校验用户\\r\\n\\r\\n客户端进行连接MySQL的命令如下：\\r\\n\\r\\n```java\\r\\nmysql -h$ip -P$port -u$user -p\\r\\n`\"},{\"url\":\"/database/mysql/MySQL日志系统.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL日志系统\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"undo.log\\r\\n\\r\\n记录被更新前的数据。\\r\\n\\r\\n\\r\\n\\r\\nInnoDB 支持事务，在事务执行失败回滚时，数据会回到操作前的样子。\\r\\n\\r\\n`undo.log` 就是为了事务回滚，恢复数据的。\\r\\n\\r\\n回滚对应的操作如下：\\r\\n\\r\\n1. insert\\r\\n   \\r\\n    插入一条记录时，将这条记录的主键记录下来，回滚时根据主键删除。\\r\\n    \\r\\n2. update\\r\\n   \\r\\n    更新一条记录时，将更新的列的旧值记录下来，回滚时将这些值更新回去。\\r\\n    \\r\\n3. delete\\r\\n   \\r\\n    删除一条记录时，将这条记录记录下来，回滚时重新插入到表中。\\r\\n    \\r\\n\\r\\n---\\r\\n\\r\\n在\"},{\"url\":\"/database/mysql/MySQL根据idb文件恢复数据.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL根据idb文件恢复数据\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL根据idb文件恢复数据\\r\\n\\r\\n1. MySQl解除表名\\r\\n   \\r\\n    `Plain Text  ALTER TABLE 表名 DISCARD TABLESPACE`\\r\\n    \\r\\n2. 复制 idb 文件到 data目录。\\r\\n   \\r\\n    \\r\\n    \\r\\n3. idb 文件增加权限。\\r\\n   \\r\\n    ```\\r\\n    chown mysql:mysql user_tenant.ibd\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n4. 重新导入表数据文件\\r\\n   \\r\\n    ```\\r\\n    ALTER TABLE 表名 IMPORT TABLESPACE\\r\\n\"},{\"url\":\"/database/mysql/MySQL的binlog日志过期删除.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL的binlog日志过期删除\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"问题\\r\\n\\r\\nmysql的binlog日志过多导致磁盘告警。\\r\\n\\r\\n部署脚本中没有配置 `binlog` 的失效时间，默认是30天。\\r\\n\\r\\n 手动清理\\r\\n\\r\\n1. 查看正在使用的binlog\\r\\n   \\r\\n    ```sql\\r\\n    show master status\\r\\n    ```\\r\\n    \\r\\n2. 删除指定binlog之前的所有binlog\\r\\n   \\r\\n    ```sql\\r\\n    purge binary logs to 'bin.000055'\\r\\n    ```\\r\\n    \\r\\n\\r\\n 配置自动清理\\r\\n\\r\\n 查看日志过期时间\\r\\n\\r\\n```sql\\r\\nshow variables li\"},{\"url\":\"/database/mysql/OrderBy和limit混用的bug.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"OrderBy和limit混用的bug\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"案例\\r\\n\\r\\n```java\\r\\nselect * from table order by month desc limit 0,10\\r\\n```\\r\\n\\r\\nmonth 重复度高的情况下，limt查询会出bug。导致部分数据丢失。可以增加区分度高的字段一起排序，比如id。\\r\\n\\r\\n```java\\r\\nselect * from table order by month desc,id desc limit 0,10\\r\\n```\"},{\"url\":\"/database/mysql/SQL语句的抖动问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SQL语句的抖动问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"有时候在执行 SQL 的时候，突然会变得很慢。这种慢比较随机，看起来像是抖动一样。\\r\\n\\r\\n更新数据流程可以简化一下。\\r\\n\\r\\n1. 内存（buffer pool）中的数据 flush 到磁盘。\\r\\n2. 数据写入到 redo log 中。\\r\\n\\r\\n其中 buffer pool 中的数据页有三种状态：\\r\\n\\r\\n1. 数据页无数据。\\r\\n2. 数据页是干净页。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n3. 数据页是脏页。\\r\\n   \\r\\n    &gt; 脏页指的是内存中的数据被更新，但是没有flush到磁盘。出现内存和磁盘数据不一致的情况，此时该数据页称为脏页面。\\r\\n    &gt; \\r\\n\\r\\n 性能问题\"},{\"url\":\"/database/mysql/explain使用总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"explain使用总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"参数\\r\\n\\r\\n| id | Columns | JSON Name | Meaning |\\r\\n| --- | --- | --- | --- |\\r\\n| 1 | id | select_id | 每个select子句的标识id |\\r\\n| 2 | select_type | None | select语句的类型 |\\r\\n| 3 | table | table_name | 当前表名 |\\r\\n| 4 | partitions | partitions | 匹配的分区 |\\r\\n| 5 | type | access_type | 当前表内访问方式 join type |\\r\\n| 6 | possible_key\"},{\"url\":\"/database/mysql/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL数据库\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL基础\\r\\n\\r\\n- MySQL基础架构\\r\\n- InnoDB存储引擎\\r\\n---\\r\\n- MySQL日志系统\\r\\n---\\r\\n- 一条更新SQL的执行过程\\r\\n---\\r\\n- 事务隔离\\r\\n---\\r\\n- B树和B+树\\r\\n- 索引\\r\\n---\\r\\n- 锁\\r\\n- 行锁\\r\\n\\r\\n\\r\\n\\r\\n MySQL总结\\r\\n\\r\\n- SQL语句的抖动问题\\r\\n- 索引失效的场景\\r\\n- explain使用总结\\r\\n- 慢查询日志\\r\\n\\r\\n\\r\\n 问题总结\\r\\n- OrderBy和limit混用的bug\\r\\n- MySQL的binlog日志过期删除\\r\\n- MySQL根据idb文件恢复数据\"},{\"url\":\"/database/mysql/一条更新SQL的执行过程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"一条更新SQL的执行过程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"juejin.cn\\r\\n\\r\\n```java\\r\\nmysql\\r\\n```\\r\\n\\r\\n 执行流程\\r\\n\\r\\n1. 执行器先找引擎取出 ID=2 这一行记录。\\r\\n    - 如果该行记录在 `Buffer Pool` 中存在，会直接返回数据给执行器。\\r\\n    - 如果该行记录不存在，则会先进行如下操作，再返回数据给执行器。\\r\\n        - 从磁盘中查找数据。\\r\\n        - 将数据写入内存 `Buffer Pool` 中。\\r\\n        - 将数据写入 `undo.log`（记录 insert、update、delete等修改数据的操作）。\\r\\n2. 执行器获取到引擎给的行数据，把这条数据更新 c\"},{\"url\":\"/database/mysql/事务隔离.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"事务隔离\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。\\r\\n\\r\\n在 MySQL 中，事务支持是在`引擎层`实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。\\r\\n\\r\\n比如 MySQL 原生的 `MyISAM 引擎就不支持事务`，这也是 MyISAM 被 InnoDB 取代的重要原因之一。\\r\\n\\r\\n 事务问题\\r\\n\\r\\n 脏读\\r\\n\\r\\n读到了别的事务 修改过 但未提交的数据\\r\\n\\r\\n 不可重复读\\r\\n\\r\\n指的是变没变化的问题。数据被修改了导致前后两次查询结果不一样。\\r\\n\\r\\n原来是 A，现在是 B，就是不可重复读。\\r\\n\\r\\n 幻读\\r\\n\\r\\n指的是存不存在的问题，原来存\"},{\"url\":\"/database/mysql/慢查询日志.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"慢查询日志\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL中，需要查看执行慢的SQL，需要先开启慢查询日志。\\r\\n\\r\\nMySQL的慢查询日志，记录了MySQL中响应时间超过阈值的SQL语句。\\r\\n\\r\\n 参数说明\\r\\n\\r\\n- slow_query_log：是否开启慢查询日志，1表示开启，0表示关闭。\\r\\n- log-slow-queries ：旧版（5.6以下版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name-slow.log\\r\\n- slow-query-log-file：新版（5.6及以上版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name\"},{\"url\":\"/database/mysql/索引.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"索引\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准。\\r\\n\\r\\n InnoDB的索引模型\\r\\n\\r\\n B+树\\r\\n\\r\\n\\r\\n\\r\\nB+树的每个叶子节点存放元素有限，每个叶子节点为一个 page，针对元素的数量会产生页分裂、页合并等现象。\\r\\n\\r\\n什么是B+树？_攻城狮百里的博客-CSDN博客_b+树\\r\\n\\r\\n\\r\\n\\r\\n 聚簇索引和二级索引\\r\\n\\r\\n- 主键索引的叶子结点存的是整行记录。InnoDB 引擎中主键索引又称为聚簇索引。\\r\\n- 非主键索引的叶子结点存的是行记录的ID。在 InnoDB 引擎中非主键索引又称为二级索引。\\r\\n\\r\\n\\r\\n\\r\\n 搜索方式\\r\\n\\r\\n- 根据主键搜索\\r\\n  \\r\\n    `\"},{\"url\":\"/database/mysql/索引失效的场景.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"索引失效的场景\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"查询条件做函数计算\\r\\n\\r\\n```sql\\r\\nselect count(*) from tradelog where month(t_modified)=7;\\r\\n```\\r\\n\\r\\n查询条件做函数计算，在查索引的时候，利用不了索引。因为索引利用的是树的有序性，但是函数计算后的结果在索引的B+树上并不连续。MySQL在查询的时候利用不到树的有序性。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。\\r\\n\\r\\n 隐式类型转换\\r\\n\\r\\n假如 tradeid 字段类型是 varchar ，查询语句\\r\\n\\r\\n```sql\\r\\nexplain   sele\"},{\"url\":\"/database/mysql/行锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"行锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL 中的行锁（row-level locking）并不是单纯指写锁（write lock），而是指锁定机制的粒度。行锁可以是共享锁（也称为读锁，S锁）或排他锁（也称为写锁，X锁），具体取决于事务所使用的隔离级别以及查询类型。\\r\\n\\r\\n- Select for Update：当执行带有 `FOR UPDATE` 子句的 `SELECT` 查询时，InnoDB 会对被选中的行加上排他锁。这确保了在事务提交之前，其他事务不能修改这些行。\\r\\n- Insert Intention Lock：当执行 `INSERT` 操作时，InnoDB 会自动为要插入的行加上意向锁。这是为了避免插入操作与其他事务\"},{\"url\":\"/database/mysql/锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL中加锁是为了处理并发问题，根据锁的粒度可以分为全局锁、表级锁和行锁。\\r\\n\\r\\n 全局锁\\r\\n\\r\\n全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 `Flush tables with read lock` (FTWRL)。\\r\\n\\r\\n加完之后整个数据库处于只读状态。\\r\\n\\r\\n---\\r\\n\\r\\n 应用场景（不推荐）\\r\\n\\r\\n全局锁的经典应用场景 数据库备份。\\r\\n\\r\\n由于加全局锁，会导致整个数据库只读，所以一般不推荐使用。\\r\\n\\r\\n 可重复读进行备份\\r\\n\\r\\n备份数据库一般可以利用可重复读的事务隔离级别来实现，因为可重复读情况开始事务，会生成当前数据库的视图，保证整个事务期间以\"},{\"url\":\"/database/redis/LRU和LFU算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"LRU和LFU算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"LRU算法\\r\\n\\r\\n 简介\\r\\n\\r\\nLRU （Least Recently Used） 算法即最近最久未使用，每次选择最近最久未使用的页面淘汰掉。\\r\\n\\r\\n 实现过程\\r\\n\\r\\n- 新增数据时，元素插入到队列头部。\\r\\n- 访问元素（查询、更新和删除）时，将元素移动到队列头部。\\r\\n- 当超过内存限制，需要淘汰数据时，将已排序队列的最后元素删除。\\r\\n\\r\\n\\r\\n\\r\\n 数据结构\\r\\n\\r\\nLRU 算法内部的数据结构需要根据元素的访问时间排序。还需要查找、插入、删除等效率要高。\\r\\n\\r\\n1. 查找、插入、删除快。\\r\\n2. 支持排序。\\r\\n\\r\\n在常用的集合中，有的是查找更新快或者插入删除快，没有数据结构能同时满足以上条件，所\"},{\"url\":\"/database/redis/Redisson.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Redisson\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还实现了可重入锁（Reentrant Lock）、公平锁（Fair Lock、联锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）等，还提供了许多分布式服务。Redisson提供了使用Redis的最简单和最便捷的方法。Redisson的宗旨是促进使用者对Redis的关注分离（Separation of Concern），从而让使用者能够将精力更集中地放在处理业务逻辑上。\\r\\n\\r\\n Redisson \"},{\"url\":\"/database/redis/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- redis数据类型\\r\\n- redis数据类型原理\\r\\n- redis的持久化\\r\\n\\r\\n\\r\\n- 过期策略\\r\\n- 内存淘汰策略\\r\\n- LRU和LFU算法\\r\\n\\r\\n- redis实现分布式锁\\r\\n- Redisson\\r\\n\\r\\n- redis事务.md\\r\\n- redis集群.md\\r\\n\\r\\n- 缓存问题\\r\\n- 布隆过滤器\"},{\"url\":\"/database/redis/redis事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis的事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis 的事务，可以一次执行多个命令，本质上是一组命令的集合，按照顺序串行化执行而不会被其它命令插入。\\r\\n\\r\\n 常用命令\\r\\n\\r\\n- 开启事务 -`multi`\\r\\n- 执行所有事务 - `exec`\\r\\n- 取消所有事务 - `discard`\\r\\n- 监控一个或多个 key - `watch`\\r\\n- 取消 watch 命令对所有 key 的监控 - `unwatch`\\r\\n  \\r\\n    \\r\\n    \\r\\n\\r\\n watch监控\\r\\n\\r\\nwatch 指令，类似乐观锁，在创建事务之前，使用 watch 指令监控某个值。在事务提交时，如果 key 的值已经被别的客户端改变，那么整个事务队列都不会执行。\\r\\n\"},{\"url\":\"/database/redis/redis实现分布式锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis实现分布式锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"分布式锁简介\\r\\n\\r\\n在分布式环境下，多个系统访问共享资源时会发生线程安全问题，分布式锁就是为了解决分布式环境下访问共享资源的线程安全问题，保证共享资源同一时间只能被一个系统的一个线程访问。\\r\\n\\r\\n 分布式锁具备的条件\\r\\n\\r\\n1. 在分布式环境下，共享资源在同一时间只能被一个系统的一个线程访问。\\r\\n2. 保证设置分布式锁和删除分布式锁操作的原子性。\\r\\n3. 具备可重入特性。\\r\\n4. 防止死锁。\\r\\n5. 具备锁超时失效的机制。\\r\\n6. 具备非阻塞锁特性，不会阻塞等待获取锁。\\r\\n\\r\\n 分布式锁主要实现方式\\r\\n\\r\\n1. zeekeeper 实现分布式锁\\r\\n2. redis 实现分布式锁\\r\\n\\r\\n---\\r\"},{\"url\":\"/database/redis/redis数据类型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis数据类型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis数据类型\\r\\n\\r\\n练习代码地址 redis-practice\\r\\n\\r\\n 键 - key\\r\\n\\r\\n在了解数据类型之前，先了解一下 redis 的键。\\r\\n\\r\\n在 redis 中 命令不区分大小写，但是注意 redis 中的 key 和 value 是区分大小写的。\\r\\n\\r\\n\\r\\n\\r\\n 字符串 - string\\r\\n\\r\\n字符串数据结构是简单的 K-V 模式数据结构。\\r\\n\\r\\n 特点\\r\\n\\r\\n- 单值单 value。\\r\\n- 二进制安全，可以包含任何数据。\\r\\n- 一个键对应 value 值最大能存储数据 512 MB。\\r\\n\\r\\n 常用命令\\r\\n\\r\\n\\r\\n\\r\\n- 设置字符串 - `set test 100`\\r\\n- 查\"},{\"url\":\"/database/redis/redis数据类型原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis数据类型原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. linkedlist (双向链表)\\r\\n    - 当列表元素较多或元素大小超过一定阈值时，Redis 会使用双向链表来存储 `list` 键。\\r\\n    - linkedlist 是一种指针结构，每个节点包含指向前后节点的指针，这使得插入和删除操作非常高效。\\r\\n    - linkedlist 的优点是支持高效的插入和删除操作，但缺点是比 ziplist 更占用内存。\\r\\n\\r\\n 全局哈希表\\r\\n\\r\\n\\r\\n\\r\\nRedis是一个 K-V 数据库，有一个全局的哈希桶存放所有的 key。\\r\\n\\r\\nkey 对应的 entry 包含了实际的 key 和 value。这里的 value 对应着不同的数据类型。\"},{\"url\":\"/database/redis/redis的持久化.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis的持久化\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis 有 RDB 和 AOF 两种持久化方式。\\r\\n\\r\\n RDB\\r\\n\\r\\nRDB 是 *Redis DataBase* 的简称，指的是在指定时间间隔内将内存中的数据集快照写入磁盘文件，也就是 Snapshot 快照，RDB 是默认开启的。\\r\\n\\r\\n RDB的原理\\r\\n\\r\\nRedis 会单独创建 （fork）一个子进程来进行持久化操作，将内存中某一时刻的数据持久化到磁盘文件。这个子进程会先将数据写入到一个临时文件中，等待持久化进程结束后，再用这个临时文件替换掉磁盘文件。\\r\\n\\r\\n\\r\\n\\r\\n在整个过程中，主进程是不进行任何 IO 操作的，这样保证了主进程存取的高性能。\\r\\n\\r\\nRDB 的持久化过程每次都是\"},{\"url\":\"/database/redis/redis集群.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis集群\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Redis集群是一个由多个主从节点群组成的分布式服务集群，它具有复制、高可用和分片特性。\\r\\n\\r\\n 主从模式\\r\\n\\r\\n\\r\\n\\r\\n- 主数据库可以进行读写操作。\\r\\n  \\r\\n    数据会通过主从同步，由主服务器同步给从服务器。\\r\\n    \\r\\n    主服务器将数据\\r\\n    \\r\\n- 从数据库一般是只读的。\\r\\n\\r\\n引入主从复制机制的目的有两个：\\r\\n\\r\\n- 一个是读写分离，分担 “master” 的读写压力\\r\\n- 一个是方便做容灾恢复，避免单点故障。\\r\\n\\r\\n 主从同步的原理\\r\\n\\r\\n\\r\\n\\r\\n- 全量复制\\r\\n  \\r\\n    从数据库在第一次同步的时候会进行全量同步。\\r\\n    \\r\\n    主库执行 bgsav\"},{\"url\":\"/database/redis/内存淘汰策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内存淘汰策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"最大内存设置\\r\\n\\r\\n1. redis 默认内存是多少？\\r\\n   \\r\\n    在 64 位操作系统不限制内存大小，在 32 位操作系统下最多使用 3GB。\\r\\n    \\r\\n2. 查看 redis 最大内存？\\r\\n   \\r\\n    `Plain Text  config get maxmemory`\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 修改 redis 内存大小？\\r\\n    - 修改配置文件\\r\\n      \\r\\n        在 `redis.conf` 第 859 行可以设置最大内存大小（单位是字节）。\\r\\n        \\r\\n        \\r\\n        &gt; \\r\\n        \"},{\"url\":\"/database/redis/布隆过滤器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"布隆过滤器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 什么是布隆过滤器？\\r\\n\\r\\n布隆过滤器（Bloom Filter）是一种数据结构，用来判断一个元素是否在一个集合中。布隆过滤器的本质上使用的是二进制向量和 k 个哈希函数组成。\\r\\n\\r\\n布隆过滤器具有如下优点：\\r\\n\\r\\n- 空间利用率高。\\r\\n  \\r\\n    布隆过滤器底层使用二进制向量保存数据，不需要保存元素本身，只需要在指定 bit 存放标识即可，故空间利用率非常高。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n- 时间效率也较高，插入和查询效率高。\\r\\n  \\r\\n    布隆过滤器的时间复杂度只跟哈希函数的个数 k 有关，插入和查询的时间复杂度均为 O(k)；\\r\\n    \\r\\n    *结合\"},{\"url\":\"/database/redis/缓存问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"缓存问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"前言\\r\\n\\r\\n在使用缓存的时候，简单的缓存处理流程如下。针对如下流程会遇到缓存穿透、缓存击穿、缓存雪崩等问题。\\r\\n\\r\\n\\r\\n\\r\\n 缓存穿透\\r\\n\\r\\n缓存穿透：当用户请求查询某个数据时，先从缓存查询，缓存中没有这个数据。然后向数据库查询数据，数据库中也没有这个数据，导致查询失败。\\r\\n\\r\\n*像一些恶意攻击时，故意查询数据库中不存在的数据，比如查询 id = -1 的数据，会造成数据库压力非常大。*\\r\\n\\r\\n\\r\\n\\r\\n 解决方案\\r\\n\\r\\n1. 对空值做缓存。\\r\\n   \\r\\n    当出现从缓存和数据库都查不到数据的情况时，可以将空值存到缓存中，即 K-V 存为 key-null，缓存过期时间可以设置短点，来防止短\"},{\"url\":\"/database/redis/过期策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"过期策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 Redis 中设置了过期时间的 key，在一定时间后都会被删除。\\r\\n\\r\\n 键的过期时间\\r\\n\\r\\n 配置过期时间\\r\\n\\r\\n1. `setex key seconds value`\\r\\n   \\r\\n    设置 key 时添加过期时间\\r\\n    \\r\\n2. `expire key seconds`\\r\\n   \\r\\n    为某个 key 设置过期时间。\\r\\n    \\r\\n3. 删除 key 的过期时间。\\r\\n   \\r\\n    `persist key`\\r\\n    \\r\\n4. 查看 key 的过期时间\\r\\n   \\r\\n    `ttl key`\\r\\n    \\r\\n\\r\\n redis保存过期时间分析\\r\\n\\r\\n[版权声明：本文为CS\"},{\"url\":\"/frame/mybatis/custom/SQL执行器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SQL执行器-executor\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"将操作数据库的操作从 sqlSession 中解耦，放到 Executor 中。\\r\\n\\r\\n包括事务操作也放到 Executor 中。\\r\\n\\r\\n```java\\r\\npublic interface Executor {\\r\\n\\r\\n    ResultHandler NO_RESULT_HANDLER = null;\\r\\n\\r\\n    &lt;E\\r\\n\\r\\n    Transaction getTransaction();\\r\\n\\r\\n    void commit(boolean required) throws SQLException;\\r\\n\\r\\n    void rollback(boolean required) \"},{\"url\":\"/frame/mybatis/custom/xml解析.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"xml解析\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"\"},{\"url\":\"/frame/mybatis/custom/手写MyBatis.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"手写MyBatis\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"整体流程\\r\\n\\r\\n\\r\\n\\r\\n整个mybatis的功能，就是代理 mapper 然后执行SQL，返回执行结果。\\r\\n\\r\\n\\r\\n\\r\\n1. 解析mybatis配置\\r\\n    - 解析数据源 （Configuration 的 environment）\\r\\n    - 解析mapper文件配置 （路径扫描）\\r\\n2. 解析mapper文件\\r\\n    - 注册mapper到mapperRegistry。（包含mapper的代理类工厂，可以获取代理过的mapper）\\r\\n    - 生成mapper方法对应的mapperStatement。（Configuration 的 mappedStatements）\\r\\n    -\"},{\"url\":\"/frame/mybatis/custom/数据源.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据源\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"数据源解析\\r\\n\\r\\n解析配置文件中的数据源\\r\\n\\r\\n1. 事务模版 - jdbc\\r\\n2. 数据源实现 - druid\\r\\n\\r\\n```xml\\r\\n&lt;configuration\\r\\n\\r\\n    &lt;!--    数据源配置   --&gt;\\r\\n    &lt;environments default=\\\"development\\\"&gt;\\r\\n        &lt;environment id=\\\"development\\\"&gt;\\r\\n            &lt;transactionManager type=\\\"JDBC\\\"/&gt;\\r\\n            &lt;dataSource type=\\\"\"},{\"url\":\"/frame/mybatis/custom/映射器-mapper.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"映射器-mapper\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- SqlSession提供了SqlId。\\r\\n- 而SqlSessionFactroy 提供了开启SqlSession的能力。]\\r\\n- MapperRegistry 包含了所有Mapper的SqlId，包含注册发现Mapper的能力。\\r\\n\\r\\n MapperFactory\\r\\n\\r\\n\\r\\n\\r\\n MapperProxy\\r\\n\\r\\n在mybatis中，调用mapper里面的方法就可以执行SQL。其实是因为mybatis隐藏了实现细节。\\r\\n\\r\\n具体做法是根据mapper里面点的方法生成代理逻辑，在调用该方法时其实是走的代理类的逻辑。\\r\\n\\r\\n而代理类封装了操作数据库的逻辑，代理类即为mapperProxy。\\r\\n\\r\"},{\"url\":\"/frame/mybatis/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MyBatis 框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"手写MyBatis\\r\\n\\r\\n- 手写MyBatis\\r\\n- 映射器-mapper\\r\\n- 数据源\\r\\n- SQL执行器\\r\\n- xml解析\"},{\"url\":\"/frame/netty/ByteBuf.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ByteBuf\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ByteBuf是Netty中用于表示字节序列的数据容器。它是Netty对Java NIO中的ByteBuffer的改进和增强。ByteBuf提供了更灵活、更强大的API，具有许多优势，使得它在网络编程中更加方便和高效。\\r\\n\\r\\n以下是ByteBuf的主要优势：\\r\\n\\r\\n1. 灵活的容量管理： ByteBuf支持动态扩容和收缩，相比Java NIO的ByteBuffer，ByteBuf的容量可以根据实际需求自动调整，无需手动扩容。\\r\\n2. 更丰富的API： ByteBuf提供了丰富的操作API，包括读取、写入、复制、切片、合并等操作。这些API使得对字节数据的操作更加便利，同时提供了更多的功能。\\r\\n\"},{\"url\":\"/frame/netty/HTTP服务和SSL&TLS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP服务和SSL/TLS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"服务端\\r\\n\\r\\n按照 pipline 执行。\\r\\n\\r\\n```java\\r\\n@Override\\r\\n    protected void initChannel(SocketChannel socketChannel) throws Exception {\\r\\n        ChannelPipeline pipeline = socketChannel.pipeline();\\r\\n        //TODO ssl\\r\\n\\r\\n        //服务端\\r\\n        //对请求内容解码\\r\\n        pipeline.addLast(\\\"decoder\\\", new HttpRequestDecode\"},{\"url\":\"/frame/netty/Handler的共享和并发安全性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Handler的共享和并发安全性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"服务端为Channel设置pipeline的时候，可以选择设置共享的还是Channel独有的。\\r\\n\\r\\n```java\\r\\nprivate void start() throws InterruptedException {\\r\\n        final MsgCountHandler msgCountHandler = new MsgCountHandler();\\r\\n        //线程组\\r\\n        EventLoopGroup boss = new NioEventLoopGroup();\\r\\n        EventLoopGroup work = new NioEventLoo\"},{\"url\":\"/frame/netty/Netty实现文件下载.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty实现文件下载\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"实例：如何使用 Netty 下载文件_channelhandlercontext下载文件-CSDN博客\\r\\n\\r\\n ChannelHandler\\r\\n\\r\\n自定义 ChannelHandler ，用来处理 Channel 里面的事件，写数据处理逻辑的。\\r\\n\\r\\n- ChannelInboundHandlerAdapter\\r\\n- SimpleChannelInboundHandler\\r\\n    \\r\\n    是 ChannelInboundHandlerAdapter 的子类，能够指定类型。\\r\\n    \\r\\n\\r\\nNetty 里面预设了很多 ChannelHandler\\r\\n\\r\\n```java\\r\\nch.pipel\"},{\"url\":\"/frame/netty/Netty实现通信框架.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty实现通信框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"功能点\\r\\n\\r\\n1. 基于Netty的NIO通信框架。\\r\\n2. 提供消息的编码解码框架，实现对象的序列化和反序列化。\\r\\n3. 消息内容的放篡改机制。\\r\\n4. 提供基于IP的白名单认证机制。\\r\\n5. 链路的有效性机制（心跳）。\\r\\n6. 链路的断连重连机制。\\r\\n\\r\\n 通信模型\\r\\n\\r\\n\\r\\n\\r\\n 调用链路\\r\\n\\r\\n\\r\\n\\r\\n粘包半包是最前面先要解决的问题。\\r\\n\\r\\n 写空闲检测\\r\\n\\r\\n```java\\r\\npublic class CheckWriteIdleHandler extends IdleStateHandler {\\r\\n\\r\\n    /**\\r\\n     * 0 表示读空闲时间不进行检测，即不对读空闲做任何\"},{\"url\":\"/frame/netty/Netty常用组件.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty常用组件\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Bootstrap\\r\\n\\r\\nNetty的启动类\\r\\n\\r\\n- Bootstrap\\r\\n\\r\\n    客户端启动类\\r\\n\\r\\n- ServerBootstrap\\r\\n\\r\\n    服务端启动类\\r\\n\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n 第一个区别\\r\\n\\r\\n- 客户端需要连接到远程主机和端口即可。\\r\\n\\r\\n- 服务端需要绑定端口。\\r\\n\\r\\n 第二个区别\\r\\n\\r\\n- 服务端需要两个 EventLoopGroup。\\r\\n\\r\\n    原因是使用了多线程主从的Reactor模式。\\r\\n\\r\\n    - 第一个EventLoopGroup，只有一个EventLoop，负责为传入的Accept请求建立连接。一旦建立连接后续，将该 Channel 放到\"},{\"url\":\"/frame/netty/TCP粘包拆包问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP粘包拆包问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"TCP 粘包\\r\\n\\r\\n由于 TCP 协议本身的机制（面向连接的可靠地协议-三次握手机制）客户端与服务器会维持一个连接（Channel），数据在连接不断开的情况下，可以持续不断地将多个数据包发往服务器。\\r\\n\\r\\n但是如果发送的网络数据包太小，那么他本身会启用 Nagle 算法（可配置是否启用）对较小的数据包进行合并（基于此，TCP 的网络延迟要 UDP 的高些）然后再发送（超时或者包大小足够）。\\r\\n\\r\\n那么这样的话，服务器在接收到消息（数据流）的时候就无法区分哪些数据包是客户端自己分开发送的，这样产生了粘包。\\r\\n\\r\\n服务器在接收到数据库后，放到缓冲区中，如果消息没有被及时从缓存区取走，下次在取数据的\"},{\"url\":\"/frame/netty/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础总结\\r\\n\\r\\n- Netty常用组件\\r\\n- Handler的共享和并发安全性\\r\\n- 资源管理和SimpleChannelInboundHandler\\r\\n- 内置通信传输模式\\r\\n- TCP粘包拆包问题\\r\\n- 编解码器\\r\\n\\r\\n\\r\\n- HTTP服务和SSL&TLS\\r\\n- 序列化问题\\r\\n- 写空闲和读空闲\\r\\n\\r\\n\\r\\n- ByteBuf\\r\\n- 线程模型\\r\\n- 零拷贝\\r\\n\\r\\n\\r\\n 练习总结\\r\\n- Netty实现通信框架\\r\\n- 基于Netty实现RPC\\r\\n- Netty实现文件下载\"},{\"url\":\"/frame/netty/内置通信传输模式.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内置通信传输模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```java\\r\\ntry {\\r\\n            //父子EventLoop\\r\\n            serverBootstrap.group(boss,work)\\r\\n                    //指定使用NIO的通信模式\\r\\n                    .channel(NioServerSocketChannel.class)\\r\\n                    .localAddress(new InetSocketAddress(port))\\r\\n                    .childHandler(new ChannelInitia\"},{\"url\":\"/frame/netty/写空闲和读空闲.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"写空闲和读空闲\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在Netty框架中，写空闲（Write Idle） 和 读空闲（Read Idle） 是空闲检测机制中的两个重要概念，它们用于监控网络连接的活跃状态，确保连接的有效性和资源的有效管理。\\r\\n\\r\\n 写空闲（Write Idle）\\r\\n\\r\\n- 定义：写空闲指的是在一段指定时间内，没有数据通过当前的`Channel`被写入到网络中传输给对方。这可能意味着在这段时间内，服务端没有向客户端发送任何数据，或者客户端没有向服务端发送数据。\\r\\n- 应用场景：在某些协议或应用场景中，如果长时间没有数据写入，可能需要触发特定的操作，比如发送心跳包以维持连接活跃，或者是判断连接是否已经失效，进而关闭连接以释放资源。\\r\\n\"},{\"url\":\"/frame/netty/基于Netty实现RPC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"基于netty实现RPC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"源码地址\\r\\n\\r\\nAlbert.Yang/JavaAdvance\\r\\n\\r\\n 服务端\\r\\n\\r\\n ServerBootstrap\\r\\n\\r\\n```java\\r\\n@Service\\r\\n@Slf4j\\r\\npublic class RpcServerFrame implements Runnable {\\r\\n\\r\\n    @Autowired\\r\\n    private ServerInit serverInit;\\r\\n\\r\\n    private EventLoopGroup bossGroup = new NioEventLoopGroup();\\r\\n    private EventLoopGroup workGroup =\"},{\"url\":\"/frame/netty/序列化问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"序列化问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java对象的序列化主要有两个：\\r\\n\\r\\n1. 网络传输\\r\\n   \\r\\n    数据在网络中传输是通过字节流形式的，到服务端需要解码。\\r\\n    \\r\\n2. 对象持久化\\r\\n\\r\\n Java序列化\\r\\n\\r\\nJava序列化机制是基于对象的类结构进行的。\\r\\n\\r\\n当对象需要序列化时，会将对象转换为字节流在网络传输。\\r\\n\\r\\n反序列化时，就是将字节流转换为对象的过程。Java会将字节流转换为对象重新加载到内存中。\\r\\n\\r\\nJava的序列化机制是通过实现`java.io.Serializable`接口来实现的。该接口是一个标记接口，没有任何方法定义。只有实现了`Serializable`接口的类的对象才能被序列化。\\r\\n\"},{\"url\":\"/frame/netty/线程模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Netty的线程模型是什么？为什么它是高效的？\\r\\n\\r\\n1. Netty的线程模型是基于事件驱动的，采用了Reactors设计模式。它的线程模型主要包含以下几个关键组件：\\r\\n2. Boss Group和Worker Group： Netty通过Boss Group和Worker Group来分别管理两类不同的线程。Boss Group负责接收客户端的连接，而Worker Group则负责处理连接后的网络流量。\\r\\n3. Channel： Channel代表了一个网络连接，可以是客户端到服务器的连接，也可以是服务器之间的连接。每个Channel都由一个EventLoop负责处理，而一个EventLo\"},{\"url\":\"/frame/netty/编解码器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"编解码器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在网络传输中，数据是通过字节流传输。\\r\\n\\r\\n对应到客户端和服务端需要进行对应的编码和解码。\\r\\n\\r\\n 解码器\\r\\n\\r\\n- 将字节解码为消息：ByteToMessageDecoder\\r\\n- 将一种消息类型解码为另一种：MessageToMessageDecoder。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 异常处理\\r\\n\\r\\n- TooLongFrameException\\r\\n    \\r\\n    由于 Netty 是一个异步框架，所以需要在字节可以解码之前在内存中缓冲它们。因此，不能让解码器缓冲大量的数据以至于耗尽可用的内存。为了解除这个常见的顾虑，Netty 提供了 TooLongFrameException 类\"},{\"url\":\"/frame/netty/资源管理和SimpleChannelInboundHandler.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"资源管理和SimpleChannelInboundHandler\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NIO中读写Channel数据，都使用了 Buffer，读写数据都是从 Buffer里面读取的。\\r\\n\\r\\n而 Netty在读写网络数据时，同样也需要 Buffer。\\r\\n\\r\\n但是这样就涉及到 Buffer的内存释放，不然会造成内存泄漏。\\r\\n\\r\\n SimpleChannelInboundHandler\\r\\n\\r\\nNetty实现了SimpleChannelInboundHandler类，提供 `channelRead0()` 方法，保证数据被该方法消费后自动释放数据。\\r\\n\\r\\n```java\\r\\n    public void channelRead(ChannelHandlerContext ctx, Ob\"},{\"url\":\"/frame/netty/零拷贝.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"零拷贝\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. ByteBuf 可以直接使用直接内存。\\r\\n    \\r\\n    Socket 通信如果采用堆内存的话，需要将堆里的对象拷贝到堆外，进行一次对象拷贝。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n    \\r\\n    但是 Socket 没有更新对象地址动作，需要的是一个固定的地址。所以堆内存不适合 Socket 使用。只能将对象拷贝到直接内存然后使用。\\r\\n    \\r\\n    而 ByteBuf 直接使用直接内存，减少了对象拷贝。\\r\\n    \\r\\n2. Netty 提供了组合 Buffer，可以将多个 Buffer 合并为一个。\\r\\n    \\r\\n    传统通过内存拷贝的方式将几个小Buffe\"},{\"url\":\"/frame/spring/AOP.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AOP\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"面向切面编程\\r\\n\\r\\n面向切面编程，指的是在运行期间生成代理对象来对类进行增强处理，比如方法执行前和方法执行后进行代码增强。\\r\\n\\r\\n 什么是切面\\r\\n\\r\\n- 切：\\r\\n  \\r\\n    指的是横切逻辑，原有方法代码不动。只能操作横切逻辑代码进行增强。\\r\\n    \\r\\n- 面：\\r\\n  \\r\\n    横切逻辑往往影响很多个方法，每个方法是一个切点，便形成了面。\\r\\n    \\r\\n\\r\\n常用的功能有：\\r\\n\\r\\n- 方法审计日志\\r\\n- 校验权限是否足够\\r\\n\\r\\n\\r\\n\\r\\n AOP体系\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n)连接点 - JoinPoint\\r\\n\\r\\n类里面哪些方法可以被增强，这些方法称为连接点。\\r\\n\\r\\n- 切面\\r\\n\\r\\n    切\"},{\"url\":\"/frame/spring/ApplicationContext和BeanFactory区别.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ApplicationContext和BeanFactory区别\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ApplicationContext 总结\\r\\n\\r\\nApplicationContext 容器上下文，包含了 BeanFactory 的所有功能，还额外提供了以下功能：\\r\\n\\r\\n- MessageSource，提供国际化的消息访问\\r\\n- 资源访问，如 URL 和文件\\r\\n- 事件传播\\r\\n\\r\\n 工具类\\r\\n\\r\\n可以通过实现 `ApplicationContextAware` 接口注入 ApplicationContext\\r\\n\\r\\n```java\\r\\n@Component\\r\\npublic class SpringBeanUtil implements ApplicationContextAware {\\r\\n\\r\\n\"},{\"url\":\"/frame/spring/Aware接口.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Aware接口\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在Spring框架中，`Aware`接口提供了一种机制，允许Bean在初始化过程中获取Spring容器的特定上下文信息或资源。这些接口通常被称作回调接口，因为它们允许Spring容器在特定时刻回调Bean，以便将一些重要的信息注入给Bean。\\r\\n\\r\\n ApplicationContextAware\\r\\n\\r\\n当Spring容器在初始化一个实现了`ApplicationContextAware`接口的Bean时，它会调用`setApplicationContext`方法，将当前的应用上下文传入。\\r\\n\\r\\n```java\\r\\npublic interface ApplicationContextAware\"},{\"url\":\"/frame/spring/BeanFactory和FactoryBean总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BeanFactory和FactoryBean总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"BeanFactory总结\\r\\n\\r\\nBeanFactory 是 Spring 中的一个接口，提供了 IOC 容器最基本的形式，给具体的 IOC 容器实现提供了规范。\\r\\n\\r\\n其本质是一个 IOC 容器或对象工厂，所有的 Bean 都是由 BeanFactory （IOC容器）来进行管理的。Spring 有许多 BeanFactory 的实现类，附件了许多功能。\\r\\n\\r\\n```java\\r\\npublic interface BeanFactory {\\r\\n  \\r\\n  Object getBean(String name) throws BeansException;\\r\\n  \\r\\n\\t&lt;T\\r\\n\\r\\n\\tObj\"},{\"url\":\"/frame/spring/ByteBuddy实现动态代理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ByteBuddy实现动态代理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Byte Buddy - runtime code generation for the Java virtual machine\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n```java\\r\\n&lt;dependency&gt;\\r\\n  &lt;groupId&gt;net.bytebuddy&lt;/groupId&gt;\\r\\n  &lt;artifactId&gt;byte-buddy&lt;/artifactId&gt;\\r\\n  &lt;version&gt;LATEST&lt;/version&gt;\\r\\n&lt;/dependency&gt;\\r\\n```\\r\\n\\r\\n```java\\r\\npublic c\"},{\"url\":\"/frame/spring/Spi机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spi机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SPI机制，全称Service Provider Interface，是Java提供的一种标准的服务发现机制。它允许第三方服务提供者扩展某个接口的实现，而无需修改接口的源代码或重新打包。\\r\\n\\r\\nSpring SPI机制常用于 starter 构建和基础库实现。\\r\\n\\r\\n通过 spi 机制，确保自动配置生效的类包含 FileAutoConfiguration\\r\\n\\r\\n\\r\\n\\r\\n使用 SPI可以可插拔的注入配置，比如 `EnableAutoConfiguration`，如果需要 MinIO的配置类，加在类里面即可开启MinIO的功能。\\r\\n\\r\\nwww.jb51.net\\r\\n\\r\\nSPI机制是什么？_java_\"},{\"url\":\"/frame/spring/Spring中Bean加载流程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring中Bean加载流程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"流程图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 创建流程\\r\\n\\r\\n1. 加载 `ApplicationContext` 上下文环境。\\r\\n2. `ApplicationContext` 通过扫描、读取配置，将 Bean对象封装为 `BeanDefinition` 对象，并注册到 `BeanDefinitionMap` 中。\\r\\n3. 在 `ApplicationContext` 执行完成之后会调用对应的后置处理器 `BeanFactoryProcessor` 和其子类 `BeanDefinitionRegistryPostProcessor` 对应方法，可以修改和注册 `BeanDefinition` 到 \"},{\"url\":\"/frame/spring/Spring中Bean的作用域.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring中Bean的作用域\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"作用域类型\\r\\n\\r\\n- singleton\\r\\n    \\r\\n    单例模式。\\r\\n    \\r\\n    使用 `singleton` 定义的 Bean 在 Spring 容器中只有一个实例，是 Bean 默认的作用域。\\r\\n    \\r\\n- prototype\\r\\n    \\r\\n    原型模式\\r\\n    \\r\\n    每次通过 Spring 容器获取 `prototype` 定义的 Bean 时，容器都将创建一个新的 Bean 实例。\\r\\n    \\r\\n- request\\r\\n    \\r\\n    在一次 HTTP 请求中，容器会返回该 Bean 的同一个实例。而对不同的 HTTP 请求，会返回不同的实例，该作用域\"},{\"url\":\"/frame/spring/Spring事务总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring事务总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"编程式事务\\r\\n\\r\\n在代码中硬编码，不推荐使用。\\r\\n\\r\\n 声明式事务\\r\\n\\r\\n- 基于注解的声明式事务\\r\\n- 基于 XML 的声明式事务\\r\\n\\r\\n @Transactional 注解\\r\\n\\r\\nException 分为运行时异常 RuntimeException 和非运行时异常。事务管理能保证出现异常情况的时候保证数据的一致性。\\r\\n\\r\\n默认 `@Transactional` 注解只会在遇到 RuntimeException 类型异常或者 Error时，才会回滚事务。遇到其它异常，Spring 不会回滚事务。\\r\\n\\r\\n 作用范围\\r\\n\\r\\n当 `@Transactional`注解作用于类上的时，该类的所有方法都\"},{\"url\":\"/frame/spring/Spring依赖注入.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring依赖注入\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"依赖注入就是通过spring将bean所需要的一些参数传递到bean实例对象的过程（将依赖关系注入到对象中，不需要每次都new对象）\\r\\n\\r\\n- set方法注入\\r\\n- 构造方法注入\\r\\n- 注解注入\\r\\n\\r\\n 注解注入的区别\\r\\n\\r\\n- @Resource\\r\\n\\r\\n  byName注入\\r\\n\\r\\n  \\r\\n\\r\\n- Autowired\\r\\n\\r\\n  byType注入\"},{\"url\":\"/frame/spring/Spring如何解决循环依赖.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring如何解决循环依赖\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"依赖注入的四种方法\\r\\n\\r\\n- 构造方法注入\\r\\n  \\r\\n    ```java\\r\\n        public HelloA(@Autowired HelloService helloService) {\\r\\n            this.helloService = helloService;\\r\\n        }\\r\\n    ```\\r\\n    \\r\\n- 工厂方法注入\\r\\n  \\r\\n    ```java\\r\\n        @Bean(initMethod = \\\"init\\\", destroyMethod = \\\"destory\\\")\\r\\n        public HelloB helloB(@Auto\"},{\"url\":\"/frame/spring/Spring框架概述.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring框架概述\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、什么是 Spring 框架？\\r\\n\\r\\nSpring 框架指的是 Spring Framework，是一种轻量级的开发框架，主要核心是控制反转 （IOC）和 面向切面编程（AOP）。\\r\\n\\r\\n 二、Spring 的优点\\r\\n\\r\\n1. 方便解耦，简化开发（高内聚低耦合）\\r\\n    - Spring 是一个容器框架，将所有对象创建和依赖关系的维护交给 Spring 管理。\\r\\n    - Spring 工厂用于生成 Bean。\\r\\n2. AOP编程的支持\\r\\n    - Spring 提供面向切面编程，可以方便的实现权限拦截、运行监控等功能\\r\\n    - 日志打印\\r\\n3. 支持声明式事务\\r\\n    - 只需\"},{\"url\":\"/frame/spring/Spring自定义注解扫描.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring自定义注解扫描\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Spring管理的类\\r\\n\\r\\n以下两种方式都可以实现。\\r\\n\\r\\n 使用@ComponentScan + Bean定义\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\n@ComponentScan(basePackages = {\\\"your.package.to.scan\\\"}) // 指定要扫描的包\\r\\npublic class AppConfig {\\r\\n\\r\\n    @Autowired\\r\\n    private ListableBeanFactory beanFactory;\\r\\n\\r\\n    @PostConstruct\\r\\n    public void processAnnotatedBea\"},{\"url\":\"/frame/spring/Spring配置文件加载顺序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring配置文件加载顺序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot配置文件的加载顺序\\r\\n\\r\\nSpringBoot项目启动会扫描以下位置的application.properties或者application.yml文件作为SpringBoot的默认配置文件，具体的目录位置见下图。\\r\\n\\r\\n1. file:./config/ （ 项目根路径下的config文件夹）\\r\\n2. file:./ （项目根路径）\\r\\n3. classpath:/config/ （类路径下的config文件夹）\\r\\n4. classpath:/ （类路径）\\r\\n\\r\\n\\r\\n\\r\\n按照配置文件的优先级，8001\\r\\n\\r\\n&gt; 注意file层是项目的最外层目录，也就是工作目录。\\r\\n&\"},{\"url\":\"/frame/spring/custom/AOP.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AOP\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ByteBuddy\\r\\n\\r\\nAOP即面向切面编程，本质上是一个 Proxy 模式。核心就是拦截核心 Bean 的方法调用。\\r\\n\\r\\n- JDK动态代理\\r\\n- CGLIB动态生成字节码代理。\\r\\n\\r\\n\\r\\n&gt;\\r\\n\\r\\n AOP实现核心\\r\\n\\r\\n- 找到符合AOP要求的原始Bean\\r\\n- 执行指定的拦截器逻辑\\r\\n\\r\\n AOP流程\\r\\n\\r\\n1. 利用 `BeanPostProcessor` 检测每个Bean。\\r\\n2. 扫描每个 Bean 的 @Around 注解。\\r\\n3. 执行 InvocationHandler 的代理方法。\\r\\n\\r\\n 实现 @Before 和 @After\\r\\n\\r\\n基于@Around的模板就\"},{\"url\":\"/frame/spring/custom/Boot.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Boot\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot 内置了 Tomcat，IOC容器和 WebMVC 模块，所以能直接启动。\\r\\n\\r\\n 启动类\\r\\n\\r\\n```java\\r\\n@Slf4j\\r\\npublic class SummerApplication {\\r\\n\\r\\n    static final String CONFIG_APP_YAML = \\\"/application.yml\\\";\\r\\n    static final String CONFIG_APP_PROP = \\\"/application.properties\\\";\\r\\n\\r\\n    public static void run(String webDir, String base\"},{\"url\":\"/frame/spring/custom/IOC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IOC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"其中构造方法注入和工厂方法注入是强依赖，因为Bean创建和属性注入放到一起了。\\r\\n\\r\\n比如构造方法注入，创建对象的同时进行属性注入，这种属于强依赖。\\r\\n\\r\\n而强依赖是解决不了循环依赖的问题的，因为创建对象和属性注入属于一体不可分的。\\r\\n\\r\\n我们解决循环依赖是先创建对象，然后属性注入的时候利用三级缓存解决的。\\r\\n\\r\\n```java\\r\\n    public BeanTest(@Value(\\\"spring.port\\\") String port, String name) {\\r\\n        System.out.println(port);\\r\\n    }\\r\\n```\\r\\n\\r\\nIOC容器有两类，Bean\"},{\"url\":\"/frame/spring/custom/JDBC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JDBC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"DataSource\\r\\n\\r\\n自动注入DataSource\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\npublic class JdbcConfiguration {\\r\\n\\r\\n    /**\\r\\n     * 自动注入HikariDataSource\\r\\n     *\\r\\n     * @param url\\r\\n     * @param username\\r\\n     * @param password\\r\\n     * @param driver\\r\\n     * @param maximumPoolSize\\r\\n     * @param minimumPoolSize\\r\\n     * @pa\"},{\"url\":\"/frame/spring/custom/MVC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MVC实现逻辑\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 应用程序必须配置一个Summer Framework提供的 Listener；\\r\\n2. Tomcat 完成 Servlet 容器的创建后，立刻根据配置创建Listener；\\r\\n    1. Listener初始化时创建 IOC 容器；\\r\\n    2. Listener继续创建DispatcherServlet实例，并向Servlet容器注册；\\r\\n    3. DispatcherServlet初始化时获取到IOC容器中的Controller实例，因此可以根据URL调用不同Controller实例的不同处理方法。\\r\\n    4. 容器中的Controller实例，因此可以根据URL调用不同\"},{\"url\":\"/frame/spring/custom/声明式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"声明式事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"事务传播模型\\r\\n\\r\\n| 传播行为 | 含义 |\\r\\n| --- | --- |\\r\\n| PROPAGATION_REQUIRED | 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。 |\\r\\n| PROPAGATION_SUPPORTS | 支持当前事务，如果当前没有事务，就以非事务方式执行。 |\\r\\n| PROPAGATION_MANDATORY | 支持当前事务，如果当前没有事务，就抛出异常。 |\\r\\n| PROPAGATION_REQUIRED_NEW | 新建事务，如果当前存在事务，把当前事务挂起。 |\\r\\n| PROPAGATION_NOT_SUPPORTED | 以非事务方式\"},{\"url\":\"/frame/spring/custom/手写Spring.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"手写Spring\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- boot模块：实现一个简化版的 `Spring Boot`，用于打包运行。\\r\\n- web模块：实现Web MVC和REST API。\\r\\n\\r\\n Spring主要模块\\r\\n\\r\\n- context模块：实现ApplicationContext容器与Bean的管理；\\r\\n- aop模块：实现AOP功能；\\r\\n- jdbc模块：实现JdbcTemplate，以及声明式事务管理；\\r\\n\\r\\n IOC\\r\\n\\r\\nIOC\\r\\n\\r\\n AOP\\r\\n\\r\\nAOP\\r\\n\\r\\n JDBC\\r\\n\\r\\nJDBC\\r\\n\\r\\n声明式事务\\r\\n\\r\\n1. 由`JdbcConfiguration`创建的`DataSource`，实现了连接池；\\r\\n2. 由`Jdb\"},{\"url\":\"/frame/spring/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Spring框架\\r\\n\\r\\n 一、Spring框架\\r\\n\\r\\n- Spring框架概述\\r\\n- ApplicationContext 和 BeanFactory 区别\\r\\n- BeanFactory 和 FactoryBean 总结\\r\\n- Spring中Bean的作用域\\r\\n- Spring中Bean加载流程\\r\\n- Spring依赖注入\\r\\n- Spring如何解决循环依赖\\r\\n\\r\\n- AOP\\r\\n- Spring事务总结\\r\\n- Aware接口\\r\\n- Spi机制\\r\\n- Spring配置文件加载顺序\\r\\n\\r\\n 二、使用总结\\r\\n\\r\\n- Spring自定义注解扫描\\r\\n- ByteBuddy实现动态代理\\r\\n\\r\\n 三、手写S\"},{\"url\":\"/frame/springboot/SpringBoot使用APO记录操作日志.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot使用APO记录操作日志\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"通过织入自定义注解 @Log，再进行解析记录操作日志。\\r\\n\\r\\n1. 自定义注解 @Log\\r\\n    \\r\\n    ```java\\r\\n    @Target({ElementType.PARAMETER, ElementType.METHOD})\\r\\n    @Retention(RetentionPolicy.RUNTIME)\\r\\n    @Documented\\r\\n    public @interface Log {\\r\\n    \\r\\n        /**\\r\\n         * 模块\\r\\n         */\\r\\n        String title() default \\\"default\\\";\\r\\n\"},{\"url\":\"/frame/springboot/SpringBoot能同时处理多少请求.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot能同时处理多少请求\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot内置了Tomcat，处理请求是 Web 容器处理的。\\r\\n\\r\\n1. 线程池线程数限制\\r\\n\\r\\n   而 Tomcat 的线程池默认最大线程池是 200，所以默认同时最多能处理 200 个请求。\\r\\n\\r\\n   \\r\\n&gt;\\r\\n2. 连接数限制\\r\\n\\r\\n   达到连接池数时，会限制请求数。此时因连接数限制为准，而不是最大线程数。\\r\\n\\r\\n    ```\\r\\n    tomcat最大连接数限制\\r\\n    server.tomcat.max-connections=12\\r\\n    ```\\r\\n\\r\\n\\r\\n---\\r\\n\\r\\n 限制配置\\r\\n\\r\\n```\\r\\ntomcat最大连接数限制\\r\\nserver.tomca\"},{\"url\":\"/frame/springboot/SpringBoot项目自动初始化数据库.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot项目自动初始化数据库\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"背景\\r\\n\\r\\n在 SpringBoot 启动的时候若配置文件中配置的数据库不存在，则自动创建数据库，并执行初始化SQL。\\r\\n\\r\\n 思路\\r\\n\\r\\n1. 判断数据库是否存在。\\r\\n2. 手动注入Datasource。\\r\\n    \\r\\n    在数据库未创建时，启动会报错\\r\\n    \\r\\n3. 初始化表。\\r\\n\\r\\n 解决方式\\r\\n\\r\\n1. 启动类排除 `DataSourceAutoConfiguration.class` ，采用手动注入的方式。\\r\\n    \\r\\n    如果配置的数据库不存在，SpringBoot启动的时候会提示找不到数据库，所以要排除掉，然后手动注入。\\r\\n    \\r\\n    ```java\\r\\n  \"},{\"url\":\"/frame/springboot/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot 框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot 框架\\r\\n\\r\\n\\r\\n 使用总结\\r\\n- SpringBoot能同时处理多少请求\\r\\n- SpringBoot使用APO记录操作日志\\r\\n- SpringBoot项目自动初始化数据库\"},{\"url\":\"/frame/springcloud/Feigh远程调用原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Feigh远程调用原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"思路\\r\\n\\r\\n根据接口地址和 FeignClient构建http请求。\\r\\n\\r\\n1. 构建 http请求模版，包含 header、body、method等参数信息。\\r\\n2. 设置 options，包含超时时间参数配置。\\r\\n3. 根据 clientName 从 nacos（类似map，保存clientName和访问地址的对应关系）中获取访问地址。\\r\\n4. 根据访问地址和http请求参数发起http请求。\\r\\n\\r\\n 代码入口\\r\\n\\r\\n`io/github/openfeign/feign-core/10.4.0/feign-core-10.4.0.jar!/feign/ReflectiveFeign.cla\"},{\"url\":\"/frame/springcloud/Gateway.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Gateway\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"请求流程\\r\\n\\r\\n&lt;img src=\\\"https://s2.loli.net/2025/06/10/RBVjazHT3NinfQe.png\\\" alt=\\\"image.png\\\" style=\\\"zoom:50%;\\\" /\\r\\n\\r\\n- Gateway Handler（网关处理器）：网关处理器是 Spring Cloud Gateway 的核心组件，负责将请求转发到匹配的路由上。它根据路由配置和断言条件进行路由匹配，选择合适的路由进行请求转发。网关处理器还会依次应用配置的过滤器链，对请求进行处理和转换。\\r\\n- Gateway Filter Chain（网关过滤器链）：网关过滤器链由一系列过滤器组成，按照\"},{\"url\":\"/frame/springcloud/Nacos.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Nacos\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"地址\\r\\n\\r\\n GitHub\\r\\n\\r\\nhttps://github.com/alibaba/nacos\\r\\n\\r\\n 文档\\r\\n\\r\\nNacos 快速开始\\r\\n\\r\\n 启动命令\\r\\n\\r\\n```sql\\r\\nsh startup.sh -m standalone\\r\\n```\\r\\n\\r\\n 可视化页面\\r\\n\\r\\n`http://localhost:8848/nacos`\\r\\n\\r\\n\\r\\n\\r\\n 注册中心原理\\r\\n\\r\\n 服务注册\\r\\n\\r\\nNocas Client 在启动的时候会通过 Rest 的方式将自己的元数据（Ip、端口）等信息发给 Nocas Server。\\r\\n\\r\\nNacos Server 收到 Client 的注册请求后，将元数据信息存到\"},{\"url\":\"/frame/springcloud/Seata分布式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Seata分布式事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在分布式情况下，一次业务请求需要调用多个系统操作多个数据源时，针对多个数据源操作会产生分布式事务问题。每个系统能够保证各自数据源的一致性问题，但是全部系统数据的一致性问题没法保证。\\r\\n\\r\\n 官网地址\\r\\n\\r\\nhttps://seata.io/zh-cn/docs/user/quickstart.html\\r\\n\\r\\n 下载地址\\r\\n\\r\\nhttps://seata.io/zh-cn/blog/download.html\\r\\n\\r\\n 基础概念\\r\\n\\r\\n事务ID + 三组件\\r\\n\\r\\n事务ID\\r\\n\\r\\n- Transaction ID(XID)\\r\\n\\r\\n三组件\\r\\n\\r\\n- TC-事务协调者\\r\\n\\r\\n  维护全局和分支事务的状态\"},{\"url\":\"/frame/springcloud/Sentinel原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Sentinel原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Sentinel工作主流程\\r\\n\\r\\n滑动窗口实现原理 · 吾爱开源 · 看云\\r\\n\\r\\n 限流算法\\r\\n\\r\\n 计数器算法\\r\\n\\r\\n计数器算法统计某个时间段的请求量，判断是否超过阈值。\\r\\n\\r\\n\\r\\n\\r\\n存在的问题：\\r\\n\\r\\n如上图中，在时间段的临界处加起来其实QPS 超过了阈值，但是平均到单个时间段未发生。\\r\\n\\r\\n单纯的计数器算法存在 临界统计不准确 的问题。\\r\\n\\r\\n 滑动窗口计数器算法\\r\\n\\r\\n解决滑动窗口存在的问题，引入了滑动窗口计数器。\\r\\n\\r\\n我们将统计时间细分，比如将 1s 统计时长分为 5个 时间窗口，通过 滚动统计所有时间窗口的QPS 作为系统实际的 QPS 的方式，就能解决上述 临界统计 问题。\\r\"},{\"url\":\"/frame/springcloud/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringCloud\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringCloud\\r\\n\\r\\n 使用总结\\r\\n\\r\\n- 注册中心的演进\\r\\n- Nacos\\r\\n- Gateway\\r\\n- Feigh远程调用原理\\r\\n- Sentinel原理\\r\\n- Seata分布式事务\\r\\n\\r\\n\\r\\n\\r\\n 项目\\r\\n\\r\\nSpringCloud总结练习-Gitee\"},{\"url\":\"/frame/springcloud/注册中心的演进.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"注册中心的演进\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 直接远程调用\\r\\n\\r\\n   \\r\\n\\r\\n2. 维护注册表，维护服务调用地址\\r\\n\\r\\n   \\r\\n\\r\\n3. 接入 nginx，利用 nginx 做负载\\r\\n\\r\\n   \\r\\n\\r\\n4. 引入注册机制，提供注册和服务发现功能\\r\\n\\r\\n   \\r\\n\\r\\n5. 引入心跳机制，解决注册中心宕机或者目标服务不可用\"},{\"url\":\"/java/cache/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Cache\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 本地缓存\\r\\n- 多级缓存\\r\\n- 缓存淘汰算法\"},{\"url\":\"/java/cache/多级缓存.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"多级缓存\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"二级缓存\\r\\n\\r\\n二级缓存没有网络开销\\r\\n\\r\\n\\r\\n\\r\\n 优点\\r\\n\\r\\n1. 减少网络请求，提高性能。\\r\\n2. 减少远程缓存的读压力。\\r\\n3. 天然分布式缓存，只存在于当前节点服务。\\r\\n\\r\\n 缺点\\r\\n\\r\\n1. 占用本地内存，空间有限，不支持大数据量。\\r\\n\\r\\n   只存储最热的数据到本地缓存，结合热点服务探测。\\r\\n\\r\\n2. 重启数据会丢失。\\r\\n\\r\\n   重启丢失数据无法避免，但是可以在重启项目的时候把最热的数据加到本地缓存。\\r\\n\\r\\n3. 分布式场景，数据可能不一致。\\r\\n4. 和远程缓存可能存在不一致的问题。\\r\\n\\r\\n   只能保证最终一致性，尽可能让本地缓存过期时间短一点，这样就能加载远程缓存，达到最终\"},{\"url\":\"/java/cache/本地缓存.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"本地缓存\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Guava\\r\\n\\r\\n- 支持最大容量限制\\r\\n- 支持两种过期删除策略\\r\\n- 支持简单的统计功能\\r\\n- 插入时间\\r\\n- 访问时间\\r\\n- 基于LRU算法实现\\r\\n\\r\\n```java\\r\\nLoadingCache&lt;Integer, String\\r\\n        //设置并发级别为8，并发级别是指可以同时写缓存的线程数\\r\\n        .concurrencyLevel(8)\\r\\n        //设置缓存的初始容量为10\\r\\n        .initialCapacity(10)\\r\\n        // 设置缓存最大容量为100，超过100之后就会按照LRU最近最少使用算法来移除缓存\\r\\n    \"},{\"url\":\"/java/cache/缓存淘汰算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"缓存淘汰算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"FIFO-先进先出\\r\\n\\r\\n\\r\\n\\r\\n比较简单，不够灵活。\\r\\n\\r\\n没有跟缓存使用频次和时间等维度联系起来。\\r\\n\\r\\n LRU-最近最少使用\\r\\n\\r\\n核心思想是最近使用的时间。比如最近一小时以内使用缓存的时间。\\r\\n\\r\\n\\r\\n\\r\\n根据数据的历史访问记录来淘汰数据，淘汰最久未被使用的数据。\\r\\n\\r\\n基于如果数据最近被访问过，那么将来访问的记录会更高。优先淘汰最久未被使用的冷数据。\\r\\n\\r\\n LFU-最近最不常用\\r\\n\\r\\n核心思想是最近使用的次数。比如最近一小时内使用缓存的次数。\\r\\n\\r\\n\\r\\n\\r\\nLFU能够提高热点数据的命中率。\\r\\n\\r\\n但是当缓存中数据都是热点数据的时候，将失去该特性。\\r\\n\\r\\n单纯的LFU存在缺陷。\\r\\n\"},{\"url\":\"/java/collection/Collection集合概述.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集合概述\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集合概述\\r\\n\\r\\n 为什么使用集合？\\r\\n\\r\\n当我们需要保存一组类型相同的数据的时候，我们应该用一个容器来保存，这个容器就是数组。\\r\\n\\r\\n但是数组的长度是固定的，当添加的元素超过了数组的长度之后，需要对数组重新定义。而且数组存储的数据是`有序的`、`可重复的`，太过于单一，扩展性不够。\\r\\n\\r\\n于是，引入了集合，Java 内部给我们提供了功能完善的集合框架。能`存储任意对象`，长度可以`动态改变`，提高了数据存储的灵活性。\\r\\n\\r\\n 数组和集合的区别\\r\\n\\r\\n1. 存储类型\\r\\n   - 数组可以存储`基本数据类型`，又可以存储`引用数据类型`。\\r\\n   - 集合只能存储`引用数据类型`。（集合中也可以存\"},{\"url\":\"/java/collection/ConcurrentHashMap1.7.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ConcurrentHashMap - 1.7\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、类简介\\r\\n\\r\\nConcurrentHashMap 是一个线程安全的 HashMap，在 JDK 1.7 HashMap的基础上实现了 `分段锁` 来保证线程安全。在 HashMap 的基础上，默认分为 16 个段，每个段都拥有独立的锁，来保证各个段的线程安全。\\r\\n\\r\\n 扩展 - 线程安全的 HashMap\\r\\n\\r\\nMap实现线程安全的三种方式\\r\\n\\r\\n Unsafe方法总结\\r\\n\\r\\n\\r\\n\\r\\n 二、主要参数\\r\\n\\r\\n```java\\r\\npublic class ConcurrentHashMap&lt;K, V\\r\\n        implements ConcurrentMap&lt;K, V&gt;\"},{\"url\":\"/java/collection/ConcurrentHashMap1.8.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ConcurrentHashMap -1.8\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ConcurrentHashMap 源码分析\\r\\n\\r\\n\\r\\n1.8的ConcurrentHashMap，采用对Node加锁机制。\\r\\n\\r\\n 加锁原理\\r\\n\\r\\n采用CAS+Synchronized组合锁的方法。\\r\\n\\r\\n- CAS\\r\\n\\r\\n  操作Node数组的时候以CAS方式操作。\\r\\n\\r\\n- Synchronized\\r\\n\\r\\n  操作Node对应的数据结构，链表或红黑树的时候加Synchronized。保证操作数据的原子性。\"},{\"url\":\"/java/collection/HashMap1.7.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HashMap - 1.7\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类简介\\r\\n\\r\\nHashMap 是一个用来存储 Key - Value 键值对的集合，每一个键值对也叫做 Entry，这些 Entry 保存在底层数组中。\\r\\n\\r\\n 1. 底层数组\\r\\n\\r\\n底层数组包含的每个元素可以称之为 桶，元素实际保存在每个桶上。\\r\\n\\r\\n```java\\r\\n    static final Entry&lt;?,?\\r\\n\\r\\n    /**\\r\\n     * The table, resized as necessary. Length MUST Always be a power of two.\\r\\n     */\\r\\n    transient Entry&lt;K,V&gt;[] t\"},{\"url\":\"/java/collection/HashMap1.8.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HashMap - 1.8\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类简介\\r\\n\\r\\n 默认参数\\r\\n\\r\\n- 默认长度\\r\\n\\r\\n  ```\\r\\n   static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4\\r\\n  ```\\r\\n\\r\\n- 最大容量\\r\\n\\r\\n  ```\\r\\n  static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;\\r\\n  ```\\r\\n\\r\\n- 默认负载因子\\r\\n\\r\\n  ```\\r\\n   static final float DEFAULT_LOAD_FACTOR = 0.75f;\\r\\n  ```\\r\\n\\r\\n- 默认树化临界点\\r\\n\\r\\n  ```\\r\\n  static final in\"},{\"url\":\"/java/collection/List集合体系.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"List集合体系\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ArrayList\\r\\n\\r\\n 特点\\r\\n\\r\\n- 底层基于数组实现。\\r\\n- 有索引，支持快速访问。\\r\\n- 查询修改快，增删慢。\\r\\n- 线程不安全。\\r\\n\\r\\n 构造方法\\r\\n\\r\\n1. 无参构造\\r\\n\\r\\n   - JDK 1.6 之前，以初始容量 10 创建一个长度为10的数组。\\r\\n   - JDK 1.6 之后，创建一个空数组。\\r\\n\\r\\n   ```java\\r\\n       public ArrayList() {\\r\\n           this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;\\r\\n       }\\r\\n   ```\\r\\n\\r\\n2. 有参构造 - 数\"},{\"url\":\"/java/collection/Set集合体系.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Set集合体系\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HashSet\\r\\n\\r\\n 特点\\r\\n\\r\\n- 底层基于哈希算法实现，使用 `HashMap` 保存数据。\\r\\n- 无序（存取顺序不一致）。\\r\\n- 不可以存储重复元素。\\r\\n- 线程不安全。\\r\\n\\r\\n 构造方法\\r\\n\\r\\n1. 无参构造\\r\\n\\r\\n   底层使用 `HashMap` 保存数据。\\r\\n   \\r\\n```java\\r\\n       public HashSet() {\\r\\n           map = new HashMap&lt;\\r\\n       }\\r\\n```\\r\\n\\r\\n3. 有参构造 - Collection 集合\\r\\n\\r\\n   根据传入的 Collection 集合 初始化底层 `HashMap`。\\r\\n\\r\\n\"},{\"url\":\"/java/collection/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集合\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Collection集合\\r\\n\\r\\n- Collection集合概述\\r\\n- List集合体系\\r\\n- Set集合体系\\r\\n\\r\\n Map集合体系\\r\\n\\r\\n- HashMap - 1.7\\r\\n- ConcurrentHashMap - 1.7\\r\\n- HashMap - 1.8\\r\\n- ConcurrentHashMap -1.8\"},{\"url\":\"/java/concurrent/Java高并发.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Java工程师成长计划-高并发\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java工程师成长计划-高并发\\r\\n\\r\\n```\\r\\n         _______________________________________________        \\r\\n        |   _      __        __                         |       \\r\\n________|  | | /| / / ___   / / ____ ___   __ _  ___    |_______\\r\\n\\\\       |  | |/ |/ / / -_) / / / __// _ \\\\ /  ' \\\\/ -_)   |      /\\r\\n \\\\      |  |\"},{\"url\":\"/java/concurrent/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"高并发\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"思维导图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 参考链接\\r\\n\\r\\n- 深入浅出Java多线程\"},{\"url\":\"/java/concurrent/single/AQS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AQS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"从ReentrantLock的实现看AQS的原理及应用\\r\\n\\r\\nAQS是一种提供了原子式管理同步状态、阻塞和唤醒线程功能以及队列模型的简单框架。\\r\\n\\r\\n 组成\\r\\n\\r\\n1. 共享资源状态维护state。\\r\\n\\r\\n   - AQS使用一个`volatile`修饰的 int 成员变量来表示同步状态，这个状态可以反映锁的当前持有情况。\\r\\n\\r\\n     例如，当状态为 0 时表示无锁状态，而当状态为非零时表示有锁被占用。\\r\\n\\r\\n2. FIFO 队列实现线程排队。\\r\\n\\r\\n   AQS维护了一个FIFO（先入先出）的双向队列，用于管理等待获取锁的线程，当一个线程尝试获取锁但失败时，它会进入这个队列并阻塞，直到锁\"},{\"url\":\"/java/concurrent/single/BlockQueue阻塞队列.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"阻塞队列BlockQueue\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"阻塞队列`BlockQueue`比起传统的`Queue`多了阻塞的功能，适合用于多线程之间的数据共享。阻塞主要发生在队列为空和队列满的情况。\\r\\n\\r\\n- 在队列为空的时候，操作元素出队的线程会进行循环等待，直到队列变为非空。\\r\\n- 在队列满的时候，操作元素入队的线程会进行循环等待，直到队列变为非满。\\r\\n\\r\\n 常见方法\\r\\n\\r\\n`BlockQueue入队`的方法有如下几种：\\r\\n\\r\\n- `offer()`方法，如果队列已满，无法存放，直接返回false。\\r\\n- `add()`方法，实际调用了offer()方法，增加了（Queue Full）的异常信息返回。\\r\\n- `put()`方法，若队列已满，会进行\"},{\"url\":\"/java/concurrent/single/CAS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"悲观和乐观策略\\r\\n\\r\\n锁有着悲观锁和乐观锁之分，悲观锁拥有资源的时候，认为随时会有人来篡改拥有的资源，所以在其拥有资源时不允许其他人访问。而乐观锁在拥有资源的时候不认为会有人来篡改其所拥有的资源，所以在其拥有资源的时候允许其他人访问。悲观锁和乐观锁是一种思想，对应的也是一种策略。\\r\\n\\r\\n加锁和使用 synchronized 其实就是一种悲观的策略，因为总是假设临界区的操作会产生冲突，如果有多个线程需要访问临界区资源，加锁和使用 synchronized 会阻塞其它线程。\\r\\n\\r\\n而无锁其实就是一种乐观的策略，它在操作的时候会假设访问资源不会冲突，所有的线程之间不存在阻塞，也就不存在等待，线程会持\"},{\"url\":\"/java/concurrent/single/ThreadLocal.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ThreadLocal总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ThreadLocal 提供了线程的局部变量，只有当前线程可以操作，不会和其它线程的局部变量产生冲突，实现了变量的线程安全。`ThreadLocal&lt;T\\r\\n\\r\\n 简单例子\\r\\n\\r\\n```java\\r\\npublic class ThreadLocalDemo {\\r\\n\\r\\n    private static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;();\\r\\n\\r\\n    public static void main(String[] args) {\\r\\n        //主线程\\r\\n        threadL\"},{\"url\":\"/java/concurrent/single/synchronized原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"synchronized原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"synchronized原理详解（通俗易懂超级好）-CSDN博客\\r\\n\\r\\n 特性\\r\\n\\r\\n- 原子性\\r\\n\\r\\n  synchronized 修饰的对象或类所有操作都是原子性的。线程需要获取锁，保证整个操作过程的原子性。\\r\\n\\r\\n  比如 i++这种赋值操作。\\r\\n\\r\\n- 可见性\\r\\n\\r\\n  一个线程如果要访问该类或对象必须先获得它的锁，而这个锁的状态对于其他任何线程都是可见的，并且在释放锁之前会将对变量的修改刷新到主存当中，保证资源变量的可见性。\\r\\n\\r\\n  如果某个线程占用了该锁，其他线程就必须在锁池中等待锁的释放。\\r\\n\\r\\n- 有序性\\r\\n\\r\\n  保证只有一个线程访问，确保了有序性。\\r\\n\\r\\n- 可重入性\\r\\n\"},{\"url\":\"/java/concurrent/single/transmittable-thread-local.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"transmittable-thread-local\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"线程池中的线程是可以复用的，假如第一个线程对  ThreadLocal 变量进行了操作，如果没有及时清理，下一个线程就会受到影响。因为 ThreadLocal  是在每个线程上维护了一个 ThreadLocalMap ，所以在线程复用的情况下，之后的线程会获取到  ThreadLocal  里之前线程设置的值。\\r\\n\\r\\n ThreadLocal多线程问题\\r\\n\\r\\n在多线程场景下传递ThreadLocal，如果线程池是池化的话，可能会导致复用ThreadLocal里面的值。\\r\\n\\r\\n\\r\\n\\r\\n 需求场景\\r\\n\\r\\n在使用线程池等池化复用线程的情况下，传递ThreadLoca值。\\r\\n\\r\\n1. 分布式跟踪 tr\"},{\"url\":\"/java/concurrent/single/原子类.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"原子类\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本类型-AtomicInteger\\r\\n\\r\\nAtomicInteger 是无锁的线程安全整数类，基于 `CAS` 实现，位于 `java.util.concurrent.atomic` 包下，该包下实现了一系列使用 `CAS` 操作实现线程安全的类型。其它原子类和 AtomicInteger 非常类似，故只分析 AtomicInteger。\\r\\n\\r\\n\\r\\n\\r\\n 比较 Integer\\r\\n\\r\\nAtomicInteger 是一个整数，与 Integer 不同的是，它是可变的并且是线程安全的。\\r\\n\\r\\n比如在多线程不加锁的情况下，操作 Integer 或者 AtomicInteger ，来比较结果是否正确。\"},{\"url\":\"/java/concurrent/single/死锁活锁和饥饿.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"死锁活锁和饥饿\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在使用锁的时候，可能会因为使用不当产生死锁、活锁和饥饿的现象。\\r\\n\\r\\n在单体应用中，加锁是否能解决所有的线程安全问题？\\r\\n\\r\\n*不能，因为加锁使用不当会有死锁、活锁和饥饿等问题。*\\r\\n\\r\\n 死锁\\r\\n\\r\\n什么是死锁？\\r\\n\\r\\n死锁指的是两个或多个线程之间，互相占用着对方请求的资源，而且不会释放已持有的资源，造成了多线程之间无限等待的现象，就叫做死锁。\\r\\n\\r\\n死锁发生后，会浪费大量的系统资源，并且在高并发下存在严重的安全隐患，甚至导致整个系统崩溃。\\r\\n\\r\\n 死锁产生的条件\\r\\n\\r\\n1. 互斥\\r\\n\\r\\n   某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结\"},{\"url\":\"/java/concurrent/single/线程池的关闭.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程池的关闭\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"线程池的关闭\\r\\n\\r\\n线程池的关闭方式有两种，一种是调用 `shutdown()` 方法，另一种是调用 `shutdownNow()` 方法。\\r\\n\\r\\n- shutdown\\r\\n\\r\\n  调用该方法后，线程池拒绝接受新提交的任务，同时等待线程池里和任务队列中的任务执行完毕再关闭线程。\\r\\n\\r\\n- shutdownNow\\r\\n\\r\\n  调用该方法后，线程池拒绝接受新提交的任务，不再执行任务队列的任务，将线程池任务队列里的任务全部返回。\\r\\n\\r\\n shutdown\\r\\n\\r\\n调用该方法后，线程池拒绝接受新提交的任务，同时等待线程池里和任务队列中的任务执行完毕再关闭线程。\\r\\n\\r\\n```java\\r\\n    public \"},{\"url\":\"/java/concurrent/single/线程池的执行流程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程池的执行\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"执行流程\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n1. 根据初始化参数创建线程池，刚创建时，线程池内没有线程。\\r\\n2. 当有新的任务提交到线程池的时候，会立即新增线程执行任务。\\r\\n3. 若运行线程数 = 核心线程数时，这时进来的任务会被添加到任务队列中，而线程会从任务队列中获取任务执行。\\r\\n4. 运行线程数 = 核心线程数 且 任务队列已满，这时候会在线程池中创建新线程来执行任务。\\r\\n5. 运行线程数 = 最大线程数，且任务队列已满，此时会执行线程池对应的拒绝策略。\\r\\n6. 当任务队列中没有任务，且线程等待时间超过空闲时间，则该线程会被回收。最终线程池中的线程数量会保持在核心线程数的大小。\\r\\n\\r\\n 源码分析\\r\\n\"},{\"url\":\"/java/concurrent/single/线程的生命周期.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程的生命周期\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 Java 中线程从新建到关闭会经过不同的状态，将线程从新建到关闭作为一个生命周期，在 Java 中整个线程的生命周期有 6 种状态。\\r\\n\\r\\n 线程状态类型\\r\\n\\r\\n在 JDK 的 Thread 类，存在 `State` 枚举类，包含了线程的 6 种状态。\\r\\n\\r\\n```java\\r\\n    public enum State {\\r\\n        \\r\\n        NEW,\\r\\n        RUNNABLE,\\r\\n        BLOCKED,\\r\\n        WAITING,\\r\\n        TIMED_WAITING,\\r\\n        TERMINATED;\\r\\n    }\\r\\n```\"},{\"url\":\"/java/distributed/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 分布式事务\\r\\n- 分布式锁\\r\\n- 分布式ID\\r\\n- 幂等性问题\"},{\"url\":\"/java/distributed/分布式ID.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式ID\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"要求\\r\\n\\r\\n1. 分布式全局唯一\\r\\n2. 有序递增\\r\\n\\r\\n 方案\\r\\n\\r\\n\\r\\n\\r\\n 数据库主键自增\\r\\n\\r\\n1. 创建一个全局主键自增的表。\\r\\n2.  从该表查询id使用。\\r\\n    - 效率低下，每次插入之前都要查一次自己的id\\r\\n\\r\\n 数据库号段模式\\r\\n\\r\\n批量从全局自增主键表获取一批主键，放到内存里。（减少数据库访问次数）\\r\\n\\r\\n```bash\\r\\nCREATE TABLE `sequence_id_generator` (\\r\\n  `id` int(10) NOT NULL,\\r\\n  `current_max_id` bigint(20) NOT NULL COMMENT '当前最大id',\\r\\n\"},{\"url\":\"/java/distributed/分布式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在分布式情况下，假如存在 A 同时调用 B、C多个微服务。假如 B 服务事务正常执行并提交，但是 C 事务提交失败，此时 B 和 C都需要回滚。\\r\\n\\r\\n而 MySQL 的事务回滚是通过 redo log 机制来实现的，保证事务的持久化和一致性。\\r\\n\\r\\n但是在分布式，使用了分布式事务的情况下，是通过一条更新SQL，还原原本的数据。\\r\\n\\r\\n\\r\\n\\r\\n一文搞明白分布式事务解决方案！真的 so easy！\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n分布式事务，原理简单，写起来全是坑！ - 掘金\\r\\n\\r\\n\\r\\n\\r\\n 分布式事务解决方案\\r\\n\\r\\n 2PC - 两阶段提交\\r\\n\\r\\n1. prepare - 准备阶段\\r\\n\\r\\n    各个参\"},{\"url\":\"/java/distributed/分布式锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- mysql\\r\\n- redis 的 setnx\\r\\n- redission\\r\\n- redLock\\r\\n- zookeeper\\r\\n- curator\\r\\n\\r\\nredis的分布式锁可用性更高，但是分布式不友好。一般单机的redis实现分布式锁性能就够用。\\r\\n\\r\\n如果非要要求可靠性，可以选择zk，只是zk是cp的，性能要差一点。\\r\\n\\r\\n\\r\\n\\r\\n Reids分布式锁\\r\\n\\r\\nredis实现分布式锁\\r\\n\\r\\n\\r\\n\\r\\n 手写 zk 分布式锁\\r\\n\\r\\nzk 实现分布式锁，是依赖 zk 的临时有序节点。\\r\\n\\r\\n多个线程在 rootPath 下面按顺序创建节点。\\r\\n\\r\\n1. 首先有持久节点lock\\r\\n2. 每个请求获取锁\"},{\"url\":\"/java/distributed/幂等性问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"幂等性问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"常见幂等问题\\r\\n\\r\\n解决常见幂等性问题采用 `一锁、二判、三更新` 就可以解决。\\r\\n\\r\\n- 一锁：锁定需要处理的订单\\r\\n- 二判：订单是否支付\\r\\n- 三更新：更新订单状态\\r\\n\\r\\n 数据库锁-悲观锁\\r\\n\\r\\n- for Update\\r\\n  \\r\\n    `FOR UPDATE` 子句告诉数据库管理系统（DBMS）在检索行的同时锁定这些行，直到当前事务结束。\\r\\n    \\r\\n\\r\\n```java\\r\\nBEGIN;\\r\\n\\r\\nSELECT * FROM orders\\r\\nWHERE order_id = 123\\r\\nFOR UPDATE;\\r\\n\\r\\n-- 进行业务逻辑处理，例如更新订单状态\\r\\nUPDATE orders \"},{\"url\":\"/java/io/BIO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BIO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"JDK 网络编程 BIO，意为阻塞的 IO。\\r\\n\\r\\nBIO 的阻塞体现在两个方面：\\r\\n\\r\\n1. 若一个服务端的服务绑定端口启动后，主线程就会一直等待客户端的连接。\\r\\n2. 客户端和服务端 Socket 端口建立连接之后，在读取到 Socket 信息之前，线程一直处于等待，一直处于阻塞状态。\\r\\n\\r\\n典型的 请求 -应答模型\\r\\n\\r\\n由一个独立的 `Acceptor` 模型监听客户端的请求，收到请求后为每一个客户端创建一个线程去处理，处理完成后将结果返回给客户端。\\r\\n\\r\\nJava BIO：传统的网络通讯模型，就是BIO，同步阻塞IO。\\r\\n\\r\\n其实就是服务端创建一个ServerSocket， 然后就是\"},{\"url\":\"/java/io/IO多路复用.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IO多路复用\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"小白也看得懂的 I/O 多路复用解析（超详细案例）_哔哩哔哩_bilibili\\r\\n\\r\\n 基础概念\\r\\n\\r\\n\\r\\n\\r\\n1. Socket\\r\\n\\r\\n   套接字，在网络通信中，就是客户端和服务端的出入口。\\r\\n\\r\\n   \\r\\n&gt;\\r\\n2. fd\\r\\n\\r\\n   文件描述符，是指向资源文件的索引。\\r\\n\\r\\n\\r\\n Socket通讯的过程\\r\\n\\r\\n\\r\\n\\r\\n1. 服务端通过 bind 绑定机器的端口号， 进程 listen 某个端口。\\r\\n2. 客户端和服务端通过 tcp 三次握手建联。\\r\\n3. 进行数据交互，\\r\\n4. 最后通过 close 断开连接。\\r\\n\\r\\n IO模型\\r\\n\\r\\n\\r\\n\\r\\n 同步阻塞IO - BIO\\r\\n\\r\\n-\"},{\"url\":\"/java/io/NIO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"NIO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NIO 是 JDK1.4 引入，为了解决 BIO 阻塞的问题，又称 `no-blocking io`。\\r\\n\\r\\n同步非阻塞\\r\\n\\r\\n NIO特点\\r\\n\\r\\n- 面向缓冲区\\r\\n  \\r\\n    BIO 是面向流的，NIO 是面向缓冲区的。\\r\\n    \\r\\n    \\r\\n\\r\\n- 非阻塞模式\\r\\n  \\r\\n    NIO 的非阻塞模式，使其线程从 Channel 获取数据时，即使获取不到数据也不会阻塞线程。\\r\\n    \\r\\n\\r\\n NIO 核心组件\\r\\n\\r\\n\\r\\n\\r\\n Selector-轮询选择器\\r\\n\\r\\nJava NIO 的选择器允许一个单独的线程来监视多个输入通道（Channel）。\\r\\n\\r\\n选择器用于检测一个或多个通道的状\"},{\"url\":\"/java/io/Reactor模式.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Reactor模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Reactor模式详解＋源码实现\\r\\n\\r\\n整个 reactor 模式解决的主要问题就是在接收到任务后根据分发器快速进行分发给相应的事件处理器，不需要从开始状态就阻塞。\\r\\n\\r\\n基于事件驱动模型，当接收到请求后会将请求封装成事件，并将事件分发给相应处理事件的Handler，handler处理完成后将事件状态修改为下一个状态，再由Reactor将事件分发给能够处理下一个状态的handler进行处理。\\r\\n\\r\\n\\r\\n\\r\\n1. EventHandler：事件处理器，可以根据事件的不同状态创建处理不同状态的处理器；\\r\\n   \\r\\n    ```java\\r\\n    public abstract class Eve\"},{\"url\":\"/java/io/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- BIO\\r\\n- 基于BIO实现RPC框架\\r\\n- NIO\\r\\n- Reactor模式\\r\\n- IO多路复用\"},{\"url\":\"/java/io/基于BIO实现RPC框架.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"基于BIO实现RPC框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基于bio手写实现简单的rpc_java 手写一个bio-CSDN博客\\r\\n\\r\\n RPC\\r\\n\\r\\n\\r\\n\\r\\n RPC设计\\r\\n\\r\\n\\r\\n\\r\\nRPC 的核心就是让客户端调用远程服务方法，就像调用本地方法一样。\\r\\n\\r\\n- 服务端将自己的类注册到远程服务。\\r\\n- 客户端通过注册中心获取到服务端地址。\\r\\n    - 客户端调用服务端地址，传入类名，调用方法、入参\\r\\n    - 服务端收到方法信息后，本地通过反射执行方法，获取结果返回给客户端。\\r\\n- 客户端需要写一个需要调用的类，和服务端的类保持一致（方法名、入参类型、入参）。\\r\\n    - 客户端需要对这个类进行动态代理，实际访问的是该类的代理对象。\\r\\n   \"},{\"url\":\"/java/jvm/CPU负载过高排查记录.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"CPU负载过高排查记录\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"解决线上微服务容器cpu占用100%问题（java进程占用100%问题）_容器cpu占用高_上树的蜗牛儿的博客-CSDN博客\\r\\n\\r\\n 平台发现问题\\r\\n\\r\\n平台发现集群节点 node219 CPU利用率过高。\\r\\n\\r\\n\\r\\n\\r\\n通过查看该节点下的 pod 发现，bookdemo 使用 CPU 过高。\\r\\n\\r\\n\\r\\n\\r\\n 主机排查\\r\\n\\r\\n top 查看进程情况\\r\\n\\r\\n使用 top 确认占用cpu过高的进程。\\r\\n\\r\\nPID=17177 占用 CPU 最高。\\r\\n\\r\\n\\r\\n\\r\\n 查看进程 PID 对应的容器\\r\\n\\r\\n由于该进程是个POD，需要找到对应容器，进入容器内部排查线程情况。\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 容器内部\"},{\"url\":\"/java/jvm/G1收集器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"G1收集器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- XX:+UseG1GC\\r\\n\\r\\nG1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对 配备多颗处理器及大容量内存的机器，以极高概率满足GC停顿时间要求的同时，还具备高吞吐量性能特征。\\r\\n\\r\\nG1 收集器 在 JDK1.7 正式启用，是 JDK 9以后的默认垃圾收集器，取代了 CMS 以及 Parallel+Parallel Old 的组合，被 Oracle 官方称为“全功能的垃圾收集器”。\\r\\n\\r\\n- 适合大内存机器，具备高吞吐量。\\r\\n- 低 GC 停顿时间。\\r\\n\\r\\n 堆分布\\r\\n\\r\\n 区域分布\\r\\n\\r\\n\\r\\n\\r\\n区分于传统的堆内存分布，G1 是将 JVM 堆内存划分为了多个 \"},{\"url\":\"/java/jvm/JDK调优命令.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JDK调优命令\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"jstack\\r\\n\\r\\n 死锁检测\\r\\n\\r\\n1. 使用 jps 命令查看运行中的 java 进程 Id。\\r\\n   \\r\\n    \\r\\n    \\r\\n2. 使用 jstack 分析线程状态。\\r\\n   \\r\\n    ```\\r\\n    jstack 进程Id\\r\\n    ```\\r\\n    \\r\\n    - 线程状态\\r\\n      \\r\\n        通过分析进程可以得到，`DeadLockTest` 进程的两个线程分别为 `pool-1-thread-2` （简称2）和 `pool-1-thread-1`（简称1）。\\r\\n        \\r\\n        通过打印的线程信息可以发现，线程 2 和 1 的线程状态都是 \"},{\"url\":\"/java/jvm/JVM内存模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JVM内存模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java 内存模型在 JDK1.7 主要包含以下区域。\\r\\n\\r\\n- 程序计数器\\r\\n- 虚拟机栈\\r\\n- 本地方法栈\\r\\n- 方法区\\r\\n- 堆\\r\\n\\r\\n而在 JDK1.8中将运行时数据区中的方法区给取消了，换成了本地内存中的元数据区。\\r\\n\\r\\n- 程序计数器\\r\\n- 虚拟机栈\\r\\n- 本地方法栈\\r\\n- 堆\\r\\n- 元数据区\\r\\n\\r\\n 内存模型图\\r\\n\\r\\n1. JDK 1.7 内存模型图\\r\\n   \\r\\n    \\r\\n    \\r\\n2. JDK 1.8 内存模型图\\r\\n   \\r\\n    JDK1.8中取消了运行时数据区中的方法区，换成了元数据区放到了本地内存里。\\r\\n    \\r\\n    \\r\\n    \\r\\n\\r\\n 运行时数据区\\r\\n\\r\\n\"},{\"url\":\"/java/jvm/Java类加载器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"类加载器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"什么是类加载器\\r\\n\\r\\n类加载器（ClassLoader）就是在系统运行过程中动态的将编译后的.class字节码文件加载到JVM中的工具。在IDE中编写的源代码文件都是`.java`文件，通过编译对应生成`.class`文件。而类加载器就是用来将`.class`文件加载到JVM中的工具。\\r\\n\\r\\n 类加载器类型\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nJava默认提供了三个类加载器，分别是 AppClassLoader、ExtClassLoader、BootstrapClassLoader，除此之外还可以自定义类加载器。类加载器之间是父级的关系，但不是通过继承实现父级关系的，而是通过组合的形式来实现的，在`Clas\"},{\"url\":\"/java/jvm/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JVM\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、类加载器\\r\\n\\r\\n- 类加载器\\r\\n- 对象创建\\r\\n\\r\\n 二、内存模型\\r\\n\\r\\n- JVM内存模型\\r\\n\\r\\n 三、垃圾回收\\r\\n\\r\\n- 垃圾回收算法\\r\\n- 垃圾回收器\\r\\n- G1收集器\\r\\n\\r\\n 四、命令工具\\r\\n\\r\\n- JDK调优命令\\r\\n- 可视化工具\\r\\n\\r\\n 五、排障记录\\r\\n\\r\\n- CPU负载过高排查记录\\r\\n- 内存问题排查总结\\r\\n- 频繁GC排查\\r\\n\\r\\n---\"},{\"url\":\"/java/jvm/内存问题排查总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内存问题排查总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"堆内存dump\\r\\n\\r\\n```\\r\\n1 jmap ‐dump:format=b,file=eureka.hprof 14660\\r\\n```\\r\\n\\r\\n可以配置自动 dump 文件，在内存溢出的时候会自动 dump 文件。\\r\\n\\r\\n```\\r\\n-XX:+HeapDumpOnOutOfMemoryError\\r\\n```\\r\\n\\r\\n比如应用的启动脚本，开启自动 dump 文件。\\r\\n\\r\\n```\\r\\nexec java -classpath $CLASSPATH -Xms1024m -Xmx2048m\\r\\n-XX:+HeapDumpOnOutOfMemoryError\\r\\n-Dquery.type=es\\r\\n-Dfile.enco\"},{\"url\":\"/java/jvm/可视化工具.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可视化工具\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"jconsole\\r\\n\\r\\njconsole是JDK 提供的可视化工具。可以查看内存、线程数量、CPU等资源信息。\\r\\n\\r\\n 使用方式\\r\\n\\r\\n 本地进程\\r\\n\\r\\n直接执行命令\\r\\n\\r\\n```java\\r\\njconsole\\r\\n```\\r\\n\\r\\n 远程进程\\r\\n\\r\\n```java\\r\\n-Djava.rmi.server.hostname=10.10.102.81-Dcom.sun.management.jmxremote.port=9999-Dcom.sun.management.jmxremote-Dcom.sun.management.jmxremote.authenticate=false\\r\\n-Dcom.sun\"},{\"url\":\"/java/jvm/垃圾回收器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"垃圾回收器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"垃圾回收类型\\r\\n\\r\\n1. 串行\\r\\n    - 单线程\\r\\n    - 适合堆内存小的时候。\\r\\n    - STW\\r\\n      \\r\\n        Stop The World 的简称。这是因为串行的机制，在垃圾回收的线程运行的时候，其它工作线程都要阻塞。\\r\\n        \\r\\n        *在垃圾回收过程中，对象的地址会发生改变。如果其它线程不阻塞，则可能会发生对象引用错误的问题。*\\r\\n    \\r\\n2. 吞吐量优先\\r\\n    - 多线程\\r\\n    - 适合堆内存较大，且多核CPU的情况。\\r\\n    - 在单位时间内，STW时间最短。\\r\\n3. 响应时间优先\\r\\n    - 多线程\\r\\n    -\"},{\"url\":\"/java/jvm/垃圾回收算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"垃圾回收算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"如何判断对象可以回收\\r\\n\\r\\n 引用计数法\\r\\n\\r\\n为对象添加引用计数器，如果对象被其它对象引用一次，计数器 +1；对应引用释放，则计数器 -1；只有当计数器为 0 时该对象才会被垃圾回收。\\r\\n\\r\\n- 引用计数法造成的内存泄漏\\r\\n  \\r\\n    像下面这种即使对象不被其它对象引用，这两个对象也一直不会被回收，因为对象A和B之间存在引用关系，引用计数器一直为 1，这样就导致了内存泄露。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n\\r\\n\\r\\n\\r\\n 可达性分析算法\\r\\n\\r\\n&gt; 如果某个对象到GC Roots间没有任何引用链相连， 或者用图论的话来说就是从GC Roots到这个对象不可达时，则证明此\"},{\"url\":\"/java/jvm/对象创建.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"对象创建\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"对象的创建流程\\r\\n\\r\\n\\r\\n\\r\\n 类加载检查\\r\\n\\r\\n判断有无加载过该类，有则直接进入下一步、没有则加载类对象。\\r\\n\\r\\n 分配内存\\r\\n\\r\\n虚拟机为新生对象分配内存。\\r\\n\\r\\n对象所需内存大小在类检查阶段便可确定，为对象分配空间就是将一块确定大小内存从 Java 堆中划分出来。\\r\\n\\r\\n 1. 划分内存的方法\\r\\n\\r\\n- 指针碰撞法\\r\\n  \\r\\n    该方法是JVM中的默认方法。\\r\\n    \\r\\n    它主要就是假设JVM中的内存是绝对规整的，使用过的内存和未使用过的内存分别放在两边，用一个指针来给他们做区分。如果要分配内存，只需要将指针向空闲的那一端移动对象大小的位置就好了。\\r\\n    \\r\\n- 空闲列表\"},{\"url\":\"/java/jvm/类加载器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"类加载器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"什么是类加载器\\r\\n\\r\\n类加载器（ClassLoader）就是在系统运行过程中动态的将编译后的.class字节码文件加载到JVM中的工具。在IDE中编写的源代码文件都是`.java`文件，通过编译对应生成`.class`文件。而类加载器就是用来将`.class`文件加载到JVM中的工具。\\r\\n\\r\\n 类加载器类型\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nJava默认提供了三个类加载器，分别是 AppClassLoader、ExtClassLoader、BootstrapClassLoader，除此之外还可以自定义类加载器。类加载器之间是父级的关系，但不是通过继承实现父级关系的，而是通过组合的形式来实现的，在`Clas\"},{\"url\":\"/java/jvm/频繁GC排查.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"频繁GC排查\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```\\r\\njstat -gcutil 1000\\r\\n```\\r\\n\\r\\n\\r\\n\\r\\n```\\r\\njmap -dump:format=b,file=dumpfile 1000\\r\\n```\\r\\n\\r\\n使用 MAT 工具分析代码\\r\\n\\r\\n---\\r\\n\\r\\n组件消费数据的线程池配置有问题。\"},{\"url\":\"/middleware/es/BulkProcessor死锁问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BulkProcessor死锁问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"问题原因\\r\\n\\r\\n- 定时flush\\r\\n- bulk操作\\r\\n- retryHandler：失败重试\\r\\n1. 定时 flush 和 retryHandler 用的是一个定时线程池，而该线程池只有一个线程。\\r\\n2. 定时 flush 的方法用的锁和 bulk 操作时的锁是同一把锁。都是类对象级别的锁。\\r\\n   \\r\\n    \\r\\n    \\r\\n    \\r\\n    \\r\\n3. 当bluk失败后，会触发默认的重试逻辑。\\r\\n4. 如果重试时候 flush 刚好运行，就会出现这种死锁情况。\\r\\n    1. bulk持有对象锁`BulkProcessor.class`，进行重试逻辑。\\r\\n    2. flush占有线\"},{\"url\":\"/middleware/es/ES分片.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES分片\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"同一个索引会划分为多个分片。分片可以设置副本数量，分为主分片和副本分片。\\r\\n\\r\\n```java\\r\\n 指定索引的主分片和副本分片数\\r\\nPUT /blogs\\r\\n{\\r\\n  \\\"settings\\\": {\\r\\n    \\\"number_of_shards\\\": 3,\\r\\n    \\\"number_of_replicas\\\": 1\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n 主分片\\r\\n\\r\\n- 解决数据水平扩展的问题。同一个索引可以按照分片分配数据，将数据平均分配到所有节点之上。\\r\\n- 主分片数创建好后就不能修改。\\r\\n- 一个分片就是一个运行的 Lucene 实例。\\r\\n\\r\\n 主分片过少\\r\\n\\r\\n- 单个分片数据量过大。查询较慢，利用\"},{\"url\":\"/middleware/es/ES压测记录和esrally使用.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES压测记录和esrally使用\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"环境信息\\r\\n\\r\\n- 压测环境\\r\\n  \\r\\n    ```\\r\\n    http://10.1.11.200:39200/\\r\\n    ```\\r\\n    \\r\\n- 开发环境\\r\\n  \\r\\n    ```java\\r\\n    http://10.10.101.69:39200\\r\\n    ```\\r\\n    \\r\\n- 测试环境\\r\\n  \\r\\n    ```java\\r\\n    http://10.10.103.218:39200/\\r\\n    ```\\r\\n    \\r\\n\\r\\n esrally安装\\r\\n\\r\\n docker安装\\r\\n\\r\\n1. 拉取镜像\\r\\n   \\r\\n    ```\\r\\n    docker pull elastic/rally\"},{\"url\":\"/middleware/es/ES参数调优.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES参数调优\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"预防脑裂\\r\\n\\r\\n\\r\\n\\r\\n重要配置的修改 | Elasticsearch: 权威指南 | Elastic\\r\\n\\r\\n 堆内存设置\\r\\n\\r\\n```\\r\\n -Xms2730m -Xmx2730m -Duser.timezone=Asia/Shanghai\\r\\n```\\r\\n\\r\\nxms和xmx设置一样大小，并设置为略小于pod分配内存的一半。\\r\\n\\r\\n 分片设置\\r\\n\\r\\n分片过小或过多都会影响es的查询速率。\\r\\n\\r\\n一经设置无法修改。\\r\\n\\r\\n目前是10个分片，数据量不大的情况下，设置为5个分片进行测试一下。1个、和node数量一致分片测试。\\r\\n\\r\\n1GB 20个分片\\r\\n\\r\\n1个 20G～40GB\\r\\n\\r\\n 副本数量\\r\\n\\r\"},{\"url\":\"/middleware/es/ES深度分页问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES深度分页问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"from+to分页\\r\\n\\r\\nes在查询时候默认使用的是分页查询，单次只会返回10条数据。\\r\\n\\r\\n可以指定size。\\r\\n\\r\\n\\r\\n\\r\\n- 查询要求默认 from+size 的结果必须不超过10000。\\r\\n  \\r\\n    可以通过修改配置\\r\\n    \\r\\n    ```java\\r\\n    \\\"index.max_result_window\\\":\\\"20000\\\"\\r\\n    ```\\r\\n    \\r\\n    限制单词查询满足条件的结果窗口的大小，由from+size共同决定。\\r\\n    \\r\\n    因为es是先将数据全查出来再做分页，这样做是为了限制内存的消耗。\\r\\n    \\r\\n    ---\\r\\n    \\r\\n    因\"},{\"url\":\"/middleware/es/ES滚动查询-Scroll.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES滚动查询-Scroll\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"原理\\r\\n\\r\\nElasticsearch中的滚动查询是基于 固定的排序规则 来加载一部分数据。\\r\\n\\r\\n当用户刷新时，将从上次加载的最后一条数据的位置再加载同样数量的数据。\\r\\n\\r\\n滚动查询的原理类似于分页查询，但是滚动查询不需要重新执行搜索，只需要继续检索下一批结果。在滚动查询中，每次只加载当前页的数据，而不是一次性加载所有数据。这使得滚动查询比分页查询更高效，因为滚动查询不需要将所有数据都存储在内存中。同时，滚动查询也适用于大量数据的处理，因为它可以分批次地处理数据，而不是一次性处理所有数据。\\r\\n\\r\\n 滚动查询的排序规则\\r\\n\\r\\n滚动查询的排序规则不一定是时间。在Elasticsearch中，滚动\"},{\"url\":\"/middleware/es/ES的log4j2日志自动清理配置.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES的log4j2日志自动清理配置\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"配置\\r\\n\\r\\n```xml\\r\\nappender.rolling.strategy.type = DefaultRolloverStrategy\\r\\nappender.rolling.strategy.fileIndex = nomax\\r\\nappender.rolling.strategy.action.type = Delete\\r\\nappender.rolling.strategy.action.basepath = ${sys:es.logs.base_path}\\r\\nappender.rolling.strategy.action.condition.type = IfFileName\\r\\napp\"},{\"url\":\"/middleware/es/ES聚合查询原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES聚合查询原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES在对海量数据进行聚合分析的时候会损失搜索的精准度来满足实时性的需求。\"},{\"url\":\"/middleware/es/ES集群.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES集群\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集群节点类型\\r\\n\\r\\n1. Master Node - 主节点\\r\\n2. DataNode - 数据节点\\r\\n3. Coordinating Node - 协调节点\\r\\n\\r\\n Master Node\\r\\n\\r\\n- 处理创建，删除索引等请求。\\r\\n- 决定分片被分配到哪个节点。\\r\\n- 维护并更新集群 state。\\r\\n\\r\\n Master Node节点最佳实践\\r\\n\\r\\n- Master节点非常重要，在部署上需要解决单点问题。\\r\\n- 为一个集群设置多个Master节点，而且节点只承担 Master 角色。\\r\\n\\r\\n Data Node\\r\\n\\r\\n保存数据的节点，负责保存分片数据。\\r\\n\\r\\n通过增加数据节点可以解决数据水平扩展\"},{\"url\":\"/middleware/es/Elasticsearch写入原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch写入原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本概念\\r\\n\\r\\n 索引\\r\\n\\r\\nElasticsearch的索引是一个逻辑上的概念，指存储了相同类型的文档集合。\\r\\n\\r\\n 映射\\r\\n\\r\\n映射（mapping）定义索引中有什么字段、进行字段类型确认。类似于数据库中表结构定义。\\r\\n\\r\\nES 默认动态创建索引和索引类型的 映射（mapping），就像是非关系型数据中的，无需定义表结构，更不用指定字段的数据类型。\\r\\n\\r\\n也可以手动指定 mapping 类型，比如通过请求设置索引的映射（mapping）。\\r\\n\\r\\n```java\\r\\ncurl --location --request POST 'localhost:9200/course/_mapping' \"},{\"url\":\"/middleware/es/Elasticsearch基础概念.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch基础概念\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础概念\\r\\n\\r\\n 一、索引库（index）\\r\\n\\r\\nElasticsearch的索引库是一个逻辑上的概念，存储了相同类型的文档内容。类似于 MySQL 数据表，MongoDB 中的集合。\\r\\n\\r\\n1. 新建索引库\\r\\n    - number_of_shards\\r\\n      \\r\\n        设置分片的数量，在集群中通常设置多个分片，表示一个索引库将拆分成多片分别存储不同 的结点，提高了ES的处理能力和高可用性，入门程序使用单机环境，这里设置为 1。\\r\\n        \\r\\n    - number_of_replicas\\r\\n      \\r\\n        设置副本的数量，设置副本是为了提高ES的\"},{\"url\":\"/middleware/es/Elasticsearch查询原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch查询原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES查询原理\\r\\n\\r\\n 查询方式\\r\\n\\r\\n- 根据 doc_id 查询。\\r\\n\\r\\n\\r\\n\\r\\n- 根据条件查询\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引\\r\\n\\r\\n根据文档中的每个字段建立倒排索引。\\r\\n\\r\\n 倒排索引的查询流程\\r\\n\\r\\n\\r\\n\\r\\n1. 查询条件分词。\\r\\n2. 查询单词词典 （term dictionary）。\\r\\n3. 获取对应分词的 doc_id 列表。\\r\\n4. 将查询结果返回。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 倒排索引的组成\\r\\n\\r\\n- postings list\\r\\n  \\r\\n    文档列表。\\r\\n    \\r\\n- term dictionary\\r\\n  \\r\\n    单词字典表。包含文档中所有的单词，es 会将单词排序\"},{\"url\":\"/middleware/es/Elasticsearch检索.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch检索\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"检索方式\\r\\n\\r\\nElasticsearch提供两种检索方式。\\r\\n\\r\\n1. RestAPI 形式通过 URL 参数进行检索。\\r\\n2. 通过 DSL 语句进行查询，通过传递 JSON 为请求体与 Elasticsearch 进行交互，这种方式更强大简洁。\\r\\n\\r\\n URL检索\\r\\n\\r\\n`GET /{index}/{type}/_search?q=*&sort=age:desc&size=5&from=0&_source=name,age,bir`\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\nq=* ：匹配所有文档\\r\\n\\r\\nsort=age：按照指定字段进行排序，默认为升序，:desc 降序排列\\r\\n\\r\\nsize：展示多少\"},{\"url\":\"/middleware/es/Elasticsearch聚合查询.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch聚合查询\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES在对海量数据进行聚合分析的时候会损失搜索的精准度来满足实时性的需求。\\r\\n\\r\\n Elasticsearch聚合查询总结\\r\\n\\r\\n 1. 求和、最大值、最小值、平均值\\r\\n\\r\\n- 求和 - sum\\r\\n- 最大值 - max\\r\\n- 最小值 - min\\r\\n- 平均值 - avg\\r\\n\\r\\n---\\r\\n\\r\\nDSL查询语句\\r\\n\\r\\n```java\\r\\n{\\r\\n    \\\"size\\\": 0,\\r\\n    \\\"query\\\": {\\r\\n        \\\"bool\\\": {\\r\\n            \\\"filter\\\": [\\r\\n                {\\r\\n                    \\\"range\\\": {\\r\\n    \"},{\"url\":\"/middleware/es/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础总结\\r\\n\\r\\n- Elasticsearch基础概念\\r\\n- Elasticsearch检索\\r\\n- Elasticsearch聚合查询\\r\\n\\r\\n\\r\\n- ES滚动查询-Scroll\\r\\n- 批量操作Bulk和BulkProcessor\\r\\n- BulkProcessor死锁问题\\r\\n\\r\\n\\r\\n- 并发场景修改文档\\r\\n- ES深度分页问题\\r\\n\\r\\n\\r\\n- ES集群\\r\\n- ES分片\\r\\n\\r\\n 原理总结\\r\\n\\r\\n- 倒排索引原理\\r\\n- Elasticsearch写入原理\\r\\n- Elasticsearch查询原理\\r\\n- ES聚合查询原理\\r\\n\\r\\n 使用问题\\r\\n- ES参数调优\\r\\n- 集群脑裂-参数配置\\r\\n\\r\\n\\r\\n- ES\"},{\"url\":\"/middleware/es/倒排索引原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"倒排索引图解\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"原理图\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引的搜索过程\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引原理\\r\\n\\r\\nElasticsearch 主要功能就是搜索，为了提高搜索效率，其内部使用了倒排索引。\\r\\n\\r\\n 正排索引\\r\\n\\r\\n在搜索引擎中，每个文件对应一个文件 ID （doc_id），文件内容是关键词的集合。\\r\\n\\r\\n\\r\\n\\r\\n根据 `doc_id` 可以查找到文档详情。\\r\\n\\r\\n*这种方式本质上就是通过文档的 key 查找 value 值。*\\r\\n\\r\\n比如查找 `name=jetty wan` 的文档，只能按照顺序从前向后匹配每个文档的 name 字段。\\r\\n\\r\\n这种查找方式的效率非常低下。\\r\\n\\r\\n 倒排索引\\r\\n\\r\\n倒排索引和正向索引\"},{\"url\":\"/middleware/es/并发场景修改文档.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"并发场景修改文档\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES从7.X版本默认使用的是乐观锁机制修改文档。\\r\\n\\r\\n当在高并发环境下使用乐观锁机制修改文档时，要带上当前文档的_seq_no和_primary_term进行更新：\\r\\n\\r\\n```java\\r\\nPOST /es_db/_doc/2?if_seq_no=21&if_primary_term=6{  \\\"name\\\": \\\"李四xxx\\\"}\\r\\n```\\r\\n\\r\\n如果冲突会提示版本冲突异常。\"},{\"url\":\"/middleware/es/批量操作Bulk和BulkProcessor.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"批量操作Bulk和BulkProcessor\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"es的批量操作，6.x版本的es中high-rest-client中可以用到以下三种。\\r\\n\\r\\n- bulk\\r\\n- bulkAsync\\r\\n- bulkProcessor\\r\\n\\r\\n Bulk\\r\\n\\r\\nbulk api 以此按顺序执行所有的 action（动作）。如果一个单个的动作因任何原因失败，它将继续处理它后面剩余的动作。当 bulk api 返回时，它将提供每个动作的状态（与发送的顺序相同），所以您可以检查是否一个指定的动作是否失败了。\\r\\n\\r\\nes可以通过 _bulk 的API实现批量操作。\\r\\n\\r\\n```java\\r\\nPOST _bulk\\r\\n{\\\"create\\\":{\\\"_index\\\":\\\"article\\\"\"},{\"url\":\"/middleware/es/集群脑裂-参数配置.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集群脑裂-参数配置\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集群脑裂的问题\\r\\n\\r\\n 什么是集群脑裂\\r\\n\\r\\nes 在主节点上产生分歧，产生多个master 节点，从而使集群分裂成多个同名集群，使得集群处于异常状态。\\r\\n\\r\\n当出现多个master节点的时候，可能发生写入请求分配到不同的master节点，而数据只保存在对应的master节点的分片上，不会复制到其它节点。此时若访问不同的节点，会发现查询的结果是不一样的。\\r\\n\\r\\n 举例说明脑裂\\r\\n\\r\\n`discovery.zen.minimum_master_nodes` 参数之前设置为 1（默认值）。\\r\\n\\r\\n这个参数的含义是限制选举master节点的数量。\\r\\n\\r\\n- 当master节点不存在时，至少有几个ma\"},{\"url\":\"/middleware/kafka/Kafka分区机制策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka分区机制策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"分区策略\\r\\n\\r\\n分区策略是决定生产者将消息发送到哪个分区的算法。\\r\\n\\r\\n 轮询策略\\r\\n\\r\\n是 Java 生产者 API 默认提供的分区策略。\\r\\n\\r\\n- 轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。\\r\\n\\r\\n\\r\\n\\r\\n 随机策略\\r\\n\\r\\n将消息随机写入分区\\r\\n\\r\\n key 指定分区\\r\\n\\r\\n当发送消息时指定了key，Kafka会根据key的hash值与分区数取模来决定将数据写入哪个分区。\\r\\n\\r\\n项目中 dr 就是生产这种方式，根据消息类型指定 key，比如 transactionId。这样能保证同一t\"},{\"url\":\"/middleware/kafka/Kafka副本机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka副本机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka 的副本是针对分区来说的，为分区创建副本。\\r\\n\\r\\n副本的作用就是提供数据冗余，在 Leader 副本挂掉之后，转换为 Leader 副本继续工作。\\r\\n\\r\\n不然当 Leader 副本挂掉之后，该分区就会停止对外提供服务。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 副本同步\\r\\n\\r\\n\\r\\n\\r\\n生产者只会往分区的 Leader 发消息，而其它 Follower 会从 Leader 拉取数据进行同步。\\r\\n\\r\\n Follower追随者副本\\r\\n\\r\\nFollower 副本是不对外提供服务的，只是定期地异步拉取领导者副本中的数据而已。\\r\\n\\r\\n LSR副本集合\\r\\n\\r\\nLSR集合里面保存的副本都是与 Leader 副本\"},{\"url\":\"/middleware/kafka/Kafka总控制器Controller.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka总控制器 Controller\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 kafka中会有多个 Broker，其中一个 Broker 会被选举为 Controller，负责管理整个集群中分区和副本的状态。\\r\\n\\r\\n Zookeeper\\r\\n\\r\\nzk 使用的数据模型类似于文件系统的树形结构，根目录也是以“/”开始。该结构上的每个节点被称为 znode，用来保存一些元数据协调信息。\\r\\n\\r\\nZooKeeper 常被用来实现集群成员管理、分布式锁、领导者选举等功能。\\r\\n\\r\\nznode 用来保存元数据信息。\\r\\n\\r\\n- 永久性 znode\\r\\n  \\r\\n    持久性 znode 不会因为 ZooKeeper 集群重启而消失。\\r\\n    \\r\\n- 临时性 znode\\r\\n  \\r\\n   \"},{\"url\":\"/middleware/kafka/Kafka手动重新分区.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka手动重新分区\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka重分配分区_kafka重新分配分区-CSDN博客\\r\\n\\r\\n1. 确定需要重新分区的 topic\\r\\n   \\r\\n    vi topics-to-move.json\\r\\n    \\r\\n    ```java\\r\\n    \\r\\n    {\\r\\n      \\\"topics\\\": [{\\r\\n         \\\"topic\\\": \\\"test-topic\\\"\\r\\n       }],\\r\\n       \\\"version\\\": 1\\r\\n    }\\r\\n    ```\\r\\n    \\r\\n    - topic 可以批量设置\\r\\n2. 根据 topic 生成执行计划\\r\\n   \\r\\n    ```java\\r\\n    bin/kafka-rea\"},{\"url\":\"/middleware/kafka/Kafka消费策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka消费策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka消费者-主动批量拉取\\r\\n\\r\\n\\r\\n&gt; \\r\\n1. kafka配置类\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\n@Slf4j\\r\\npublic class KafkaConfig {\\r\\n\\r\\n    @Bean\\r\\n    public KafkaListenerContainerFactory&lt;?&gt; batchFactory(ConsumerFactory consumerFactory){\\r\\n        ConcurrentKafkaListenerContainerFactory&lt;Integer,String&gt; factory =\\r\\n    \"},{\"url\":\"/middleware/kafka/Kafka生产者参数.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka生产者参数\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- bootstrap.servers： broker的地址\\r\\n- key.serializer：关键字的序列化方式\\r\\n- value.serializer：消息值的序列化方式\\r\\n- acks：指定必须要有多少个分区的副本接收到该消息，服务端才会向生产者发送响应，可选值为：0,1,2，…，all\\r\\n- buffer.memory：生产者的内存缓冲区大小。如果生产者发送消息的速度 \\r\\n- max.block.ms：表示send()方法在抛出异常之前可以阻塞多久的时间，默认是60s\\r\\n- compression.type：消息在发往kafka之前可以进行压缩处理，以此来降低存储开销和网络带宽。默认\"},{\"url\":\"/middleware/kafka/Kafka高性能的原因.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka高性能的原因\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 写数据是按照磁盘顺序读写。\\r\\n   \\r\\n    保证顺序读写，比随机写性能要高很多。\\r\\n    \\r\\n    数据保存在 log 中，并对 log 进行了分段（logSegment）技术，对 logSegment 还增加了日志索引。\\r\\n    \\r\\n2. 数据传输的零拷贝，使的数据在内核空间中就完成了读写操作。\\r\\n   \\r\\n    零拷贝原理：\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 读写数据的批量处理以及压缩传输。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n\\r\\n 零拷贝\\r\\n\\r\\n- 传统数据文件拷贝过程\\r\\n  \\r\\n    整个过程需要在内核空间和应用空间之间拷贝 2 次。\\r\\n    \"},{\"url\":\"/middleware/kafka/Producer发布消息机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Producer发布消息机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"写入机制\\r\\n\\r\\nProducer 通过push模式将消息发给 Broker，每条消息都被追加到对应的 Partition。而且是采用顺序写磁盘的方式（顺序写比随机写效率高，保障 Kafka 高吞吐量）。\\r\\n\\r\\n 消息路由模式\\r\\n\\r\\nProducer 如何确认消息发到哪个 Partition 上？\\r\\n\\r\\n1. 指定了 Partition，直接使用。\\r\\n2. 如果未指定 Partition，指定了 Key。根据 Key 的 Hash 值计算 Partition。\\r\\n   \\r\\n    Hash(key) % num(Partition)\\r\\n    \\r\\n3. 如果未指定 Partition，也未指定 \"},{\"url\":\"/middleware/kafka/__consumer_offsets.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"__consumer_offsets\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"将 Consumer 的位移数据作为一条条普通的 Kafka 消息，提交到 consumer*offsets 中。可以这么说，consumer*offsets 的主要作用是保存 Kafka 消费者的位移信息。\\r\\n\\r\\n_*consumer*offsets也是一个 topic，也有分区。和 kafka 的 topic 基本一致支持自定义写入。但是它是内部的 topic，一般最好不要自动修改。\\r\\n\\r\\n 消息格式\\r\\n\\r\\n1. 分区消费的 offset\\r\\n    \\r\\n    位移主题的 Key 中应该保存 3 部分内容：\\r\\n    \\r\\n    标识某个消费者组里面某个 topic 的某个分区，已经被消费\"},{\"url\":\"/middleware/kafka/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka配置\\r\\n\\r\\n- Kafka消费策略\\r\\n- Kafka生产者参数\\r\\n- kafka的分区副本规划\\r\\n\\r\\n\\r\\n Kafka原理总结\\r\\n- kafka消费模型\\r\\n- kafka-ACK应答机制\\r\\n- kafka解决重复消费\\r\\n\\r\\n\\r\\n- Kafka分区机制策略\\r\\n- kafka保证消息不丢失\\r\\n- 消费者组\\r\\n- __consumer_offsets\\r\\n- Kafka总控制器Controller\\r\\n- Kafka副本机制\\r\\n\\r\\n\\r\\n- Producer发布消息机制\\r\\n- 高水位HW和LEO\\r\\n- 数据日志分段存储\\r\\n\\r\\n\\r\\n- Kafka高性能的原因\\r\\n\\r\\n 使用总结\\r\\n- Kafka手动\"},{\"url\":\"/middleware/kafka/kafka-ACK应答机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka生产者保证消息不丢失-ACK应答机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka 生产者写入数据的时候，引入了 ACK 应答机制。\\r\\n\\r\\n```java\\r\\n            Properties props = new Properties();\\r\\n            props.put(\\\"bootstrap.servers\\\", Configuration.KAFKA_ADDRESS);\\r\\n\\t\\t\\t\\t\\t\\t//1:leader应答就可以发送下一条，确保发送成功。\\r\\n            props.put(\\\"acks\\\", \\\"1\\\");\\r\\n\\t\\t\\t\\t\\t\\t......\\r\\n            props.put(\\\"key.serializer\\\", \\\"org.a\"},{\"url\":\"/middleware/kafka/kafka保证消息不丢失.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka保证消息不丢失\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。\\r\\n\\r\\n 生产者端消息丢失\\r\\n\\r\\n生产者发送消息的时候，如果没有发到 kafka 导致消息丢失（网络抖动），其实这并不是 kafka 的原因。\\r\\n\\r\\nkafka 能保证已经提交到 borker 的数据，不会丢失。\\r\\n\\r\\n默认生产者发数据，采用 `send(msg)`发数据，这样发数据之后生产者并不知道是否发送成功。\\r\\n\\r\\n最好使用 `producer.send(msg, callback)` 发数据，这样通过`callback`能够清楚的知道消息是否发送成功。\\r\\n\\r\\n 消费者端消息丢失\\r\\n\\r\\nConsu\"},{\"url\":\"/middleware/kafka/kafka消费模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka消费模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka消费模型分为两种。\\r\\n\\r\\n1. 消费组消费\\r\\n   \\r\\n    消费组里面的单个消费者消费一个分区的数据。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n    \\r\\n    \\r\\n    \\r\\n2. 消费者-worker进程消费。\\r\\n\\r\\n\\r\\n\\r\\n&gt; 第一种消费模型，每个分区对应一个 consumer。\\r\\n&gt; \\r\\n\\r\\n第二种消费模型，只消费数据不处理，处理的工作单独交给 worker线程池，这样可以避免很多 consumer产生的问题。不要把很重的处理逻辑放到消费者中。\\r\\n\\r\\n&gt; 难以保证 offset 的语义正确性，可能导致重复消费。\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n--\"},{\"url\":\"/middleware/kafka/kafka的分区副本规划.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka的分区副本规划\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. topic划分\\r\\n\\r\\n每个日志对应一个topic。\\r\\n\\r\\ntopic 有自己的分区数量和副本数量。一般根据kafka指定的默认数量自动生成。\\r\\n\\r\\n---\\r\\n\\r\\n 2. 分区数量\\r\\n\\r\\n当生产者发给kafka一条消息时，根据规则分到 topic 的指定分区（partition），所以每个分区的数据是不一样的。\\r\\n\\r\\n 规划分区数量\\r\\n\\r\\n消费者在消费数据的时候，也是从分区中消费的，同一个分区只能被消费组里的一个消费者去消费。\\r\\n\\r\\n比如kafka有3个borker时，假如配置topic有5个分区，分配到3个borker就会出现 2 2 1 的情况。\\r\\n\\r\\n所以在指定topic的分区数量时\"},{\"url\":\"/middleware/kafka/kafka解决重复消费.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka解决重复消费\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"技术干货分享 | Kafka重复消费场景及解决方案\\r\\n\\r\\n 导致重复消费的原因\\r\\n\\r\\n- enable.auto.commit 默认值true，表示消费者会周期性自动提交消费的offset\\r\\n- auto.commit.interval.ms 在enable.auto.commit 为true的情况下， 自动提交的间隔，默认值5000ms\\r\\n- max.poll.records 单次消费者拉取的最大数据条数，默认值 500\\r\\n- max.poll.interval.ms 默认值5分钟，表示若5分钟之内消费者没有消费完上一次poll的消息，那么consumer会主动发起离开group的请求\\r\\n1\"},{\"url\":\"/middleware/kafka/数据日志分段存储.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据日志分段存储\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"数据保存机制\\r\\n\\r\\n\\r\\n\\r\\nKafka 的数据是按照分区存储的，以 topic-partition 为目录保存数据。\\r\\n\\r\\n数据是存到 log 中，而 log 又引入了LogSegment机制。\\r\\n\\r\\n`log.segment.bytes`，默认 1G。当超过1G 之后，日志就会开始分割。\\r\\n\\r\\n而日志分段文件以及索引文件都是以基准偏移量（offset）命名的。\\r\\n\\r\\n基本每段的日志文件包含一个数据文件和两个索引文件。\\r\\n\\r\\n- 以offset 为索引的 `.index`。\\r\\n- 以时间戳为索引的 `.timeindex`。\\r\\n\\r\\n索引里面并不是保留全量的数据索引，而是以稀疏索引的方式保存（方\"},{\"url\":\"/middleware/kafka/消费者组.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"消费者组\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。\\r\\n\\r\\n- 组内的所有消费者协调在一起来消费订阅主题（Subscribed Topics）的所有分区（Partition）。\\r\\n- 每个分区只能由同一个消费者组内的一个 Consumer 实例来消费。\\r\\n\\r\\n比如 topic 有 6 个分区，消费者组里面的消费者数量最理想状态是 6 个，每个消费者消费一个分区。也可以是 3 个或者两个，这样分区能够平均分配。\\r\\n\\r\\n但是最好不要超过 6 个消费者，这样的话会有消费者分不到分区。\\r\\n\\r\\n而 topic 的分区设计时，最好和 broker 的数量成比例。比如 3 个\"},{\"url\":\"/middleware/kafka/高水位HW和LEO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"高水位HW和LEO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"LEO（log_end_offset) 指的是当前分区日志末端的 offset。\\r\\n\\r\\n而 HW 指的是整个 LSR 集合副本中，LEO 最小的。保障 Consumer 只能消费到 HW 的位置。\\r\\n\\r\\n首先Leader 和 Followers 都有自己的 HW和 LEO，当有新消息写入 Leader 时，Consumer 并不能立即消费。\\r\\n\\r\\nFollowers 会 pull leader 最新的消息，同步完之后，发送 ACK 给 Leader。然后 Leader会增加 HW。增加之后，新产生的消息才能被 Consumer 消费掉。\\r\\n\\r\\n这样的目的是为了保证当 Leader 挂掉之后，重\"},{\"url\":\"/middleware/rocketmq/Kakfa和RocketMQ的区别.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kakfa和RocketMQ的区别\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"消费者组\\r\\n\\r\\nRocketMQ和Kafka虽然都使用了Consumer Group的概念来实现消息的分发和负载均衡，但两者在具体实现和一些特性上存在一些差异：\\r\\n\\r\\n1. Rebalance机制：\\r\\n    - RocketMQ：RocketMQ的Consumer Group在成员增减或Topic队列发生变化时会触发Rebalance，旨在重新分配队列到各个消费者实例，确保消息的公平消费。RocketMQ的Rebalance更加灵活，支持多种分配策略，例如平均分配、广播消费等，可以根据业务需求进行配置。\\r\\n    - Kafka：Kafka同样在Consumer Group中进行Rebala\"},{\"url\":\"/middleware/rocketmq/MQ接收消息幂等性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MQ接收消息幂等性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"幂等性\\r\\n\\r\\nMQ的消息幂性，指的是MQ接收消息时候的幂等性。\\r\\n\\r\\n- 最多一次\\r\\n    \\r\\n    消息最多只会被消费一次。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n- 最少一次\\r\\n    \\r\\n    消息最少被消费一次。\\r\\n    \\r\\n    &gt; 同步发送、事务消息。\\r\\n    &gt; \\r\\n- 准确消费一次\\r\\n    \\r\\n    默认RocketMQ保证不了准确消费一次。但是商业版本有。\\r\\n    \\r\\n\\r\\n 消息幂等的必要性\\r\\n\\r\\n- 生产者发送消息时，MQ收到消息，但是网络波动导致ACK没有给到生产者。可能会导致重推消息。\"},{\"url\":\"/middleware/rocketmq/RocketMQ基础学习.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ基础学习\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础架构\\r\\n\\r\\n\\r\\n\\r\\n 生产者\\r\\n\\r\\nRocketMQ提供多种发送方式，同步发送、异步发送、顺序发送、单向发送。\\r\\n\\r\\n同步和异步方式均需要 Broker 返回确认信息，单向发送不需要。\\r\\n\\r\\n生产者中，会把同一类 Producer 组成一个集合，叫做生产者组。同一组的 Producer 被认为是发送同一类消息且发送逻辑一致。\\r\\n\\r\\n 消费者\\r\\n\\r\\n 消费者组\\r\\n\\r\\n消费者组消费同一组数据，消费相同topic，并且消费逻辑一致。消费者组的消费者实例必须订阅完全相同的Topic。\\r\\n\\r\\n 消费模式\\r\\n\\r\\nRocketMQ 支持两种消息模式：集群消费（Clustering）和广播消费（Broad\"},{\"url\":\"/middleware/rocketmq/RocketMQ集群架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ集群架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NameServer：提供Broker的路由服务\\r\\n\\r\\nBroker：负责接收Producer的消息，存储消息，将消息投递给Consumer。\\r\\n\\r\\n- Broker需要管理数据，频繁处理数据，所以需要G1、ZGC这种更先进的垃圾回收器。\\r\\n- 而NameServer类似于Broker的注册中心，提供路由功能，只需要简单的垃圾回收算法就可以，比如CMS。\\r\\n\\r\\nProducer：生产者\\r\\n\\r\\nConsumer：消费者\\r\\n\\r\\n 集群架构说明\\r\\n\\r\\n整个RocketMQ集群里面主要分为两部分，Broker和NameServer。\\r\\n\\r\\n整个RocketMQ遵循的是AP架构，追求可用性。\\r\\n\\r\\n N\"},{\"url\":\"/middleware/rocketmq/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- RocketMQ基础学习\\r\\n- RocketMQ集群架构\\r\\n\\r\\n\\r\\n- 消息样例\\r\\n- 顺序消息\\r\\n- 事务消息\\r\\n\\r\\n\\r\\n- 如何保证发送消息有序\\r\\n- 如何保证消息不丢失\\r\\n- MQ接收消息幂等性\\r\\n\\r\\n\\r\\n- Kakfa和RocketMQ的区别\"},{\"url\":\"/middleware/rocketmq/事务消息.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"事务消息\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"事务消息的流程\\r\\n\\r\\n- 先写half消息到RocketMQ\\r\\n- 再执行本地事务\\r\\n  \\r\\n    本地事务有两个方法，一个是回调执行本地事务，另一个是检查本地事务。\\r\\n    \\r\\n    ```java\\r\\n    /**\\r\\n     * 事务监听器，用来处理本地事务\\r\\n     * @author yangjunwei\\r\\n     * @date 2024/7/4\\r\\n     */\\r\\n    public class TransactionListenerImpl implements TransactionListener {\\r\\n        private AtomicInteger\"},{\"url\":\"/middleware/rocketmq/如何保证发送消息有序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"如何保证发送消息有序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类比Kafka的ParitationKey，RocketMQ是messageQueue。\\r\\n\\r\\n将需要保证顺序的消息发给RocketMQ的messageQueue，被同一个消费者消费，即可保证有序。\\r\\n\\r\\n1. 消费者在发送的时候可以指定selector，指定消息发给哪个messageQueue。\\r\\n2. messageQueue是一个FIFO的队列，能够保证消费时按照写入消息的顺序去消费。\\r\\n\\r\\n所以需要保证有顺序的消息，比如相同产品的订单，可以按照产品 code 设置 selector，保证消息发到同一个 messageQueue，这样就能被同一个消费者消费。\\r\\n\\r\\n```java\\r\\nSe\"},{\"url\":\"/middleware/rocketmq/如何保证消息不丢失.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"如何保证消息不丢失\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"消息丢失场景\\r\\n\\r\\n数据丢失在MQ中比较常见，一般丢失数据都是在跨网络的部分，比如1、2、4。\\r\\n\\r\\n- 生产者发数据\\r\\n- 消费者消费数据\\r\\n- MQ内部主从同步\\r\\n\\r\\n而MQ写数据到磁盘过程也是有丢失数据的可能的。\\r\\n\\r\\n一般写数据到磁盘不会直接去写，而是利用操作系统的缓存，先写数据到缓存中，等待操作系统异步刷进磁盘。\\r\\n\\r\\n比如 Prometheus 的 WAL 机制。\\r\\n\\r\\n\\r\\n\\r\\n 事务消息-生产者\\r\\n\\r\\n使用事务消息能保证本地事务和写入MQ的事务一致性。\\r\\n\\r\\n比如订单场景，只保证本地下订单和向MQ发消息的事务一致性。不会像MySQL一样保证数据库事务。\\r\\n\\r\\n只是保证了业务的分布\"},{\"url\":\"/middleware/rocketmq/消息样例.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"消息样例\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"顺序消息\\r\\n\\r\\nkafka的顺序消息可以指定paritationKey实现，相同paritationKey的消息会被发给同一个paritation。\\r\\n\\r\\nRocketMQ可以通过实现 `MessageQueueSelector` 的 `select` 方法自定义实现消息所发给 MessageQueue的逻辑。\\r\\n\\r\\n```java\\r\\n    @SneakyThrows\\r\\n    @Test\\r\\n    public void orderSend() {\\r\\n        try {\\r\\n            DefaultMQProducer producer = new DefaultMQP\"},{\"url\":\"/middleware/rocketmq/顺序消息.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"顺序消息\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"生产者\\r\\n\\r\\n生产者发送消息到MQ的过程，如果要保证顺序消费。\\r\\n\\r\\n只能采用单线程去生产消息，因为多线程无法控制消息生产顺序。\\r\\n\\r\\n还需要保证 sharding key 相同，保证同一类消息发到同一个 ConsumerQueue。\\r\\n\\r\\n\\r\\n&gt; \\r\\n- 单线程生产消息\\r\\n- 发送到同一个ConsumerQueue\\r\\n\\r\\n 存储\\r\\n\\r\\nRocketMQ的存储是按照时间顺序 append write 到 commitlog 中的，同时它会被分发到 ConsumeQueue中。\\r\\n\\r\\n所以只需要生产时候保证消息采用单线程发送到同一个ConsumerQueue，存储时候就能够顺序存储。\\r\\n\\r\"},{\"url\":\"/other/algorithm/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 时间复杂度\\r\\n- 查找\\r\\n- 排序\\r\\n- 动态规划\"},{\"url\":\"/other/algorithm/动态规划.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"动态规划\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"动态规划重要特性\\r\\n\\r\\n动态规划的核心问题是穷举，因为要求最值，要把所有可行答案找出来，找最值。但是穷举的过程中，会存在【重叠子问题】。\\r\\n\\r\\n 重叠子问题\\r\\n\\r\\n在求解的过程中，存在重复的子问题，若是重复解决这些子问题，存在效率低下的问题。\\r\\n\\r\\n而解决重叠子问题，可以使用【备忘录】或者【DP table】方法来解决。\\r\\n\\r\\n- 备忘录\\r\\n  \\r\\n    备忘录的思想就是将已经解决的子问题结果记录在备忘录中（可以是数组等数据结构）。\\r\\n    \\r\\n\\r\\n\\r\\n&gt; \\r\\n- DP table\\r\\n  \\r\\n    使用 DP table 保存每个子问题的结果，自下向上推算结果。\\r\\n    \\r\\n\\r\\n\"},{\"url\":\"/other/algorithm/排序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"排序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"概念\\r\\n\\r\\n 稳定性\\r\\n\\r\\n稳定性指的是相同的数据所在的位置经过排序后是否发生变化。若是排序后，次序不变，则是稳定的。\\r\\n\\r\\n 内部排序\\r\\n\\r\\n排序记录全部存放在内存中进行排序的过程。\\r\\n\\r\\n 外部排序\\r\\n\\r\\n待排序记录的数量很大，以至于内存不能容纳全部记录，在排序过程中尚需对外存进行访问的排序过程。\\r\\n\\r\\n\\r\\n\\r\\n 选择排序-不稳定\\r\\n\\r\\n每次选择剩余待排序元素中的最小值，放到已排序元素的末尾。\\r\\n\\r\\n原理：每次排序选出最小的元素，替换到对应顺序末尾的位置。\\r\\n思路：第一次排序选出最小的元素，和待排序数组第一位的元素进行交换。\\r\\n\\r\\n```json\\r\\n/**\\r\\n     * 选择排序的思路：\"},{\"url\":\"/other/algorithm/时间复杂度.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"时间复杂度\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"O(1)\\r\\n\\r\\n- 数组下表查询\\r\\n\\r\\n O(n)\\r\\n\\r\\n- 链表元素查询，最坏情况是要查n次。\\r\\n\\r\\n O(logn)\\r\\n\\r\\n- 平衡二叉树\\r\\n- 数组二分法查找指定元素\\r\\n\\r\\n开根号\\r\\n\\r\\n- 比如16长度的数组，想要找到指定元素最多需要4次、\\r\\n  \\r\\n    16→8→4→2→1\\r\\n    \\r\\n- 红黑树（平衡二叉树、完全二叉树）\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n O(log n) \\r\\n\\r\\n复杂度解释：\\r\\n\\r\\n- 在一个理想平衡的二叉搜索树中，每次查找操作从根节点开始，通过比较目标值与当前节点的值来决定是向左还是向右子树进行下一步查找。\\r\\n- 每次比较后，查找范围大致减半，这类似于\"},{\"url\":\"/other/algorithm/查找.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"查找\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"静态查找表\\r\\n\\r\\n 顺序查找\\r\\n\\r\\n线性表查询，查找效率（n+1)/2\\r\\n\\r\\n\\r\\n\\r\\n 折半查找\\r\\n\\r\\n\\r\\n\\r\\n二分查找，仅适用于有序的线性表。\\r\\n\\r\\n折半查找比较次数最多为 [log2n]+1 次。n=2^x，比如8个元素最多需要3次，对应 8=2^3。\\r\\n\\r\\n所以时间复杂度为 O(log2n) 。\\r\\n\\r\\n 分块查找\\r\\n\\r\\n特点是块内无序，但是块间有序。\\r\\n\\r\\n- 先在索引表确定目标所在块。\\r\\n- 在块内顺序查找。\\r\\n\\r\\n\\r\\n\\r\\n比如索引表或者索引文件。\\r\\n\\r\\n 哈希表\\r\\n\\r\\n\\r\\n\\r\\n按照哈希存储元素到哈希表里。\\r\\n\\r\\n 哈希冲突解决方式\\r\\n\\r\\n按照值的哈希值存储会出现哈希冲突的问题，可以通\"},{\"url\":\"/other/datastructure/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据结构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 常用数据结构\\r\\n- 二叉树\"},{\"url\":\"/other/datastructure/二叉树.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"二叉树\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"推荐一个练习数据结构的网站\\r\\n\\r\\nData Structure Visualization\\r\\n\\r\\n 二叉树的遍历（重要）\\r\\n\\r\\n以图示二叉树为例。\\r\\n\\r\\n\\r\\n\\r\\n 中序遍历\\r\\n\\r\\n简化为每个树，都是左中右即可。\\r\\n\\r\\n中序遍历（LDR）是二叉树遍历的一种，也叫做中根遍历、中序周游。在二叉树中，中序遍历首先遍历左子树，然后访问根结点，最后遍历右子树。\\r\\n\\r\\n*左子树 → 根节点 → 右子树*\\r\\n\\r\\n图示二叉树中序遍历结果为：`3、5、6、10、14、15、17、20`；\\r\\n\\r\\n参考代码：Java实现中序遍历\\r\\n\\r\\n 前序遍历\\r\\n\\r\\n前序遍历（VLR）， 1] 是[二叉树遍历的一种，也叫做先根遍历\"},{\"url\":\"/other/datastructure/常用数据结构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"常用数据结构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"存储结构\\r\\n\\r\\n\\r\\n\\r\\n 复杂度\\r\\n\\r\\n时间复杂度\\r\\n\\r\\n空间复杂度\\r\\n\\r\\n 线性表\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 串\\r\\n\\r\\n比如字符串。\\r\\n\\r\\n\\r\\n\\r\\n 数组\\r\\n\\r\\n\\r\\n\\r\\n 矩阵\\r\\n\\r\\n\\r\\n\\r\\n求矩阵元素下标，直接代入即可。\\r\\n\\r\\n\\r\\n\\r\\n代入 A(0,0) 和 A(0,1)，分别对应 M(1) 和 M(2)。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 广义表\\r\\n\\r\\n\\r\\n\\r\\n例1：长度为3，深度为2\\r\\n\\r\\n例2: 先取表尾，再取表头，再取表头。\\r\\n\\r\\nhead (head ( tail(LS1) ) )\\r\\n\\r\\n 广义表的基本运算\\r\\n\\r\\n1. 取表头\\r\\n2. 取表尾\\r\\n\\r\\n 二叉树\\r\\n\\r\\n\\r\\n\\r\\n- 满二叉树\"},{\"url\":\"/other/design/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"设计模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"设计模式的目的\\r\\n\\r\\n* 代码重用性（提取重复代码）\\r\\n* 可读性（代码规范，便于阅读）\\r\\n* 可扩展性（方便增加新功能）\\r\\n* 可靠性（增加新功能，对以前的功能没有影响）\\r\\n* 使程序呈现高内聚、低耦合的特性\\r\\n\\r\\n 设计模式的七大基本原则\\r\\n\\r\\ndesign-principle\\r\\n\\r\\n* 单一职责原则\\r\\n\\r\\n* 接口隔离原则\\r\\n\\r\\n* 依赖倒置原则\\r\\n\\r\\n* 里氏替换原则\\r\\n\\r\\n* 开闭原则\\r\\n\\r\\n* 迪米特法则\\r\\n\\r\\n* 合成复用法则\\r\\n\\r\\n 设计模式三大类型\\r\\n\\r\\n 1. 创建型模式\\r\\n\\r\\ndesign-create\\r\\n\\r\\n* 单例模式\\r\\n\\r\\n    * 序列化和反序列化\\r\\n\\r\\n* 工\"},{\"url\":\"/other/design/七大基本原则.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"七大基本原则\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-principle\\r\\n\\r\\n 单一职责原则\\r\\n\\r\\n1. 一种类只能具有一种职责，降低类的复杂度。\\r\\n2. 提高类的可读性，可维护性。\\r\\n3. 降低变更引起的风险。\\r\\n4. 在类中的方法比较少的时候，可以在方法级别保持单一职责原则。其他情况下，都要保持类的类单一职责原则。\\r\\n\\r\\n 接口隔离原则\\r\\n\\r\\n1. 客户端不应该依赖它不需要的接口。\\r\\n2. 一个类对另一个类的依赖应该建立在最小的接口上。\\r\\n\\r\\n 依赖倒置原则\\r\\n\\r\\n1. 依赖倒置原则的中心思想是面向接口编程。\\r\\n2. 抽象不应该依赖细节，细节应该依赖抽象。抽象是接口或者抽象类，细节即为实现类。\\r\\n3. 对于细节的多变性，抽象的\"},{\"url\":\"/other/design/创建型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"创建型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-create\\r\\n\\r\\n 单例模式\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 饿汉式\\r\\n\\r\\n特点：类创建时创建对象，节省时间，占用内存，`以空间换时间`。\\r\\n\\r\\n1. 静态变量实现\\r\\n    \\r\\n    类加载时创建对象，节省时间，占用内存，`以空间换时间`。`推荐使用`，但是比较浪费空间。\\r\\n    \\r\\n    ```java\\r\\n    \\t\\t/**\\r\\n         * 类加载时创建对象，节省时间，占用内存，以空间换时间\\r\\n         */\\r\\n        private final static SingletonHungryOne INSTANCE = new Singleton\"},{\"url\":\"/other/design/结构型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"结构型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-structural\\r\\n\\r\\n 代理模式\\r\\n\\r\\n代理模式是属于结构型的设计模式,指客户端的请求到达真正的对象之前，做一些额外的操作。\\r\\n\\r\\n 静态代理模式\\r\\n\\r\\n\\r\\n以 AspectJ 为代表。指代理类在编译期生成的，与动态代理相比，效率会很高，但是会生成大量代理类。\\r\\n\\r\\n 动态代理模式\\r\\n\\r\\n以 SpringAOP 为代表为代表，代理类是动态生成的。虽然会效率会低一点，但是大大简化了代码和开发量。\\r\\n\\r\\n- JDK 动态代理\\r\\n- CGlib 动态代理\\r\\n\\r\\n 桥接模式\\r\\n\\r\\n抽象类：定义一个抽象类，作为系统的一部分。\\r\\n\\r\\n实现类：定义一个或多个实现类，与抽象类通过聚合（而非\"},{\"url\":\"/other/design/行为型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"行为型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-behavioral\\r\\n\\r\\n 责任链模式\\r\\n\\r\\n责任链模式——某个请求需要多个对象进行处理，从而避免请求的发送者和接收之间的耦合关系。将这些对象连成一条链子，并沿着这条链子传递该请求，直到有对象处理它为止。主要涉及两个角色：\\r\\n\\r\\n\\r\\n- 抽象处理者角色（Handler）：定义出一个处理请求的接口。这个接口通常由接口或抽象类来实现。\\r\\n- 具体处理者角色（ConcreteHandler）：具体处理者接受到请求后，可以选择将该请求处理掉，或者将请求传给下一个处理者。因此，每个具体处理者需要保存下一个处理者的引用，以便把请求传递下去。\\r\\n\\r\\n 优缺点比较\\r\\n\\r\\n优点\\r\\n\\r\\n- 降低耦\"},{\"url\":\"/other/network/HTTP1x和HTTP2x.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP1x和HTTP2.x\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HTTP1.x\\r\\n\\r\\n 数据格式\\r\\n\\r\\nHTTP1.x基于文本传输。\\r\\n\\r\\n- 请求行\\r\\n- 请求头\\r\\n- 请求体\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 缺点\\r\\n\\r\\n1. 占用字节：在HTTP请求中，包含很多空格和换行符。\\r\\n2. 头部不能压缩：在HTTP1.x中，请求头不能压缩。所以存在请求头比较大的问题，出现大头儿子。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n3. 传输效率低：同一个链接（`Keep-Alive`的情况）同时只能处理一个请求，收到响应才会开始发送下一个请求。\\r\\n    - 如果不设置 `Keep-Alive`，则每一次HTTP请求都会新建一个TCP链接。\\r\\n    \\r\\n    &g\"},{\"url\":\"/other/network/HTTP和HTTPS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP和HTTPS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HTTP 和 HTTPS 的区别\\r\\n\\r\\n- 传输问题。\\r\\n    - HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。\\r\\n    - HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。\\r\\n- 建立连接过程。\\r\\n    - HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。\\r\\n    - HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。\\r\\n- 两者的默认端口不一样。\\r\\n    - HTTP 默认端口号是 80。\\r\\n\"},{\"url\":\"/other/network/HTTP常见字段.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP常见字段\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```json\\r\\nPOST /apmServer-sl/sys-user/login HTTP/1.1\\r\\nAccept: application/json, text/plain, */*\\r\\nAccept-Encoding: gzip, deflate\\r\\nAccept-Language: zh-CN,zh;q=0.9\\r\\nAuthorization: clusterid34\\r\\nConnection: keep-alive\\r\\nContent-Length: 101\\r\\nContent-Type: application/json\\r\\nCookie: apm.name=admin\\r\\nHost: 10.1\"},{\"url\":\"/other/network/Linux如何收发网络包.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Linux如何收发网络包\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"2.3 Linux 系统是如何收发网络包的？\\r\\n\\r\\n 网络协议栈\\r\\n\\r\\n\\r\\n\\r\\n1. 应用程序需要通过系统调用，来和 Socket 进程数据交互。\\r\\n2. Socket 层是介于应用层和传输层之间的抽象层。\\r\\n3. 最下面的一层，则是网卡驱动程序和硬件网卡设备。\\r\\n\\r\\n Linux 接收和发送网络包的流程\"},{\"url\":\"/other/network/OSI七层网络模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"OSI七层网络模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 应用层，负责给应用程序提供统一的接口；\\r\\n- 表示层，负责把数据转换成兼容另一个系统能识别的格式；\\r\\n- 会话层，负责建立、管理和终止表示层实体之间的通信会话；\\r\\n- 传输层，负责端到端的数据传输；\\r\\n- 网络层，负责数据的路由、转发、分片；\\r\\n- 数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址；\\r\\n- 物理层，负责在物理网络中传输数据帧；\"},{\"url\":\"/other/network/RTT和SRTT.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RTT和SRTT\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"RTT\\r\\n\\r\\nRTT 指的是客户端发出数据 → 客户端收到服务端发送的确认数据的时间。\\r\\n\\r\\nRTT 称为往返时延。\\r\\n\\r\\n SRTT\\r\\n\\r\\nSRTT（Smoothed Round Trip Time）是一种用于衡量网络延迟的指标，通常用于评估网络连接的质量和性能。SRTT表示在一系列网络往返（Round Trip）中的平滑往返时间。\\r\\n\\r\\nSRTT是通过在每次往返时间（RTT）的基础上应用加权平均算法来计算得出的。加权平均算法会给最近的RTT值更高的权重，以反映出网络延迟的实时变化。\\r\\n\\r\\nSRTT的值越小，表示网络延迟越低，网络连接的质量越好。较低的SRTT值通常意味着网络响应更快，数据传\"},{\"url\":\"/other/network/Socket.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Socket\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Socket 位于应用层和传输层之前的抽象层，是一组调用接口，TCP/IP网络的API函数。\\r\\n\\r\\n实际上是对 TCP/IP协议的封装，只是为了更方便使用 TCP/IP 协议。\\r\\n\\r\\n\\r\\n这个就像操作系统会提供标准的编程接口，比如win32编程接口一样。\\r\\nTCP/IP也要提供可供程序员做网络开发所用的接口，这就是Socket编程接口。\\r\\n&gt; \\r\\n\\r\\n Socket 通信流程\\r\\n\\r\\n\\r\\n\\r\\nSocket按照四元组来标识不同客户端与服务端之间的连接。\\r\\n\\r\\n四元组「源 IP、源端口、目的 IP、目的端口」\\r\\n\\r\\n- `accept()`\\r\\n  \\r\\n    服务端绑定端口之后，进入 `acc\"},{\"url\":\"/other/network/TCPIP四层网络模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP/IP四层网络模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"为什么要有网络模型\\r\\n\\r\\n进程通信的方式\\r\\n\\r\\n- 本机\\r\\n    - 消息队列\\r\\n    - 共享内存\\r\\n    - 管道（程序用来交换数据的地方）\\r\\n- 不同主机\\r\\n    - 网络通信\\r\\n\\r\\n需要网络通信的设备是多种多样的，所以要兼容，就要设定网络通信之间的网络协议。\\r\\n\\r\\n 应用层\\r\\n\\r\\n应用层定义了应用进程之间通信和交互的规则，应用层交互数据单元为报文。\\r\\n\\r\\n不关心数据如何传输，将报文传给传输层做传输。\\r\\n\\r\\n在这一层有很多熟悉的协议，比如 HTTP、HTTPS、DNS等。\\r\\n\\r\\n【计算机网络】TCP / IP 四层协议_tcp/ip协议包含哪几层_L Jiawen的博客-CSDN\"},{\"url\":\"/other/network/TCP分析工具.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP分析工具\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Wireshark · Go Deep\\r\\n\\r\\n\\r\\n\\r\\n 三次握手\\r\\n\\r\\n\\r\\n\\r\\n 第1次握手\\r\\n\\r\\n\\r\\n\\r\\nsyn设置为1，表明这是一个 SYN包\\r\\n\\r\\n\\r\\n\\r\\nseq = 1390201126\\r\\n\\r\\n\\r\\n\\r\\n 第2次握手\\r\\n\\r\\nsyn=1 同时 ACK=1，表明这是一个 SYN/ACK包\\r\\n\\r\\n\\r\\n\\r\\n服务端返回的 ACK = 客户端第一次发送的 seq+1 = 1390201126+1\\r\\n\\r\\n同时服务端向客户端返回了自己的 seq（如果第三次握手客户端返回的ack=seq+1，代表客户端收到了自己发的seq）\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n 第3次握手\\r\\n\\r\\n可以看到第 3 次握手的\"},{\"url\":\"/other/network/TCP协议.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP协议\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"TCP 协议灵魂 12 问，巩固你的网路底层基础！-腾讯云开发者社区-腾讯云\\r\\n\\r\\n\\r\\n\\r\\n TCP和UDP的区别\\r\\n\\r\\n- 面向连接\\r\\n    - TCP 需要客户端与服务端之间通过三次握手建联，之后才可以发送数据。\\r\\n    - UDP直接向服务端发数据包。\\r\\n- 可靠性\\r\\n    - 有状态\\r\\n        - TCP发数据包时，保证数据包按顺序到达。\\r\\n    - 可控制\\r\\n        - 当TCP协议丢包时，可以控制重发和自己的发送速度，保证数据包完整和有序。\\r\\n    - UDP 是无状态并且不可控的。\\r\\n- 基于字节流\\r\\n    - TCP将数据包通过字节流发送。\\r\\n   \"},{\"url\":\"/other/network/TCP粘包拆包.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP粘包拆包\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"发生粘包的原因\\r\\n\\r\\n- 要发送的数据小于 TCP 发送缓冲区的大小，TCP 将多次写入缓冲区的数据一次发送出去，将会发生粘包；\\r\\n- 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包；\\r\\n- 要发送的数据大于 TCP 发送缓冲区剩余空间大小，将会发生拆包；\\r\\n- 待发送数据大于 MSS（最大报文长度），TCP 在传输前将进行拆包。即 TCP 报文长度 - TCP 头部长度 \\r\\n\\r\\n 解决粘包拆包问题\\r\\n\\r\\n- 定长消息：发送端将每个数据包封装为固定长度\\r\\n- 特殊分隔符：在数据尾部增加特殊字符进行分割\\r\\n- 消息头：将数据分为两部分，一部分是头部，一部分是内容体；其中头部结构大小\"},{\"url\":\"/other/network/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"计算机网络\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础\\r\\n\\r\\n- TCP/IP四层网络模型\\r\\n- OSI七层网络模型\\r\\n- 网址访问页面中间发生了哪些过程\\r\\n- Linux如何收发网络包\\r\\n- 网络包的封装原理\\r\\n- Socket\\r\\n\\r\\n TCP\\r\\n\\r\\n- TCP协议\\r\\n- TCP分析工具\\r\\n\\r\\n\\r\\n- RTT和SRTT\\r\\n- 流量控制-滑动窗口\\r\\n\\r\\n- 拥塞控制\\r\\n- 重传机制\\r\\n- TCP粘包拆包\\r\\n\\r\\n\\r\\n UDP\\r\\n\\r\\nUDP不需要连接，可以单播和广播。\\r\\n\\r\\n HTTP\\r\\n- HTTP常见字段\\r\\n- HTTP和HTTPS\\r\\n- HTTP1x和HTTP2x\\r\\n\\r\\n 参考链接\\r\\n\\r\\n图解网络介绍\"},{\"url\":\"/other/network/拥塞控制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"拥塞控制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"流量控制是避免数据填满发送方的缓冲区。\\r\\n\\r\\n而拥塞控制是避免发送方的数据填满整个网络。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n在⽹络出现拥堵时，如果继续发送⼤量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是⼀重传就会导致⽹络的负担更重，于是会导致更⼤的延迟以及更多的丢包，这个情况就会进⼊恶性循环被不断地放⼤….\\r\\n\\r\\n所以，TCP 不能忽略整个网络中发⽣的事，它被设计成⼀个⽆私的协议，当⽹络发送拥塞时，TCP 会⾃我牺牲，降低发送的数据流。\\r\\n\\r\\n 拥塞窗口\\r\\n\\r\\n拥塞窗⼝ cwnd是发送⽅维护的⼀个的状态变量，它会根据⽹络的拥塞程度动态变化的。\\r\\n\\r\\n发送窗⼝ swnd 和接\"},{\"url\":\"/other/network/流量控制-滑动窗口.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"流量控制-滑动窗口\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在TCP中，滑动窗口用来流量控制。确保发送方不会过快的发送数据导致接收方无法处理数据。\\r\\n\\r\\nTCP拥塞控制是为了解决发送方以过高的速率发送导致网络中出现阻塞，其核心思想就是发生重传时控制发送方滑动窗口（通过控制拥塞窗口cwnd）的大小，从而控制其发送速率。\\r\\n\\r\\n 滑动窗口\\r\\n\\r\\nTCP窗口包括发送窗口和接收窗口，用来限制不同端所能容纳数据的上限，达到控制发送数据的速率。\\r\\n\\r\\n\\r\\n\\r\\nTCP报文里面的窗口大小，作用是告诉对方本端的接受缓冲区还能容纳多少字节的数据。\\r\\n\\r\\n\\r\\n\\r\\n在通信过程中，接收方每次收到数据包，在发送确认报文的时候，还需要告诉发送方自己的缓冲区剩余大小。缓冲区剩余大小，\"},{\"url\":\"/other/network/网址访问页面中间发生了哪些过程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"网址访问页面中间发生了哪些过程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"2.2 键入网址到网页显示，期间发生了什么？\\r\\n\\r\\n URL解析\\r\\n\\r\\n URL组成信息\\r\\n\\r\\nURL实际上就是访问 Web服务器里面的文件资源。\\r\\n\\r\\n\\r\\n\\r\\n 组装HTTP报文\\r\\n\\r\\n根据 URL 解析得到的内容，进行报文组装。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n DNS域名解析\\r\\n\\r\\n解析URL时，如果web服务器是域名，需要走DNS服务器进行域名解析，得到真实访问的IP地址。\\r\\n\\r\\n 域名组成\\r\\n\\r\\n`www.server.com.` 类似树状结构，越右等级越高。\\r\\n\\r\\n域名组成都代表了DNS服务器，里面保存了域名和IP的对应关系。\\r\\n\\r\\n域名服务器就像是一个树状结构。\\r\\n\\r\\n- 根\"},{\"url\":\"/other/network/网络包的封装原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"网络包的封装原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 TCP/IP 四层网络模型中，网络包每层的包装如下：\\r\\n\\r\\n- 传输层，给应用数据前面增加了 TCP 头；\\r\\n- 网络层，给 TCP 数据包前面增加了 IP 头；\\r\\n- 网络接口层，给 IP 数据包前后分别增加了帧头和帧尾；\\r\\n\\r\\n每层增加的头部和尾部，都有每层独特的作用，按照各自的协议填充。\\r\\n\\r\\n在物理链路上并不能传输任意大小的数据包，在以太网中，规定了最大传输单元（MTU）为 1500 字节，规定了单次传输的最大 IP 包的大小。\\r\\n\\r\\n当网络包超过 MTU 时，就会在网络层分片，确保分片后的包不会超过 MTU 大小。\\r\\n\\r\\n- 如果 MTU 越小，网络包分片数越多，那么网络吞吐能力\"},{\"url\":\"/other/network/重传机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"重传机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"超时重传\\r\\n\\r\\n原理是在发送某一个数据以后就开启一个计时器，在一定时间内如果没有得到发送的数据报的 ACK 报文，那么就重新发送数据，直到发送成功为止。\\r\\n\\r\\n RTT\\r\\n\\r\\nRTT（Round-Trip Time，往返时间）。数据包一次的往返时间。\\r\\n\\r\\n\\r\\n\\r\\nSRTT：平均的RTT\\r\\n\\r\\n 缺点\\r\\n\\r\\n- 当一个报文丢失时，会等待一定的超时周期，才重传分组，增加了端到端的时延。\\r\\n- 当一个报文丢失时，在其等待超时的过程中，可能会出现这种情况：其后的报文段已经被接收端接收但却迟迟得不到确认，发送端会认为也丢失了，从而引起不必要的重传，既浪费资源也浪费时间。\\r\\n- 并且，对于 TCP，如果\"},{\"url\":\"/other/observability/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可观测性常见维度\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"可观测性指的是对于系统内部运行状态的全面洞察和理解能力。\\r\\n\\r\\n可观测性项⽬旨在提供⼯具和解决⽅案，帮助开发⼈员和运维团队更好地监视、调试和理解其应⽤程序的行为。\\r\\n\\r\\n 维度\\r\\n\\r\\n- 日志采集 （log）\\r\\n- 指标采集 （Metric）\\r\\n- 链路追踪（Trace）\\r\\n- 告警管理（AlertManager）\\r\\n- 可视化（Visualization）\\r\\n\\r\\n整个可观测项目，维度除了常见的 log、metric、trace之外。还包括告警和可视化。\\r\\n\\r\\n 指标\\r\\n\\r\\n指标又可以分为：\\r\\n\\r\\n- 基础设施\\r\\n\\r\\n  服务器、数据库、MQ的指标。\\r\\n\\r\\n- 应用维度\\r\\n\\r\\n  应用包含模块\"},{\"url\":\"/other/observability/log/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"日志收集全链路\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ELFK\\r\\n\\r\\nELFK 指的是 elasticsearch+logstash+filebeat+kibana\\r\\n\\r\\n 日志管理\\r\\n\\r\\n日志收集→格式化分析→检索和可视化→日志告警\\r\\n\\r\\n\\r\\n\\r\\n 日志架构\\r\\n\\r\\n 小规模环境\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 大规模生产环境\\r\\n\\r\\nELFK + Kafka\\r\\n\\r\\n Logstash\\r\\n\\r\\n从多个来源采集数据，转换数据，然后将数据放到不同的数据库中。\\r\\n\\r\\nda 就很像 logstash 的功能设计。\\r\\n\\r\\n 架构\\r\\n\\r\\n\\r\\n\\r\\nLogstash 接入数据源数据，经过内部 Pipeline，将数据可以写到不同的存储（ES、Kafka）里面。\\r\\n\\r\\nLog\"},{\"url\":\"/other/observability/opentelemetry/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Opentelemetry\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"docs-cn/OT.md at main · open-telemetry/docs-cn\\r\\n\\r\\n OpenTracing&OpenCensus\\r\\n\\r\\n- OpenTracing 制定了一套平台无关、厂商无关的协议标准，使得开发人员能够方便的添加或更换底层 APM 的实现。\\r\\n- OpenCensus支持Metrics、分布式跟踪。\\r\\n\\r\\n OpenTelemetry\\r\\n\\r\\nOpenTelemetry 的核心工作目前主要集中在 3 个部分：\\r\\n\\r\\n1. 规范的制定和协议的统一，规范包含数据传输、API的规范。协议的统一包含：HTTP W3C的标准支持及GRPC 等框架的协议标准。\\r\\n2. 多\"},{\"url\":\"/other/observability/opentelemetry/可观测性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可观测性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"可观测性指的是对于系统内部运行状态的全面洞察和理解能力。\\r\\n\\r\\n可观测性项⽬旨在提供⼯具和解决⽅案，帮助开发⼈员和运维团队更好地监视、调试和理解其应⽤程序的行为。\\r\\n\\r\\n 维度\\r\\n\\r\\n- 日志采集 （log）\\r\\n- 指标采集 （Metric）\\r\\n- 链路追踪（Trace）\\r\\n- 告警管理（AlertManager）\\r\\n- 可视化（Visualization）\\r\\n\\r\\n整个可观测项目，维度除了常见的 log、metric、trace之外。还包括告警和可视化。\\r\\n\\r\\n 指标\\r\\n\\r\\n指标又可以分为：\\r\\n\\r\\n- 基础设施\\r\\n\\r\\n  服务器、数据库、MQ的指标。\\r\\n\\r\\n- 应用维度\\r\\n\\r\\n  应用包含模块\"},{\"url\":\"/other/observability/skywalking/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Skywalking\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Skywalking\\r\\n\\r\\n- 组件安装\\r\\n- 源码学习\"},{\"url\":\"/other/observability/skywalking/源码学习.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"源码学习\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Category: SkyWalking | 芋道源码 —— 纯源码解析博客\\r\\n\\r\\nSkyWalking8.7源码解析\\r\\n\\r\\n 告警组件\\r\\n\\r\\n 初始化Kafka消费者\\r\\n\\r\\n```java\\r\\n@Slf4j\\r\\npublic class KafkaFetcherProvider extends ModuleProvider {\\r\\n    private KafkaFetcherHandlerRegister handlerRegister;\\r\\n    private KafkaFetcherConfig config;\\r\\n\\r\\n    @Override\\r\\n    public String na\"},{\"url\":\"/other/observability/skywalking/组件安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"组件安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"OAP\\r\\n\\r\\n- 配置文件\\r\\n  \\r\\n    ```java\\r\\n    apache-skywalking-apm-bin/config/application.yml\\r\\n    ```\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n- 启动脚本\\r\\n  \\r\\n    ```java\\r\\n    sh bin/oapService.sh\\r\\n    ```\\r\\n    \\r\\n\\r\\n UI\\r\\n\\r\\n- 配置\\r\\n  \\r\\n    ```java\\r\\n    apache-skywalking-apm-bin/webapp/webapp.yml\\r\\n    ```\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n- 启动脚本\\r\\n  \\r\\n    ```java\\r\\n\"},{\"url\":\"/personal/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"personal\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"&lt;div align=\\\"center\\\"\\r\\n  &lt;img src=\\\"https://capsule-render.vercel.app/api?type=waving&color=gradient&height=300&section=header&text=Albert%20Yang&fontSize=90&animation=fadeIn&fontAlignY=38&desc=热爱编程%20|%20追求卓越%20|%20创新思维&descAlignY=55&descAlign=62\\\" /&gt;\\r\\n&lt;/div&gt;\\r\\n&lt;p align=\\\"center\\\" style=\"}],\"sortPostsByDateAndSticky\":[{\"url\":\"/cloudnative/docker/Docker学习总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Docker学习总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本知识\\r\\n\\r\\n 1. Docker 是什么？\\r\\n\\r\\ndocker 是一种容器化虚拟技术，解决了运行环境和配置问题，方便持续集成并有助于项目整体发布。\\r\\n\\r\\n 2. Docker 能干嘛？\\r\\n\\r\\n*一次构建、随处运行。*\\r\\n\\r\\n- 更快速的应用交付和部署。\\r\\n- 更便捷的升级和扩缩容。\\r\\n- 更简单的系统运维。\\r\\n- 更高效的计算源利用。\\r\\n\\r\\n 基本组成\\r\\n\\r\\n 1. 镜像\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 2. 容器\\r\\n\\r\\n&gt; Docker 利用容器（Container）独立运行一个或一组应，容器是用镜像创建的运行实例。\\r\\n&gt; \\r\\n\\r\\n它可以被启动、开始、停止、删除。每个容器都是相\"},{\"url\":\"/cloudnative/docker/docker镜像压缩.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"docker镜像压缩\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"tar包\\r\\n\\r\\n\\r\\n\\r\\n```\\r\\ndocker save tomcat-apm-0915 -o ./tomcat-apm-0915.tar\\r\\n```\\r\\n\\r\\n```\\r\\ndocker load &lt; tomcat-apm-0915.tar\\r\\n```\\r\\n\\r\\nDocker 复制镜像到其他主机 - 彦祚 - 博客园\\r\\n\\r\\n tar.gz包\\r\\n\\r\\n 保存镜像\\r\\n\\r\\n`docker save &lt;myimage\\r\\n\\r\\n```\\r\\ndocker save xxx:xxx| gzip&gt;xxx.tar.gz\\r\\n```\\r\\n\\r\\n 加载镜像\\r\\n\\r\\n`gunzip -c &lt;myimage&gt;_&lt\"},{\"url\":\"/cloudnative/docker/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Docker\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"学习总结\\r\\n- Docker学习总结\\r\\n\\r\\n\\r\\n 使用总结\\r\\n- 容器软件安装\\r\\n- docker镜像压缩\\r\\n- 制作Tomcat镜像\\r\\n- 容器新增bash\"},{\"url\":\"/cloudnative/docker/制作Tomcat镜像.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"制作Tomcat镜像\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"DockerFile文件内容\\r\\n\\r\\n- tomcat 基础镜像\\r\\n  \\r\\n    ```bash\\r\\n    \\r\\n     使用基于 JDK 8 的官方 Tomcat 镜像作为基础镜像\\r\\n    FROM tomcat:8-jdk8\\r\\n    \\r\\n     修改默认的 shell\\r\\n    RUN ln -sf /bin/bash /bin/sh\\r\\n    \\r\\n     暴露 Tomcat 的默认 HTTP 端口\\r\\n    EXPOSE 8080\\r\\n    \\r\\n     设置容器启动时执行的命令\\r\\n    CMD [\\\"catalina.sh\\\", \\\"run\\\"]\\r\\n    ```\\r\\n    \\r\\n- \"},{\"url\":\"/cloudnative/docker/容器新增bash.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"容器新增bash\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"安装方式\\r\\n\\r\\n- wget 下载\\r\\n  \\r\\n    ```bash\\r\\n    from busybox\\r\\n    \\r\\n     下载 bash 二进制文件\\r\\n    RUN wget -O /bin/bash http://ftp.gnu.org/gnu/bash/bash-5.1.tar.gz\\r\\n    \\r\\n     设置可执行权限\\r\\n    RUN chmod +x /bin/bash\\r\\n    \\r\\n     运行命令\\r\\n    CMD [\\\"echo\\\", \\\"Hello, World!\\\"]\\r\\n    ```\\r\\n    \\r\\n- 本地安装\\r\\n  \\r\\n    ```bash\\r\\n    from \"},{\"url\":\"/cloudnative/docker/容器软件安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"容器软件安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"RabbitMQ\\r\\n\\r\\n参考博客\\r\\n\\r\\ndocker安装RabbitMQ\\r\\n\\r\\n---\\r\\n\\r\\n1. 查找镜像\\r\\n   \\r\\n    ```java\\r\\n    docker search rabbitmq\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n2. 拉取镜像\\r\\n   \\r\\n    ```java\\r\\n    docker pull rabbitmq\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 启动镜像\\r\\n   \\r\\n    ```java\\r\\n    docker run -d --hostname my-rabbit --name rabbit -p 15672:15\"},{\"url\":\"/cloudnative/k8s/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"K8s\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- k8s常用命令\\r\\n- k8s问题排查流程图\"},{\"url\":\"/cloudnative/k8s/k8s常用命令.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"k8s常用命令\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"常用命令总结\\r\\n\\r\\n node\\r\\n\\r\\n- 查看所有的node\\r\\n  \\r\\n    ```\\r\\n    kubectl get nodes\\r\\n    ```\\r\\n    \\r\\n- 查看node名与Host文件的相互解析\\r\\n  \\r\\n    ```\\r\\n    cat /etc/hosts\\r\\n    ```\\r\\n    \\r\\n- 查看本机 hostname\\r\\n  \\r\\n    `Plain Text   cat /etc/hostname`\\r\\n    \\r\\n\\r\\n namespace\\r\\n\\r\\n- 查看所有的namespace\\r\\n  \\r\\n    ```\\r\\n    [root@master ~] kubectl  get n\"},{\"url\":\"/cloudnative/k8s/k8s问题排查流程图.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"k8s问题排查流程图\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"深度解密｜基于 eBPF 的 Kubernetes 问题排查全景图发布-阿里云开发者社区\"},{\"url\":\"/cloudnative/prometheus/TSDB.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TSDB\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Prometheus的 TSDB（Time Series Database）作为内置的时序数据库。\\r\\n\\r\\n 存储原理\\r\\n\\r\\nTSDB 既使用内存也使用磁盘进行数据存储。\\r\\n\\r\\n\\r\\n\\r\\n Head\\r\\n\\r\\n在Prometheus中，Head 是数据库的内存部分，用于存储最近写入的数据。\\r\\n\\r\\n当数据在Head中存储2小时后，会被转移到磁盘上的持久块（block）中。这些持久块是不变的，每个块代表一段时间的数据，并且按照时间顺序进行组织和存储。\\r\\n\\r\\n\\r\\n\\r\\n Block块\\r\\n\\r\\nPrometheus中以每2个小时为一个时间窗口，即将2小时内产生的数据存储在一个block中，监控数据会以时间段的形式\"},{\"url\":\"/cloudnative/prometheus/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Prometheus\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 架构\\r\\n- TSDB\\r\\n- 数据模型\\r\\n- node_exporter源码\"},{\"url\":\"/cloudnative/prometheus/node_exporter源码.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"node_exporter源码\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"简单流程\\r\\n\\r\\n1. 定时任务 30s 执行一次\\r\\n    1. 调用采集指标的方法\\r\\n2. 不同 Collector 采集自己的指标\\r\\n    1. 内存\\r\\n        - 读取 `/`@\\r\\n          \\r\\n            `proc/meminfo`文件内容\\r\\n            \\r\\n            ```go\\r\\n            MemTotal:       16267496 kB\\r\\n            MemFree:          803084 kB\\r\\n            MemAvailable:    1507880 kB\\r\\n \"},{\"url\":\"/cloudnative/prometheus/数据模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Prometheus的存储实现上所有的监控样本都是以 time-series 的形式保存在 Prometheus 内置的TSDB（时序数据库）中，而 time-series 所对应的监控指标 (metric) 也是通过 labelset 进行唯一命名的。\\r\\n\\r\\n 样本数据\\r\\n\\r\\n- 指标(metric)：metric name 和描述当前样本特征的 labelsets;\\r\\n- 时间戳(timestamp)：一个精确到毫秒的时间戳;\\r\\n- 样本值(value)： 一个float64的浮点型数据表示当前样本的值。\\r\\n\\r\\n```\\r\\n&lt;--------------- metric -------\"},{\"url\":\"/cloudnative/prometheus/架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Prometheus架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- Promtheus 默认采取主动拉的策略，可以配置各个exporter的拉取间隔。\\r\\n    - Exporter 被动暴露数据，Prometheus 主动拉取。\\r\\n- 但是Promtheus也可以使用 Pushgateway 实现 Push 模型。\\r\\n    - exporter 将数据推给 Pushgateway，Promtheus从Pushgateway拉数据。\"},{\"url\":\"/database/clickhouse/ClickHouse基础.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse基础\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"列式存储\\r\\n\\r\\nclickhouse 是 *列式存储* 数据库\\r\\n\\r\\n在磁盘上按列存储，即按某个字段进行存储。\\r\\n\\r\\n\\r\\n\\r\\n所以列式存储更适合进行查询，比如某一行的聚合、计算、求和等。\\r\\n\\r\\n 列式存储的好处\\r\\n\\r\\n1. 对于某列的聚合、计数、求和等操作要比行式存储更快。\\r\\n   \\r\\n    查询更快。\\r\\n    \\r\\n    - 行式存储，增改删更加方便，因为只需要找到对应的行记录，直接删除即可。但是列式存储对比起来，增改删要更繁琐一点。\\r\\n2. 每一列的数据类型是一样的，这样能更好的进行数据压缩。\\r\\n   \\r\\n    方便数据压缩，节省磁盘\\r\\n    \\r\\n    - 与 es 相比，作为常\"},{\"url\":\"/database/clickhouse/ClickHouse安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"docker下安装clickhouse_docker 安装clickhouse-CSDN博客\\r\\n\\r\\n使用 clickhouse-client 进入 ck\\r\\n\\r\\n mac 安装\\r\\n\\r\\n```java\\r\\ndocker run --rm -d --name=clickhouse \\\\\\r\\n-e CLICKHOUSE_ADMIN_PASSWORD=\\\"123456\\\" \\\\\\r\\n--ulimit nofile=262144:262144 \\\\\\r\\n-p 8123:8123 -p 9009:9009 -p 9090:9000 \\\\\\r\\n-v /Users/yangjunwei/ck/config:/etc/clickhou\"},{\"url\":\"/database/clickhouse/ClickHouse物化列序列化报错.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse物化列序列化报错问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"报错内容\\r\\n\\r\\n```java\\r\\nNo serializer found for column 'date'. Did you forget to register it?\\r\\n\\tat com.clickhouse.client.api.Client.insert(Client.java:1317)\\r\\n\\tat com.clickhouse.client.api.Client.insert(Client.java:1266)\\r\\n```\\r\\n\\r\\n 表结构\\r\\n\\r\\n```java\\r\\nCREATE TABLE IF NOT EXISTS metric_data\\r\\n(\\r\\n    `placeId` UInt3\"},{\"url\":\"/database/clickhouse/ClickHouse高级.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse高级\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MergeTree\\r\\n\\r\\nClickHouse 中最强大的表引擎当属 MergeTree（合并树）引擎及该系列（MergeTree）中的其他引擎，支持索引和分区，地位可以相当于 innodb 之于 Mysql。而且基于 MergeTree，还衍生除了很多小弟，也是非常有特色的引擎。\\r\\n\\r\\n建表语句\\r\\n\\r\\n```sql\\r\\ncreate table t_order_mt(\\r\\n id UInt32,\\r\\n sku_id String,\\r\\n total_amount Decimal(16,2),\\r\\n create_time Datetime\\r\\n) engine = MergeTree\\r\\n partiti\"},{\"url\":\"/database/clickhouse/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- ClickHouse安装\\r\\n- ClickHouse基础\\r\\n- ClickHouse高级\\r\\n- 为什么弃用Elasticsearch\"},{\"url\":\"/database/clickhouse/为什么弃用Elasticsearch.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"对于开发来说：\\r\\n\\r\\n1. 大批量数据查询导致 es 的 CPU 飙升。\\r\\n2. 数据量增大之后，es 的查询效率下降，影响接口性能。\\r\\n3. 聚合效率低。\\r\\n\\r\\n对于运维来说：\\r\\n\\r\\n1. 维护成本很大，在数据量大的情况，es 占用磁盘空间很大，没有很好的压缩手段。\\r\\n2. es 很占内存，内存配置为整体内存的一半。\\r\\n\\r\\n 问题记录\\r\\n\\r\\n- 缓存计算系统评分导致 es 的 cpu 飙升。\\r\\n\\r\\n  系统评分需要查询 es 的流量信息进行计算，实时查询很慢。做了定时任务计算分数信息并作缓存。\\r\\n\\r\\n    - 经常发现 es 的 cpu 会被打满。排查发现随着系统的增多，当定时任务跑的时候\"},{\"url\":\"/database/mysql/B树和B+树.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"B树和B+树\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"B树\\r\\n\\r\\n\\r\\n\\r\\n每个节点是一个磁盘快。每个磁盘快有固定大小，可以存储多个K-V键值对。\\r\\n\\r\\n每个磁盘快包含指向下层节点的指针，方便查找。\\r\\n\\r\\n*由于每个节点存储了更多的键值对数据，可以有效降低查找树的次数，并减少查询磁盘。*\\r\\n\\r\\n- \\r\\n\\r\\n B+树\\r\\n\\r\\n\\r\\n\\r\\n 存储空间\\r\\n\\r\\nB+树是在B树的基础上演进的。\\r\\n\\r\\nB+树的非叶子结点是不保存数据的，仅保存键值。\\r\\n\\r\\n在 InnoDB中页大小是固定的，在只保存键值的情况下，同一个数据页能保存更多的键值。这样就能保证整个树的层级大大降低，减少向下搜索时候的磁盘IO次数，会提高数据的查询效率。\\r\\n\\r\\nInnoDB 中页的默认大小是 \"},{\"url\":\"/database/mysql/InnoDB存储引擎.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"InnoDB存储引擎\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"存储引擎\\r\\n\\r\\n在系统执行 `update` 语句时，经过 `Server层` 的处理，最终要由执行器去调用存储引擎去执行。\\r\\n\\r\\n而 MySQL 存储引擎有很多种，比如 `InnoDB`、`MyISAM`等。\\r\\n\\r\\nMySQL的默认存储引擎已经变更为了 `InnoDB`\\r\\n\\r\\n---\\r\\n\\r\\n`update` 语句操作的数据最终是要写入磁盘中的，但是如果每次都直接操作磁盘，磁盘I/O的开销是很大的。所以需要每次将操作的数据加载到内存中，减少磁盘I/O次数，再在适当时机进行刷盘操作即可。InnoDB 中使用的这块内存叫做 `Buffer Pool`。\\r\\n\\r\\n 缓冲池 - Buffer Pool\\r\"},{\"url\":\"/database/mysql/MySQL基础架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL基础架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL是 `C/S（Client端 / Server端）` 架构。\\r\\n\\r\\n 架构图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nMySQL架构包含 `Server层` 和 `存储引擎层` 。\\r\\n\\r\\n- Server 层包含 `连接器` 、`分析器`、`优化器`、`执行器`。\\r\\n- 存储引擎层包含 `引擎层`、`存储层`。\\r\\n\\r\\n 一、连接器\\r\\n\\r\\n 连接器的作用\\r\\n\\r\\n- 跟客户端建立连接。\\r\\n- 维持和管理连接。\\r\\n- 校验用户和获取用户权限。\\r\\n\\r\\n---\\r\\n\\r\\n 校验用户\\r\\n\\r\\n客户端进行连接MySQL的命令如下：\\r\\n\\r\\n```java\\r\\nmysql -h$ip -P$port -u$user -p\\r\\n`\"},{\"url\":\"/database/mysql/MySQL日志系统.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL日志系统\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"undo.log\\r\\n\\r\\n记录被更新前的数据。\\r\\n\\r\\n\\r\\n\\r\\nInnoDB 支持事务，在事务执行失败回滚时，数据会回到操作前的样子。\\r\\n\\r\\n`undo.log` 就是为了事务回滚，恢复数据的。\\r\\n\\r\\n回滚对应的操作如下：\\r\\n\\r\\n1. insert\\r\\n   \\r\\n    插入一条记录时，将这条记录的主键记录下来，回滚时根据主键删除。\\r\\n    \\r\\n2. update\\r\\n   \\r\\n    更新一条记录时，将更新的列的旧值记录下来，回滚时将这些值更新回去。\\r\\n    \\r\\n3. delete\\r\\n   \\r\\n    删除一条记录时，将这条记录记录下来，回滚时重新插入到表中。\\r\\n    \\r\\n\\r\\n---\\r\\n\\r\\n在\"},{\"url\":\"/database/mysql/MySQL根据idb文件恢复数据.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL根据idb文件恢复数据\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL根据idb文件恢复数据\\r\\n\\r\\n1. MySQl解除表名\\r\\n   \\r\\n    `Plain Text  ALTER TABLE 表名 DISCARD TABLESPACE`\\r\\n    \\r\\n2. 复制 idb 文件到 data目录。\\r\\n   \\r\\n    \\r\\n    \\r\\n3. idb 文件增加权限。\\r\\n   \\r\\n    ```\\r\\n    chown mysql:mysql user_tenant.ibd\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n4. 重新导入表数据文件\\r\\n   \\r\\n    ```\\r\\n    ALTER TABLE 表名 IMPORT TABLESPACE\\r\\n\"},{\"url\":\"/database/mysql/MySQL的binlog日志过期删除.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL的binlog日志过期删除\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"问题\\r\\n\\r\\nmysql的binlog日志过多导致磁盘告警。\\r\\n\\r\\n部署脚本中没有配置 `binlog` 的失效时间，默认是30天。\\r\\n\\r\\n 手动清理\\r\\n\\r\\n1. 查看正在使用的binlog\\r\\n   \\r\\n    ```sql\\r\\n    show master status\\r\\n    ```\\r\\n    \\r\\n2. 删除指定binlog之前的所有binlog\\r\\n   \\r\\n    ```sql\\r\\n    purge binary logs to 'bin.000055'\\r\\n    ```\\r\\n    \\r\\n\\r\\n 配置自动清理\\r\\n\\r\\n 查看日志过期时间\\r\\n\\r\\n```sql\\r\\nshow variables li\"},{\"url\":\"/database/mysql/OrderBy和limit混用的bug.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"OrderBy和limit混用的bug\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"案例\\r\\n\\r\\n```java\\r\\nselect * from table order by month desc limit 0,10\\r\\n```\\r\\n\\r\\nmonth 重复度高的情况下，limt查询会出bug。导致部分数据丢失。可以增加区分度高的字段一起排序，比如id。\\r\\n\\r\\n```java\\r\\nselect * from table order by month desc,id desc limit 0,10\\r\\n```\"},{\"url\":\"/database/mysql/SQL语句的抖动问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SQL语句的抖动问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"有时候在执行 SQL 的时候，突然会变得很慢。这种慢比较随机，看起来像是抖动一样。\\r\\n\\r\\n更新数据流程可以简化一下。\\r\\n\\r\\n1. 内存（buffer pool）中的数据 flush 到磁盘。\\r\\n2. 数据写入到 redo log 中。\\r\\n\\r\\n其中 buffer pool 中的数据页有三种状态：\\r\\n\\r\\n1. 数据页无数据。\\r\\n2. 数据页是干净页。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n3. 数据页是脏页。\\r\\n   \\r\\n    &gt; 脏页指的是内存中的数据被更新，但是没有flush到磁盘。出现内存和磁盘数据不一致的情况，此时该数据页称为脏页面。\\r\\n    &gt; \\r\\n\\r\\n 性能问题\"},{\"url\":\"/database/mysql/explain使用总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"explain使用总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"参数\\r\\n\\r\\n| id | Columns | JSON Name | Meaning |\\r\\n| --- | --- | --- | --- |\\r\\n| 1 | id | select_id | 每个select子句的标识id |\\r\\n| 2 | select_type | None | select语句的类型 |\\r\\n| 3 | table | table_name | 当前表名 |\\r\\n| 4 | partitions | partitions | 匹配的分区 |\\r\\n| 5 | type | access_type | 当前表内访问方式 join type |\\r\\n| 6 | possible_key\"},{\"url\":\"/database/mysql/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL数据库\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL基础\\r\\n\\r\\n- MySQL基础架构\\r\\n- InnoDB存储引擎\\r\\n---\\r\\n- MySQL日志系统\\r\\n---\\r\\n- 一条更新SQL的执行过程\\r\\n---\\r\\n- 事务隔离\\r\\n---\\r\\n- B树和B+树\\r\\n- 索引\\r\\n---\\r\\n- 锁\\r\\n- 行锁\\r\\n\\r\\n\\r\\n\\r\\n MySQL总结\\r\\n\\r\\n- SQL语句的抖动问题\\r\\n- 索引失效的场景\\r\\n- explain使用总结\\r\\n- 慢查询日志\\r\\n\\r\\n\\r\\n 问题总结\\r\\n- OrderBy和limit混用的bug\\r\\n- MySQL的binlog日志过期删除\\r\\n- MySQL根据idb文件恢复数据\"},{\"url\":\"/database/mysql/一条更新SQL的执行过程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"一条更新SQL的执行过程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"juejin.cn\\r\\n\\r\\n```java\\r\\nmysql\\r\\n```\\r\\n\\r\\n 执行流程\\r\\n\\r\\n1. 执行器先找引擎取出 ID=2 这一行记录。\\r\\n    - 如果该行记录在 `Buffer Pool` 中存在，会直接返回数据给执行器。\\r\\n    - 如果该行记录不存在，则会先进行如下操作，再返回数据给执行器。\\r\\n        - 从磁盘中查找数据。\\r\\n        - 将数据写入内存 `Buffer Pool` 中。\\r\\n        - 将数据写入 `undo.log`（记录 insert、update、delete等修改数据的操作）。\\r\\n2. 执行器获取到引擎给的行数据，把这条数据更新 c\"},{\"url\":\"/database/mysql/事务隔离.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"事务隔离\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。\\r\\n\\r\\n在 MySQL 中，事务支持是在`引擎层`实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。\\r\\n\\r\\n比如 MySQL 原生的 `MyISAM 引擎就不支持事务`，这也是 MyISAM 被 InnoDB 取代的重要原因之一。\\r\\n\\r\\n 事务问题\\r\\n\\r\\n 脏读\\r\\n\\r\\n读到了别的事务 修改过 但未提交的数据\\r\\n\\r\\n 不可重复读\\r\\n\\r\\n指的是变没变化的问题。数据被修改了导致前后两次查询结果不一样。\\r\\n\\r\\n原来是 A，现在是 B，就是不可重复读。\\r\\n\\r\\n 幻读\\r\\n\\r\\n指的是存不存在的问题，原来存\"},{\"url\":\"/database/mysql/慢查询日志.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"慢查询日志\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL中，需要查看执行慢的SQL，需要先开启慢查询日志。\\r\\n\\r\\nMySQL的慢查询日志，记录了MySQL中响应时间超过阈值的SQL语句。\\r\\n\\r\\n 参数说明\\r\\n\\r\\n- slow_query_log：是否开启慢查询日志，1表示开启，0表示关闭。\\r\\n- log-slow-queries ：旧版（5.6以下版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name-slow.log\\r\\n- slow-query-log-file：新版（5.6及以上版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name\"},{\"url\":\"/database/mysql/索引.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"索引\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准。\\r\\n\\r\\n InnoDB的索引模型\\r\\n\\r\\n B+树\\r\\n\\r\\n\\r\\n\\r\\nB+树的每个叶子节点存放元素有限，每个叶子节点为一个 page，针对元素的数量会产生页分裂、页合并等现象。\\r\\n\\r\\n什么是B+树？_攻城狮百里的博客-CSDN博客_b+树\\r\\n\\r\\n\\r\\n\\r\\n 聚簇索引和二级索引\\r\\n\\r\\n- 主键索引的叶子结点存的是整行记录。InnoDB 引擎中主键索引又称为聚簇索引。\\r\\n- 非主键索引的叶子结点存的是行记录的ID。在 InnoDB 引擎中非主键索引又称为二级索引。\\r\\n\\r\\n\\r\\n\\r\\n 搜索方式\\r\\n\\r\\n- 根据主键搜索\\r\\n  \\r\\n    `\"},{\"url\":\"/database/mysql/索引失效的场景.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"索引失效的场景\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"查询条件做函数计算\\r\\n\\r\\n```sql\\r\\nselect count(*) from tradelog where month(t_modified)=7;\\r\\n```\\r\\n\\r\\n查询条件做函数计算，在查索引的时候，利用不了索引。因为索引利用的是树的有序性，但是函数计算后的结果在索引的B+树上并不连续。MySQL在查询的时候利用不到树的有序性。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。\\r\\n\\r\\n 隐式类型转换\\r\\n\\r\\n假如 tradeid 字段类型是 varchar ，查询语句\\r\\n\\r\\n```sql\\r\\nexplain   sele\"},{\"url\":\"/database/mysql/行锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"行锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL 中的行锁（row-level locking）并不是单纯指写锁（write lock），而是指锁定机制的粒度。行锁可以是共享锁（也称为读锁，S锁）或排他锁（也称为写锁，X锁），具体取决于事务所使用的隔离级别以及查询类型。\\r\\n\\r\\n- Select for Update：当执行带有 `FOR UPDATE` 子句的 `SELECT` 查询时，InnoDB 会对被选中的行加上排他锁。这确保了在事务提交之前，其他事务不能修改这些行。\\r\\n- Insert Intention Lock：当执行 `INSERT` 操作时，InnoDB 会自动为要插入的行加上意向锁。这是为了避免插入操作与其他事务\"},{\"url\":\"/database/mysql/锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL中加锁是为了处理并发问题，根据锁的粒度可以分为全局锁、表级锁和行锁。\\r\\n\\r\\n 全局锁\\r\\n\\r\\n全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 `Flush tables with read lock` (FTWRL)。\\r\\n\\r\\n加完之后整个数据库处于只读状态。\\r\\n\\r\\n---\\r\\n\\r\\n 应用场景（不推荐）\\r\\n\\r\\n全局锁的经典应用场景 数据库备份。\\r\\n\\r\\n由于加全局锁，会导致整个数据库只读，所以一般不推荐使用。\\r\\n\\r\\n 可重复读进行备份\\r\\n\\r\\n备份数据库一般可以利用可重复读的事务隔离级别来实现，因为可重复读情况开始事务，会生成当前数据库的视图，保证整个事务期间以\"},{\"url\":\"/database/redis/LRU和LFU算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"LRU和LFU算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"LRU算法\\r\\n\\r\\n 简介\\r\\n\\r\\nLRU （Least Recently Used） 算法即最近最久未使用，每次选择最近最久未使用的页面淘汰掉。\\r\\n\\r\\n 实现过程\\r\\n\\r\\n- 新增数据时，元素插入到队列头部。\\r\\n- 访问元素（查询、更新和删除）时，将元素移动到队列头部。\\r\\n- 当超过内存限制，需要淘汰数据时，将已排序队列的最后元素删除。\\r\\n\\r\\n\\r\\n\\r\\n 数据结构\\r\\n\\r\\nLRU 算法内部的数据结构需要根据元素的访问时间排序。还需要查找、插入、删除等效率要高。\\r\\n\\r\\n1. 查找、插入、删除快。\\r\\n2. 支持排序。\\r\\n\\r\\n在常用的集合中，有的是查找更新快或者插入删除快，没有数据结构能同时满足以上条件，所\"},{\"url\":\"/database/redis/Redisson.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Redisson\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还实现了可重入锁（Reentrant Lock）、公平锁（Fair Lock、联锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）等，还提供了许多分布式服务。Redisson提供了使用Redis的最简单和最便捷的方法。Redisson的宗旨是促进使用者对Redis的关注分离（Separation of Concern），从而让使用者能够将精力更集中地放在处理业务逻辑上。\\r\\n\\r\\n Redisson \"},{\"url\":\"/database/redis/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- redis数据类型\\r\\n- redis数据类型原理\\r\\n- redis的持久化\\r\\n\\r\\n\\r\\n- 过期策略\\r\\n- 内存淘汰策略\\r\\n- LRU和LFU算法\\r\\n\\r\\n- redis实现分布式锁\\r\\n- Redisson\\r\\n\\r\\n- redis事务.md\\r\\n- redis集群.md\\r\\n\\r\\n- 缓存问题\\r\\n- 布隆过滤器\"},{\"url\":\"/database/redis/redis事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis的事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis 的事务，可以一次执行多个命令，本质上是一组命令的集合，按照顺序串行化执行而不会被其它命令插入。\\r\\n\\r\\n 常用命令\\r\\n\\r\\n- 开启事务 -`multi`\\r\\n- 执行所有事务 - `exec`\\r\\n- 取消所有事务 - `discard`\\r\\n- 监控一个或多个 key - `watch`\\r\\n- 取消 watch 命令对所有 key 的监控 - `unwatch`\\r\\n  \\r\\n    \\r\\n    \\r\\n\\r\\n watch监控\\r\\n\\r\\nwatch 指令，类似乐观锁，在创建事务之前，使用 watch 指令监控某个值。在事务提交时，如果 key 的值已经被别的客户端改变，那么整个事务队列都不会执行。\\r\\n\"},{\"url\":\"/database/redis/redis实现分布式锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis实现分布式锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"分布式锁简介\\r\\n\\r\\n在分布式环境下，多个系统访问共享资源时会发生线程安全问题，分布式锁就是为了解决分布式环境下访问共享资源的线程安全问题，保证共享资源同一时间只能被一个系统的一个线程访问。\\r\\n\\r\\n 分布式锁具备的条件\\r\\n\\r\\n1. 在分布式环境下，共享资源在同一时间只能被一个系统的一个线程访问。\\r\\n2. 保证设置分布式锁和删除分布式锁操作的原子性。\\r\\n3. 具备可重入特性。\\r\\n4. 防止死锁。\\r\\n5. 具备锁超时失效的机制。\\r\\n6. 具备非阻塞锁特性，不会阻塞等待获取锁。\\r\\n\\r\\n 分布式锁主要实现方式\\r\\n\\r\\n1. zeekeeper 实现分布式锁\\r\\n2. redis 实现分布式锁\\r\\n\\r\\n---\\r\"},{\"url\":\"/database/redis/redis数据类型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis数据类型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis数据类型\\r\\n\\r\\n练习代码地址 redis-practice\\r\\n\\r\\n 键 - key\\r\\n\\r\\n在了解数据类型之前，先了解一下 redis 的键。\\r\\n\\r\\n在 redis 中 命令不区分大小写，但是注意 redis 中的 key 和 value 是区分大小写的。\\r\\n\\r\\n\\r\\n\\r\\n 字符串 - string\\r\\n\\r\\n字符串数据结构是简单的 K-V 模式数据结构。\\r\\n\\r\\n 特点\\r\\n\\r\\n- 单值单 value。\\r\\n- 二进制安全，可以包含任何数据。\\r\\n- 一个键对应 value 值最大能存储数据 512 MB。\\r\\n\\r\\n 常用命令\\r\\n\\r\\n\\r\\n\\r\\n- 设置字符串 - `set test 100`\\r\\n- 查\"},{\"url\":\"/database/redis/redis数据类型原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis数据类型原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. linkedlist (双向链表)\\r\\n    - 当列表元素较多或元素大小超过一定阈值时，Redis 会使用双向链表来存储 `list` 键。\\r\\n    - linkedlist 是一种指针结构，每个节点包含指向前后节点的指针，这使得插入和删除操作非常高效。\\r\\n    - linkedlist 的优点是支持高效的插入和删除操作，但缺点是比 ziplist 更占用内存。\\r\\n\\r\\n 全局哈希表\\r\\n\\r\\n\\r\\n\\r\\nRedis是一个 K-V 数据库，有一个全局的哈希桶存放所有的 key。\\r\\n\\r\\nkey 对应的 entry 包含了实际的 key 和 value。这里的 value 对应着不同的数据类型。\"},{\"url\":\"/database/redis/redis的持久化.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis的持久化\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis 有 RDB 和 AOF 两种持久化方式。\\r\\n\\r\\n RDB\\r\\n\\r\\nRDB 是 *Redis DataBase* 的简称，指的是在指定时间间隔内将内存中的数据集快照写入磁盘文件，也就是 Snapshot 快照，RDB 是默认开启的。\\r\\n\\r\\n RDB的原理\\r\\n\\r\\nRedis 会单独创建 （fork）一个子进程来进行持久化操作，将内存中某一时刻的数据持久化到磁盘文件。这个子进程会先将数据写入到一个临时文件中，等待持久化进程结束后，再用这个临时文件替换掉磁盘文件。\\r\\n\\r\\n\\r\\n\\r\\n在整个过程中，主进程是不进行任何 IO 操作的，这样保证了主进程存取的高性能。\\r\\n\\r\\nRDB 的持久化过程每次都是\"},{\"url\":\"/database/redis/redis集群.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis集群\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Redis集群是一个由多个主从节点群组成的分布式服务集群，它具有复制、高可用和分片特性。\\r\\n\\r\\n 主从模式\\r\\n\\r\\n\\r\\n\\r\\n- 主数据库可以进行读写操作。\\r\\n  \\r\\n    数据会通过主从同步，由主服务器同步给从服务器。\\r\\n    \\r\\n    主服务器将数据\\r\\n    \\r\\n- 从数据库一般是只读的。\\r\\n\\r\\n引入主从复制机制的目的有两个：\\r\\n\\r\\n- 一个是读写分离，分担 “master” 的读写压力\\r\\n- 一个是方便做容灾恢复，避免单点故障。\\r\\n\\r\\n 主从同步的原理\\r\\n\\r\\n\\r\\n\\r\\n- 全量复制\\r\\n  \\r\\n    从数据库在第一次同步的时候会进行全量同步。\\r\\n    \\r\\n    主库执行 bgsav\"},{\"url\":\"/database/redis/内存淘汰策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内存淘汰策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"最大内存设置\\r\\n\\r\\n1. redis 默认内存是多少？\\r\\n   \\r\\n    在 64 位操作系统不限制内存大小，在 32 位操作系统下最多使用 3GB。\\r\\n    \\r\\n2. 查看 redis 最大内存？\\r\\n   \\r\\n    `Plain Text  config get maxmemory`\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 修改 redis 内存大小？\\r\\n    - 修改配置文件\\r\\n      \\r\\n        在 `redis.conf` 第 859 行可以设置最大内存大小（单位是字节）。\\r\\n        \\r\\n        \\r\\n        &gt; \\r\\n        \"},{\"url\":\"/database/redis/布隆过滤器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"布隆过滤器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 什么是布隆过滤器？\\r\\n\\r\\n布隆过滤器（Bloom Filter）是一种数据结构，用来判断一个元素是否在一个集合中。布隆过滤器的本质上使用的是二进制向量和 k 个哈希函数组成。\\r\\n\\r\\n布隆过滤器具有如下优点：\\r\\n\\r\\n- 空间利用率高。\\r\\n  \\r\\n    布隆过滤器底层使用二进制向量保存数据，不需要保存元素本身，只需要在指定 bit 存放标识即可，故空间利用率非常高。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n- 时间效率也较高，插入和查询效率高。\\r\\n  \\r\\n    布隆过滤器的时间复杂度只跟哈希函数的个数 k 有关，插入和查询的时间复杂度均为 O(k)；\\r\\n    \\r\\n    *结合\"},{\"url\":\"/database/redis/缓存问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"缓存问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"前言\\r\\n\\r\\n在使用缓存的时候，简单的缓存处理流程如下。针对如下流程会遇到缓存穿透、缓存击穿、缓存雪崩等问题。\\r\\n\\r\\n\\r\\n\\r\\n 缓存穿透\\r\\n\\r\\n缓存穿透：当用户请求查询某个数据时，先从缓存查询，缓存中没有这个数据。然后向数据库查询数据，数据库中也没有这个数据，导致查询失败。\\r\\n\\r\\n*像一些恶意攻击时，故意查询数据库中不存在的数据，比如查询 id = -1 的数据，会造成数据库压力非常大。*\\r\\n\\r\\n\\r\\n\\r\\n 解决方案\\r\\n\\r\\n1. 对空值做缓存。\\r\\n   \\r\\n    当出现从缓存和数据库都查不到数据的情况时，可以将空值存到缓存中，即 K-V 存为 key-null，缓存过期时间可以设置短点，来防止短\"},{\"url\":\"/database/redis/过期策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"过期策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 Redis 中设置了过期时间的 key，在一定时间后都会被删除。\\r\\n\\r\\n 键的过期时间\\r\\n\\r\\n 配置过期时间\\r\\n\\r\\n1. `setex key seconds value`\\r\\n   \\r\\n    设置 key 时添加过期时间\\r\\n    \\r\\n2. `expire key seconds`\\r\\n   \\r\\n    为某个 key 设置过期时间。\\r\\n    \\r\\n3. 删除 key 的过期时间。\\r\\n   \\r\\n    `persist key`\\r\\n    \\r\\n4. 查看 key 的过期时间\\r\\n   \\r\\n    `ttl key`\\r\\n    \\r\\n\\r\\n redis保存过期时间分析\\r\\n\\r\\n[版权声明：本文为CS\"},{\"url\":\"/frame/mybatis/custom/SQL执行器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SQL执行器-executor\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"将操作数据库的操作从 sqlSession 中解耦，放到 Executor 中。\\r\\n\\r\\n包括事务操作也放到 Executor 中。\\r\\n\\r\\n```java\\r\\npublic interface Executor {\\r\\n\\r\\n    ResultHandler NO_RESULT_HANDLER = null;\\r\\n\\r\\n    &lt;E\\r\\n\\r\\n    Transaction getTransaction();\\r\\n\\r\\n    void commit(boolean required) throws SQLException;\\r\\n\\r\\n    void rollback(boolean required) \"},{\"url\":\"/frame/mybatis/custom/xml解析.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"xml解析\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"\"},{\"url\":\"/frame/mybatis/custom/手写MyBatis.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"手写MyBatis\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"整体流程\\r\\n\\r\\n\\r\\n\\r\\n整个mybatis的功能，就是代理 mapper 然后执行SQL，返回执行结果。\\r\\n\\r\\n\\r\\n\\r\\n1. 解析mybatis配置\\r\\n    - 解析数据源 （Configuration 的 environment）\\r\\n    - 解析mapper文件配置 （路径扫描）\\r\\n2. 解析mapper文件\\r\\n    - 注册mapper到mapperRegistry。（包含mapper的代理类工厂，可以获取代理过的mapper）\\r\\n    - 生成mapper方法对应的mapperStatement。（Configuration 的 mappedStatements）\\r\\n    -\"},{\"url\":\"/frame/mybatis/custom/数据源.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据源\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"数据源解析\\r\\n\\r\\n解析配置文件中的数据源\\r\\n\\r\\n1. 事务模版 - jdbc\\r\\n2. 数据源实现 - druid\\r\\n\\r\\n```xml\\r\\n&lt;configuration\\r\\n\\r\\n    &lt;!--    数据源配置   --&gt;\\r\\n    &lt;environments default=\\\"development\\\"&gt;\\r\\n        &lt;environment id=\\\"development\\\"&gt;\\r\\n            &lt;transactionManager type=\\\"JDBC\\\"/&gt;\\r\\n            &lt;dataSource type=\\\"\"},{\"url\":\"/frame/mybatis/custom/映射器-mapper.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"映射器-mapper\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- SqlSession提供了SqlId。\\r\\n- 而SqlSessionFactroy 提供了开启SqlSession的能力。]\\r\\n- MapperRegistry 包含了所有Mapper的SqlId，包含注册发现Mapper的能力。\\r\\n\\r\\n MapperFactory\\r\\n\\r\\n\\r\\n\\r\\n MapperProxy\\r\\n\\r\\n在mybatis中，调用mapper里面的方法就可以执行SQL。其实是因为mybatis隐藏了实现细节。\\r\\n\\r\\n具体做法是根据mapper里面点的方法生成代理逻辑，在调用该方法时其实是走的代理类的逻辑。\\r\\n\\r\\n而代理类封装了操作数据库的逻辑，代理类即为mapperProxy。\\r\\n\\r\"},{\"url\":\"/frame/mybatis/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MyBatis 框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"手写MyBatis\\r\\n\\r\\n- 手写MyBatis\\r\\n- 映射器-mapper\\r\\n- 数据源\\r\\n- SQL执行器\\r\\n- xml解析\"},{\"url\":\"/frame/netty/ByteBuf.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ByteBuf\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ByteBuf是Netty中用于表示字节序列的数据容器。它是Netty对Java NIO中的ByteBuffer的改进和增强。ByteBuf提供了更灵活、更强大的API，具有许多优势，使得它在网络编程中更加方便和高效。\\r\\n\\r\\n以下是ByteBuf的主要优势：\\r\\n\\r\\n1. 灵活的容量管理： ByteBuf支持动态扩容和收缩，相比Java NIO的ByteBuffer，ByteBuf的容量可以根据实际需求自动调整，无需手动扩容。\\r\\n2. 更丰富的API： ByteBuf提供了丰富的操作API，包括读取、写入、复制、切片、合并等操作。这些API使得对字节数据的操作更加便利，同时提供了更多的功能。\\r\\n\"},{\"url\":\"/frame/netty/HTTP服务和SSL&TLS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP服务和SSL/TLS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"服务端\\r\\n\\r\\n按照 pipline 执行。\\r\\n\\r\\n```java\\r\\n@Override\\r\\n    protected void initChannel(SocketChannel socketChannel) throws Exception {\\r\\n        ChannelPipeline pipeline = socketChannel.pipeline();\\r\\n        //TODO ssl\\r\\n\\r\\n        //服务端\\r\\n        //对请求内容解码\\r\\n        pipeline.addLast(\\\"decoder\\\", new HttpRequestDecode\"},{\"url\":\"/frame/netty/Handler的共享和并发安全性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Handler的共享和并发安全性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"服务端为Channel设置pipeline的时候，可以选择设置共享的还是Channel独有的。\\r\\n\\r\\n```java\\r\\nprivate void start() throws InterruptedException {\\r\\n        final MsgCountHandler msgCountHandler = new MsgCountHandler();\\r\\n        //线程组\\r\\n        EventLoopGroup boss = new NioEventLoopGroup();\\r\\n        EventLoopGroup work = new NioEventLoo\"},{\"url\":\"/frame/netty/Netty实现文件下载.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty实现文件下载\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"实例：如何使用 Netty 下载文件_channelhandlercontext下载文件-CSDN博客\\r\\n\\r\\n ChannelHandler\\r\\n\\r\\n自定义 ChannelHandler ，用来处理 Channel 里面的事件，写数据处理逻辑的。\\r\\n\\r\\n- ChannelInboundHandlerAdapter\\r\\n- SimpleChannelInboundHandler\\r\\n    \\r\\n    是 ChannelInboundHandlerAdapter 的子类，能够指定类型。\\r\\n    \\r\\n\\r\\nNetty 里面预设了很多 ChannelHandler\\r\\n\\r\\n```java\\r\\nch.pipel\"},{\"url\":\"/frame/netty/Netty实现通信框架.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty实现通信框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"功能点\\r\\n\\r\\n1. 基于Netty的NIO通信框架。\\r\\n2. 提供消息的编码解码框架，实现对象的序列化和反序列化。\\r\\n3. 消息内容的放篡改机制。\\r\\n4. 提供基于IP的白名单认证机制。\\r\\n5. 链路的有效性机制（心跳）。\\r\\n6. 链路的断连重连机制。\\r\\n\\r\\n 通信模型\\r\\n\\r\\n\\r\\n\\r\\n 调用链路\\r\\n\\r\\n\\r\\n\\r\\n粘包半包是最前面先要解决的问题。\\r\\n\\r\\n 写空闲检测\\r\\n\\r\\n```java\\r\\npublic class CheckWriteIdleHandler extends IdleStateHandler {\\r\\n\\r\\n    /**\\r\\n     * 0 表示读空闲时间不进行检测，即不对读空闲做任何\"},{\"url\":\"/frame/netty/Netty常用组件.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty常用组件\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Bootstrap\\r\\n\\r\\nNetty的启动类\\r\\n\\r\\n- Bootstrap\\r\\n\\r\\n    客户端启动类\\r\\n\\r\\n- ServerBootstrap\\r\\n\\r\\n    服务端启动类\\r\\n\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n 第一个区别\\r\\n\\r\\n- 客户端需要连接到远程主机和端口即可。\\r\\n\\r\\n- 服务端需要绑定端口。\\r\\n\\r\\n 第二个区别\\r\\n\\r\\n- 服务端需要两个 EventLoopGroup。\\r\\n\\r\\n    原因是使用了多线程主从的Reactor模式。\\r\\n\\r\\n    - 第一个EventLoopGroup，只有一个EventLoop，负责为传入的Accept请求建立连接。一旦建立连接后续，将该 Channel 放到\"},{\"url\":\"/frame/netty/TCP粘包拆包问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP粘包拆包问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"TCP 粘包\\r\\n\\r\\n由于 TCP 协议本身的机制（面向连接的可靠地协议-三次握手机制）客户端与服务器会维持一个连接（Channel），数据在连接不断开的情况下，可以持续不断地将多个数据包发往服务器。\\r\\n\\r\\n但是如果发送的网络数据包太小，那么他本身会启用 Nagle 算法（可配置是否启用）对较小的数据包进行合并（基于此，TCP 的网络延迟要 UDP 的高些）然后再发送（超时或者包大小足够）。\\r\\n\\r\\n那么这样的话，服务器在接收到消息（数据流）的时候就无法区分哪些数据包是客户端自己分开发送的，这样产生了粘包。\\r\\n\\r\\n服务器在接收到数据库后，放到缓冲区中，如果消息没有被及时从缓存区取走，下次在取数据的\"},{\"url\":\"/frame/netty/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础总结\\r\\n\\r\\n- Netty常用组件\\r\\n- Handler的共享和并发安全性\\r\\n- 资源管理和SimpleChannelInboundHandler\\r\\n- 内置通信传输模式\\r\\n- TCP粘包拆包问题\\r\\n- 编解码器\\r\\n\\r\\n\\r\\n- HTTP服务和SSL&TLS\\r\\n- 序列化问题\\r\\n- 写空闲和读空闲\\r\\n\\r\\n\\r\\n- ByteBuf\\r\\n- 线程模型\\r\\n- 零拷贝\\r\\n\\r\\n\\r\\n 练习总结\\r\\n- Netty实现通信框架\\r\\n- 基于Netty实现RPC\\r\\n- Netty实现文件下载\"},{\"url\":\"/frame/netty/内置通信传输模式.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内置通信传输模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```java\\r\\ntry {\\r\\n            //父子EventLoop\\r\\n            serverBootstrap.group(boss,work)\\r\\n                    //指定使用NIO的通信模式\\r\\n                    .channel(NioServerSocketChannel.class)\\r\\n                    .localAddress(new InetSocketAddress(port))\\r\\n                    .childHandler(new ChannelInitia\"},{\"url\":\"/frame/netty/写空闲和读空闲.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"写空闲和读空闲\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在Netty框架中，写空闲（Write Idle） 和 读空闲（Read Idle） 是空闲检测机制中的两个重要概念，它们用于监控网络连接的活跃状态，确保连接的有效性和资源的有效管理。\\r\\n\\r\\n 写空闲（Write Idle）\\r\\n\\r\\n- 定义：写空闲指的是在一段指定时间内，没有数据通过当前的`Channel`被写入到网络中传输给对方。这可能意味着在这段时间内，服务端没有向客户端发送任何数据，或者客户端没有向服务端发送数据。\\r\\n- 应用场景：在某些协议或应用场景中，如果长时间没有数据写入，可能需要触发特定的操作，比如发送心跳包以维持连接活跃，或者是判断连接是否已经失效，进而关闭连接以释放资源。\\r\\n\"},{\"url\":\"/frame/netty/基于Netty实现RPC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"基于netty实现RPC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"源码地址\\r\\n\\r\\nAlbert.Yang/JavaAdvance\\r\\n\\r\\n 服务端\\r\\n\\r\\n ServerBootstrap\\r\\n\\r\\n```java\\r\\n@Service\\r\\n@Slf4j\\r\\npublic class RpcServerFrame implements Runnable {\\r\\n\\r\\n    @Autowired\\r\\n    private ServerInit serverInit;\\r\\n\\r\\n    private EventLoopGroup bossGroup = new NioEventLoopGroup();\\r\\n    private EventLoopGroup workGroup =\"},{\"url\":\"/frame/netty/序列化问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"序列化问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java对象的序列化主要有两个：\\r\\n\\r\\n1. 网络传输\\r\\n   \\r\\n    数据在网络中传输是通过字节流形式的，到服务端需要解码。\\r\\n    \\r\\n2. 对象持久化\\r\\n\\r\\n Java序列化\\r\\n\\r\\nJava序列化机制是基于对象的类结构进行的。\\r\\n\\r\\n当对象需要序列化时，会将对象转换为字节流在网络传输。\\r\\n\\r\\n反序列化时，就是将字节流转换为对象的过程。Java会将字节流转换为对象重新加载到内存中。\\r\\n\\r\\nJava的序列化机制是通过实现`java.io.Serializable`接口来实现的。该接口是一个标记接口，没有任何方法定义。只有实现了`Serializable`接口的类的对象才能被序列化。\\r\\n\"},{\"url\":\"/frame/netty/线程模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Netty的线程模型是什么？为什么它是高效的？\\r\\n\\r\\n1. Netty的线程模型是基于事件驱动的，采用了Reactors设计模式。它的线程模型主要包含以下几个关键组件：\\r\\n2. Boss Group和Worker Group： Netty通过Boss Group和Worker Group来分别管理两类不同的线程。Boss Group负责接收客户端的连接，而Worker Group则负责处理连接后的网络流量。\\r\\n3. Channel： Channel代表了一个网络连接，可以是客户端到服务器的连接，也可以是服务器之间的连接。每个Channel都由一个EventLoop负责处理，而一个EventLo\"},{\"url\":\"/frame/netty/编解码器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"编解码器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在网络传输中，数据是通过字节流传输。\\r\\n\\r\\n对应到客户端和服务端需要进行对应的编码和解码。\\r\\n\\r\\n 解码器\\r\\n\\r\\n- 将字节解码为消息：ByteToMessageDecoder\\r\\n- 将一种消息类型解码为另一种：MessageToMessageDecoder。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 异常处理\\r\\n\\r\\n- TooLongFrameException\\r\\n    \\r\\n    由于 Netty 是一个异步框架，所以需要在字节可以解码之前在内存中缓冲它们。因此，不能让解码器缓冲大量的数据以至于耗尽可用的内存。为了解除这个常见的顾虑，Netty 提供了 TooLongFrameException 类\"},{\"url\":\"/frame/netty/资源管理和SimpleChannelInboundHandler.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"资源管理和SimpleChannelInboundHandler\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NIO中读写Channel数据，都使用了 Buffer，读写数据都是从 Buffer里面读取的。\\r\\n\\r\\n而 Netty在读写网络数据时，同样也需要 Buffer。\\r\\n\\r\\n但是这样就涉及到 Buffer的内存释放，不然会造成内存泄漏。\\r\\n\\r\\n SimpleChannelInboundHandler\\r\\n\\r\\nNetty实现了SimpleChannelInboundHandler类，提供 `channelRead0()` 方法，保证数据被该方法消费后自动释放数据。\\r\\n\\r\\n```java\\r\\n    public void channelRead(ChannelHandlerContext ctx, Ob\"},{\"url\":\"/frame/netty/零拷贝.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"零拷贝\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. ByteBuf 可以直接使用直接内存。\\r\\n    \\r\\n    Socket 通信如果采用堆内存的话，需要将堆里的对象拷贝到堆外，进行一次对象拷贝。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n    \\r\\n    但是 Socket 没有更新对象地址动作，需要的是一个固定的地址。所以堆内存不适合 Socket 使用。只能将对象拷贝到直接内存然后使用。\\r\\n    \\r\\n    而 ByteBuf 直接使用直接内存，减少了对象拷贝。\\r\\n    \\r\\n2. Netty 提供了组合 Buffer，可以将多个 Buffer 合并为一个。\\r\\n    \\r\\n    传统通过内存拷贝的方式将几个小Buffe\"},{\"url\":\"/frame/spring/AOP.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AOP\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"面向切面编程\\r\\n\\r\\n面向切面编程，指的是在运行期间生成代理对象来对类进行增强处理，比如方法执行前和方法执行后进行代码增强。\\r\\n\\r\\n 什么是切面\\r\\n\\r\\n- 切：\\r\\n  \\r\\n    指的是横切逻辑，原有方法代码不动。只能操作横切逻辑代码进行增强。\\r\\n    \\r\\n- 面：\\r\\n  \\r\\n    横切逻辑往往影响很多个方法，每个方法是一个切点，便形成了面。\\r\\n    \\r\\n\\r\\n常用的功能有：\\r\\n\\r\\n- 方法审计日志\\r\\n- 校验权限是否足够\\r\\n\\r\\n\\r\\n\\r\\n AOP体系\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n)连接点 - JoinPoint\\r\\n\\r\\n类里面哪些方法可以被增强，这些方法称为连接点。\\r\\n\\r\\n- 切面\\r\\n\\r\\n    切\"},{\"url\":\"/frame/spring/ApplicationContext和BeanFactory区别.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ApplicationContext和BeanFactory区别\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ApplicationContext 总结\\r\\n\\r\\nApplicationContext 容器上下文，包含了 BeanFactory 的所有功能，还额外提供了以下功能：\\r\\n\\r\\n- MessageSource，提供国际化的消息访问\\r\\n- 资源访问，如 URL 和文件\\r\\n- 事件传播\\r\\n\\r\\n 工具类\\r\\n\\r\\n可以通过实现 `ApplicationContextAware` 接口注入 ApplicationContext\\r\\n\\r\\n```java\\r\\n@Component\\r\\npublic class SpringBeanUtil implements ApplicationContextAware {\\r\\n\\r\\n\"},{\"url\":\"/frame/spring/Aware接口.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Aware接口\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在Spring框架中，`Aware`接口提供了一种机制，允许Bean在初始化过程中获取Spring容器的特定上下文信息或资源。这些接口通常被称作回调接口，因为它们允许Spring容器在特定时刻回调Bean，以便将一些重要的信息注入给Bean。\\r\\n\\r\\n ApplicationContextAware\\r\\n\\r\\n当Spring容器在初始化一个实现了`ApplicationContextAware`接口的Bean时，它会调用`setApplicationContext`方法，将当前的应用上下文传入。\\r\\n\\r\\n```java\\r\\npublic interface ApplicationContextAware\"},{\"url\":\"/frame/spring/BeanFactory和FactoryBean总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BeanFactory和FactoryBean总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"BeanFactory总结\\r\\n\\r\\nBeanFactory 是 Spring 中的一个接口，提供了 IOC 容器最基本的形式，给具体的 IOC 容器实现提供了规范。\\r\\n\\r\\n其本质是一个 IOC 容器或对象工厂，所有的 Bean 都是由 BeanFactory （IOC容器）来进行管理的。Spring 有许多 BeanFactory 的实现类，附件了许多功能。\\r\\n\\r\\n```java\\r\\npublic interface BeanFactory {\\r\\n  \\r\\n  Object getBean(String name) throws BeansException;\\r\\n  \\r\\n\\t&lt;T\\r\\n\\r\\n\\tObj\"},{\"url\":\"/frame/spring/ByteBuddy实现动态代理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ByteBuddy实现动态代理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Byte Buddy - runtime code generation for the Java virtual machine\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n```java\\r\\n&lt;dependency&gt;\\r\\n  &lt;groupId&gt;net.bytebuddy&lt;/groupId&gt;\\r\\n  &lt;artifactId&gt;byte-buddy&lt;/artifactId&gt;\\r\\n  &lt;version&gt;LATEST&lt;/version&gt;\\r\\n&lt;/dependency&gt;\\r\\n```\\r\\n\\r\\n```java\\r\\npublic c\"},{\"url\":\"/frame/spring/Spi机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spi机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SPI机制，全称Service Provider Interface，是Java提供的一种标准的服务发现机制。它允许第三方服务提供者扩展某个接口的实现，而无需修改接口的源代码或重新打包。\\r\\n\\r\\nSpring SPI机制常用于 starter 构建和基础库实现。\\r\\n\\r\\n通过 spi 机制，确保自动配置生效的类包含 FileAutoConfiguration\\r\\n\\r\\n\\r\\n\\r\\n使用 SPI可以可插拔的注入配置，比如 `EnableAutoConfiguration`，如果需要 MinIO的配置类，加在类里面即可开启MinIO的功能。\\r\\n\\r\\nwww.jb51.net\\r\\n\\r\\nSPI机制是什么？_java_\"},{\"url\":\"/frame/spring/Spring中Bean加载流程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring中Bean加载流程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"流程图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 创建流程\\r\\n\\r\\n1. 加载 `ApplicationContext` 上下文环境。\\r\\n2. `ApplicationContext` 通过扫描、读取配置，将 Bean对象封装为 `BeanDefinition` 对象，并注册到 `BeanDefinitionMap` 中。\\r\\n3. 在 `ApplicationContext` 执行完成之后会调用对应的后置处理器 `BeanFactoryProcessor` 和其子类 `BeanDefinitionRegistryPostProcessor` 对应方法，可以修改和注册 `BeanDefinition` 到 \"},{\"url\":\"/frame/spring/Spring中Bean的作用域.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring中Bean的作用域\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"作用域类型\\r\\n\\r\\n- singleton\\r\\n    \\r\\n    单例模式。\\r\\n    \\r\\n    使用 `singleton` 定义的 Bean 在 Spring 容器中只有一个实例，是 Bean 默认的作用域。\\r\\n    \\r\\n- prototype\\r\\n    \\r\\n    原型模式\\r\\n    \\r\\n    每次通过 Spring 容器获取 `prototype` 定义的 Bean 时，容器都将创建一个新的 Bean 实例。\\r\\n    \\r\\n- request\\r\\n    \\r\\n    在一次 HTTP 请求中，容器会返回该 Bean 的同一个实例。而对不同的 HTTP 请求，会返回不同的实例，该作用域\"},{\"url\":\"/frame/spring/Spring事务总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring事务总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"编程式事务\\r\\n\\r\\n在代码中硬编码，不推荐使用。\\r\\n\\r\\n 声明式事务\\r\\n\\r\\n- 基于注解的声明式事务\\r\\n- 基于 XML 的声明式事务\\r\\n\\r\\n @Transactional 注解\\r\\n\\r\\nException 分为运行时异常 RuntimeException 和非运行时异常。事务管理能保证出现异常情况的时候保证数据的一致性。\\r\\n\\r\\n默认 `@Transactional` 注解只会在遇到 RuntimeException 类型异常或者 Error时，才会回滚事务。遇到其它异常，Spring 不会回滚事务。\\r\\n\\r\\n 作用范围\\r\\n\\r\\n当 `@Transactional`注解作用于类上的时，该类的所有方法都\"},{\"url\":\"/frame/spring/Spring依赖注入.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring依赖注入\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"依赖注入就是通过spring将bean所需要的一些参数传递到bean实例对象的过程（将依赖关系注入到对象中，不需要每次都new对象）\\r\\n\\r\\n- set方法注入\\r\\n- 构造方法注入\\r\\n- 注解注入\\r\\n\\r\\n 注解注入的区别\\r\\n\\r\\n- @Resource\\r\\n\\r\\n  byName注入\\r\\n\\r\\n  \\r\\n\\r\\n- Autowired\\r\\n\\r\\n  byType注入\"},{\"url\":\"/frame/spring/Spring如何解决循环依赖.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring如何解决循环依赖\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"依赖注入的四种方法\\r\\n\\r\\n- 构造方法注入\\r\\n  \\r\\n    ```java\\r\\n        public HelloA(@Autowired HelloService helloService) {\\r\\n            this.helloService = helloService;\\r\\n        }\\r\\n    ```\\r\\n    \\r\\n- 工厂方法注入\\r\\n  \\r\\n    ```java\\r\\n        @Bean(initMethod = \\\"init\\\", destroyMethod = \\\"destory\\\")\\r\\n        public HelloB helloB(@Auto\"},{\"url\":\"/frame/spring/Spring框架概述.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring框架概述\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、什么是 Spring 框架？\\r\\n\\r\\nSpring 框架指的是 Spring Framework，是一种轻量级的开发框架，主要核心是控制反转 （IOC）和 面向切面编程（AOP）。\\r\\n\\r\\n 二、Spring 的优点\\r\\n\\r\\n1. 方便解耦，简化开发（高内聚低耦合）\\r\\n    - Spring 是一个容器框架，将所有对象创建和依赖关系的维护交给 Spring 管理。\\r\\n    - Spring 工厂用于生成 Bean。\\r\\n2. AOP编程的支持\\r\\n    - Spring 提供面向切面编程，可以方便的实现权限拦截、运行监控等功能\\r\\n    - 日志打印\\r\\n3. 支持声明式事务\\r\\n    - 只需\"},{\"url\":\"/frame/spring/Spring自定义注解扫描.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring自定义注解扫描\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Spring管理的类\\r\\n\\r\\n以下两种方式都可以实现。\\r\\n\\r\\n 使用@ComponentScan + Bean定义\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\n@ComponentScan(basePackages = {\\\"your.package.to.scan\\\"}) // 指定要扫描的包\\r\\npublic class AppConfig {\\r\\n\\r\\n    @Autowired\\r\\n    private ListableBeanFactory beanFactory;\\r\\n\\r\\n    @PostConstruct\\r\\n    public void processAnnotatedBea\"},{\"url\":\"/frame/spring/Spring配置文件加载顺序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring配置文件加载顺序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot配置文件的加载顺序\\r\\n\\r\\nSpringBoot项目启动会扫描以下位置的application.properties或者application.yml文件作为SpringBoot的默认配置文件，具体的目录位置见下图。\\r\\n\\r\\n1. file:./config/ （ 项目根路径下的config文件夹）\\r\\n2. file:./ （项目根路径）\\r\\n3. classpath:/config/ （类路径下的config文件夹）\\r\\n4. classpath:/ （类路径）\\r\\n\\r\\n\\r\\n\\r\\n按照配置文件的优先级，8001\\r\\n\\r\\n&gt; 注意file层是项目的最外层目录，也就是工作目录。\\r\\n&\"},{\"url\":\"/frame/spring/custom/AOP.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AOP\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ByteBuddy\\r\\n\\r\\nAOP即面向切面编程，本质上是一个 Proxy 模式。核心就是拦截核心 Bean 的方法调用。\\r\\n\\r\\n- JDK动态代理\\r\\n- CGLIB动态生成字节码代理。\\r\\n\\r\\n\\r\\n&gt;\\r\\n\\r\\n AOP实现核心\\r\\n\\r\\n- 找到符合AOP要求的原始Bean\\r\\n- 执行指定的拦截器逻辑\\r\\n\\r\\n AOP流程\\r\\n\\r\\n1. 利用 `BeanPostProcessor` 检测每个Bean。\\r\\n2. 扫描每个 Bean 的 @Around 注解。\\r\\n3. 执行 InvocationHandler 的代理方法。\\r\\n\\r\\n 实现 @Before 和 @After\\r\\n\\r\\n基于@Around的模板就\"},{\"url\":\"/frame/spring/custom/Boot.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Boot\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot 内置了 Tomcat，IOC容器和 WebMVC 模块，所以能直接启动。\\r\\n\\r\\n 启动类\\r\\n\\r\\n```java\\r\\n@Slf4j\\r\\npublic class SummerApplication {\\r\\n\\r\\n    static final String CONFIG_APP_YAML = \\\"/application.yml\\\";\\r\\n    static final String CONFIG_APP_PROP = \\\"/application.properties\\\";\\r\\n\\r\\n    public static void run(String webDir, String base\"},{\"url\":\"/frame/spring/custom/IOC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IOC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"其中构造方法注入和工厂方法注入是强依赖，因为Bean创建和属性注入放到一起了。\\r\\n\\r\\n比如构造方法注入，创建对象的同时进行属性注入，这种属于强依赖。\\r\\n\\r\\n而强依赖是解决不了循环依赖的问题的，因为创建对象和属性注入属于一体不可分的。\\r\\n\\r\\n我们解决循环依赖是先创建对象，然后属性注入的时候利用三级缓存解决的。\\r\\n\\r\\n```java\\r\\n    public BeanTest(@Value(\\\"spring.port\\\") String port, String name) {\\r\\n        System.out.println(port);\\r\\n    }\\r\\n```\\r\\n\\r\\nIOC容器有两类，Bean\"},{\"url\":\"/frame/spring/custom/JDBC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JDBC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"DataSource\\r\\n\\r\\n自动注入DataSource\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\npublic class JdbcConfiguration {\\r\\n\\r\\n    /**\\r\\n     * 自动注入HikariDataSource\\r\\n     *\\r\\n     * @param url\\r\\n     * @param username\\r\\n     * @param password\\r\\n     * @param driver\\r\\n     * @param maximumPoolSize\\r\\n     * @param minimumPoolSize\\r\\n     * @pa\"},{\"url\":\"/frame/spring/custom/MVC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MVC实现逻辑\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 应用程序必须配置一个Summer Framework提供的 Listener；\\r\\n2. Tomcat 完成 Servlet 容器的创建后，立刻根据配置创建Listener；\\r\\n    1. Listener初始化时创建 IOC 容器；\\r\\n    2. Listener继续创建DispatcherServlet实例，并向Servlet容器注册；\\r\\n    3. DispatcherServlet初始化时获取到IOC容器中的Controller实例，因此可以根据URL调用不同Controller实例的不同处理方法。\\r\\n    4. 容器中的Controller实例，因此可以根据URL调用不同\"},{\"url\":\"/frame/spring/custom/声明式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"声明式事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"事务传播模型\\r\\n\\r\\n| 传播行为 | 含义 |\\r\\n| --- | --- |\\r\\n| PROPAGATION_REQUIRED | 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。 |\\r\\n| PROPAGATION_SUPPORTS | 支持当前事务，如果当前没有事务，就以非事务方式执行。 |\\r\\n| PROPAGATION_MANDATORY | 支持当前事务，如果当前没有事务，就抛出异常。 |\\r\\n| PROPAGATION_REQUIRED_NEW | 新建事务，如果当前存在事务，把当前事务挂起。 |\\r\\n| PROPAGATION_NOT_SUPPORTED | 以非事务方式\"},{\"url\":\"/frame/spring/custom/手写Spring.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"手写Spring\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- boot模块：实现一个简化版的 `Spring Boot`，用于打包运行。\\r\\n- web模块：实现Web MVC和REST API。\\r\\n\\r\\n Spring主要模块\\r\\n\\r\\n- context模块：实现ApplicationContext容器与Bean的管理；\\r\\n- aop模块：实现AOP功能；\\r\\n- jdbc模块：实现JdbcTemplate，以及声明式事务管理；\\r\\n\\r\\n IOC\\r\\n\\r\\nIOC\\r\\n\\r\\n AOP\\r\\n\\r\\nAOP\\r\\n\\r\\n JDBC\\r\\n\\r\\nJDBC\\r\\n\\r\\n声明式事务\\r\\n\\r\\n1. 由`JdbcConfiguration`创建的`DataSource`，实现了连接池；\\r\\n2. 由`Jdb\"},{\"url\":\"/frame/spring/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Spring框架\\r\\n\\r\\n 一、Spring框架\\r\\n\\r\\n- Spring框架概述\\r\\n- ApplicationContext 和 BeanFactory 区别\\r\\n- BeanFactory 和 FactoryBean 总结\\r\\n- Spring中Bean的作用域\\r\\n- Spring中Bean加载流程\\r\\n- Spring依赖注入\\r\\n- Spring如何解决循环依赖\\r\\n\\r\\n- AOP\\r\\n- Spring事务总结\\r\\n- Aware接口\\r\\n- Spi机制\\r\\n- Spring配置文件加载顺序\\r\\n\\r\\n 二、使用总结\\r\\n\\r\\n- Spring自定义注解扫描\\r\\n- ByteBuddy实现动态代理\\r\\n\\r\\n 三、手写S\"},{\"url\":\"/frame/springboot/SpringBoot使用APO记录操作日志.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot使用APO记录操作日志\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"通过织入自定义注解 @Log，再进行解析记录操作日志。\\r\\n\\r\\n1. 自定义注解 @Log\\r\\n    \\r\\n    ```java\\r\\n    @Target({ElementType.PARAMETER, ElementType.METHOD})\\r\\n    @Retention(RetentionPolicy.RUNTIME)\\r\\n    @Documented\\r\\n    public @interface Log {\\r\\n    \\r\\n        /**\\r\\n         * 模块\\r\\n         */\\r\\n        String title() default \\\"default\\\";\\r\\n\"},{\"url\":\"/frame/springboot/SpringBoot能同时处理多少请求.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot能同时处理多少请求\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot内置了Tomcat，处理请求是 Web 容器处理的。\\r\\n\\r\\n1. 线程池线程数限制\\r\\n\\r\\n   而 Tomcat 的线程池默认最大线程池是 200，所以默认同时最多能处理 200 个请求。\\r\\n\\r\\n   \\r\\n&gt;\\r\\n2. 连接数限制\\r\\n\\r\\n   达到连接池数时，会限制请求数。此时因连接数限制为准，而不是最大线程数。\\r\\n\\r\\n    ```\\r\\n    tomcat最大连接数限制\\r\\n    server.tomcat.max-connections=12\\r\\n    ```\\r\\n\\r\\n\\r\\n---\\r\\n\\r\\n 限制配置\\r\\n\\r\\n```\\r\\ntomcat最大连接数限制\\r\\nserver.tomca\"},{\"url\":\"/frame/springboot/SpringBoot项目自动初始化数据库.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot项目自动初始化数据库\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"背景\\r\\n\\r\\n在 SpringBoot 启动的时候若配置文件中配置的数据库不存在，则自动创建数据库，并执行初始化SQL。\\r\\n\\r\\n 思路\\r\\n\\r\\n1. 判断数据库是否存在。\\r\\n2. 手动注入Datasource。\\r\\n    \\r\\n    在数据库未创建时，启动会报错\\r\\n    \\r\\n3. 初始化表。\\r\\n\\r\\n 解决方式\\r\\n\\r\\n1. 启动类排除 `DataSourceAutoConfiguration.class` ，采用手动注入的方式。\\r\\n    \\r\\n    如果配置的数据库不存在，SpringBoot启动的时候会提示找不到数据库，所以要排除掉，然后手动注入。\\r\\n    \\r\\n    ```java\\r\\n  \"},{\"url\":\"/frame/springboot/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot 框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot 框架\\r\\n\\r\\n\\r\\n 使用总结\\r\\n- SpringBoot能同时处理多少请求\\r\\n- SpringBoot使用APO记录操作日志\\r\\n- SpringBoot项目自动初始化数据库\"},{\"url\":\"/frame/springcloud/Feigh远程调用原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Feigh远程调用原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"思路\\r\\n\\r\\n根据接口地址和 FeignClient构建http请求。\\r\\n\\r\\n1. 构建 http请求模版，包含 header、body、method等参数信息。\\r\\n2. 设置 options，包含超时时间参数配置。\\r\\n3. 根据 clientName 从 nacos（类似map，保存clientName和访问地址的对应关系）中获取访问地址。\\r\\n4. 根据访问地址和http请求参数发起http请求。\\r\\n\\r\\n 代码入口\\r\\n\\r\\n`io/github/openfeign/feign-core/10.4.0/feign-core-10.4.0.jar!/feign/ReflectiveFeign.cla\"},{\"url\":\"/frame/springcloud/Gateway.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Gateway\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"请求流程\\r\\n\\r\\n&lt;img src=\\\"https://s2.loli.net/2025/06/10/RBVjazHT3NinfQe.png\\\" alt=\\\"image.png\\\" style=\\\"zoom:50%;\\\" /\\r\\n\\r\\n- Gateway Handler（网关处理器）：网关处理器是 Spring Cloud Gateway 的核心组件，负责将请求转发到匹配的路由上。它根据路由配置和断言条件进行路由匹配，选择合适的路由进行请求转发。网关处理器还会依次应用配置的过滤器链，对请求进行处理和转换。\\r\\n- Gateway Filter Chain（网关过滤器链）：网关过滤器链由一系列过滤器组成，按照\"},{\"url\":\"/frame/springcloud/Nacos.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Nacos\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"地址\\r\\n\\r\\n GitHub\\r\\n\\r\\nhttps://github.com/alibaba/nacos\\r\\n\\r\\n 文档\\r\\n\\r\\nNacos 快速开始\\r\\n\\r\\n 启动命令\\r\\n\\r\\n```sql\\r\\nsh startup.sh -m standalone\\r\\n```\\r\\n\\r\\n 可视化页面\\r\\n\\r\\n`http://localhost:8848/nacos`\\r\\n\\r\\n\\r\\n\\r\\n 注册中心原理\\r\\n\\r\\n 服务注册\\r\\n\\r\\nNocas Client 在启动的时候会通过 Rest 的方式将自己的元数据（Ip、端口）等信息发给 Nocas Server。\\r\\n\\r\\nNacos Server 收到 Client 的注册请求后，将元数据信息存到\"},{\"url\":\"/frame/springcloud/Seata分布式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Seata分布式事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在分布式情况下，一次业务请求需要调用多个系统操作多个数据源时，针对多个数据源操作会产生分布式事务问题。每个系统能够保证各自数据源的一致性问题，但是全部系统数据的一致性问题没法保证。\\r\\n\\r\\n 官网地址\\r\\n\\r\\nhttps://seata.io/zh-cn/docs/user/quickstart.html\\r\\n\\r\\n 下载地址\\r\\n\\r\\nhttps://seata.io/zh-cn/blog/download.html\\r\\n\\r\\n 基础概念\\r\\n\\r\\n事务ID + 三组件\\r\\n\\r\\n事务ID\\r\\n\\r\\n- Transaction ID(XID)\\r\\n\\r\\n三组件\\r\\n\\r\\n- TC-事务协调者\\r\\n\\r\\n  维护全局和分支事务的状态\"},{\"url\":\"/frame/springcloud/Sentinel原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Sentinel原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Sentinel工作主流程\\r\\n\\r\\n滑动窗口实现原理 · 吾爱开源 · 看云\\r\\n\\r\\n 限流算法\\r\\n\\r\\n 计数器算法\\r\\n\\r\\n计数器算法统计某个时间段的请求量，判断是否超过阈值。\\r\\n\\r\\n\\r\\n\\r\\n存在的问题：\\r\\n\\r\\n如上图中，在时间段的临界处加起来其实QPS 超过了阈值，但是平均到单个时间段未发生。\\r\\n\\r\\n单纯的计数器算法存在 临界统计不准确 的问题。\\r\\n\\r\\n 滑动窗口计数器算法\\r\\n\\r\\n解决滑动窗口存在的问题，引入了滑动窗口计数器。\\r\\n\\r\\n我们将统计时间细分，比如将 1s 统计时长分为 5个 时间窗口，通过 滚动统计所有时间窗口的QPS 作为系统实际的 QPS 的方式，就能解决上述 临界统计 问题。\\r\"},{\"url\":\"/frame/springcloud/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringCloud\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringCloud\\r\\n\\r\\n 使用总结\\r\\n\\r\\n- 注册中心的演进\\r\\n- Nacos\\r\\n- Gateway\\r\\n- Feigh远程调用原理\\r\\n- Sentinel原理\\r\\n- Seata分布式事务\\r\\n\\r\\n\\r\\n\\r\\n 项目\\r\\n\\r\\nSpringCloud总结练习-Gitee\"},{\"url\":\"/frame/springcloud/注册中心的演进.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"注册中心的演进\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 直接远程调用\\r\\n\\r\\n   \\r\\n\\r\\n2. 维护注册表，维护服务调用地址\\r\\n\\r\\n   \\r\\n\\r\\n3. 接入 nginx，利用 nginx 做负载\\r\\n\\r\\n   \\r\\n\\r\\n4. 引入注册机制，提供注册和服务发现功能\\r\\n\\r\\n   \\r\\n\\r\\n5. 引入心跳机制，解决注册中心宕机或者目标服务不可用\"},{\"url\":\"/java/cache/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Cache\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 本地缓存\\r\\n- 多级缓存\\r\\n- 缓存淘汰算法\"},{\"url\":\"/java/cache/多级缓存.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"多级缓存\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"二级缓存\\r\\n\\r\\n二级缓存没有网络开销\\r\\n\\r\\n\\r\\n\\r\\n 优点\\r\\n\\r\\n1. 减少网络请求，提高性能。\\r\\n2. 减少远程缓存的读压力。\\r\\n3. 天然分布式缓存，只存在于当前节点服务。\\r\\n\\r\\n 缺点\\r\\n\\r\\n1. 占用本地内存，空间有限，不支持大数据量。\\r\\n\\r\\n   只存储最热的数据到本地缓存，结合热点服务探测。\\r\\n\\r\\n2. 重启数据会丢失。\\r\\n\\r\\n   重启丢失数据无法避免，但是可以在重启项目的时候把最热的数据加到本地缓存。\\r\\n\\r\\n3. 分布式场景，数据可能不一致。\\r\\n4. 和远程缓存可能存在不一致的问题。\\r\\n\\r\\n   只能保证最终一致性，尽可能让本地缓存过期时间短一点，这样就能加载远程缓存，达到最终\"},{\"url\":\"/java/cache/本地缓存.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"本地缓存\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Guava\\r\\n\\r\\n- 支持最大容量限制\\r\\n- 支持两种过期删除策略\\r\\n- 支持简单的统计功能\\r\\n- 插入时间\\r\\n- 访问时间\\r\\n- 基于LRU算法实现\\r\\n\\r\\n```java\\r\\nLoadingCache&lt;Integer, String\\r\\n        //设置并发级别为8，并发级别是指可以同时写缓存的线程数\\r\\n        .concurrencyLevel(8)\\r\\n        //设置缓存的初始容量为10\\r\\n        .initialCapacity(10)\\r\\n        // 设置缓存最大容量为100，超过100之后就会按照LRU最近最少使用算法来移除缓存\\r\\n    \"},{\"url\":\"/java/cache/缓存淘汰算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"缓存淘汰算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"FIFO-先进先出\\r\\n\\r\\n\\r\\n\\r\\n比较简单，不够灵活。\\r\\n\\r\\n没有跟缓存使用频次和时间等维度联系起来。\\r\\n\\r\\n LRU-最近最少使用\\r\\n\\r\\n核心思想是最近使用的时间。比如最近一小时以内使用缓存的时间。\\r\\n\\r\\n\\r\\n\\r\\n根据数据的历史访问记录来淘汰数据，淘汰最久未被使用的数据。\\r\\n\\r\\n基于如果数据最近被访问过，那么将来访问的记录会更高。优先淘汰最久未被使用的冷数据。\\r\\n\\r\\n LFU-最近最不常用\\r\\n\\r\\n核心思想是最近使用的次数。比如最近一小时内使用缓存的次数。\\r\\n\\r\\n\\r\\n\\r\\nLFU能够提高热点数据的命中率。\\r\\n\\r\\n但是当缓存中数据都是热点数据的时候，将失去该特性。\\r\\n\\r\\n单纯的LFU存在缺陷。\\r\\n\"},{\"url\":\"/java/collection/Collection集合概述.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集合概述\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集合概述\\r\\n\\r\\n 为什么使用集合？\\r\\n\\r\\n当我们需要保存一组类型相同的数据的时候，我们应该用一个容器来保存，这个容器就是数组。\\r\\n\\r\\n但是数组的长度是固定的，当添加的元素超过了数组的长度之后，需要对数组重新定义。而且数组存储的数据是`有序的`、`可重复的`，太过于单一，扩展性不够。\\r\\n\\r\\n于是，引入了集合，Java 内部给我们提供了功能完善的集合框架。能`存储任意对象`，长度可以`动态改变`，提高了数据存储的灵活性。\\r\\n\\r\\n 数组和集合的区别\\r\\n\\r\\n1. 存储类型\\r\\n   - 数组可以存储`基本数据类型`，又可以存储`引用数据类型`。\\r\\n   - 集合只能存储`引用数据类型`。（集合中也可以存\"},{\"url\":\"/java/collection/ConcurrentHashMap1.7.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ConcurrentHashMap - 1.7\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、类简介\\r\\n\\r\\nConcurrentHashMap 是一个线程安全的 HashMap，在 JDK 1.7 HashMap的基础上实现了 `分段锁` 来保证线程安全。在 HashMap 的基础上，默认分为 16 个段，每个段都拥有独立的锁，来保证各个段的线程安全。\\r\\n\\r\\n 扩展 - 线程安全的 HashMap\\r\\n\\r\\nMap实现线程安全的三种方式\\r\\n\\r\\n Unsafe方法总结\\r\\n\\r\\n\\r\\n\\r\\n 二、主要参数\\r\\n\\r\\n```java\\r\\npublic class ConcurrentHashMap&lt;K, V\\r\\n        implements ConcurrentMap&lt;K, V&gt;\"},{\"url\":\"/java/collection/ConcurrentHashMap1.8.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ConcurrentHashMap -1.8\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ConcurrentHashMap 源码分析\\r\\n\\r\\n\\r\\n1.8的ConcurrentHashMap，采用对Node加锁机制。\\r\\n\\r\\n 加锁原理\\r\\n\\r\\n采用CAS+Synchronized组合锁的方法。\\r\\n\\r\\n- CAS\\r\\n\\r\\n  操作Node数组的时候以CAS方式操作。\\r\\n\\r\\n- Synchronized\\r\\n\\r\\n  操作Node对应的数据结构，链表或红黑树的时候加Synchronized。保证操作数据的原子性。\"},{\"url\":\"/java/collection/HashMap1.7.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HashMap - 1.7\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类简介\\r\\n\\r\\nHashMap 是一个用来存储 Key - Value 键值对的集合，每一个键值对也叫做 Entry，这些 Entry 保存在底层数组中。\\r\\n\\r\\n 1. 底层数组\\r\\n\\r\\n底层数组包含的每个元素可以称之为 桶，元素实际保存在每个桶上。\\r\\n\\r\\n```java\\r\\n    static final Entry&lt;?,?\\r\\n\\r\\n    /**\\r\\n     * The table, resized as necessary. Length MUST Always be a power of two.\\r\\n     */\\r\\n    transient Entry&lt;K,V&gt;[] t\"},{\"url\":\"/java/collection/HashMap1.8.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HashMap - 1.8\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类简介\\r\\n\\r\\n 默认参数\\r\\n\\r\\n- 默认长度\\r\\n\\r\\n  ```\\r\\n   static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4\\r\\n  ```\\r\\n\\r\\n- 最大容量\\r\\n\\r\\n  ```\\r\\n  static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;\\r\\n  ```\\r\\n\\r\\n- 默认负载因子\\r\\n\\r\\n  ```\\r\\n   static final float DEFAULT_LOAD_FACTOR = 0.75f;\\r\\n  ```\\r\\n\\r\\n- 默认树化临界点\\r\\n\\r\\n  ```\\r\\n  static final in\"},{\"url\":\"/java/collection/List集合体系.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"List集合体系\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ArrayList\\r\\n\\r\\n 特点\\r\\n\\r\\n- 底层基于数组实现。\\r\\n- 有索引，支持快速访问。\\r\\n- 查询修改快，增删慢。\\r\\n- 线程不安全。\\r\\n\\r\\n 构造方法\\r\\n\\r\\n1. 无参构造\\r\\n\\r\\n   - JDK 1.6 之前，以初始容量 10 创建一个长度为10的数组。\\r\\n   - JDK 1.6 之后，创建一个空数组。\\r\\n\\r\\n   ```java\\r\\n       public ArrayList() {\\r\\n           this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;\\r\\n       }\\r\\n   ```\\r\\n\\r\\n2. 有参构造 - 数\"},{\"url\":\"/java/collection/Set集合体系.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Set集合体系\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HashSet\\r\\n\\r\\n 特点\\r\\n\\r\\n- 底层基于哈希算法实现，使用 `HashMap` 保存数据。\\r\\n- 无序（存取顺序不一致）。\\r\\n- 不可以存储重复元素。\\r\\n- 线程不安全。\\r\\n\\r\\n 构造方法\\r\\n\\r\\n1. 无参构造\\r\\n\\r\\n   底层使用 `HashMap` 保存数据。\\r\\n   \\r\\n```java\\r\\n       public HashSet() {\\r\\n           map = new HashMap&lt;\\r\\n       }\\r\\n```\\r\\n\\r\\n3. 有参构造 - Collection 集合\\r\\n\\r\\n   根据传入的 Collection 集合 初始化底层 `HashMap`。\\r\\n\\r\\n\"},{\"url\":\"/java/collection/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集合\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Collection集合\\r\\n\\r\\n- Collection集合概述\\r\\n- List集合体系\\r\\n- Set集合体系\\r\\n\\r\\n Map集合体系\\r\\n\\r\\n- HashMap - 1.7\\r\\n- ConcurrentHashMap - 1.7\\r\\n- HashMap - 1.8\\r\\n- ConcurrentHashMap -1.8\"},{\"url\":\"/java/concurrent/Java高并发.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Java工程师成长计划-高并发\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java工程师成长计划-高并发\\r\\n\\r\\n```\\r\\n         _______________________________________________        \\r\\n        |   _      __        __                         |       \\r\\n________|  | | /| / / ___   / / ____ ___   __ _  ___    |_______\\r\\n\\\\       |  | |/ |/ / / -_) / / / __// _ \\\\ /  ' \\\\/ -_)   |      /\\r\\n \\\\      |  |\"},{\"url\":\"/java/concurrent/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"高并发\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"思维导图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 参考链接\\r\\n\\r\\n- 深入浅出Java多线程\"},{\"url\":\"/java/concurrent/single/AQS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AQS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"从ReentrantLock的实现看AQS的原理及应用\\r\\n\\r\\nAQS是一种提供了原子式管理同步状态、阻塞和唤醒线程功能以及队列模型的简单框架。\\r\\n\\r\\n 组成\\r\\n\\r\\n1. 共享资源状态维护state。\\r\\n\\r\\n   - AQS使用一个`volatile`修饰的 int 成员变量来表示同步状态，这个状态可以反映锁的当前持有情况。\\r\\n\\r\\n     例如，当状态为 0 时表示无锁状态，而当状态为非零时表示有锁被占用。\\r\\n\\r\\n2. FIFO 队列实现线程排队。\\r\\n\\r\\n   AQS维护了一个FIFO（先入先出）的双向队列，用于管理等待获取锁的线程，当一个线程尝试获取锁但失败时，它会进入这个队列并阻塞，直到锁\"},{\"url\":\"/java/concurrent/single/BlockQueue阻塞队列.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"阻塞队列BlockQueue\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"阻塞队列`BlockQueue`比起传统的`Queue`多了阻塞的功能，适合用于多线程之间的数据共享。阻塞主要发生在队列为空和队列满的情况。\\r\\n\\r\\n- 在队列为空的时候，操作元素出队的线程会进行循环等待，直到队列变为非空。\\r\\n- 在队列满的时候，操作元素入队的线程会进行循环等待，直到队列变为非满。\\r\\n\\r\\n 常见方法\\r\\n\\r\\n`BlockQueue入队`的方法有如下几种：\\r\\n\\r\\n- `offer()`方法，如果队列已满，无法存放，直接返回false。\\r\\n- `add()`方法，实际调用了offer()方法，增加了（Queue Full）的异常信息返回。\\r\\n- `put()`方法，若队列已满，会进行\"},{\"url\":\"/java/concurrent/single/CAS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"悲观和乐观策略\\r\\n\\r\\n锁有着悲观锁和乐观锁之分，悲观锁拥有资源的时候，认为随时会有人来篡改拥有的资源，所以在其拥有资源时不允许其他人访问。而乐观锁在拥有资源的时候不认为会有人来篡改其所拥有的资源，所以在其拥有资源的时候允许其他人访问。悲观锁和乐观锁是一种思想，对应的也是一种策略。\\r\\n\\r\\n加锁和使用 synchronized 其实就是一种悲观的策略，因为总是假设临界区的操作会产生冲突，如果有多个线程需要访问临界区资源，加锁和使用 synchronized 会阻塞其它线程。\\r\\n\\r\\n而无锁其实就是一种乐观的策略，它在操作的时候会假设访问资源不会冲突，所有的线程之间不存在阻塞，也就不存在等待，线程会持\"},{\"url\":\"/java/concurrent/single/ThreadLocal.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ThreadLocal总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ThreadLocal 提供了线程的局部变量，只有当前线程可以操作，不会和其它线程的局部变量产生冲突，实现了变量的线程安全。`ThreadLocal&lt;T\\r\\n\\r\\n 简单例子\\r\\n\\r\\n```java\\r\\npublic class ThreadLocalDemo {\\r\\n\\r\\n    private static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;();\\r\\n\\r\\n    public static void main(String[] args) {\\r\\n        //主线程\\r\\n        threadL\"},{\"url\":\"/java/concurrent/single/synchronized原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"synchronized原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"synchronized原理详解（通俗易懂超级好）-CSDN博客\\r\\n\\r\\n 特性\\r\\n\\r\\n- 原子性\\r\\n\\r\\n  synchronized 修饰的对象或类所有操作都是原子性的。线程需要获取锁，保证整个操作过程的原子性。\\r\\n\\r\\n  比如 i++这种赋值操作。\\r\\n\\r\\n- 可见性\\r\\n\\r\\n  一个线程如果要访问该类或对象必须先获得它的锁，而这个锁的状态对于其他任何线程都是可见的，并且在释放锁之前会将对变量的修改刷新到主存当中，保证资源变量的可见性。\\r\\n\\r\\n  如果某个线程占用了该锁，其他线程就必须在锁池中等待锁的释放。\\r\\n\\r\\n- 有序性\\r\\n\\r\\n  保证只有一个线程访问，确保了有序性。\\r\\n\\r\\n- 可重入性\\r\\n\"},{\"url\":\"/java/concurrent/single/transmittable-thread-local.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"transmittable-thread-local\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"线程池中的线程是可以复用的，假如第一个线程对  ThreadLocal 变量进行了操作，如果没有及时清理，下一个线程就会受到影响。因为 ThreadLocal  是在每个线程上维护了一个 ThreadLocalMap ，所以在线程复用的情况下，之后的线程会获取到  ThreadLocal  里之前线程设置的值。\\r\\n\\r\\n ThreadLocal多线程问题\\r\\n\\r\\n在多线程场景下传递ThreadLocal，如果线程池是池化的话，可能会导致复用ThreadLocal里面的值。\\r\\n\\r\\n\\r\\n\\r\\n 需求场景\\r\\n\\r\\n在使用线程池等池化复用线程的情况下，传递ThreadLoca值。\\r\\n\\r\\n1. 分布式跟踪 tr\"},{\"url\":\"/java/concurrent/single/原子类.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"原子类\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本类型-AtomicInteger\\r\\n\\r\\nAtomicInteger 是无锁的线程安全整数类，基于 `CAS` 实现，位于 `java.util.concurrent.atomic` 包下，该包下实现了一系列使用 `CAS` 操作实现线程安全的类型。其它原子类和 AtomicInteger 非常类似，故只分析 AtomicInteger。\\r\\n\\r\\n\\r\\n\\r\\n 比较 Integer\\r\\n\\r\\nAtomicInteger 是一个整数，与 Integer 不同的是，它是可变的并且是线程安全的。\\r\\n\\r\\n比如在多线程不加锁的情况下，操作 Integer 或者 AtomicInteger ，来比较结果是否正确。\"},{\"url\":\"/java/concurrent/single/死锁活锁和饥饿.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"死锁活锁和饥饿\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在使用锁的时候，可能会因为使用不当产生死锁、活锁和饥饿的现象。\\r\\n\\r\\n在单体应用中，加锁是否能解决所有的线程安全问题？\\r\\n\\r\\n*不能，因为加锁使用不当会有死锁、活锁和饥饿等问题。*\\r\\n\\r\\n 死锁\\r\\n\\r\\n什么是死锁？\\r\\n\\r\\n死锁指的是两个或多个线程之间，互相占用着对方请求的资源，而且不会释放已持有的资源，造成了多线程之间无限等待的现象，就叫做死锁。\\r\\n\\r\\n死锁发生后，会浪费大量的系统资源，并且在高并发下存在严重的安全隐患，甚至导致整个系统崩溃。\\r\\n\\r\\n 死锁产生的条件\\r\\n\\r\\n1. 互斥\\r\\n\\r\\n   某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结\"},{\"url\":\"/java/concurrent/single/线程池的关闭.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程池的关闭\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"线程池的关闭\\r\\n\\r\\n线程池的关闭方式有两种，一种是调用 `shutdown()` 方法，另一种是调用 `shutdownNow()` 方法。\\r\\n\\r\\n- shutdown\\r\\n\\r\\n  调用该方法后，线程池拒绝接受新提交的任务，同时等待线程池里和任务队列中的任务执行完毕再关闭线程。\\r\\n\\r\\n- shutdownNow\\r\\n\\r\\n  调用该方法后，线程池拒绝接受新提交的任务，不再执行任务队列的任务，将线程池任务队列里的任务全部返回。\\r\\n\\r\\n shutdown\\r\\n\\r\\n调用该方法后，线程池拒绝接受新提交的任务，同时等待线程池里和任务队列中的任务执行完毕再关闭线程。\\r\\n\\r\\n```java\\r\\n    public \"},{\"url\":\"/java/concurrent/single/线程池的执行流程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程池的执行\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"执行流程\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n1. 根据初始化参数创建线程池，刚创建时，线程池内没有线程。\\r\\n2. 当有新的任务提交到线程池的时候，会立即新增线程执行任务。\\r\\n3. 若运行线程数 = 核心线程数时，这时进来的任务会被添加到任务队列中，而线程会从任务队列中获取任务执行。\\r\\n4. 运行线程数 = 核心线程数 且 任务队列已满，这时候会在线程池中创建新线程来执行任务。\\r\\n5. 运行线程数 = 最大线程数，且任务队列已满，此时会执行线程池对应的拒绝策略。\\r\\n6. 当任务队列中没有任务，且线程等待时间超过空闲时间，则该线程会被回收。最终线程池中的线程数量会保持在核心线程数的大小。\\r\\n\\r\\n 源码分析\\r\\n\"},{\"url\":\"/java/concurrent/single/线程的生命周期.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程的生命周期\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 Java 中线程从新建到关闭会经过不同的状态，将线程从新建到关闭作为一个生命周期，在 Java 中整个线程的生命周期有 6 种状态。\\r\\n\\r\\n 线程状态类型\\r\\n\\r\\n在 JDK 的 Thread 类，存在 `State` 枚举类，包含了线程的 6 种状态。\\r\\n\\r\\n```java\\r\\n    public enum State {\\r\\n        \\r\\n        NEW,\\r\\n        RUNNABLE,\\r\\n        BLOCKED,\\r\\n        WAITING,\\r\\n        TIMED_WAITING,\\r\\n        TERMINATED;\\r\\n    }\\r\\n```\"},{\"url\":\"/java/distributed/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 分布式事务\\r\\n- 分布式锁\\r\\n- 分布式ID\\r\\n- 幂等性问题\"},{\"url\":\"/java/distributed/分布式ID.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式ID\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"要求\\r\\n\\r\\n1. 分布式全局唯一\\r\\n2. 有序递增\\r\\n\\r\\n 方案\\r\\n\\r\\n\\r\\n\\r\\n 数据库主键自增\\r\\n\\r\\n1. 创建一个全局主键自增的表。\\r\\n2.  从该表查询id使用。\\r\\n    - 效率低下，每次插入之前都要查一次自己的id\\r\\n\\r\\n 数据库号段模式\\r\\n\\r\\n批量从全局自增主键表获取一批主键，放到内存里。（减少数据库访问次数）\\r\\n\\r\\n```bash\\r\\nCREATE TABLE `sequence_id_generator` (\\r\\n  `id` int(10) NOT NULL,\\r\\n  `current_max_id` bigint(20) NOT NULL COMMENT '当前最大id',\\r\\n\"},{\"url\":\"/java/distributed/分布式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在分布式情况下，假如存在 A 同时调用 B、C多个微服务。假如 B 服务事务正常执行并提交，但是 C 事务提交失败，此时 B 和 C都需要回滚。\\r\\n\\r\\n而 MySQL 的事务回滚是通过 redo log 机制来实现的，保证事务的持久化和一致性。\\r\\n\\r\\n但是在分布式，使用了分布式事务的情况下，是通过一条更新SQL，还原原本的数据。\\r\\n\\r\\n\\r\\n\\r\\n一文搞明白分布式事务解决方案！真的 so easy！\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n分布式事务，原理简单，写起来全是坑！ - 掘金\\r\\n\\r\\n\\r\\n\\r\\n 分布式事务解决方案\\r\\n\\r\\n 2PC - 两阶段提交\\r\\n\\r\\n1. prepare - 准备阶段\\r\\n\\r\\n    各个参\"},{\"url\":\"/java/distributed/分布式锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- mysql\\r\\n- redis 的 setnx\\r\\n- redission\\r\\n- redLock\\r\\n- zookeeper\\r\\n- curator\\r\\n\\r\\nredis的分布式锁可用性更高，但是分布式不友好。一般单机的redis实现分布式锁性能就够用。\\r\\n\\r\\n如果非要要求可靠性，可以选择zk，只是zk是cp的，性能要差一点。\\r\\n\\r\\n\\r\\n\\r\\n Reids分布式锁\\r\\n\\r\\nredis实现分布式锁\\r\\n\\r\\n\\r\\n\\r\\n 手写 zk 分布式锁\\r\\n\\r\\nzk 实现分布式锁，是依赖 zk 的临时有序节点。\\r\\n\\r\\n多个线程在 rootPath 下面按顺序创建节点。\\r\\n\\r\\n1. 首先有持久节点lock\\r\\n2. 每个请求获取锁\"},{\"url\":\"/java/distributed/幂等性问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"幂等性问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"常见幂等问题\\r\\n\\r\\n解决常见幂等性问题采用 `一锁、二判、三更新` 就可以解决。\\r\\n\\r\\n- 一锁：锁定需要处理的订单\\r\\n- 二判：订单是否支付\\r\\n- 三更新：更新订单状态\\r\\n\\r\\n 数据库锁-悲观锁\\r\\n\\r\\n- for Update\\r\\n  \\r\\n    `FOR UPDATE` 子句告诉数据库管理系统（DBMS）在检索行的同时锁定这些行，直到当前事务结束。\\r\\n    \\r\\n\\r\\n```java\\r\\nBEGIN;\\r\\n\\r\\nSELECT * FROM orders\\r\\nWHERE order_id = 123\\r\\nFOR UPDATE;\\r\\n\\r\\n-- 进行业务逻辑处理，例如更新订单状态\\r\\nUPDATE orders \"},{\"url\":\"/java/io/BIO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BIO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"JDK 网络编程 BIO，意为阻塞的 IO。\\r\\n\\r\\nBIO 的阻塞体现在两个方面：\\r\\n\\r\\n1. 若一个服务端的服务绑定端口启动后，主线程就会一直等待客户端的连接。\\r\\n2. 客户端和服务端 Socket 端口建立连接之后，在读取到 Socket 信息之前，线程一直处于等待，一直处于阻塞状态。\\r\\n\\r\\n典型的 请求 -应答模型\\r\\n\\r\\n由一个独立的 `Acceptor` 模型监听客户端的请求，收到请求后为每一个客户端创建一个线程去处理，处理完成后将结果返回给客户端。\\r\\n\\r\\nJava BIO：传统的网络通讯模型，就是BIO，同步阻塞IO。\\r\\n\\r\\n其实就是服务端创建一个ServerSocket， 然后就是\"},{\"url\":\"/java/io/IO多路复用.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IO多路复用\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"小白也看得懂的 I/O 多路复用解析（超详细案例）_哔哩哔哩_bilibili\\r\\n\\r\\n 基础概念\\r\\n\\r\\n\\r\\n\\r\\n1. Socket\\r\\n\\r\\n   套接字，在网络通信中，就是客户端和服务端的出入口。\\r\\n\\r\\n   \\r\\n&gt;\\r\\n2. fd\\r\\n\\r\\n   文件描述符，是指向资源文件的索引。\\r\\n\\r\\n\\r\\n Socket通讯的过程\\r\\n\\r\\n\\r\\n\\r\\n1. 服务端通过 bind 绑定机器的端口号， 进程 listen 某个端口。\\r\\n2. 客户端和服务端通过 tcp 三次握手建联。\\r\\n3. 进行数据交互，\\r\\n4. 最后通过 close 断开连接。\\r\\n\\r\\n IO模型\\r\\n\\r\\n\\r\\n\\r\\n 同步阻塞IO - BIO\\r\\n\\r\\n-\"},{\"url\":\"/java/io/NIO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"NIO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NIO 是 JDK1.4 引入，为了解决 BIO 阻塞的问题，又称 `no-blocking io`。\\r\\n\\r\\n同步非阻塞\\r\\n\\r\\n NIO特点\\r\\n\\r\\n- 面向缓冲区\\r\\n  \\r\\n    BIO 是面向流的，NIO 是面向缓冲区的。\\r\\n    \\r\\n    \\r\\n\\r\\n- 非阻塞模式\\r\\n  \\r\\n    NIO 的非阻塞模式，使其线程从 Channel 获取数据时，即使获取不到数据也不会阻塞线程。\\r\\n    \\r\\n\\r\\n NIO 核心组件\\r\\n\\r\\n\\r\\n\\r\\n Selector-轮询选择器\\r\\n\\r\\nJava NIO 的选择器允许一个单独的线程来监视多个输入通道（Channel）。\\r\\n\\r\\n选择器用于检测一个或多个通道的状\"},{\"url\":\"/java/io/Reactor模式.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Reactor模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Reactor模式详解＋源码实现\\r\\n\\r\\n整个 reactor 模式解决的主要问题就是在接收到任务后根据分发器快速进行分发给相应的事件处理器，不需要从开始状态就阻塞。\\r\\n\\r\\n基于事件驱动模型，当接收到请求后会将请求封装成事件，并将事件分发给相应处理事件的Handler，handler处理完成后将事件状态修改为下一个状态，再由Reactor将事件分发给能够处理下一个状态的handler进行处理。\\r\\n\\r\\n\\r\\n\\r\\n1. EventHandler：事件处理器，可以根据事件的不同状态创建处理不同状态的处理器；\\r\\n   \\r\\n    ```java\\r\\n    public abstract class Eve\"},{\"url\":\"/java/io/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- BIO\\r\\n- 基于BIO实现RPC框架\\r\\n- NIO\\r\\n- Reactor模式\\r\\n- IO多路复用\"},{\"url\":\"/java/io/基于BIO实现RPC框架.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"基于BIO实现RPC框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基于bio手写实现简单的rpc_java 手写一个bio-CSDN博客\\r\\n\\r\\n RPC\\r\\n\\r\\n\\r\\n\\r\\n RPC设计\\r\\n\\r\\n\\r\\n\\r\\nRPC 的核心就是让客户端调用远程服务方法，就像调用本地方法一样。\\r\\n\\r\\n- 服务端将自己的类注册到远程服务。\\r\\n- 客户端通过注册中心获取到服务端地址。\\r\\n    - 客户端调用服务端地址，传入类名，调用方法、入参\\r\\n    - 服务端收到方法信息后，本地通过反射执行方法，获取结果返回给客户端。\\r\\n- 客户端需要写一个需要调用的类，和服务端的类保持一致（方法名、入参类型、入参）。\\r\\n    - 客户端需要对这个类进行动态代理，实际访问的是该类的代理对象。\\r\\n   \"},{\"url\":\"/java/jvm/CPU负载过高排查记录.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"CPU负载过高排查记录\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"解决线上微服务容器cpu占用100%问题（java进程占用100%问题）_容器cpu占用高_上树的蜗牛儿的博客-CSDN博客\\r\\n\\r\\n 平台发现问题\\r\\n\\r\\n平台发现集群节点 node219 CPU利用率过高。\\r\\n\\r\\n\\r\\n\\r\\n通过查看该节点下的 pod 发现，bookdemo 使用 CPU 过高。\\r\\n\\r\\n\\r\\n\\r\\n 主机排查\\r\\n\\r\\n top 查看进程情况\\r\\n\\r\\n使用 top 确认占用cpu过高的进程。\\r\\n\\r\\nPID=17177 占用 CPU 最高。\\r\\n\\r\\n\\r\\n\\r\\n 查看进程 PID 对应的容器\\r\\n\\r\\n由于该进程是个POD，需要找到对应容器，进入容器内部排查线程情况。\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 容器内部\"},{\"url\":\"/java/jvm/G1收集器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"G1收集器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- XX:+UseG1GC\\r\\n\\r\\nG1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对 配备多颗处理器及大容量内存的机器，以极高概率满足GC停顿时间要求的同时，还具备高吞吐量性能特征。\\r\\n\\r\\nG1 收集器 在 JDK1.7 正式启用，是 JDK 9以后的默认垃圾收集器，取代了 CMS 以及 Parallel+Parallel Old 的组合，被 Oracle 官方称为“全功能的垃圾收集器”。\\r\\n\\r\\n- 适合大内存机器，具备高吞吐量。\\r\\n- 低 GC 停顿时间。\\r\\n\\r\\n 堆分布\\r\\n\\r\\n 区域分布\\r\\n\\r\\n\\r\\n\\r\\n区分于传统的堆内存分布，G1 是将 JVM 堆内存划分为了多个 \"},{\"url\":\"/java/jvm/JDK调优命令.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JDK调优命令\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"jstack\\r\\n\\r\\n 死锁检测\\r\\n\\r\\n1. 使用 jps 命令查看运行中的 java 进程 Id。\\r\\n   \\r\\n    \\r\\n    \\r\\n2. 使用 jstack 分析线程状态。\\r\\n   \\r\\n    ```\\r\\n    jstack 进程Id\\r\\n    ```\\r\\n    \\r\\n    - 线程状态\\r\\n      \\r\\n        通过分析进程可以得到，`DeadLockTest` 进程的两个线程分别为 `pool-1-thread-2` （简称2）和 `pool-1-thread-1`（简称1）。\\r\\n        \\r\\n        通过打印的线程信息可以发现，线程 2 和 1 的线程状态都是 \"},{\"url\":\"/java/jvm/JVM内存模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JVM内存模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java 内存模型在 JDK1.7 主要包含以下区域。\\r\\n\\r\\n- 程序计数器\\r\\n- 虚拟机栈\\r\\n- 本地方法栈\\r\\n- 方法区\\r\\n- 堆\\r\\n\\r\\n而在 JDK1.8中将运行时数据区中的方法区给取消了，换成了本地内存中的元数据区。\\r\\n\\r\\n- 程序计数器\\r\\n- 虚拟机栈\\r\\n- 本地方法栈\\r\\n- 堆\\r\\n- 元数据区\\r\\n\\r\\n 内存模型图\\r\\n\\r\\n1. JDK 1.7 内存模型图\\r\\n   \\r\\n    \\r\\n    \\r\\n2. JDK 1.8 内存模型图\\r\\n   \\r\\n    JDK1.8中取消了运行时数据区中的方法区，换成了元数据区放到了本地内存里。\\r\\n    \\r\\n    \\r\\n    \\r\\n\\r\\n 运行时数据区\\r\\n\\r\\n\"},{\"url\":\"/java/jvm/Java类加载器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"类加载器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"什么是类加载器\\r\\n\\r\\n类加载器（ClassLoader）就是在系统运行过程中动态的将编译后的.class字节码文件加载到JVM中的工具。在IDE中编写的源代码文件都是`.java`文件，通过编译对应生成`.class`文件。而类加载器就是用来将`.class`文件加载到JVM中的工具。\\r\\n\\r\\n 类加载器类型\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nJava默认提供了三个类加载器，分别是 AppClassLoader、ExtClassLoader、BootstrapClassLoader，除此之外还可以自定义类加载器。类加载器之间是父级的关系，但不是通过继承实现父级关系的，而是通过组合的形式来实现的，在`Clas\"},{\"url\":\"/java/jvm/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JVM\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、类加载器\\r\\n\\r\\n- 类加载器\\r\\n- 对象创建\\r\\n\\r\\n 二、内存模型\\r\\n\\r\\n- JVM内存模型\\r\\n\\r\\n 三、垃圾回收\\r\\n\\r\\n- 垃圾回收算法\\r\\n- 垃圾回收器\\r\\n- G1收集器\\r\\n\\r\\n 四、命令工具\\r\\n\\r\\n- JDK调优命令\\r\\n- 可视化工具\\r\\n\\r\\n 五、排障记录\\r\\n\\r\\n- CPU负载过高排查记录\\r\\n- 内存问题排查总结\\r\\n- 频繁GC排查\\r\\n\\r\\n---\"},{\"url\":\"/java/jvm/内存问题排查总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内存问题排查总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"堆内存dump\\r\\n\\r\\n```\\r\\n1 jmap ‐dump:format=b,file=eureka.hprof 14660\\r\\n```\\r\\n\\r\\n可以配置自动 dump 文件，在内存溢出的时候会自动 dump 文件。\\r\\n\\r\\n```\\r\\n-XX:+HeapDumpOnOutOfMemoryError\\r\\n```\\r\\n\\r\\n比如应用的启动脚本，开启自动 dump 文件。\\r\\n\\r\\n```\\r\\nexec java -classpath $CLASSPATH -Xms1024m -Xmx2048m\\r\\n-XX:+HeapDumpOnOutOfMemoryError\\r\\n-Dquery.type=es\\r\\n-Dfile.enco\"},{\"url\":\"/java/jvm/可视化工具.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可视化工具\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"jconsole\\r\\n\\r\\njconsole是JDK 提供的可视化工具。可以查看内存、线程数量、CPU等资源信息。\\r\\n\\r\\n 使用方式\\r\\n\\r\\n 本地进程\\r\\n\\r\\n直接执行命令\\r\\n\\r\\n```java\\r\\njconsole\\r\\n```\\r\\n\\r\\n 远程进程\\r\\n\\r\\n```java\\r\\n-Djava.rmi.server.hostname=10.10.102.81-Dcom.sun.management.jmxremote.port=9999-Dcom.sun.management.jmxremote-Dcom.sun.management.jmxremote.authenticate=false\\r\\n-Dcom.sun\"},{\"url\":\"/java/jvm/垃圾回收器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"垃圾回收器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"垃圾回收类型\\r\\n\\r\\n1. 串行\\r\\n    - 单线程\\r\\n    - 适合堆内存小的时候。\\r\\n    - STW\\r\\n      \\r\\n        Stop The World 的简称。这是因为串行的机制，在垃圾回收的线程运行的时候，其它工作线程都要阻塞。\\r\\n        \\r\\n        *在垃圾回收过程中，对象的地址会发生改变。如果其它线程不阻塞，则可能会发生对象引用错误的问题。*\\r\\n    \\r\\n2. 吞吐量优先\\r\\n    - 多线程\\r\\n    - 适合堆内存较大，且多核CPU的情况。\\r\\n    - 在单位时间内，STW时间最短。\\r\\n3. 响应时间优先\\r\\n    - 多线程\\r\\n    -\"},{\"url\":\"/java/jvm/垃圾回收算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"垃圾回收算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"如何判断对象可以回收\\r\\n\\r\\n 引用计数法\\r\\n\\r\\n为对象添加引用计数器，如果对象被其它对象引用一次，计数器 +1；对应引用释放，则计数器 -1；只有当计数器为 0 时该对象才会被垃圾回收。\\r\\n\\r\\n- 引用计数法造成的内存泄漏\\r\\n  \\r\\n    像下面这种即使对象不被其它对象引用，这两个对象也一直不会被回收，因为对象A和B之间存在引用关系，引用计数器一直为 1，这样就导致了内存泄露。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n\\r\\n\\r\\n\\r\\n 可达性分析算法\\r\\n\\r\\n&gt; 如果某个对象到GC Roots间没有任何引用链相连， 或者用图论的话来说就是从GC Roots到这个对象不可达时，则证明此\"},{\"url\":\"/java/jvm/对象创建.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"对象创建\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"对象的创建流程\\r\\n\\r\\n\\r\\n\\r\\n 类加载检查\\r\\n\\r\\n判断有无加载过该类，有则直接进入下一步、没有则加载类对象。\\r\\n\\r\\n 分配内存\\r\\n\\r\\n虚拟机为新生对象分配内存。\\r\\n\\r\\n对象所需内存大小在类检查阶段便可确定，为对象分配空间就是将一块确定大小内存从 Java 堆中划分出来。\\r\\n\\r\\n 1. 划分内存的方法\\r\\n\\r\\n- 指针碰撞法\\r\\n  \\r\\n    该方法是JVM中的默认方法。\\r\\n    \\r\\n    它主要就是假设JVM中的内存是绝对规整的，使用过的内存和未使用过的内存分别放在两边，用一个指针来给他们做区分。如果要分配内存，只需要将指针向空闲的那一端移动对象大小的位置就好了。\\r\\n    \\r\\n- 空闲列表\"},{\"url\":\"/java/jvm/类加载器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"类加载器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"什么是类加载器\\r\\n\\r\\n类加载器（ClassLoader）就是在系统运行过程中动态的将编译后的.class字节码文件加载到JVM中的工具。在IDE中编写的源代码文件都是`.java`文件，通过编译对应生成`.class`文件。而类加载器就是用来将`.class`文件加载到JVM中的工具。\\r\\n\\r\\n 类加载器类型\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nJava默认提供了三个类加载器，分别是 AppClassLoader、ExtClassLoader、BootstrapClassLoader，除此之外还可以自定义类加载器。类加载器之间是父级的关系，但不是通过继承实现父级关系的，而是通过组合的形式来实现的，在`Clas\"},{\"url\":\"/java/jvm/频繁GC排查.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"频繁GC排查\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```\\r\\njstat -gcutil 1000\\r\\n```\\r\\n\\r\\n\\r\\n\\r\\n```\\r\\njmap -dump:format=b,file=dumpfile 1000\\r\\n```\\r\\n\\r\\n使用 MAT 工具分析代码\\r\\n\\r\\n---\\r\\n\\r\\n组件消费数据的线程池配置有问题。\"},{\"url\":\"/middleware/es/BulkProcessor死锁问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BulkProcessor死锁问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"问题原因\\r\\n\\r\\n- 定时flush\\r\\n- bulk操作\\r\\n- retryHandler：失败重试\\r\\n1. 定时 flush 和 retryHandler 用的是一个定时线程池，而该线程池只有一个线程。\\r\\n2. 定时 flush 的方法用的锁和 bulk 操作时的锁是同一把锁。都是类对象级别的锁。\\r\\n   \\r\\n    \\r\\n    \\r\\n    \\r\\n    \\r\\n3. 当bluk失败后，会触发默认的重试逻辑。\\r\\n4. 如果重试时候 flush 刚好运行，就会出现这种死锁情况。\\r\\n    1. bulk持有对象锁`BulkProcessor.class`，进行重试逻辑。\\r\\n    2. flush占有线\"},{\"url\":\"/middleware/es/ES分片.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES分片\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"同一个索引会划分为多个分片。分片可以设置副本数量，分为主分片和副本分片。\\r\\n\\r\\n```java\\r\\n 指定索引的主分片和副本分片数\\r\\nPUT /blogs\\r\\n{\\r\\n  \\\"settings\\\": {\\r\\n    \\\"number_of_shards\\\": 3,\\r\\n    \\\"number_of_replicas\\\": 1\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n 主分片\\r\\n\\r\\n- 解决数据水平扩展的问题。同一个索引可以按照分片分配数据，将数据平均分配到所有节点之上。\\r\\n- 主分片数创建好后就不能修改。\\r\\n- 一个分片就是一个运行的 Lucene 实例。\\r\\n\\r\\n 主分片过少\\r\\n\\r\\n- 单个分片数据量过大。查询较慢，利用\"},{\"url\":\"/middleware/es/ES压测记录和esrally使用.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES压测记录和esrally使用\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"环境信息\\r\\n\\r\\n- 压测环境\\r\\n  \\r\\n    ```\\r\\n    http://10.1.11.200:39200/\\r\\n    ```\\r\\n    \\r\\n- 开发环境\\r\\n  \\r\\n    ```java\\r\\n    http://10.10.101.69:39200\\r\\n    ```\\r\\n    \\r\\n- 测试环境\\r\\n  \\r\\n    ```java\\r\\n    http://10.10.103.218:39200/\\r\\n    ```\\r\\n    \\r\\n\\r\\n esrally安装\\r\\n\\r\\n docker安装\\r\\n\\r\\n1. 拉取镜像\\r\\n   \\r\\n    ```\\r\\n    docker pull elastic/rally\"},{\"url\":\"/middleware/es/ES参数调优.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES参数调优\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"预防脑裂\\r\\n\\r\\n\\r\\n\\r\\n重要配置的修改 | Elasticsearch: 权威指南 | Elastic\\r\\n\\r\\n 堆内存设置\\r\\n\\r\\n```\\r\\n -Xms2730m -Xmx2730m -Duser.timezone=Asia/Shanghai\\r\\n```\\r\\n\\r\\nxms和xmx设置一样大小，并设置为略小于pod分配内存的一半。\\r\\n\\r\\n 分片设置\\r\\n\\r\\n分片过小或过多都会影响es的查询速率。\\r\\n\\r\\n一经设置无法修改。\\r\\n\\r\\n目前是10个分片，数据量不大的情况下，设置为5个分片进行测试一下。1个、和node数量一致分片测试。\\r\\n\\r\\n1GB 20个分片\\r\\n\\r\\n1个 20G～40GB\\r\\n\\r\\n 副本数量\\r\\n\\r\"},{\"url\":\"/middleware/es/ES深度分页问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES深度分页问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"from+to分页\\r\\n\\r\\nes在查询时候默认使用的是分页查询，单次只会返回10条数据。\\r\\n\\r\\n可以指定size。\\r\\n\\r\\n\\r\\n\\r\\n- 查询要求默认 from+size 的结果必须不超过10000。\\r\\n  \\r\\n    可以通过修改配置\\r\\n    \\r\\n    ```java\\r\\n    \\\"index.max_result_window\\\":\\\"20000\\\"\\r\\n    ```\\r\\n    \\r\\n    限制单词查询满足条件的结果窗口的大小，由from+size共同决定。\\r\\n    \\r\\n    因为es是先将数据全查出来再做分页，这样做是为了限制内存的消耗。\\r\\n    \\r\\n    ---\\r\\n    \\r\\n    因\"},{\"url\":\"/middleware/es/ES滚动查询-Scroll.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES滚动查询-Scroll\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"原理\\r\\n\\r\\nElasticsearch中的滚动查询是基于 固定的排序规则 来加载一部分数据。\\r\\n\\r\\n当用户刷新时，将从上次加载的最后一条数据的位置再加载同样数量的数据。\\r\\n\\r\\n滚动查询的原理类似于分页查询，但是滚动查询不需要重新执行搜索，只需要继续检索下一批结果。在滚动查询中，每次只加载当前页的数据，而不是一次性加载所有数据。这使得滚动查询比分页查询更高效，因为滚动查询不需要将所有数据都存储在内存中。同时，滚动查询也适用于大量数据的处理，因为它可以分批次地处理数据，而不是一次性处理所有数据。\\r\\n\\r\\n 滚动查询的排序规则\\r\\n\\r\\n滚动查询的排序规则不一定是时间。在Elasticsearch中，滚动\"},{\"url\":\"/middleware/es/ES的log4j2日志自动清理配置.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES的log4j2日志自动清理配置\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"配置\\r\\n\\r\\n```xml\\r\\nappender.rolling.strategy.type = DefaultRolloverStrategy\\r\\nappender.rolling.strategy.fileIndex = nomax\\r\\nappender.rolling.strategy.action.type = Delete\\r\\nappender.rolling.strategy.action.basepath = ${sys:es.logs.base_path}\\r\\nappender.rolling.strategy.action.condition.type = IfFileName\\r\\napp\"},{\"url\":\"/middleware/es/ES聚合查询原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES聚合查询原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES在对海量数据进行聚合分析的时候会损失搜索的精准度来满足实时性的需求。\"},{\"url\":\"/middleware/es/ES集群.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES集群\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集群节点类型\\r\\n\\r\\n1. Master Node - 主节点\\r\\n2. DataNode - 数据节点\\r\\n3. Coordinating Node - 协调节点\\r\\n\\r\\n Master Node\\r\\n\\r\\n- 处理创建，删除索引等请求。\\r\\n- 决定分片被分配到哪个节点。\\r\\n- 维护并更新集群 state。\\r\\n\\r\\n Master Node节点最佳实践\\r\\n\\r\\n- Master节点非常重要，在部署上需要解决单点问题。\\r\\n- 为一个集群设置多个Master节点，而且节点只承担 Master 角色。\\r\\n\\r\\n Data Node\\r\\n\\r\\n保存数据的节点，负责保存分片数据。\\r\\n\\r\\n通过增加数据节点可以解决数据水平扩展\"},{\"url\":\"/middleware/es/Elasticsearch写入原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch写入原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本概念\\r\\n\\r\\n 索引\\r\\n\\r\\nElasticsearch的索引是一个逻辑上的概念，指存储了相同类型的文档集合。\\r\\n\\r\\n 映射\\r\\n\\r\\n映射（mapping）定义索引中有什么字段、进行字段类型确认。类似于数据库中表结构定义。\\r\\n\\r\\nES 默认动态创建索引和索引类型的 映射（mapping），就像是非关系型数据中的，无需定义表结构，更不用指定字段的数据类型。\\r\\n\\r\\n也可以手动指定 mapping 类型，比如通过请求设置索引的映射（mapping）。\\r\\n\\r\\n```java\\r\\ncurl --location --request POST 'localhost:9200/course/_mapping' \"},{\"url\":\"/middleware/es/Elasticsearch基础概念.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch基础概念\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础概念\\r\\n\\r\\n 一、索引库（index）\\r\\n\\r\\nElasticsearch的索引库是一个逻辑上的概念，存储了相同类型的文档内容。类似于 MySQL 数据表，MongoDB 中的集合。\\r\\n\\r\\n1. 新建索引库\\r\\n    - number_of_shards\\r\\n      \\r\\n        设置分片的数量，在集群中通常设置多个分片，表示一个索引库将拆分成多片分别存储不同 的结点，提高了ES的处理能力和高可用性，入门程序使用单机环境，这里设置为 1。\\r\\n        \\r\\n    - number_of_replicas\\r\\n      \\r\\n        设置副本的数量，设置副本是为了提高ES的\"},{\"url\":\"/middleware/es/Elasticsearch查询原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch查询原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES查询原理\\r\\n\\r\\n 查询方式\\r\\n\\r\\n- 根据 doc_id 查询。\\r\\n\\r\\n\\r\\n\\r\\n- 根据条件查询\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引\\r\\n\\r\\n根据文档中的每个字段建立倒排索引。\\r\\n\\r\\n 倒排索引的查询流程\\r\\n\\r\\n\\r\\n\\r\\n1. 查询条件分词。\\r\\n2. 查询单词词典 （term dictionary）。\\r\\n3. 获取对应分词的 doc_id 列表。\\r\\n4. 将查询结果返回。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 倒排索引的组成\\r\\n\\r\\n- postings list\\r\\n  \\r\\n    文档列表。\\r\\n    \\r\\n- term dictionary\\r\\n  \\r\\n    单词字典表。包含文档中所有的单词，es 会将单词排序\"},{\"url\":\"/middleware/es/Elasticsearch检索.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch检索\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"检索方式\\r\\n\\r\\nElasticsearch提供两种检索方式。\\r\\n\\r\\n1. RestAPI 形式通过 URL 参数进行检索。\\r\\n2. 通过 DSL 语句进行查询，通过传递 JSON 为请求体与 Elasticsearch 进行交互，这种方式更强大简洁。\\r\\n\\r\\n URL检索\\r\\n\\r\\n`GET /{index}/{type}/_search?q=*&sort=age:desc&size=5&from=0&_source=name,age,bir`\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\nq=* ：匹配所有文档\\r\\n\\r\\nsort=age：按照指定字段进行排序，默认为升序，:desc 降序排列\\r\\n\\r\\nsize：展示多少\"},{\"url\":\"/middleware/es/Elasticsearch聚合查询.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch聚合查询\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES在对海量数据进行聚合分析的时候会损失搜索的精准度来满足实时性的需求。\\r\\n\\r\\n Elasticsearch聚合查询总结\\r\\n\\r\\n 1. 求和、最大值、最小值、平均值\\r\\n\\r\\n- 求和 - sum\\r\\n- 最大值 - max\\r\\n- 最小值 - min\\r\\n- 平均值 - avg\\r\\n\\r\\n---\\r\\n\\r\\nDSL查询语句\\r\\n\\r\\n```java\\r\\n{\\r\\n    \\\"size\\\": 0,\\r\\n    \\\"query\\\": {\\r\\n        \\\"bool\\\": {\\r\\n            \\\"filter\\\": [\\r\\n                {\\r\\n                    \\\"range\\\": {\\r\\n    \"},{\"url\":\"/middleware/es/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础总结\\r\\n\\r\\n- Elasticsearch基础概念\\r\\n- Elasticsearch检索\\r\\n- Elasticsearch聚合查询\\r\\n\\r\\n\\r\\n- ES滚动查询-Scroll\\r\\n- 批量操作Bulk和BulkProcessor\\r\\n- BulkProcessor死锁问题\\r\\n\\r\\n\\r\\n- 并发场景修改文档\\r\\n- ES深度分页问题\\r\\n\\r\\n\\r\\n- ES集群\\r\\n- ES分片\\r\\n\\r\\n 原理总结\\r\\n\\r\\n- 倒排索引原理\\r\\n- Elasticsearch写入原理\\r\\n- Elasticsearch查询原理\\r\\n- ES聚合查询原理\\r\\n\\r\\n 使用问题\\r\\n- ES参数调优\\r\\n- 集群脑裂-参数配置\\r\\n\\r\\n\\r\\n- ES\"},{\"url\":\"/middleware/es/倒排索引原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"倒排索引图解\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"原理图\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引的搜索过程\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引原理\\r\\n\\r\\nElasticsearch 主要功能就是搜索，为了提高搜索效率，其内部使用了倒排索引。\\r\\n\\r\\n 正排索引\\r\\n\\r\\n在搜索引擎中，每个文件对应一个文件 ID （doc_id），文件内容是关键词的集合。\\r\\n\\r\\n\\r\\n\\r\\n根据 `doc_id` 可以查找到文档详情。\\r\\n\\r\\n*这种方式本质上就是通过文档的 key 查找 value 值。*\\r\\n\\r\\n比如查找 `name=jetty wan` 的文档，只能按照顺序从前向后匹配每个文档的 name 字段。\\r\\n\\r\\n这种查找方式的效率非常低下。\\r\\n\\r\\n 倒排索引\\r\\n\\r\\n倒排索引和正向索引\"},{\"url\":\"/middleware/es/并发场景修改文档.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"并发场景修改文档\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES从7.X版本默认使用的是乐观锁机制修改文档。\\r\\n\\r\\n当在高并发环境下使用乐观锁机制修改文档时，要带上当前文档的_seq_no和_primary_term进行更新：\\r\\n\\r\\n```java\\r\\nPOST /es_db/_doc/2?if_seq_no=21&if_primary_term=6{  \\\"name\\\": \\\"李四xxx\\\"}\\r\\n```\\r\\n\\r\\n如果冲突会提示版本冲突异常。\"},{\"url\":\"/middleware/es/批量操作Bulk和BulkProcessor.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"批量操作Bulk和BulkProcessor\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"es的批量操作，6.x版本的es中high-rest-client中可以用到以下三种。\\r\\n\\r\\n- bulk\\r\\n- bulkAsync\\r\\n- bulkProcessor\\r\\n\\r\\n Bulk\\r\\n\\r\\nbulk api 以此按顺序执行所有的 action（动作）。如果一个单个的动作因任何原因失败，它将继续处理它后面剩余的动作。当 bulk api 返回时，它将提供每个动作的状态（与发送的顺序相同），所以您可以检查是否一个指定的动作是否失败了。\\r\\n\\r\\nes可以通过 _bulk 的API实现批量操作。\\r\\n\\r\\n```java\\r\\nPOST _bulk\\r\\n{\\\"create\\\":{\\\"_index\\\":\\\"article\\\"\"},{\"url\":\"/middleware/es/集群脑裂-参数配置.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集群脑裂-参数配置\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集群脑裂的问题\\r\\n\\r\\n 什么是集群脑裂\\r\\n\\r\\nes 在主节点上产生分歧，产生多个master 节点，从而使集群分裂成多个同名集群，使得集群处于异常状态。\\r\\n\\r\\n当出现多个master节点的时候，可能发生写入请求分配到不同的master节点，而数据只保存在对应的master节点的分片上，不会复制到其它节点。此时若访问不同的节点，会发现查询的结果是不一样的。\\r\\n\\r\\n 举例说明脑裂\\r\\n\\r\\n`discovery.zen.minimum_master_nodes` 参数之前设置为 1（默认值）。\\r\\n\\r\\n这个参数的含义是限制选举master节点的数量。\\r\\n\\r\\n- 当master节点不存在时，至少有几个ma\"},{\"url\":\"/middleware/kafka/Kafka分区机制策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka分区机制策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"分区策略\\r\\n\\r\\n分区策略是决定生产者将消息发送到哪个分区的算法。\\r\\n\\r\\n 轮询策略\\r\\n\\r\\n是 Java 生产者 API 默认提供的分区策略。\\r\\n\\r\\n- 轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。\\r\\n\\r\\n\\r\\n\\r\\n 随机策略\\r\\n\\r\\n将消息随机写入分区\\r\\n\\r\\n key 指定分区\\r\\n\\r\\n当发送消息时指定了key，Kafka会根据key的hash值与分区数取模来决定将数据写入哪个分区。\\r\\n\\r\\n项目中 dr 就是生产这种方式，根据消息类型指定 key，比如 transactionId。这样能保证同一t\"},{\"url\":\"/middleware/kafka/Kafka副本机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka副本机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka 的副本是针对分区来说的，为分区创建副本。\\r\\n\\r\\n副本的作用就是提供数据冗余，在 Leader 副本挂掉之后，转换为 Leader 副本继续工作。\\r\\n\\r\\n不然当 Leader 副本挂掉之后，该分区就会停止对外提供服务。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 副本同步\\r\\n\\r\\n\\r\\n\\r\\n生产者只会往分区的 Leader 发消息，而其它 Follower 会从 Leader 拉取数据进行同步。\\r\\n\\r\\n Follower追随者副本\\r\\n\\r\\nFollower 副本是不对外提供服务的，只是定期地异步拉取领导者副本中的数据而已。\\r\\n\\r\\n LSR副本集合\\r\\n\\r\\nLSR集合里面保存的副本都是与 Leader 副本\"},{\"url\":\"/middleware/kafka/Kafka总控制器Controller.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka总控制器 Controller\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 kafka中会有多个 Broker，其中一个 Broker 会被选举为 Controller，负责管理整个集群中分区和副本的状态。\\r\\n\\r\\n Zookeeper\\r\\n\\r\\nzk 使用的数据模型类似于文件系统的树形结构，根目录也是以“/”开始。该结构上的每个节点被称为 znode，用来保存一些元数据协调信息。\\r\\n\\r\\nZooKeeper 常被用来实现集群成员管理、分布式锁、领导者选举等功能。\\r\\n\\r\\nznode 用来保存元数据信息。\\r\\n\\r\\n- 永久性 znode\\r\\n  \\r\\n    持久性 znode 不会因为 ZooKeeper 集群重启而消失。\\r\\n    \\r\\n- 临时性 znode\\r\\n  \\r\\n   \"},{\"url\":\"/middleware/kafka/Kafka手动重新分区.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka手动重新分区\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka重分配分区_kafka重新分配分区-CSDN博客\\r\\n\\r\\n1. 确定需要重新分区的 topic\\r\\n   \\r\\n    vi topics-to-move.json\\r\\n    \\r\\n    ```java\\r\\n    \\r\\n    {\\r\\n      \\\"topics\\\": [{\\r\\n         \\\"topic\\\": \\\"test-topic\\\"\\r\\n       }],\\r\\n       \\\"version\\\": 1\\r\\n    }\\r\\n    ```\\r\\n    \\r\\n    - topic 可以批量设置\\r\\n2. 根据 topic 生成执行计划\\r\\n   \\r\\n    ```java\\r\\n    bin/kafka-rea\"},{\"url\":\"/middleware/kafka/Kafka消费策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka消费策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka消费者-主动批量拉取\\r\\n\\r\\n\\r\\n&gt; \\r\\n1. kafka配置类\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\n@Slf4j\\r\\npublic class KafkaConfig {\\r\\n\\r\\n    @Bean\\r\\n    public KafkaListenerContainerFactory&lt;?&gt; batchFactory(ConsumerFactory consumerFactory){\\r\\n        ConcurrentKafkaListenerContainerFactory&lt;Integer,String&gt; factory =\\r\\n    \"},{\"url\":\"/middleware/kafka/Kafka生产者参数.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka生产者参数\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- bootstrap.servers： broker的地址\\r\\n- key.serializer：关键字的序列化方式\\r\\n- value.serializer：消息值的序列化方式\\r\\n- acks：指定必须要有多少个分区的副本接收到该消息，服务端才会向生产者发送响应，可选值为：0,1,2，…，all\\r\\n- buffer.memory：生产者的内存缓冲区大小。如果生产者发送消息的速度 \\r\\n- max.block.ms：表示send()方法在抛出异常之前可以阻塞多久的时间，默认是60s\\r\\n- compression.type：消息在发往kafka之前可以进行压缩处理，以此来降低存储开销和网络带宽。默认\"},{\"url\":\"/middleware/kafka/Kafka高性能的原因.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka高性能的原因\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 写数据是按照磁盘顺序读写。\\r\\n   \\r\\n    保证顺序读写，比随机写性能要高很多。\\r\\n    \\r\\n    数据保存在 log 中，并对 log 进行了分段（logSegment）技术，对 logSegment 还增加了日志索引。\\r\\n    \\r\\n2. 数据传输的零拷贝，使的数据在内核空间中就完成了读写操作。\\r\\n   \\r\\n    零拷贝原理：\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 读写数据的批量处理以及压缩传输。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n\\r\\n 零拷贝\\r\\n\\r\\n- 传统数据文件拷贝过程\\r\\n  \\r\\n    整个过程需要在内核空间和应用空间之间拷贝 2 次。\\r\\n    \"},{\"url\":\"/middleware/kafka/Producer发布消息机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Producer发布消息机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"写入机制\\r\\n\\r\\nProducer 通过push模式将消息发给 Broker，每条消息都被追加到对应的 Partition。而且是采用顺序写磁盘的方式（顺序写比随机写效率高，保障 Kafka 高吞吐量）。\\r\\n\\r\\n 消息路由模式\\r\\n\\r\\nProducer 如何确认消息发到哪个 Partition 上？\\r\\n\\r\\n1. 指定了 Partition，直接使用。\\r\\n2. 如果未指定 Partition，指定了 Key。根据 Key 的 Hash 值计算 Partition。\\r\\n   \\r\\n    Hash(key) % num(Partition)\\r\\n    \\r\\n3. 如果未指定 Partition，也未指定 \"},{\"url\":\"/middleware/kafka/__consumer_offsets.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"__consumer_offsets\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"将 Consumer 的位移数据作为一条条普通的 Kafka 消息，提交到 consumer*offsets 中。可以这么说，consumer*offsets 的主要作用是保存 Kafka 消费者的位移信息。\\r\\n\\r\\n_*consumer*offsets也是一个 topic，也有分区。和 kafka 的 topic 基本一致支持自定义写入。但是它是内部的 topic，一般最好不要自动修改。\\r\\n\\r\\n 消息格式\\r\\n\\r\\n1. 分区消费的 offset\\r\\n    \\r\\n    位移主题的 Key 中应该保存 3 部分内容：\\r\\n    \\r\\n    标识某个消费者组里面某个 topic 的某个分区，已经被消费\"},{\"url\":\"/middleware/kafka/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka配置\\r\\n\\r\\n- Kafka消费策略\\r\\n- Kafka生产者参数\\r\\n- kafka的分区副本规划\\r\\n\\r\\n\\r\\n Kafka原理总结\\r\\n- kafka消费模型\\r\\n- kafka-ACK应答机制\\r\\n- kafka解决重复消费\\r\\n\\r\\n\\r\\n- Kafka分区机制策略\\r\\n- kafka保证消息不丢失\\r\\n- 消费者组\\r\\n- __consumer_offsets\\r\\n- Kafka总控制器Controller\\r\\n- Kafka副本机制\\r\\n\\r\\n\\r\\n- Producer发布消息机制\\r\\n- 高水位HW和LEO\\r\\n- 数据日志分段存储\\r\\n\\r\\n\\r\\n- Kafka高性能的原因\\r\\n\\r\\n 使用总结\\r\\n- Kafka手动\"},{\"url\":\"/middleware/kafka/kafka-ACK应答机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka生产者保证消息不丢失-ACK应答机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka 生产者写入数据的时候，引入了 ACK 应答机制。\\r\\n\\r\\n```java\\r\\n            Properties props = new Properties();\\r\\n            props.put(\\\"bootstrap.servers\\\", Configuration.KAFKA_ADDRESS);\\r\\n\\t\\t\\t\\t\\t\\t//1:leader应答就可以发送下一条，确保发送成功。\\r\\n            props.put(\\\"acks\\\", \\\"1\\\");\\r\\n\\t\\t\\t\\t\\t\\t......\\r\\n            props.put(\\\"key.serializer\\\", \\\"org.a\"},{\"url\":\"/middleware/kafka/kafka保证消息不丢失.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka保证消息不丢失\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。\\r\\n\\r\\n 生产者端消息丢失\\r\\n\\r\\n生产者发送消息的时候，如果没有发到 kafka 导致消息丢失（网络抖动），其实这并不是 kafka 的原因。\\r\\n\\r\\nkafka 能保证已经提交到 borker 的数据，不会丢失。\\r\\n\\r\\n默认生产者发数据，采用 `send(msg)`发数据，这样发数据之后生产者并不知道是否发送成功。\\r\\n\\r\\n最好使用 `producer.send(msg, callback)` 发数据，这样通过`callback`能够清楚的知道消息是否发送成功。\\r\\n\\r\\n 消费者端消息丢失\\r\\n\\r\\nConsu\"},{\"url\":\"/middleware/kafka/kafka消费模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka消费模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka消费模型分为两种。\\r\\n\\r\\n1. 消费组消费\\r\\n   \\r\\n    消费组里面的单个消费者消费一个分区的数据。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n    \\r\\n    \\r\\n    \\r\\n2. 消费者-worker进程消费。\\r\\n\\r\\n\\r\\n\\r\\n&gt; 第一种消费模型，每个分区对应一个 consumer。\\r\\n&gt; \\r\\n\\r\\n第二种消费模型，只消费数据不处理，处理的工作单独交给 worker线程池，这样可以避免很多 consumer产生的问题。不要把很重的处理逻辑放到消费者中。\\r\\n\\r\\n&gt; 难以保证 offset 的语义正确性，可能导致重复消费。\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n--\"},{\"url\":\"/middleware/kafka/kafka的分区副本规划.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka的分区副本规划\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. topic划分\\r\\n\\r\\n每个日志对应一个topic。\\r\\n\\r\\ntopic 有自己的分区数量和副本数量。一般根据kafka指定的默认数量自动生成。\\r\\n\\r\\n---\\r\\n\\r\\n 2. 分区数量\\r\\n\\r\\n当生产者发给kafka一条消息时，根据规则分到 topic 的指定分区（partition），所以每个分区的数据是不一样的。\\r\\n\\r\\n 规划分区数量\\r\\n\\r\\n消费者在消费数据的时候，也是从分区中消费的，同一个分区只能被消费组里的一个消费者去消费。\\r\\n\\r\\n比如kafka有3个borker时，假如配置topic有5个分区，分配到3个borker就会出现 2 2 1 的情况。\\r\\n\\r\\n所以在指定topic的分区数量时\"},{\"url\":\"/middleware/kafka/kafka解决重复消费.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka解决重复消费\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"技术干货分享 | Kafka重复消费场景及解决方案\\r\\n\\r\\n 导致重复消费的原因\\r\\n\\r\\n- enable.auto.commit 默认值true，表示消费者会周期性自动提交消费的offset\\r\\n- auto.commit.interval.ms 在enable.auto.commit 为true的情况下， 自动提交的间隔，默认值5000ms\\r\\n- max.poll.records 单次消费者拉取的最大数据条数，默认值 500\\r\\n- max.poll.interval.ms 默认值5分钟，表示若5分钟之内消费者没有消费完上一次poll的消息，那么consumer会主动发起离开group的请求\\r\\n1\"},{\"url\":\"/middleware/kafka/数据日志分段存储.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据日志分段存储\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"数据保存机制\\r\\n\\r\\n\\r\\n\\r\\nKafka 的数据是按照分区存储的，以 topic-partition 为目录保存数据。\\r\\n\\r\\n数据是存到 log 中，而 log 又引入了LogSegment机制。\\r\\n\\r\\n`log.segment.bytes`，默认 1G。当超过1G 之后，日志就会开始分割。\\r\\n\\r\\n而日志分段文件以及索引文件都是以基准偏移量（offset）命名的。\\r\\n\\r\\n基本每段的日志文件包含一个数据文件和两个索引文件。\\r\\n\\r\\n- 以offset 为索引的 `.index`。\\r\\n- 以时间戳为索引的 `.timeindex`。\\r\\n\\r\\n索引里面并不是保留全量的数据索引，而是以稀疏索引的方式保存（方\"},{\"url\":\"/middleware/kafka/消费者组.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"消费者组\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。\\r\\n\\r\\n- 组内的所有消费者协调在一起来消费订阅主题（Subscribed Topics）的所有分区（Partition）。\\r\\n- 每个分区只能由同一个消费者组内的一个 Consumer 实例来消费。\\r\\n\\r\\n比如 topic 有 6 个分区，消费者组里面的消费者数量最理想状态是 6 个，每个消费者消费一个分区。也可以是 3 个或者两个，这样分区能够平均分配。\\r\\n\\r\\n但是最好不要超过 6 个消费者，这样的话会有消费者分不到分区。\\r\\n\\r\\n而 topic 的分区设计时，最好和 broker 的数量成比例。比如 3 个\"},{\"url\":\"/middleware/kafka/高水位HW和LEO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"高水位HW和LEO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"LEO（log_end_offset) 指的是当前分区日志末端的 offset。\\r\\n\\r\\n而 HW 指的是整个 LSR 集合副本中，LEO 最小的。保障 Consumer 只能消费到 HW 的位置。\\r\\n\\r\\n首先Leader 和 Followers 都有自己的 HW和 LEO，当有新消息写入 Leader 时，Consumer 并不能立即消费。\\r\\n\\r\\nFollowers 会 pull leader 最新的消息，同步完之后，发送 ACK 给 Leader。然后 Leader会增加 HW。增加之后，新产生的消息才能被 Consumer 消费掉。\\r\\n\\r\\n这样的目的是为了保证当 Leader 挂掉之后，重\"},{\"url\":\"/middleware/rocketmq/Kakfa和RocketMQ的区别.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kakfa和RocketMQ的区别\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"消费者组\\r\\n\\r\\nRocketMQ和Kafka虽然都使用了Consumer Group的概念来实现消息的分发和负载均衡，但两者在具体实现和一些特性上存在一些差异：\\r\\n\\r\\n1. Rebalance机制：\\r\\n    - RocketMQ：RocketMQ的Consumer Group在成员增减或Topic队列发生变化时会触发Rebalance，旨在重新分配队列到各个消费者实例，确保消息的公平消费。RocketMQ的Rebalance更加灵活，支持多种分配策略，例如平均分配、广播消费等，可以根据业务需求进行配置。\\r\\n    - Kafka：Kafka同样在Consumer Group中进行Rebala\"},{\"url\":\"/middleware/rocketmq/MQ接收消息幂等性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MQ接收消息幂等性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"幂等性\\r\\n\\r\\nMQ的消息幂性，指的是MQ接收消息时候的幂等性。\\r\\n\\r\\n- 最多一次\\r\\n    \\r\\n    消息最多只会被消费一次。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n- 最少一次\\r\\n    \\r\\n    消息最少被消费一次。\\r\\n    \\r\\n    &gt; 同步发送、事务消息。\\r\\n    &gt; \\r\\n- 准确消费一次\\r\\n    \\r\\n    默认RocketMQ保证不了准确消费一次。但是商业版本有。\\r\\n    \\r\\n\\r\\n 消息幂等的必要性\\r\\n\\r\\n- 生产者发送消息时，MQ收到消息，但是网络波动导致ACK没有给到生产者。可能会导致重推消息。\"},{\"url\":\"/middleware/rocketmq/RocketMQ基础学习.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ基础学习\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础架构\\r\\n\\r\\n\\r\\n\\r\\n 生产者\\r\\n\\r\\nRocketMQ提供多种发送方式，同步发送、异步发送、顺序发送、单向发送。\\r\\n\\r\\n同步和异步方式均需要 Broker 返回确认信息，单向发送不需要。\\r\\n\\r\\n生产者中，会把同一类 Producer 组成一个集合，叫做生产者组。同一组的 Producer 被认为是发送同一类消息且发送逻辑一致。\\r\\n\\r\\n 消费者\\r\\n\\r\\n 消费者组\\r\\n\\r\\n消费者组消费同一组数据，消费相同topic，并且消费逻辑一致。消费者组的消费者实例必须订阅完全相同的Topic。\\r\\n\\r\\n 消费模式\\r\\n\\r\\nRocketMQ 支持两种消息模式：集群消费（Clustering）和广播消费（Broad\"},{\"url\":\"/middleware/rocketmq/RocketMQ集群架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ集群架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NameServer：提供Broker的路由服务\\r\\n\\r\\nBroker：负责接收Producer的消息，存储消息，将消息投递给Consumer。\\r\\n\\r\\n- Broker需要管理数据，频繁处理数据，所以需要G1、ZGC这种更先进的垃圾回收器。\\r\\n- 而NameServer类似于Broker的注册中心，提供路由功能，只需要简单的垃圾回收算法就可以，比如CMS。\\r\\n\\r\\nProducer：生产者\\r\\n\\r\\nConsumer：消费者\\r\\n\\r\\n 集群架构说明\\r\\n\\r\\n整个RocketMQ集群里面主要分为两部分，Broker和NameServer。\\r\\n\\r\\n整个RocketMQ遵循的是AP架构，追求可用性。\\r\\n\\r\\n N\"},{\"url\":\"/middleware/rocketmq/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- RocketMQ基础学习\\r\\n- RocketMQ集群架构\\r\\n\\r\\n\\r\\n- 消息样例\\r\\n- 顺序消息\\r\\n- 事务消息\\r\\n\\r\\n\\r\\n- 如何保证发送消息有序\\r\\n- 如何保证消息不丢失\\r\\n- MQ接收消息幂等性\\r\\n\\r\\n\\r\\n- Kakfa和RocketMQ的区别\"},{\"url\":\"/middleware/rocketmq/事务消息.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"事务消息\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"事务消息的流程\\r\\n\\r\\n- 先写half消息到RocketMQ\\r\\n- 再执行本地事务\\r\\n  \\r\\n    本地事务有两个方法，一个是回调执行本地事务，另一个是检查本地事务。\\r\\n    \\r\\n    ```java\\r\\n    /**\\r\\n     * 事务监听器，用来处理本地事务\\r\\n     * @author yangjunwei\\r\\n     * @date 2024/7/4\\r\\n     */\\r\\n    public class TransactionListenerImpl implements TransactionListener {\\r\\n        private AtomicInteger\"},{\"url\":\"/middleware/rocketmq/如何保证发送消息有序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"如何保证发送消息有序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类比Kafka的ParitationKey，RocketMQ是messageQueue。\\r\\n\\r\\n将需要保证顺序的消息发给RocketMQ的messageQueue，被同一个消费者消费，即可保证有序。\\r\\n\\r\\n1. 消费者在发送的时候可以指定selector，指定消息发给哪个messageQueue。\\r\\n2. messageQueue是一个FIFO的队列，能够保证消费时按照写入消息的顺序去消费。\\r\\n\\r\\n所以需要保证有顺序的消息，比如相同产品的订单，可以按照产品 code 设置 selector，保证消息发到同一个 messageQueue，这样就能被同一个消费者消费。\\r\\n\\r\\n```java\\r\\nSe\"},{\"url\":\"/middleware/rocketmq/如何保证消息不丢失.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"如何保证消息不丢失\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"消息丢失场景\\r\\n\\r\\n数据丢失在MQ中比较常见，一般丢失数据都是在跨网络的部分，比如1、2、4。\\r\\n\\r\\n- 生产者发数据\\r\\n- 消费者消费数据\\r\\n- MQ内部主从同步\\r\\n\\r\\n而MQ写数据到磁盘过程也是有丢失数据的可能的。\\r\\n\\r\\n一般写数据到磁盘不会直接去写，而是利用操作系统的缓存，先写数据到缓存中，等待操作系统异步刷进磁盘。\\r\\n\\r\\n比如 Prometheus 的 WAL 机制。\\r\\n\\r\\n\\r\\n\\r\\n 事务消息-生产者\\r\\n\\r\\n使用事务消息能保证本地事务和写入MQ的事务一致性。\\r\\n\\r\\n比如订单场景，只保证本地下订单和向MQ发消息的事务一致性。不会像MySQL一样保证数据库事务。\\r\\n\\r\\n只是保证了业务的分布\"},{\"url\":\"/middleware/rocketmq/消息样例.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"消息样例\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"顺序消息\\r\\n\\r\\nkafka的顺序消息可以指定paritationKey实现，相同paritationKey的消息会被发给同一个paritation。\\r\\n\\r\\nRocketMQ可以通过实现 `MessageQueueSelector` 的 `select` 方法自定义实现消息所发给 MessageQueue的逻辑。\\r\\n\\r\\n```java\\r\\n    @SneakyThrows\\r\\n    @Test\\r\\n    public void orderSend() {\\r\\n        try {\\r\\n            DefaultMQProducer producer = new DefaultMQP\"},{\"url\":\"/middleware/rocketmq/顺序消息.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"顺序消息\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"生产者\\r\\n\\r\\n生产者发送消息到MQ的过程，如果要保证顺序消费。\\r\\n\\r\\n只能采用单线程去生产消息，因为多线程无法控制消息生产顺序。\\r\\n\\r\\n还需要保证 sharding key 相同，保证同一类消息发到同一个 ConsumerQueue。\\r\\n\\r\\n\\r\\n&gt; \\r\\n- 单线程生产消息\\r\\n- 发送到同一个ConsumerQueue\\r\\n\\r\\n 存储\\r\\n\\r\\nRocketMQ的存储是按照时间顺序 append write 到 commitlog 中的，同时它会被分发到 ConsumeQueue中。\\r\\n\\r\\n所以只需要生产时候保证消息采用单线程发送到同一个ConsumerQueue，存储时候就能够顺序存储。\\r\\n\\r\"},{\"url\":\"/other/algorithm/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 时间复杂度\\r\\n- 查找\\r\\n- 排序\\r\\n- 动态规划\"},{\"url\":\"/other/algorithm/动态规划.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"动态规划\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"动态规划重要特性\\r\\n\\r\\n动态规划的核心问题是穷举，因为要求最值，要把所有可行答案找出来，找最值。但是穷举的过程中，会存在【重叠子问题】。\\r\\n\\r\\n 重叠子问题\\r\\n\\r\\n在求解的过程中，存在重复的子问题，若是重复解决这些子问题，存在效率低下的问题。\\r\\n\\r\\n而解决重叠子问题，可以使用【备忘录】或者【DP table】方法来解决。\\r\\n\\r\\n- 备忘录\\r\\n  \\r\\n    备忘录的思想就是将已经解决的子问题结果记录在备忘录中（可以是数组等数据结构）。\\r\\n    \\r\\n\\r\\n\\r\\n&gt; \\r\\n- DP table\\r\\n  \\r\\n    使用 DP table 保存每个子问题的结果，自下向上推算结果。\\r\\n    \\r\\n\\r\\n\"},{\"url\":\"/other/algorithm/排序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"排序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"概念\\r\\n\\r\\n 稳定性\\r\\n\\r\\n稳定性指的是相同的数据所在的位置经过排序后是否发生变化。若是排序后，次序不变，则是稳定的。\\r\\n\\r\\n 内部排序\\r\\n\\r\\n排序记录全部存放在内存中进行排序的过程。\\r\\n\\r\\n 外部排序\\r\\n\\r\\n待排序记录的数量很大，以至于内存不能容纳全部记录，在排序过程中尚需对外存进行访问的排序过程。\\r\\n\\r\\n\\r\\n\\r\\n 选择排序-不稳定\\r\\n\\r\\n每次选择剩余待排序元素中的最小值，放到已排序元素的末尾。\\r\\n\\r\\n原理：每次排序选出最小的元素，替换到对应顺序末尾的位置。\\r\\n思路：第一次排序选出最小的元素，和待排序数组第一位的元素进行交换。\\r\\n\\r\\n```json\\r\\n/**\\r\\n     * 选择排序的思路：\"},{\"url\":\"/other/algorithm/时间复杂度.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"时间复杂度\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"O(1)\\r\\n\\r\\n- 数组下表查询\\r\\n\\r\\n O(n)\\r\\n\\r\\n- 链表元素查询，最坏情况是要查n次。\\r\\n\\r\\n O(logn)\\r\\n\\r\\n- 平衡二叉树\\r\\n- 数组二分法查找指定元素\\r\\n\\r\\n开根号\\r\\n\\r\\n- 比如16长度的数组，想要找到指定元素最多需要4次、\\r\\n  \\r\\n    16→8→4→2→1\\r\\n    \\r\\n- 红黑树（平衡二叉树、完全二叉树）\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n O(log n) \\r\\n\\r\\n复杂度解释：\\r\\n\\r\\n- 在一个理想平衡的二叉搜索树中，每次查找操作从根节点开始，通过比较目标值与当前节点的值来决定是向左还是向右子树进行下一步查找。\\r\\n- 每次比较后，查找范围大致减半，这类似于\"},{\"url\":\"/other/algorithm/查找.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"查找\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"静态查找表\\r\\n\\r\\n 顺序查找\\r\\n\\r\\n线性表查询，查找效率（n+1)/2\\r\\n\\r\\n\\r\\n\\r\\n 折半查找\\r\\n\\r\\n\\r\\n\\r\\n二分查找，仅适用于有序的线性表。\\r\\n\\r\\n折半查找比较次数最多为 [log2n]+1 次。n=2^x，比如8个元素最多需要3次，对应 8=2^3。\\r\\n\\r\\n所以时间复杂度为 O(log2n) 。\\r\\n\\r\\n 分块查找\\r\\n\\r\\n特点是块内无序，但是块间有序。\\r\\n\\r\\n- 先在索引表确定目标所在块。\\r\\n- 在块内顺序查找。\\r\\n\\r\\n\\r\\n\\r\\n比如索引表或者索引文件。\\r\\n\\r\\n 哈希表\\r\\n\\r\\n\\r\\n\\r\\n按照哈希存储元素到哈希表里。\\r\\n\\r\\n 哈希冲突解决方式\\r\\n\\r\\n按照值的哈希值存储会出现哈希冲突的问题，可以通\"},{\"url\":\"/other/datastructure/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据结构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 常用数据结构\\r\\n- 二叉树\"},{\"url\":\"/other/datastructure/二叉树.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"二叉树\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"推荐一个练习数据结构的网站\\r\\n\\r\\nData Structure Visualization\\r\\n\\r\\n 二叉树的遍历（重要）\\r\\n\\r\\n以图示二叉树为例。\\r\\n\\r\\n\\r\\n\\r\\n 中序遍历\\r\\n\\r\\n简化为每个树，都是左中右即可。\\r\\n\\r\\n中序遍历（LDR）是二叉树遍历的一种，也叫做中根遍历、中序周游。在二叉树中，中序遍历首先遍历左子树，然后访问根结点，最后遍历右子树。\\r\\n\\r\\n*左子树 → 根节点 → 右子树*\\r\\n\\r\\n图示二叉树中序遍历结果为：`3、5、6、10、14、15、17、20`；\\r\\n\\r\\n参考代码：Java实现中序遍历\\r\\n\\r\\n 前序遍历\\r\\n\\r\\n前序遍历（VLR）， 1] 是[二叉树遍历的一种，也叫做先根遍历\"},{\"url\":\"/other/datastructure/常用数据结构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"常用数据结构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"存储结构\\r\\n\\r\\n\\r\\n\\r\\n 复杂度\\r\\n\\r\\n时间复杂度\\r\\n\\r\\n空间复杂度\\r\\n\\r\\n 线性表\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 串\\r\\n\\r\\n比如字符串。\\r\\n\\r\\n\\r\\n\\r\\n 数组\\r\\n\\r\\n\\r\\n\\r\\n 矩阵\\r\\n\\r\\n\\r\\n\\r\\n求矩阵元素下标，直接代入即可。\\r\\n\\r\\n\\r\\n\\r\\n代入 A(0,0) 和 A(0,1)，分别对应 M(1) 和 M(2)。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 广义表\\r\\n\\r\\n\\r\\n\\r\\n例1：长度为3，深度为2\\r\\n\\r\\n例2: 先取表尾，再取表头，再取表头。\\r\\n\\r\\nhead (head ( tail(LS1) ) )\\r\\n\\r\\n 广义表的基本运算\\r\\n\\r\\n1. 取表头\\r\\n2. 取表尾\\r\\n\\r\\n 二叉树\\r\\n\\r\\n\\r\\n\\r\\n- 满二叉树\"},{\"url\":\"/other/design/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"设计模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"设计模式的目的\\r\\n\\r\\n* 代码重用性（提取重复代码）\\r\\n* 可读性（代码规范，便于阅读）\\r\\n* 可扩展性（方便增加新功能）\\r\\n* 可靠性（增加新功能，对以前的功能没有影响）\\r\\n* 使程序呈现高内聚、低耦合的特性\\r\\n\\r\\n 设计模式的七大基本原则\\r\\n\\r\\ndesign-principle\\r\\n\\r\\n* 单一职责原则\\r\\n\\r\\n* 接口隔离原则\\r\\n\\r\\n* 依赖倒置原则\\r\\n\\r\\n* 里氏替换原则\\r\\n\\r\\n* 开闭原则\\r\\n\\r\\n* 迪米特法则\\r\\n\\r\\n* 合成复用法则\\r\\n\\r\\n 设计模式三大类型\\r\\n\\r\\n 1. 创建型模式\\r\\n\\r\\ndesign-create\\r\\n\\r\\n* 单例模式\\r\\n\\r\\n    * 序列化和反序列化\\r\\n\\r\\n* 工\"},{\"url\":\"/other/design/七大基本原则.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"七大基本原则\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-principle\\r\\n\\r\\n 单一职责原则\\r\\n\\r\\n1. 一种类只能具有一种职责，降低类的复杂度。\\r\\n2. 提高类的可读性，可维护性。\\r\\n3. 降低变更引起的风险。\\r\\n4. 在类中的方法比较少的时候，可以在方法级别保持单一职责原则。其他情况下，都要保持类的类单一职责原则。\\r\\n\\r\\n 接口隔离原则\\r\\n\\r\\n1. 客户端不应该依赖它不需要的接口。\\r\\n2. 一个类对另一个类的依赖应该建立在最小的接口上。\\r\\n\\r\\n 依赖倒置原则\\r\\n\\r\\n1. 依赖倒置原则的中心思想是面向接口编程。\\r\\n2. 抽象不应该依赖细节，细节应该依赖抽象。抽象是接口或者抽象类，细节即为实现类。\\r\\n3. 对于细节的多变性，抽象的\"},{\"url\":\"/other/design/创建型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"创建型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-create\\r\\n\\r\\n 单例模式\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 饿汉式\\r\\n\\r\\n特点：类创建时创建对象，节省时间，占用内存，`以空间换时间`。\\r\\n\\r\\n1. 静态变量实现\\r\\n    \\r\\n    类加载时创建对象，节省时间，占用内存，`以空间换时间`。`推荐使用`，但是比较浪费空间。\\r\\n    \\r\\n    ```java\\r\\n    \\t\\t/**\\r\\n         * 类加载时创建对象，节省时间，占用内存，以空间换时间\\r\\n         */\\r\\n        private final static SingletonHungryOne INSTANCE = new Singleton\"},{\"url\":\"/other/design/结构型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"结构型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-structural\\r\\n\\r\\n 代理模式\\r\\n\\r\\n代理模式是属于结构型的设计模式,指客户端的请求到达真正的对象之前，做一些额外的操作。\\r\\n\\r\\n 静态代理模式\\r\\n\\r\\n\\r\\n以 AspectJ 为代表。指代理类在编译期生成的，与动态代理相比，效率会很高，但是会生成大量代理类。\\r\\n\\r\\n 动态代理模式\\r\\n\\r\\n以 SpringAOP 为代表为代表，代理类是动态生成的。虽然会效率会低一点，但是大大简化了代码和开发量。\\r\\n\\r\\n- JDK 动态代理\\r\\n- CGlib 动态代理\\r\\n\\r\\n 桥接模式\\r\\n\\r\\n抽象类：定义一个抽象类，作为系统的一部分。\\r\\n\\r\\n实现类：定义一个或多个实现类，与抽象类通过聚合（而非\"},{\"url\":\"/other/design/行为型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"行为型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-behavioral\\r\\n\\r\\n 责任链模式\\r\\n\\r\\n责任链模式——某个请求需要多个对象进行处理，从而避免请求的发送者和接收之间的耦合关系。将这些对象连成一条链子，并沿着这条链子传递该请求，直到有对象处理它为止。主要涉及两个角色：\\r\\n\\r\\n\\r\\n- 抽象处理者角色（Handler）：定义出一个处理请求的接口。这个接口通常由接口或抽象类来实现。\\r\\n- 具体处理者角色（ConcreteHandler）：具体处理者接受到请求后，可以选择将该请求处理掉，或者将请求传给下一个处理者。因此，每个具体处理者需要保存下一个处理者的引用，以便把请求传递下去。\\r\\n\\r\\n 优缺点比较\\r\\n\\r\\n优点\\r\\n\\r\\n- 降低耦\"},{\"url\":\"/other/network/HTTP1x和HTTP2x.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP1x和HTTP2.x\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HTTP1.x\\r\\n\\r\\n 数据格式\\r\\n\\r\\nHTTP1.x基于文本传输。\\r\\n\\r\\n- 请求行\\r\\n- 请求头\\r\\n- 请求体\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 缺点\\r\\n\\r\\n1. 占用字节：在HTTP请求中，包含很多空格和换行符。\\r\\n2. 头部不能压缩：在HTTP1.x中，请求头不能压缩。所以存在请求头比较大的问题，出现大头儿子。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n3. 传输效率低：同一个链接（`Keep-Alive`的情况）同时只能处理一个请求，收到响应才会开始发送下一个请求。\\r\\n    - 如果不设置 `Keep-Alive`，则每一次HTTP请求都会新建一个TCP链接。\\r\\n    \\r\\n    &g\"},{\"url\":\"/other/network/HTTP和HTTPS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP和HTTPS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HTTP 和 HTTPS 的区别\\r\\n\\r\\n- 传输问题。\\r\\n    - HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。\\r\\n    - HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。\\r\\n- 建立连接过程。\\r\\n    - HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。\\r\\n    - HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。\\r\\n- 两者的默认端口不一样。\\r\\n    - HTTP 默认端口号是 80。\\r\\n\"},{\"url\":\"/other/network/HTTP常见字段.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP常见字段\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```json\\r\\nPOST /apmServer-sl/sys-user/login HTTP/1.1\\r\\nAccept: application/json, text/plain, */*\\r\\nAccept-Encoding: gzip, deflate\\r\\nAccept-Language: zh-CN,zh;q=0.9\\r\\nAuthorization: clusterid34\\r\\nConnection: keep-alive\\r\\nContent-Length: 101\\r\\nContent-Type: application/json\\r\\nCookie: apm.name=admin\\r\\nHost: 10.1\"},{\"url\":\"/other/network/Linux如何收发网络包.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Linux如何收发网络包\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"2.3 Linux 系统是如何收发网络包的？\\r\\n\\r\\n 网络协议栈\\r\\n\\r\\n\\r\\n\\r\\n1. 应用程序需要通过系统调用，来和 Socket 进程数据交互。\\r\\n2. Socket 层是介于应用层和传输层之间的抽象层。\\r\\n3. 最下面的一层，则是网卡驱动程序和硬件网卡设备。\\r\\n\\r\\n Linux 接收和发送网络包的流程\"},{\"url\":\"/other/network/OSI七层网络模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"OSI七层网络模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 应用层，负责给应用程序提供统一的接口；\\r\\n- 表示层，负责把数据转换成兼容另一个系统能识别的格式；\\r\\n- 会话层，负责建立、管理和终止表示层实体之间的通信会话；\\r\\n- 传输层，负责端到端的数据传输；\\r\\n- 网络层，负责数据的路由、转发、分片；\\r\\n- 数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址；\\r\\n- 物理层，负责在物理网络中传输数据帧；\"},{\"url\":\"/other/network/RTT和SRTT.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RTT和SRTT\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"RTT\\r\\n\\r\\nRTT 指的是客户端发出数据 → 客户端收到服务端发送的确认数据的时间。\\r\\n\\r\\nRTT 称为往返时延。\\r\\n\\r\\n SRTT\\r\\n\\r\\nSRTT（Smoothed Round Trip Time）是一种用于衡量网络延迟的指标，通常用于评估网络连接的质量和性能。SRTT表示在一系列网络往返（Round Trip）中的平滑往返时间。\\r\\n\\r\\nSRTT是通过在每次往返时间（RTT）的基础上应用加权平均算法来计算得出的。加权平均算法会给最近的RTT值更高的权重，以反映出网络延迟的实时变化。\\r\\n\\r\\nSRTT的值越小，表示网络延迟越低，网络连接的质量越好。较低的SRTT值通常意味着网络响应更快，数据传\"},{\"url\":\"/other/network/Socket.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Socket\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Socket 位于应用层和传输层之前的抽象层，是一组调用接口，TCP/IP网络的API函数。\\r\\n\\r\\n实际上是对 TCP/IP协议的封装，只是为了更方便使用 TCP/IP 协议。\\r\\n\\r\\n\\r\\n这个就像操作系统会提供标准的编程接口，比如win32编程接口一样。\\r\\nTCP/IP也要提供可供程序员做网络开发所用的接口，这就是Socket编程接口。\\r\\n&gt; \\r\\n\\r\\n Socket 通信流程\\r\\n\\r\\n\\r\\n\\r\\nSocket按照四元组来标识不同客户端与服务端之间的连接。\\r\\n\\r\\n四元组「源 IP、源端口、目的 IP、目的端口」\\r\\n\\r\\n- `accept()`\\r\\n  \\r\\n    服务端绑定端口之后，进入 `acc\"},{\"url\":\"/other/network/TCPIP四层网络模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP/IP四层网络模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"为什么要有网络模型\\r\\n\\r\\n进程通信的方式\\r\\n\\r\\n- 本机\\r\\n    - 消息队列\\r\\n    - 共享内存\\r\\n    - 管道（程序用来交换数据的地方）\\r\\n- 不同主机\\r\\n    - 网络通信\\r\\n\\r\\n需要网络通信的设备是多种多样的，所以要兼容，就要设定网络通信之间的网络协议。\\r\\n\\r\\n 应用层\\r\\n\\r\\n应用层定义了应用进程之间通信和交互的规则，应用层交互数据单元为报文。\\r\\n\\r\\n不关心数据如何传输，将报文传给传输层做传输。\\r\\n\\r\\n在这一层有很多熟悉的协议，比如 HTTP、HTTPS、DNS等。\\r\\n\\r\\n【计算机网络】TCP / IP 四层协议_tcp/ip协议包含哪几层_L Jiawen的博客-CSDN\"},{\"url\":\"/other/network/TCP分析工具.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP分析工具\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Wireshark · Go Deep\\r\\n\\r\\n\\r\\n\\r\\n 三次握手\\r\\n\\r\\n\\r\\n\\r\\n 第1次握手\\r\\n\\r\\n\\r\\n\\r\\nsyn设置为1，表明这是一个 SYN包\\r\\n\\r\\n\\r\\n\\r\\nseq = 1390201126\\r\\n\\r\\n\\r\\n\\r\\n 第2次握手\\r\\n\\r\\nsyn=1 同时 ACK=1，表明这是一个 SYN/ACK包\\r\\n\\r\\n\\r\\n\\r\\n服务端返回的 ACK = 客户端第一次发送的 seq+1 = 1390201126+1\\r\\n\\r\\n同时服务端向客户端返回了自己的 seq（如果第三次握手客户端返回的ack=seq+1，代表客户端收到了自己发的seq）\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n 第3次握手\\r\\n\\r\\n可以看到第 3 次握手的\"},{\"url\":\"/other/network/TCP协议.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP协议\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"TCP 协议灵魂 12 问，巩固你的网路底层基础！-腾讯云开发者社区-腾讯云\\r\\n\\r\\n\\r\\n\\r\\n TCP和UDP的区别\\r\\n\\r\\n- 面向连接\\r\\n    - TCP 需要客户端与服务端之间通过三次握手建联，之后才可以发送数据。\\r\\n    - UDP直接向服务端发数据包。\\r\\n- 可靠性\\r\\n    - 有状态\\r\\n        - TCP发数据包时，保证数据包按顺序到达。\\r\\n    - 可控制\\r\\n        - 当TCP协议丢包时，可以控制重发和自己的发送速度，保证数据包完整和有序。\\r\\n    - UDP 是无状态并且不可控的。\\r\\n- 基于字节流\\r\\n    - TCP将数据包通过字节流发送。\\r\\n   \"},{\"url\":\"/other/network/TCP粘包拆包.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP粘包拆包\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"发生粘包的原因\\r\\n\\r\\n- 要发送的数据小于 TCP 发送缓冲区的大小，TCP 将多次写入缓冲区的数据一次发送出去，将会发生粘包；\\r\\n- 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包；\\r\\n- 要发送的数据大于 TCP 发送缓冲区剩余空间大小，将会发生拆包；\\r\\n- 待发送数据大于 MSS（最大报文长度），TCP 在传输前将进行拆包。即 TCP 报文长度 - TCP 头部长度 \\r\\n\\r\\n 解决粘包拆包问题\\r\\n\\r\\n- 定长消息：发送端将每个数据包封装为固定长度\\r\\n- 特殊分隔符：在数据尾部增加特殊字符进行分割\\r\\n- 消息头：将数据分为两部分，一部分是头部，一部分是内容体；其中头部结构大小\"},{\"url\":\"/other/network/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"计算机网络\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础\\r\\n\\r\\n- TCP/IP四层网络模型\\r\\n- OSI七层网络模型\\r\\n- 网址访问页面中间发生了哪些过程\\r\\n- Linux如何收发网络包\\r\\n- 网络包的封装原理\\r\\n- Socket\\r\\n\\r\\n TCP\\r\\n\\r\\n- TCP协议\\r\\n- TCP分析工具\\r\\n\\r\\n\\r\\n- RTT和SRTT\\r\\n- 流量控制-滑动窗口\\r\\n\\r\\n- 拥塞控制\\r\\n- 重传机制\\r\\n- TCP粘包拆包\\r\\n\\r\\n\\r\\n UDP\\r\\n\\r\\nUDP不需要连接，可以单播和广播。\\r\\n\\r\\n HTTP\\r\\n- HTTP常见字段\\r\\n- HTTP和HTTPS\\r\\n- HTTP1x和HTTP2x\\r\\n\\r\\n 参考链接\\r\\n\\r\\n图解网络介绍\"},{\"url\":\"/other/network/拥塞控制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"拥塞控制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"流量控制是避免数据填满发送方的缓冲区。\\r\\n\\r\\n而拥塞控制是避免发送方的数据填满整个网络。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n在⽹络出现拥堵时，如果继续发送⼤量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是⼀重传就会导致⽹络的负担更重，于是会导致更⼤的延迟以及更多的丢包，这个情况就会进⼊恶性循环被不断地放⼤….\\r\\n\\r\\n所以，TCP 不能忽略整个网络中发⽣的事，它被设计成⼀个⽆私的协议，当⽹络发送拥塞时，TCP 会⾃我牺牲，降低发送的数据流。\\r\\n\\r\\n 拥塞窗口\\r\\n\\r\\n拥塞窗⼝ cwnd是发送⽅维护的⼀个的状态变量，它会根据⽹络的拥塞程度动态变化的。\\r\\n\\r\\n发送窗⼝ swnd 和接\"},{\"url\":\"/other/network/流量控制-滑动窗口.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"流量控制-滑动窗口\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在TCP中，滑动窗口用来流量控制。确保发送方不会过快的发送数据导致接收方无法处理数据。\\r\\n\\r\\nTCP拥塞控制是为了解决发送方以过高的速率发送导致网络中出现阻塞，其核心思想就是发生重传时控制发送方滑动窗口（通过控制拥塞窗口cwnd）的大小，从而控制其发送速率。\\r\\n\\r\\n 滑动窗口\\r\\n\\r\\nTCP窗口包括发送窗口和接收窗口，用来限制不同端所能容纳数据的上限，达到控制发送数据的速率。\\r\\n\\r\\n\\r\\n\\r\\nTCP报文里面的窗口大小，作用是告诉对方本端的接受缓冲区还能容纳多少字节的数据。\\r\\n\\r\\n\\r\\n\\r\\n在通信过程中，接收方每次收到数据包，在发送确认报文的时候，还需要告诉发送方自己的缓冲区剩余大小。缓冲区剩余大小，\"},{\"url\":\"/other/network/网址访问页面中间发生了哪些过程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"网址访问页面中间发生了哪些过程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"2.2 键入网址到网页显示，期间发生了什么？\\r\\n\\r\\n URL解析\\r\\n\\r\\n URL组成信息\\r\\n\\r\\nURL实际上就是访问 Web服务器里面的文件资源。\\r\\n\\r\\n\\r\\n\\r\\n 组装HTTP报文\\r\\n\\r\\n根据 URL 解析得到的内容，进行报文组装。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n DNS域名解析\\r\\n\\r\\n解析URL时，如果web服务器是域名，需要走DNS服务器进行域名解析，得到真实访问的IP地址。\\r\\n\\r\\n 域名组成\\r\\n\\r\\n`www.server.com.` 类似树状结构，越右等级越高。\\r\\n\\r\\n域名组成都代表了DNS服务器，里面保存了域名和IP的对应关系。\\r\\n\\r\\n域名服务器就像是一个树状结构。\\r\\n\\r\\n- 根\"},{\"url\":\"/other/network/网络包的封装原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"网络包的封装原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 TCP/IP 四层网络模型中，网络包每层的包装如下：\\r\\n\\r\\n- 传输层，给应用数据前面增加了 TCP 头；\\r\\n- 网络层，给 TCP 数据包前面增加了 IP 头；\\r\\n- 网络接口层，给 IP 数据包前后分别增加了帧头和帧尾；\\r\\n\\r\\n每层增加的头部和尾部，都有每层独特的作用，按照各自的协议填充。\\r\\n\\r\\n在物理链路上并不能传输任意大小的数据包，在以太网中，规定了最大传输单元（MTU）为 1500 字节，规定了单次传输的最大 IP 包的大小。\\r\\n\\r\\n当网络包超过 MTU 时，就会在网络层分片，确保分片后的包不会超过 MTU 大小。\\r\\n\\r\\n- 如果 MTU 越小，网络包分片数越多，那么网络吞吐能力\"},{\"url\":\"/other/network/重传机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"重传机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"超时重传\\r\\n\\r\\n原理是在发送某一个数据以后就开启一个计时器，在一定时间内如果没有得到发送的数据报的 ACK 报文，那么就重新发送数据，直到发送成功为止。\\r\\n\\r\\n RTT\\r\\n\\r\\nRTT（Round-Trip Time，往返时间）。数据包一次的往返时间。\\r\\n\\r\\n\\r\\n\\r\\nSRTT：平均的RTT\\r\\n\\r\\n 缺点\\r\\n\\r\\n- 当一个报文丢失时，会等待一定的超时周期，才重传分组，增加了端到端的时延。\\r\\n- 当一个报文丢失时，在其等待超时的过程中，可能会出现这种情况：其后的报文段已经被接收端接收但却迟迟得不到确认，发送端会认为也丢失了，从而引起不必要的重传，既浪费资源也浪费时间。\\r\\n- 并且，对于 TCP，如果\"},{\"url\":\"/other/observability/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可观测性常见维度\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"可观测性指的是对于系统内部运行状态的全面洞察和理解能力。\\r\\n\\r\\n可观测性项⽬旨在提供⼯具和解决⽅案，帮助开发⼈员和运维团队更好地监视、调试和理解其应⽤程序的行为。\\r\\n\\r\\n 维度\\r\\n\\r\\n- 日志采集 （log）\\r\\n- 指标采集 （Metric）\\r\\n- 链路追踪（Trace）\\r\\n- 告警管理（AlertManager）\\r\\n- 可视化（Visualization）\\r\\n\\r\\n整个可观测项目，维度除了常见的 log、metric、trace之外。还包括告警和可视化。\\r\\n\\r\\n 指标\\r\\n\\r\\n指标又可以分为：\\r\\n\\r\\n- 基础设施\\r\\n\\r\\n  服务器、数据库、MQ的指标。\\r\\n\\r\\n- 应用维度\\r\\n\\r\\n  应用包含模块\"},{\"url\":\"/other/observability/log/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"日志收集全链路\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ELFK\\r\\n\\r\\nELFK 指的是 elasticsearch+logstash+filebeat+kibana\\r\\n\\r\\n 日志管理\\r\\n\\r\\n日志收集→格式化分析→检索和可视化→日志告警\\r\\n\\r\\n\\r\\n\\r\\n 日志架构\\r\\n\\r\\n 小规模环境\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 大规模生产环境\\r\\n\\r\\nELFK + Kafka\\r\\n\\r\\n Logstash\\r\\n\\r\\n从多个来源采集数据，转换数据，然后将数据放到不同的数据库中。\\r\\n\\r\\nda 就很像 logstash 的功能设计。\\r\\n\\r\\n 架构\\r\\n\\r\\n\\r\\n\\r\\nLogstash 接入数据源数据，经过内部 Pipeline，将数据可以写到不同的存储（ES、Kafka）里面。\\r\\n\\r\\nLog\"},{\"url\":\"/other/observability/opentelemetry/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Opentelemetry\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"docs-cn/OT.md at main · open-telemetry/docs-cn\\r\\n\\r\\n OpenTracing&OpenCensus\\r\\n\\r\\n- OpenTracing 制定了一套平台无关、厂商无关的协议标准，使得开发人员能够方便的添加或更换底层 APM 的实现。\\r\\n- OpenCensus支持Metrics、分布式跟踪。\\r\\n\\r\\n OpenTelemetry\\r\\n\\r\\nOpenTelemetry 的核心工作目前主要集中在 3 个部分：\\r\\n\\r\\n1. 规范的制定和协议的统一，规范包含数据传输、API的规范。协议的统一包含：HTTP W3C的标准支持及GRPC 等框架的协议标准。\\r\\n2. 多\"},{\"url\":\"/other/observability/opentelemetry/可观测性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可观测性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"可观测性指的是对于系统内部运行状态的全面洞察和理解能力。\\r\\n\\r\\n可观测性项⽬旨在提供⼯具和解决⽅案，帮助开发⼈员和运维团队更好地监视、调试和理解其应⽤程序的行为。\\r\\n\\r\\n 维度\\r\\n\\r\\n- 日志采集 （log）\\r\\n- 指标采集 （Metric）\\r\\n- 链路追踪（Trace）\\r\\n- 告警管理（AlertManager）\\r\\n- 可视化（Visualization）\\r\\n\\r\\n整个可观测项目，维度除了常见的 log、metric、trace之外。还包括告警和可视化。\\r\\n\\r\\n 指标\\r\\n\\r\\n指标又可以分为：\\r\\n\\r\\n- 基础设施\\r\\n\\r\\n  服务器、数据库、MQ的指标。\\r\\n\\r\\n- 应用维度\\r\\n\\r\\n  应用包含模块\"},{\"url\":\"/other/observability/skywalking/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Skywalking\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Skywalking\\r\\n\\r\\n- 组件安装\\r\\n- 源码学习\"},{\"url\":\"/other/observability/skywalking/源码学习.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"源码学习\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Category: SkyWalking | 芋道源码 —— 纯源码解析博客\\r\\n\\r\\nSkyWalking8.7源码解析\\r\\n\\r\\n 告警组件\\r\\n\\r\\n 初始化Kafka消费者\\r\\n\\r\\n```java\\r\\n@Slf4j\\r\\npublic class KafkaFetcherProvider extends ModuleProvider {\\r\\n    private KafkaFetcherHandlerRegister handlerRegister;\\r\\n    private KafkaFetcherConfig config;\\r\\n\\r\\n    @Override\\r\\n    public String na\"},{\"url\":\"/other/observability/skywalking/组件安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"组件安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"OAP\\r\\n\\r\\n- 配置文件\\r\\n  \\r\\n    ```java\\r\\n    apache-skywalking-apm-bin/config/application.yml\\r\\n    ```\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n- 启动脚本\\r\\n  \\r\\n    ```java\\r\\n    sh bin/oapService.sh\\r\\n    ```\\r\\n    \\r\\n\\r\\n UI\\r\\n\\r\\n- 配置\\r\\n  \\r\\n    ```java\\r\\n    apache-skywalking-apm-bin/webapp/webapp.yml\\r\\n    ```\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n- 启动脚本\\r\\n  \\r\\n    ```java\\r\\n\"},{\"url\":\"/personal/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"personal\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"&lt;div align=\\\"center\\\"\\r\\n  &lt;img src=\\\"https://capsule-render.vercel.app/api?type=waving&color=gradient&height=300&section=header&text=Albert%20Yang&fontSize=90&animation=fadeIn&fontAlignY=38&desc=热爱编程%20|%20追求卓越%20|%20创新思维&descAlignY=55&descAlign=62\\\" /&gt;\\r\\n&lt;/div&gt;\\r\\n&lt;p align=\\\"center\\\" style=\"}],\"sortPostsByDate\":[{\"url\":\"/cloudnative/docker/Docker学习总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Docker学习总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本知识\\r\\n\\r\\n 1. Docker 是什么？\\r\\n\\r\\ndocker 是一种容器化虚拟技术，解决了运行环境和配置问题，方便持续集成并有助于项目整体发布。\\r\\n\\r\\n 2. Docker 能干嘛？\\r\\n\\r\\n*一次构建、随处运行。*\\r\\n\\r\\n- 更快速的应用交付和部署。\\r\\n- 更便捷的升级和扩缩容。\\r\\n- 更简单的系统运维。\\r\\n- 更高效的计算源利用。\\r\\n\\r\\n 基本组成\\r\\n\\r\\n 1. 镜像\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 2. 容器\\r\\n\\r\\n&gt; Docker 利用容器（Container）独立运行一个或一组应，容器是用镜像创建的运行实例。\\r\\n&gt; \\r\\n\\r\\n它可以被启动、开始、停止、删除。每个容器都是相\"},{\"url\":\"/cloudnative/docker/docker镜像压缩.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"docker镜像压缩\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"tar包\\r\\n\\r\\n\\r\\n\\r\\n```\\r\\ndocker save tomcat-apm-0915 -o ./tomcat-apm-0915.tar\\r\\n```\\r\\n\\r\\n```\\r\\ndocker load &lt; tomcat-apm-0915.tar\\r\\n```\\r\\n\\r\\nDocker 复制镜像到其他主机 - 彦祚 - 博客园\\r\\n\\r\\n tar.gz包\\r\\n\\r\\n 保存镜像\\r\\n\\r\\n`docker save &lt;myimage\\r\\n\\r\\n```\\r\\ndocker save xxx:xxx| gzip&gt;xxx.tar.gz\\r\\n```\\r\\n\\r\\n 加载镜像\\r\\n\\r\\n`gunzip -c &lt;myimage&gt;_&lt\"},{\"url\":\"/cloudnative/docker/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Docker\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"学习总结\\r\\n- Docker学习总结\\r\\n\\r\\n\\r\\n 使用总结\\r\\n- 容器软件安装\\r\\n- docker镜像压缩\\r\\n- 制作Tomcat镜像\\r\\n- 容器新增bash\"},{\"url\":\"/cloudnative/docker/制作Tomcat镜像.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"制作Tomcat镜像\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"DockerFile文件内容\\r\\n\\r\\n- tomcat 基础镜像\\r\\n  \\r\\n    ```bash\\r\\n    \\r\\n     使用基于 JDK 8 的官方 Tomcat 镜像作为基础镜像\\r\\n    FROM tomcat:8-jdk8\\r\\n    \\r\\n     修改默认的 shell\\r\\n    RUN ln -sf /bin/bash /bin/sh\\r\\n    \\r\\n     暴露 Tomcat 的默认 HTTP 端口\\r\\n    EXPOSE 8080\\r\\n    \\r\\n     设置容器启动时执行的命令\\r\\n    CMD [\\\"catalina.sh\\\", \\\"run\\\"]\\r\\n    ```\\r\\n    \\r\\n- \"},{\"url\":\"/cloudnative/docker/容器新增bash.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"容器新增bash\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"安装方式\\r\\n\\r\\n- wget 下载\\r\\n  \\r\\n    ```bash\\r\\n    from busybox\\r\\n    \\r\\n     下载 bash 二进制文件\\r\\n    RUN wget -O /bin/bash http://ftp.gnu.org/gnu/bash/bash-5.1.tar.gz\\r\\n    \\r\\n     设置可执行权限\\r\\n    RUN chmod +x /bin/bash\\r\\n    \\r\\n     运行命令\\r\\n    CMD [\\\"echo\\\", \\\"Hello, World!\\\"]\\r\\n    ```\\r\\n    \\r\\n- 本地安装\\r\\n  \\r\\n    ```bash\\r\\n    from \"},{\"url\":\"/cloudnative/docker/容器软件安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"容器软件安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"RabbitMQ\\r\\n\\r\\n参考博客\\r\\n\\r\\ndocker安装RabbitMQ\\r\\n\\r\\n---\\r\\n\\r\\n1. 查找镜像\\r\\n   \\r\\n    ```java\\r\\n    docker search rabbitmq\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n2. 拉取镜像\\r\\n   \\r\\n    ```java\\r\\n    docker pull rabbitmq\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 启动镜像\\r\\n   \\r\\n    ```java\\r\\n    docker run -d --hostname my-rabbit --name rabbit -p 15672:15\"},{\"url\":\"/cloudnative/k8s/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"K8s\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- k8s常用命令\\r\\n- k8s问题排查流程图\"},{\"url\":\"/cloudnative/k8s/k8s常用命令.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"k8s常用命令\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"常用命令总结\\r\\n\\r\\n node\\r\\n\\r\\n- 查看所有的node\\r\\n  \\r\\n    ```\\r\\n    kubectl get nodes\\r\\n    ```\\r\\n    \\r\\n- 查看node名与Host文件的相互解析\\r\\n  \\r\\n    ```\\r\\n    cat /etc/hosts\\r\\n    ```\\r\\n    \\r\\n- 查看本机 hostname\\r\\n  \\r\\n    `Plain Text   cat /etc/hostname`\\r\\n    \\r\\n\\r\\n namespace\\r\\n\\r\\n- 查看所有的namespace\\r\\n  \\r\\n    ```\\r\\n    [root@master ~] kubectl  get n\"},{\"url\":\"/cloudnative/k8s/k8s问题排查流程图.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"k8s问题排查流程图\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"深度解密｜基于 eBPF 的 Kubernetes 问题排查全景图发布-阿里云开发者社区\"},{\"url\":\"/cloudnative/prometheus/TSDB.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TSDB\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Prometheus的 TSDB（Time Series Database）作为内置的时序数据库。\\r\\n\\r\\n 存储原理\\r\\n\\r\\nTSDB 既使用内存也使用磁盘进行数据存储。\\r\\n\\r\\n\\r\\n\\r\\n Head\\r\\n\\r\\n在Prometheus中，Head 是数据库的内存部分，用于存储最近写入的数据。\\r\\n\\r\\n当数据在Head中存储2小时后，会被转移到磁盘上的持久块（block）中。这些持久块是不变的，每个块代表一段时间的数据，并且按照时间顺序进行组织和存储。\\r\\n\\r\\n\\r\\n\\r\\n Block块\\r\\n\\r\\nPrometheus中以每2个小时为一个时间窗口，即将2小时内产生的数据存储在一个block中，监控数据会以时间段的形式\"},{\"url\":\"/cloudnative/prometheus/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Prometheus\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 架构\\r\\n- TSDB\\r\\n- 数据模型\\r\\n- node_exporter源码\"},{\"url\":\"/cloudnative/prometheus/node_exporter源码.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"node_exporter源码\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"简单流程\\r\\n\\r\\n1. 定时任务 30s 执行一次\\r\\n    1. 调用采集指标的方法\\r\\n2. 不同 Collector 采集自己的指标\\r\\n    1. 内存\\r\\n        - 读取 `/`@\\r\\n          \\r\\n            `proc/meminfo`文件内容\\r\\n            \\r\\n            ```go\\r\\n            MemTotal:       16267496 kB\\r\\n            MemFree:          803084 kB\\r\\n            MemAvailable:    1507880 kB\\r\\n \"},{\"url\":\"/cloudnative/prometheus/数据模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Prometheus的存储实现上所有的监控样本都是以 time-series 的形式保存在 Prometheus 内置的TSDB（时序数据库）中，而 time-series 所对应的监控指标 (metric) 也是通过 labelset 进行唯一命名的。\\r\\n\\r\\n 样本数据\\r\\n\\r\\n- 指标(metric)：metric name 和描述当前样本特征的 labelsets;\\r\\n- 时间戳(timestamp)：一个精确到毫秒的时间戳;\\r\\n- 样本值(value)： 一个float64的浮点型数据表示当前样本的值。\\r\\n\\r\\n```\\r\\n&lt;--------------- metric -------\"},{\"url\":\"/cloudnative/prometheus/架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Prometheus架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- Promtheus 默认采取主动拉的策略，可以配置各个exporter的拉取间隔。\\r\\n    - Exporter 被动暴露数据，Prometheus 主动拉取。\\r\\n- 但是Promtheus也可以使用 Pushgateway 实现 Push 模型。\\r\\n    - exporter 将数据推给 Pushgateway，Promtheus从Pushgateway拉数据。\"},{\"url\":\"/database/clickhouse/ClickHouse基础.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse基础\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"列式存储\\r\\n\\r\\nclickhouse 是 *列式存储* 数据库\\r\\n\\r\\n在磁盘上按列存储，即按某个字段进行存储。\\r\\n\\r\\n\\r\\n\\r\\n所以列式存储更适合进行查询，比如某一行的聚合、计算、求和等。\\r\\n\\r\\n 列式存储的好处\\r\\n\\r\\n1. 对于某列的聚合、计数、求和等操作要比行式存储更快。\\r\\n   \\r\\n    查询更快。\\r\\n    \\r\\n    - 行式存储，增改删更加方便，因为只需要找到对应的行记录，直接删除即可。但是列式存储对比起来，增改删要更繁琐一点。\\r\\n2. 每一列的数据类型是一样的，这样能更好的进行数据压缩。\\r\\n   \\r\\n    方便数据压缩，节省磁盘\\r\\n    \\r\\n    - 与 es 相比，作为常\"},{\"url\":\"/database/clickhouse/ClickHouse安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"docker下安装clickhouse_docker 安装clickhouse-CSDN博客\\r\\n\\r\\n使用 clickhouse-client 进入 ck\\r\\n\\r\\n mac 安装\\r\\n\\r\\n```java\\r\\ndocker run --rm -d --name=clickhouse \\\\\\r\\n-e CLICKHOUSE_ADMIN_PASSWORD=\\\"123456\\\" \\\\\\r\\n--ulimit nofile=262144:262144 \\\\\\r\\n-p 8123:8123 -p 9009:9009 -p 9090:9000 \\\\\\r\\n-v /Users/yangjunwei/ck/config:/etc/clickhou\"},{\"url\":\"/database/clickhouse/ClickHouse物化列序列化报错.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse物化列序列化报错问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"报错内容\\r\\n\\r\\n```java\\r\\nNo serializer found for column 'date'. Did you forget to register it?\\r\\n\\tat com.clickhouse.client.api.Client.insert(Client.java:1317)\\r\\n\\tat com.clickhouse.client.api.Client.insert(Client.java:1266)\\r\\n```\\r\\n\\r\\n 表结构\\r\\n\\r\\n```java\\r\\nCREATE TABLE IF NOT EXISTS metric_data\\r\\n(\\r\\n    `placeId` UInt3\"},{\"url\":\"/database/clickhouse/ClickHouse高级.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse高级\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MergeTree\\r\\n\\r\\nClickHouse 中最强大的表引擎当属 MergeTree（合并树）引擎及该系列（MergeTree）中的其他引擎，支持索引和分区，地位可以相当于 innodb 之于 Mysql。而且基于 MergeTree，还衍生除了很多小弟，也是非常有特色的引擎。\\r\\n\\r\\n建表语句\\r\\n\\r\\n```sql\\r\\ncreate table t_order_mt(\\r\\n id UInt32,\\r\\n sku_id String,\\r\\n total_amount Decimal(16,2),\\r\\n create_time Datetime\\r\\n) engine = MergeTree\\r\\n partiti\"},{\"url\":\"/database/clickhouse/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- ClickHouse安装\\r\\n- ClickHouse基础\\r\\n- ClickHouse高级\\r\\n- 为什么弃用Elasticsearch\"},{\"url\":\"/database/clickhouse/为什么弃用Elasticsearch.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"对于开发来说：\\r\\n\\r\\n1. 大批量数据查询导致 es 的 CPU 飙升。\\r\\n2. 数据量增大之后，es 的查询效率下降，影响接口性能。\\r\\n3. 聚合效率低。\\r\\n\\r\\n对于运维来说：\\r\\n\\r\\n1. 维护成本很大，在数据量大的情况，es 占用磁盘空间很大，没有很好的压缩手段。\\r\\n2. es 很占内存，内存配置为整体内存的一半。\\r\\n\\r\\n 问题记录\\r\\n\\r\\n- 缓存计算系统评分导致 es 的 cpu 飙升。\\r\\n\\r\\n  系统评分需要查询 es 的流量信息进行计算，实时查询很慢。做了定时任务计算分数信息并作缓存。\\r\\n\\r\\n    - 经常发现 es 的 cpu 会被打满。排查发现随着系统的增多，当定时任务跑的时候\"},{\"url\":\"/database/mysql/B树和B+树.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"B树和B+树\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"B树\\r\\n\\r\\n\\r\\n\\r\\n每个节点是一个磁盘快。每个磁盘快有固定大小，可以存储多个K-V键值对。\\r\\n\\r\\n每个磁盘快包含指向下层节点的指针，方便查找。\\r\\n\\r\\n*由于每个节点存储了更多的键值对数据，可以有效降低查找树的次数，并减少查询磁盘。*\\r\\n\\r\\n- \\r\\n\\r\\n B+树\\r\\n\\r\\n\\r\\n\\r\\n 存储空间\\r\\n\\r\\nB+树是在B树的基础上演进的。\\r\\n\\r\\nB+树的非叶子结点是不保存数据的，仅保存键值。\\r\\n\\r\\n在 InnoDB中页大小是固定的，在只保存键值的情况下，同一个数据页能保存更多的键值。这样就能保证整个树的层级大大降低，减少向下搜索时候的磁盘IO次数，会提高数据的查询效率。\\r\\n\\r\\nInnoDB 中页的默认大小是 \"},{\"url\":\"/database/mysql/InnoDB存储引擎.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"InnoDB存储引擎\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"存储引擎\\r\\n\\r\\n在系统执行 `update` 语句时，经过 `Server层` 的处理，最终要由执行器去调用存储引擎去执行。\\r\\n\\r\\n而 MySQL 存储引擎有很多种，比如 `InnoDB`、`MyISAM`等。\\r\\n\\r\\nMySQL的默认存储引擎已经变更为了 `InnoDB`\\r\\n\\r\\n---\\r\\n\\r\\n`update` 语句操作的数据最终是要写入磁盘中的，但是如果每次都直接操作磁盘，磁盘I/O的开销是很大的。所以需要每次将操作的数据加载到内存中，减少磁盘I/O次数，再在适当时机进行刷盘操作即可。InnoDB 中使用的这块内存叫做 `Buffer Pool`。\\r\\n\\r\\n 缓冲池 - Buffer Pool\\r\"},{\"url\":\"/database/mysql/MySQL基础架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL基础架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL是 `C/S（Client端 / Server端）` 架构。\\r\\n\\r\\n 架构图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nMySQL架构包含 `Server层` 和 `存储引擎层` 。\\r\\n\\r\\n- Server 层包含 `连接器` 、`分析器`、`优化器`、`执行器`。\\r\\n- 存储引擎层包含 `引擎层`、`存储层`。\\r\\n\\r\\n 一、连接器\\r\\n\\r\\n 连接器的作用\\r\\n\\r\\n- 跟客户端建立连接。\\r\\n- 维持和管理连接。\\r\\n- 校验用户和获取用户权限。\\r\\n\\r\\n---\\r\\n\\r\\n 校验用户\\r\\n\\r\\n客户端进行连接MySQL的命令如下：\\r\\n\\r\\n```java\\r\\nmysql -h$ip -P$port -u$user -p\\r\\n`\"},{\"url\":\"/database/mysql/MySQL日志系统.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL日志系统\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"undo.log\\r\\n\\r\\n记录被更新前的数据。\\r\\n\\r\\n\\r\\n\\r\\nInnoDB 支持事务，在事务执行失败回滚时，数据会回到操作前的样子。\\r\\n\\r\\n`undo.log` 就是为了事务回滚，恢复数据的。\\r\\n\\r\\n回滚对应的操作如下：\\r\\n\\r\\n1. insert\\r\\n   \\r\\n    插入一条记录时，将这条记录的主键记录下来，回滚时根据主键删除。\\r\\n    \\r\\n2. update\\r\\n   \\r\\n    更新一条记录时，将更新的列的旧值记录下来，回滚时将这些值更新回去。\\r\\n    \\r\\n3. delete\\r\\n   \\r\\n    删除一条记录时，将这条记录记录下来，回滚时重新插入到表中。\\r\\n    \\r\\n\\r\\n---\\r\\n\\r\\n在\"},{\"url\":\"/database/mysql/MySQL根据idb文件恢复数据.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL根据idb文件恢复数据\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL根据idb文件恢复数据\\r\\n\\r\\n1. MySQl解除表名\\r\\n   \\r\\n    `Plain Text  ALTER TABLE 表名 DISCARD TABLESPACE`\\r\\n    \\r\\n2. 复制 idb 文件到 data目录。\\r\\n   \\r\\n    \\r\\n    \\r\\n3. idb 文件增加权限。\\r\\n   \\r\\n    ```\\r\\n    chown mysql:mysql user_tenant.ibd\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n4. 重新导入表数据文件\\r\\n   \\r\\n    ```\\r\\n    ALTER TABLE 表名 IMPORT TABLESPACE\\r\\n\"},{\"url\":\"/database/mysql/MySQL的binlog日志过期删除.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL的binlog日志过期删除\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"问题\\r\\n\\r\\nmysql的binlog日志过多导致磁盘告警。\\r\\n\\r\\n部署脚本中没有配置 `binlog` 的失效时间，默认是30天。\\r\\n\\r\\n 手动清理\\r\\n\\r\\n1. 查看正在使用的binlog\\r\\n   \\r\\n    ```sql\\r\\n    show master status\\r\\n    ```\\r\\n    \\r\\n2. 删除指定binlog之前的所有binlog\\r\\n   \\r\\n    ```sql\\r\\n    purge binary logs to 'bin.000055'\\r\\n    ```\\r\\n    \\r\\n\\r\\n 配置自动清理\\r\\n\\r\\n 查看日志过期时间\\r\\n\\r\\n```sql\\r\\nshow variables li\"},{\"url\":\"/database/mysql/OrderBy和limit混用的bug.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"OrderBy和limit混用的bug\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"案例\\r\\n\\r\\n```java\\r\\nselect * from table order by month desc limit 0,10\\r\\n```\\r\\n\\r\\nmonth 重复度高的情况下，limt查询会出bug。导致部分数据丢失。可以增加区分度高的字段一起排序，比如id。\\r\\n\\r\\n```java\\r\\nselect * from table order by month desc,id desc limit 0,10\\r\\n```\"},{\"url\":\"/database/mysql/SQL语句的抖动问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SQL语句的抖动问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"有时候在执行 SQL 的时候，突然会变得很慢。这种慢比较随机，看起来像是抖动一样。\\r\\n\\r\\n更新数据流程可以简化一下。\\r\\n\\r\\n1. 内存（buffer pool）中的数据 flush 到磁盘。\\r\\n2. 数据写入到 redo log 中。\\r\\n\\r\\n其中 buffer pool 中的数据页有三种状态：\\r\\n\\r\\n1. 数据页无数据。\\r\\n2. 数据页是干净页。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n3. 数据页是脏页。\\r\\n   \\r\\n    &gt; 脏页指的是内存中的数据被更新，但是没有flush到磁盘。出现内存和磁盘数据不一致的情况，此时该数据页称为脏页面。\\r\\n    &gt; \\r\\n\\r\\n 性能问题\"},{\"url\":\"/database/mysql/explain使用总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"explain使用总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"参数\\r\\n\\r\\n| id | Columns | JSON Name | Meaning |\\r\\n| --- | --- | --- | --- |\\r\\n| 1 | id | select_id | 每个select子句的标识id |\\r\\n| 2 | select_type | None | select语句的类型 |\\r\\n| 3 | table | table_name | 当前表名 |\\r\\n| 4 | partitions | partitions | 匹配的分区 |\\r\\n| 5 | type | access_type | 当前表内访问方式 join type |\\r\\n| 6 | possible_key\"},{\"url\":\"/database/mysql/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL数据库\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL基础\\r\\n\\r\\n- MySQL基础架构\\r\\n- InnoDB存储引擎\\r\\n---\\r\\n- MySQL日志系统\\r\\n---\\r\\n- 一条更新SQL的执行过程\\r\\n---\\r\\n- 事务隔离\\r\\n---\\r\\n- B树和B+树\\r\\n- 索引\\r\\n---\\r\\n- 锁\\r\\n- 行锁\\r\\n\\r\\n\\r\\n\\r\\n MySQL总结\\r\\n\\r\\n- SQL语句的抖动问题\\r\\n- 索引失效的场景\\r\\n- explain使用总结\\r\\n- 慢查询日志\\r\\n\\r\\n\\r\\n 问题总结\\r\\n- OrderBy和limit混用的bug\\r\\n- MySQL的binlog日志过期删除\\r\\n- MySQL根据idb文件恢复数据\"},{\"url\":\"/database/mysql/一条更新SQL的执行过程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"一条更新SQL的执行过程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"juejin.cn\\r\\n\\r\\n```java\\r\\nmysql\\r\\n```\\r\\n\\r\\n 执行流程\\r\\n\\r\\n1. 执行器先找引擎取出 ID=2 这一行记录。\\r\\n    - 如果该行记录在 `Buffer Pool` 中存在，会直接返回数据给执行器。\\r\\n    - 如果该行记录不存在，则会先进行如下操作，再返回数据给执行器。\\r\\n        - 从磁盘中查找数据。\\r\\n        - 将数据写入内存 `Buffer Pool` 中。\\r\\n        - 将数据写入 `undo.log`（记录 insert、update、delete等修改数据的操作）。\\r\\n2. 执行器获取到引擎给的行数据，把这条数据更新 c\"},{\"url\":\"/database/mysql/事务隔离.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"事务隔离\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。\\r\\n\\r\\n在 MySQL 中，事务支持是在`引擎层`实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。\\r\\n\\r\\n比如 MySQL 原生的 `MyISAM 引擎就不支持事务`，这也是 MyISAM 被 InnoDB 取代的重要原因之一。\\r\\n\\r\\n 事务问题\\r\\n\\r\\n 脏读\\r\\n\\r\\n读到了别的事务 修改过 但未提交的数据\\r\\n\\r\\n 不可重复读\\r\\n\\r\\n指的是变没变化的问题。数据被修改了导致前后两次查询结果不一样。\\r\\n\\r\\n原来是 A，现在是 B，就是不可重复读。\\r\\n\\r\\n 幻读\\r\\n\\r\\n指的是存不存在的问题，原来存\"},{\"url\":\"/database/mysql/慢查询日志.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"慢查询日志\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL中，需要查看执行慢的SQL，需要先开启慢查询日志。\\r\\n\\r\\nMySQL的慢查询日志，记录了MySQL中响应时间超过阈值的SQL语句。\\r\\n\\r\\n 参数说明\\r\\n\\r\\n- slow_query_log：是否开启慢查询日志，1表示开启，0表示关闭。\\r\\n- log-slow-queries ：旧版（5.6以下版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name-slow.log\\r\\n- slow-query-log-file：新版（5.6及以上版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name\"},{\"url\":\"/database/mysql/索引.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"索引\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准。\\r\\n\\r\\n InnoDB的索引模型\\r\\n\\r\\n B+树\\r\\n\\r\\n\\r\\n\\r\\nB+树的每个叶子节点存放元素有限，每个叶子节点为一个 page，针对元素的数量会产生页分裂、页合并等现象。\\r\\n\\r\\n什么是B+树？_攻城狮百里的博客-CSDN博客_b+树\\r\\n\\r\\n\\r\\n\\r\\n 聚簇索引和二级索引\\r\\n\\r\\n- 主键索引的叶子结点存的是整行记录。InnoDB 引擎中主键索引又称为聚簇索引。\\r\\n- 非主键索引的叶子结点存的是行记录的ID。在 InnoDB 引擎中非主键索引又称为二级索引。\\r\\n\\r\\n\\r\\n\\r\\n 搜索方式\\r\\n\\r\\n- 根据主键搜索\\r\\n  \\r\\n    `\"},{\"url\":\"/database/mysql/索引失效的场景.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"索引失效的场景\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"查询条件做函数计算\\r\\n\\r\\n```sql\\r\\nselect count(*) from tradelog where month(t_modified)=7;\\r\\n```\\r\\n\\r\\n查询条件做函数计算，在查索引的时候，利用不了索引。因为索引利用的是树的有序性，但是函数计算后的结果在索引的B+树上并不连续。MySQL在查询的时候利用不到树的有序性。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。\\r\\n\\r\\n 隐式类型转换\\r\\n\\r\\n假如 tradeid 字段类型是 varchar ，查询语句\\r\\n\\r\\n```sql\\r\\nexplain   sele\"},{\"url\":\"/database/mysql/行锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"行锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL 中的行锁（row-level locking）并不是单纯指写锁（write lock），而是指锁定机制的粒度。行锁可以是共享锁（也称为读锁，S锁）或排他锁（也称为写锁，X锁），具体取决于事务所使用的隔离级别以及查询类型。\\r\\n\\r\\n- Select for Update：当执行带有 `FOR UPDATE` 子句的 `SELECT` 查询时，InnoDB 会对被选中的行加上排他锁。这确保了在事务提交之前，其他事务不能修改这些行。\\r\\n- Insert Intention Lock：当执行 `INSERT` 操作时，InnoDB 会自动为要插入的行加上意向锁。这是为了避免插入操作与其他事务\"},{\"url\":\"/database/mysql/锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL中加锁是为了处理并发问题，根据锁的粒度可以分为全局锁、表级锁和行锁。\\r\\n\\r\\n 全局锁\\r\\n\\r\\n全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 `Flush tables with read lock` (FTWRL)。\\r\\n\\r\\n加完之后整个数据库处于只读状态。\\r\\n\\r\\n---\\r\\n\\r\\n 应用场景（不推荐）\\r\\n\\r\\n全局锁的经典应用场景 数据库备份。\\r\\n\\r\\n由于加全局锁，会导致整个数据库只读，所以一般不推荐使用。\\r\\n\\r\\n 可重复读进行备份\\r\\n\\r\\n备份数据库一般可以利用可重复读的事务隔离级别来实现，因为可重复读情况开始事务，会生成当前数据库的视图，保证整个事务期间以\"},{\"url\":\"/database/redis/LRU和LFU算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"LRU和LFU算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"LRU算法\\r\\n\\r\\n 简介\\r\\n\\r\\nLRU （Least Recently Used） 算法即最近最久未使用，每次选择最近最久未使用的页面淘汰掉。\\r\\n\\r\\n 实现过程\\r\\n\\r\\n- 新增数据时，元素插入到队列头部。\\r\\n- 访问元素（查询、更新和删除）时，将元素移动到队列头部。\\r\\n- 当超过内存限制，需要淘汰数据时，将已排序队列的最后元素删除。\\r\\n\\r\\n\\r\\n\\r\\n 数据结构\\r\\n\\r\\nLRU 算法内部的数据结构需要根据元素的访问时间排序。还需要查找、插入、删除等效率要高。\\r\\n\\r\\n1. 查找、插入、删除快。\\r\\n2. 支持排序。\\r\\n\\r\\n在常用的集合中，有的是查找更新快或者插入删除快，没有数据结构能同时满足以上条件，所\"},{\"url\":\"/database/redis/Redisson.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Redisson\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还实现了可重入锁（Reentrant Lock）、公平锁（Fair Lock、联锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）等，还提供了许多分布式服务。Redisson提供了使用Redis的最简单和最便捷的方法。Redisson的宗旨是促进使用者对Redis的关注分离（Separation of Concern），从而让使用者能够将精力更集中地放在处理业务逻辑上。\\r\\n\\r\\n Redisson \"},{\"url\":\"/database/redis/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- redis数据类型\\r\\n- redis数据类型原理\\r\\n- redis的持久化\\r\\n\\r\\n\\r\\n- 过期策略\\r\\n- 内存淘汰策略\\r\\n- LRU和LFU算法\\r\\n\\r\\n- redis实现分布式锁\\r\\n- Redisson\\r\\n\\r\\n- redis事务.md\\r\\n- redis集群.md\\r\\n\\r\\n- 缓存问题\\r\\n- 布隆过滤器\"},{\"url\":\"/database/redis/redis事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis的事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis 的事务，可以一次执行多个命令，本质上是一组命令的集合，按照顺序串行化执行而不会被其它命令插入。\\r\\n\\r\\n 常用命令\\r\\n\\r\\n- 开启事务 -`multi`\\r\\n- 执行所有事务 - `exec`\\r\\n- 取消所有事务 - `discard`\\r\\n- 监控一个或多个 key - `watch`\\r\\n- 取消 watch 命令对所有 key 的监控 - `unwatch`\\r\\n  \\r\\n    \\r\\n    \\r\\n\\r\\n watch监控\\r\\n\\r\\nwatch 指令，类似乐观锁，在创建事务之前，使用 watch 指令监控某个值。在事务提交时，如果 key 的值已经被别的客户端改变，那么整个事务队列都不会执行。\\r\\n\"},{\"url\":\"/database/redis/redis实现分布式锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis实现分布式锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"分布式锁简介\\r\\n\\r\\n在分布式环境下，多个系统访问共享资源时会发生线程安全问题，分布式锁就是为了解决分布式环境下访问共享资源的线程安全问题，保证共享资源同一时间只能被一个系统的一个线程访问。\\r\\n\\r\\n 分布式锁具备的条件\\r\\n\\r\\n1. 在分布式环境下，共享资源在同一时间只能被一个系统的一个线程访问。\\r\\n2. 保证设置分布式锁和删除分布式锁操作的原子性。\\r\\n3. 具备可重入特性。\\r\\n4. 防止死锁。\\r\\n5. 具备锁超时失效的机制。\\r\\n6. 具备非阻塞锁特性，不会阻塞等待获取锁。\\r\\n\\r\\n 分布式锁主要实现方式\\r\\n\\r\\n1. zeekeeper 实现分布式锁\\r\\n2. redis 实现分布式锁\\r\\n\\r\\n---\\r\"},{\"url\":\"/database/redis/redis数据类型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis数据类型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis数据类型\\r\\n\\r\\n练习代码地址 redis-practice\\r\\n\\r\\n 键 - key\\r\\n\\r\\n在了解数据类型之前，先了解一下 redis 的键。\\r\\n\\r\\n在 redis 中 命令不区分大小写，但是注意 redis 中的 key 和 value 是区分大小写的。\\r\\n\\r\\n\\r\\n\\r\\n 字符串 - string\\r\\n\\r\\n字符串数据结构是简单的 K-V 模式数据结构。\\r\\n\\r\\n 特点\\r\\n\\r\\n- 单值单 value。\\r\\n- 二进制安全，可以包含任何数据。\\r\\n- 一个键对应 value 值最大能存储数据 512 MB。\\r\\n\\r\\n 常用命令\\r\\n\\r\\n\\r\\n\\r\\n- 设置字符串 - `set test 100`\\r\\n- 查\"},{\"url\":\"/database/redis/redis数据类型原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis数据类型原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. linkedlist (双向链表)\\r\\n    - 当列表元素较多或元素大小超过一定阈值时，Redis 会使用双向链表来存储 `list` 键。\\r\\n    - linkedlist 是一种指针结构，每个节点包含指向前后节点的指针，这使得插入和删除操作非常高效。\\r\\n    - linkedlist 的优点是支持高效的插入和删除操作，但缺点是比 ziplist 更占用内存。\\r\\n\\r\\n 全局哈希表\\r\\n\\r\\n\\r\\n\\r\\nRedis是一个 K-V 数据库，有一个全局的哈希桶存放所有的 key。\\r\\n\\r\\nkey 对应的 entry 包含了实际的 key 和 value。这里的 value 对应着不同的数据类型。\"},{\"url\":\"/database/redis/redis的持久化.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis的持久化\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis 有 RDB 和 AOF 两种持久化方式。\\r\\n\\r\\n RDB\\r\\n\\r\\nRDB 是 *Redis DataBase* 的简称，指的是在指定时间间隔内将内存中的数据集快照写入磁盘文件，也就是 Snapshot 快照，RDB 是默认开启的。\\r\\n\\r\\n RDB的原理\\r\\n\\r\\nRedis 会单独创建 （fork）一个子进程来进行持久化操作，将内存中某一时刻的数据持久化到磁盘文件。这个子进程会先将数据写入到一个临时文件中，等待持久化进程结束后，再用这个临时文件替换掉磁盘文件。\\r\\n\\r\\n\\r\\n\\r\\n在整个过程中，主进程是不进行任何 IO 操作的，这样保证了主进程存取的高性能。\\r\\n\\r\\nRDB 的持久化过程每次都是\"},{\"url\":\"/database/redis/redis集群.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis集群\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Redis集群是一个由多个主从节点群组成的分布式服务集群，它具有复制、高可用和分片特性。\\r\\n\\r\\n 主从模式\\r\\n\\r\\n\\r\\n\\r\\n- 主数据库可以进行读写操作。\\r\\n  \\r\\n    数据会通过主从同步，由主服务器同步给从服务器。\\r\\n    \\r\\n    主服务器将数据\\r\\n    \\r\\n- 从数据库一般是只读的。\\r\\n\\r\\n引入主从复制机制的目的有两个：\\r\\n\\r\\n- 一个是读写分离，分担 “master” 的读写压力\\r\\n- 一个是方便做容灾恢复，避免单点故障。\\r\\n\\r\\n 主从同步的原理\\r\\n\\r\\n\\r\\n\\r\\n- 全量复制\\r\\n  \\r\\n    从数据库在第一次同步的时候会进行全量同步。\\r\\n    \\r\\n    主库执行 bgsav\"},{\"url\":\"/database/redis/内存淘汰策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内存淘汰策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"最大内存设置\\r\\n\\r\\n1. redis 默认内存是多少？\\r\\n   \\r\\n    在 64 位操作系统不限制内存大小，在 32 位操作系统下最多使用 3GB。\\r\\n    \\r\\n2. 查看 redis 最大内存？\\r\\n   \\r\\n    `Plain Text  config get maxmemory`\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 修改 redis 内存大小？\\r\\n    - 修改配置文件\\r\\n      \\r\\n        在 `redis.conf` 第 859 行可以设置最大内存大小（单位是字节）。\\r\\n        \\r\\n        \\r\\n        &gt; \\r\\n        \"},{\"url\":\"/database/redis/布隆过滤器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"布隆过滤器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 什么是布隆过滤器？\\r\\n\\r\\n布隆过滤器（Bloom Filter）是一种数据结构，用来判断一个元素是否在一个集合中。布隆过滤器的本质上使用的是二进制向量和 k 个哈希函数组成。\\r\\n\\r\\n布隆过滤器具有如下优点：\\r\\n\\r\\n- 空间利用率高。\\r\\n  \\r\\n    布隆过滤器底层使用二进制向量保存数据，不需要保存元素本身，只需要在指定 bit 存放标识即可，故空间利用率非常高。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n- 时间效率也较高，插入和查询效率高。\\r\\n  \\r\\n    布隆过滤器的时间复杂度只跟哈希函数的个数 k 有关，插入和查询的时间复杂度均为 O(k)；\\r\\n    \\r\\n    *结合\"},{\"url\":\"/database/redis/缓存问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"缓存问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"前言\\r\\n\\r\\n在使用缓存的时候，简单的缓存处理流程如下。针对如下流程会遇到缓存穿透、缓存击穿、缓存雪崩等问题。\\r\\n\\r\\n\\r\\n\\r\\n 缓存穿透\\r\\n\\r\\n缓存穿透：当用户请求查询某个数据时，先从缓存查询，缓存中没有这个数据。然后向数据库查询数据，数据库中也没有这个数据，导致查询失败。\\r\\n\\r\\n*像一些恶意攻击时，故意查询数据库中不存在的数据，比如查询 id = -1 的数据，会造成数据库压力非常大。*\\r\\n\\r\\n\\r\\n\\r\\n 解决方案\\r\\n\\r\\n1. 对空值做缓存。\\r\\n   \\r\\n    当出现从缓存和数据库都查不到数据的情况时，可以将空值存到缓存中，即 K-V 存为 key-null，缓存过期时间可以设置短点，来防止短\"},{\"url\":\"/database/redis/过期策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"过期策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 Redis 中设置了过期时间的 key，在一定时间后都会被删除。\\r\\n\\r\\n 键的过期时间\\r\\n\\r\\n 配置过期时间\\r\\n\\r\\n1. `setex key seconds value`\\r\\n   \\r\\n    设置 key 时添加过期时间\\r\\n    \\r\\n2. `expire key seconds`\\r\\n   \\r\\n    为某个 key 设置过期时间。\\r\\n    \\r\\n3. 删除 key 的过期时间。\\r\\n   \\r\\n    `persist key`\\r\\n    \\r\\n4. 查看 key 的过期时间\\r\\n   \\r\\n    `ttl key`\\r\\n    \\r\\n\\r\\n redis保存过期时间分析\\r\\n\\r\\n[版权声明：本文为CS\"},{\"url\":\"/frame/mybatis/custom/SQL执行器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SQL执行器-executor\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"将操作数据库的操作从 sqlSession 中解耦，放到 Executor 中。\\r\\n\\r\\n包括事务操作也放到 Executor 中。\\r\\n\\r\\n```java\\r\\npublic interface Executor {\\r\\n\\r\\n    ResultHandler NO_RESULT_HANDLER = null;\\r\\n\\r\\n    &lt;E\\r\\n\\r\\n    Transaction getTransaction();\\r\\n\\r\\n    void commit(boolean required) throws SQLException;\\r\\n\\r\\n    void rollback(boolean required) \"},{\"url\":\"/frame/mybatis/custom/xml解析.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"xml解析\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"\"},{\"url\":\"/frame/mybatis/custom/手写MyBatis.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"手写MyBatis\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"整体流程\\r\\n\\r\\n\\r\\n\\r\\n整个mybatis的功能，就是代理 mapper 然后执行SQL，返回执行结果。\\r\\n\\r\\n\\r\\n\\r\\n1. 解析mybatis配置\\r\\n    - 解析数据源 （Configuration 的 environment）\\r\\n    - 解析mapper文件配置 （路径扫描）\\r\\n2. 解析mapper文件\\r\\n    - 注册mapper到mapperRegistry。（包含mapper的代理类工厂，可以获取代理过的mapper）\\r\\n    - 生成mapper方法对应的mapperStatement。（Configuration 的 mappedStatements）\\r\\n    -\"},{\"url\":\"/frame/mybatis/custom/数据源.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据源\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"数据源解析\\r\\n\\r\\n解析配置文件中的数据源\\r\\n\\r\\n1. 事务模版 - jdbc\\r\\n2. 数据源实现 - druid\\r\\n\\r\\n```xml\\r\\n&lt;configuration\\r\\n\\r\\n    &lt;!--    数据源配置   --&gt;\\r\\n    &lt;environments default=\\\"development\\\"&gt;\\r\\n        &lt;environment id=\\\"development\\\"&gt;\\r\\n            &lt;transactionManager type=\\\"JDBC\\\"/&gt;\\r\\n            &lt;dataSource type=\\\"\"},{\"url\":\"/frame/mybatis/custom/映射器-mapper.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"映射器-mapper\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- SqlSession提供了SqlId。\\r\\n- 而SqlSessionFactroy 提供了开启SqlSession的能力。]\\r\\n- MapperRegistry 包含了所有Mapper的SqlId，包含注册发现Mapper的能力。\\r\\n\\r\\n MapperFactory\\r\\n\\r\\n\\r\\n\\r\\n MapperProxy\\r\\n\\r\\n在mybatis中，调用mapper里面的方法就可以执行SQL。其实是因为mybatis隐藏了实现细节。\\r\\n\\r\\n具体做法是根据mapper里面点的方法生成代理逻辑，在调用该方法时其实是走的代理类的逻辑。\\r\\n\\r\\n而代理类封装了操作数据库的逻辑，代理类即为mapperProxy。\\r\\n\\r\"},{\"url\":\"/frame/mybatis/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MyBatis 框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"手写MyBatis\\r\\n\\r\\n- 手写MyBatis\\r\\n- 映射器-mapper\\r\\n- 数据源\\r\\n- SQL执行器\\r\\n- xml解析\"},{\"url\":\"/frame/netty/ByteBuf.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ByteBuf\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ByteBuf是Netty中用于表示字节序列的数据容器。它是Netty对Java NIO中的ByteBuffer的改进和增强。ByteBuf提供了更灵活、更强大的API，具有许多优势，使得它在网络编程中更加方便和高效。\\r\\n\\r\\n以下是ByteBuf的主要优势：\\r\\n\\r\\n1. 灵活的容量管理： ByteBuf支持动态扩容和收缩，相比Java NIO的ByteBuffer，ByteBuf的容量可以根据实际需求自动调整，无需手动扩容。\\r\\n2. 更丰富的API： ByteBuf提供了丰富的操作API，包括读取、写入、复制、切片、合并等操作。这些API使得对字节数据的操作更加便利，同时提供了更多的功能。\\r\\n\"},{\"url\":\"/frame/netty/HTTP服务和SSL&TLS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP服务和SSL/TLS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"服务端\\r\\n\\r\\n按照 pipline 执行。\\r\\n\\r\\n```java\\r\\n@Override\\r\\n    protected void initChannel(SocketChannel socketChannel) throws Exception {\\r\\n        ChannelPipeline pipeline = socketChannel.pipeline();\\r\\n        //TODO ssl\\r\\n\\r\\n        //服务端\\r\\n        //对请求内容解码\\r\\n        pipeline.addLast(\\\"decoder\\\", new HttpRequestDecode\"},{\"url\":\"/frame/netty/Handler的共享和并发安全性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Handler的共享和并发安全性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"服务端为Channel设置pipeline的时候，可以选择设置共享的还是Channel独有的。\\r\\n\\r\\n```java\\r\\nprivate void start() throws InterruptedException {\\r\\n        final MsgCountHandler msgCountHandler = new MsgCountHandler();\\r\\n        //线程组\\r\\n        EventLoopGroup boss = new NioEventLoopGroup();\\r\\n        EventLoopGroup work = new NioEventLoo\"},{\"url\":\"/frame/netty/Netty实现文件下载.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty实现文件下载\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"实例：如何使用 Netty 下载文件_channelhandlercontext下载文件-CSDN博客\\r\\n\\r\\n ChannelHandler\\r\\n\\r\\n自定义 ChannelHandler ，用来处理 Channel 里面的事件，写数据处理逻辑的。\\r\\n\\r\\n- ChannelInboundHandlerAdapter\\r\\n- SimpleChannelInboundHandler\\r\\n    \\r\\n    是 ChannelInboundHandlerAdapter 的子类，能够指定类型。\\r\\n    \\r\\n\\r\\nNetty 里面预设了很多 ChannelHandler\\r\\n\\r\\n```java\\r\\nch.pipel\"},{\"url\":\"/frame/netty/Netty实现通信框架.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty实现通信框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"功能点\\r\\n\\r\\n1. 基于Netty的NIO通信框架。\\r\\n2. 提供消息的编码解码框架，实现对象的序列化和反序列化。\\r\\n3. 消息内容的放篡改机制。\\r\\n4. 提供基于IP的白名单认证机制。\\r\\n5. 链路的有效性机制（心跳）。\\r\\n6. 链路的断连重连机制。\\r\\n\\r\\n 通信模型\\r\\n\\r\\n\\r\\n\\r\\n 调用链路\\r\\n\\r\\n\\r\\n\\r\\n粘包半包是最前面先要解决的问题。\\r\\n\\r\\n 写空闲检测\\r\\n\\r\\n```java\\r\\npublic class CheckWriteIdleHandler extends IdleStateHandler {\\r\\n\\r\\n    /**\\r\\n     * 0 表示读空闲时间不进行检测，即不对读空闲做任何\"},{\"url\":\"/frame/netty/Netty常用组件.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty常用组件\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Bootstrap\\r\\n\\r\\nNetty的启动类\\r\\n\\r\\n- Bootstrap\\r\\n\\r\\n    客户端启动类\\r\\n\\r\\n- ServerBootstrap\\r\\n\\r\\n    服务端启动类\\r\\n\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n 第一个区别\\r\\n\\r\\n- 客户端需要连接到远程主机和端口即可。\\r\\n\\r\\n- 服务端需要绑定端口。\\r\\n\\r\\n 第二个区别\\r\\n\\r\\n- 服务端需要两个 EventLoopGroup。\\r\\n\\r\\n    原因是使用了多线程主从的Reactor模式。\\r\\n\\r\\n    - 第一个EventLoopGroup，只有一个EventLoop，负责为传入的Accept请求建立连接。一旦建立连接后续，将该 Channel 放到\"},{\"url\":\"/frame/netty/TCP粘包拆包问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP粘包拆包问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"TCP 粘包\\r\\n\\r\\n由于 TCP 协议本身的机制（面向连接的可靠地协议-三次握手机制）客户端与服务器会维持一个连接（Channel），数据在连接不断开的情况下，可以持续不断地将多个数据包发往服务器。\\r\\n\\r\\n但是如果发送的网络数据包太小，那么他本身会启用 Nagle 算法（可配置是否启用）对较小的数据包进行合并（基于此，TCP 的网络延迟要 UDP 的高些）然后再发送（超时或者包大小足够）。\\r\\n\\r\\n那么这样的话，服务器在接收到消息（数据流）的时候就无法区分哪些数据包是客户端自己分开发送的，这样产生了粘包。\\r\\n\\r\\n服务器在接收到数据库后，放到缓冲区中，如果消息没有被及时从缓存区取走，下次在取数据的\"},{\"url\":\"/frame/netty/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础总结\\r\\n\\r\\n- Netty常用组件\\r\\n- Handler的共享和并发安全性\\r\\n- 资源管理和SimpleChannelInboundHandler\\r\\n- 内置通信传输模式\\r\\n- TCP粘包拆包问题\\r\\n- 编解码器\\r\\n\\r\\n\\r\\n- HTTP服务和SSL&TLS\\r\\n- 序列化问题\\r\\n- 写空闲和读空闲\\r\\n\\r\\n\\r\\n- ByteBuf\\r\\n- 线程模型\\r\\n- 零拷贝\\r\\n\\r\\n\\r\\n 练习总结\\r\\n- Netty实现通信框架\\r\\n- 基于Netty实现RPC\\r\\n- Netty实现文件下载\"},{\"url\":\"/frame/netty/内置通信传输模式.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内置通信传输模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```java\\r\\ntry {\\r\\n            //父子EventLoop\\r\\n            serverBootstrap.group(boss,work)\\r\\n                    //指定使用NIO的通信模式\\r\\n                    .channel(NioServerSocketChannel.class)\\r\\n                    .localAddress(new InetSocketAddress(port))\\r\\n                    .childHandler(new ChannelInitia\"},{\"url\":\"/frame/netty/写空闲和读空闲.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"写空闲和读空闲\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在Netty框架中，写空闲（Write Idle） 和 读空闲（Read Idle） 是空闲检测机制中的两个重要概念，它们用于监控网络连接的活跃状态，确保连接的有效性和资源的有效管理。\\r\\n\\r\\n 写空闲（Write Idle）\\r\\n\\r\\n- 定义：写空闲指的是在一段指定时间内，没有数据通过当前的`Channel`被写入到网络中传输给对方。这可能意味着在这段时间内，服务端没有向客户端发送任何数据，或者客户端没有向服务端发送数据。\\r\\n- 应用场景：在某些协议或应用场景中，如果长时间没有数据写入，可能需要触发特定的操作，比如发送心跳包以维持连接活跃，或者是判断连接是否已经失效，进而关闭连接以释放资源。\\r\\n\"},{\"url\":\"/frame/netty/基于Netty实现RPC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"基于netty实现RPC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"源码地址\\r\\n\\r\\nAlbert.Yang/JavaAdvance\\r\\n\\r\\n 服务端\\r\\n\\r\\n ServerBootstrap\\r\\n\\r\\n```java\\r\\n@Service\\r\\n@Slf4j\\r\\npublic class RpcServerFrame implements Runnable {\\r\\n\\r\\n    @Autowired\\r\\n    private ServerInit serverInit;\\r\\n\\r\\n    private EventLoopGroup bossGroup = new NioEventLoopGroup();\\r\\n    private EventLoopGroup workGroup =\"},{\"url\":\"/frame/netty/序列化问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"序列化问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java对象的序列化主要有两个：\\r\\n\\r\\n1. 网络传输\\r\\n   \\r\\n    数据在网络中传输是通过字节流形式的，到服务端需要解码。\\r\\n    \\r\\n2. 对象持久化\\r\\n\\r\\n Java序列化\\r\\n\\r\\nJava序列化机制是基于对象的类结构进行的。\\r\\n\\r\\n当对象需要序列化时，会将对象转换为字节流在网络传输。\\r\\n\\r\\n反序列化时，就是将字节流转换为对象的过程。Java会将字节流转换为对象重新加载到内存中。\\r\\n\\r\\nJava的序列化机制是通过实现`java.io.Serializable`接口来实现的。该接口是一个标记接口，没有任何方法定义。只有实现了`Serializable`接口的类的对象才能被序列化。\\r\\n\"},{\"url\":\"/frame/netty/线程模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Netty的线程模型是什么？为什么它是高效的？\\r\\n\\r\\n1. Netty的线程模型是基于事件驱动的，采用了Reactors设计模式。它的线程模型主要包含以下几个关键组件：\\r\\n2. Boss Group和Worker Group： Netty通过Boss Group和Worker Group来分别管理两类不同的线程。Boss Group负责接收客户端的连接，而Worker Group则负责处理连接后的网络流量。\\r\\n3. Channel： Channel代表了一个网络连接，可以是客户端到服务器的连接，也可以是服务器之间的连接。每个Channel都由一个EventLoop负责处理，而一个EventLo\"},{\"url\":\"/frame/netty/编解码器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"编解码器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在网络传输中，数据是通过字节流传输。\\r\\n\\r\\n对应到客户端和服务端需要进行对应的编码和解码。\\r\\n\\r\\n 解码器\\r\\n\\r\\n- 将字节解码为消息：ByteToMessageDecoder\\r\\n- 将一种消息类型解码为另一种：MessageToMessageDecoder。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 异常处理\\r\\n\\r\\n- TooLongFrameException\\r\\n    \\r\\n    由于 Netty 是一个异步框架，所以需要在字节可以解码之前在内存中缓冲它们。因此，不能让解码器缓冲大量的数据以至于耗尽可用的内存。为了解除这个常见的顾虑，Netty 提供了 TooLongFrameException 类\"},{\"url\":\"/frame/netty/资源管理和SimpleChannelInboundHandler.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"资源管理和SimpleChannelInboundHandler\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NIO中读写Channel数据，都使用了 Buffer，读写数据都是从 Buffer里面读取的。\\r\\n\\r\\n而 Netty在读写网络数据时，同样也需要 Buffer。\\r\\n\\r\\n但是这样就涉及到 Buffer的内存释放，不然会造成内存泄漏。\\r\\n\\r\\n SimpleChannelInboundHandler\\r\\n\\r\\nNetty实现了SimpleChannelInboundHandler类，提供 `channelRead0()` 方法，保证数据被该方法消费后自动释放数据。\\r\\n\\r\\n```java\\r\\n    public void channelRead(ChannelHandlerContext ctx, Ob\"},{\"url\":\"/frame/netty/零拷贝.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"零拷贝\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. ByteBuf 可以直接使用直接内存。\\r\\n    \\r\\n    Socket 通信如果采用堆内存的话，需要将堆里的对象拷贝到堆外，进行一次对象拷贝。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n    \\r\\n    但是 Socket 没有更新对象地址动作，需要的是一个固定的地址。所以堆内存不适合 Socket 使用。只能将对象拷贝到直接内存然后使用。\\r\\n    \\r\\n    而 ByteBuf 直接使用直接内存，减少了对象拷贝。\\r\\n    \\r\\n2. Netty 提供了组合 Buffer，可以将多个 Buffer 合并为一个。\\r\\n    \\r\\n    传统通过内存拷贝的方式将几个小Buffe\"},{\"url\":\"/frame/spring/AOP.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AOP\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"面向切面编程\\r\\n\\r\\n面向切面编程，指的是在运行期间生成代理对象来对类进行增强处理，比如方法执行前和方法执行后进行代码增强。\\r\\n\\r\\n 什么是切面\\r\\n\\r\\n- 切：\\r\\n  \\r\\n    指的是横切逻辑，原有方法代码不动。只能操作横切逻辑代码进行增强。\\r\\n    \\r\\n- 面：\\r\\n  \\r\\n    横切逻辑往往影响很多个方法，每个方法是一个切点，便形成了面。\\r\\n    \\r\\n\\r\\n常用的功能有：\\r\\n\\r\\n- 方法审计日志\\r\\n- 校验权限是否足够\\r\\n\\r\\n\\r\\n\\r\\n AOP体系\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n)连接点 - JoinPoint\\r\\n\\r\\n类里面哪些方法可以被增强，这些方法称为连接点。\\r\\n\\r\\n- 切面\\r\\n\\r\\n    切\"},{\"url\":\"/frame/spring/ApplicationContext和BeanFactory区别.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ApplicationContext和BeanFactory区别\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ApplicationContext 总结\\r\\n\\r\\nApplicationContext 容器上下文，包含了 BeanFactory 的所有功能，还额外提供了以下功能：\\r\\n\\r\\n- MessageSource，提供国际化的消息访问\\r\\n- 资源访问，如 URL 和文件\\r\\n- 事件传播\\r\\n\\r\\n 工具类\\r\\n\\r\\n可以通过实现 `ApplicationContextAware` 接口注入 ApplicationContext\\r\\n\\r\\n```java\\r\\n@Component\\r\\npublic class SpringBeanUtil implements ApplicationContextAware {\\r\\n\\r\\n\"},{\"url\":\"/frame/spring/Aware接口.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Aware接口\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在Spring框架中，`Aware`接口提供了一种机制，允许Bean在初始化过程中获取Spring容器的特定上下文信息或资源。这些接口通常被称作回调接口，因为它们允许Spring容器在特定时刻回调Bean，以便将一些重要的信息注入给Bean。\\r\\n\\r\\n ApplicationContextAware\\r\\n\\r\\n当Spring容器在初始化一个实现了`ApplicationContextAware`接口的Bean时，它会调用`setApplicationContext`方法，将当前的应用上下文传入。\\r\\n\\r\\n```java\\r\\npublic interface ApplicationContextAware\"},{\"url\":\"/frame/spring/BeanFactory和FactoryBean总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BeanFactory和FactoryBean总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"BeanFactory总结\\r\\n\\r\\nBeanFactory 是 Spring 中的一个接口，提供了 IOC 容器最基本的形式，给具体的 IOC 容器实现提供了规范。\\r\\n\\r\\n其本质是一个 IOC 容器或对象工厂，所有的 Bean 都是由 BeanFactory （IOC容器）来进行管理的。Spring 有许多 BeanFactory 的实现类，附件了许多功能。\\r\\n\\r\\n```java\\r\\npublic interface BeanFactory {\\r\\n  \\r\\n  Object getBean(String name) throws BeansException;\\r\\n  \\r\\n\\t&lt;T\\r\\n\\r\\n\\tObj\"},{\"url\":\"/frame/spring/ByteBuddy实现动态代理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ByteBuddy实现动态代理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Byte Buddy - runtime code generation for the Java virtual machine\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n```java\\r\\n&lt;dependency&gt;\\r\\n  &lt;groupId&gt;net.bytebuddy&lt;/groupId&gt;\\r\\n  &lt;artifactId&gt;byte-buddy&lt;/artifactId&gt;\\r\\n  &lt;version&gt;LATEST&lt;/version&gt;\\r\\n&lt;/dependency&gt;\\r\\n```\\r\\n\\r\\n```java\\r\\npublic c\"},{\"url\":\"/frame/spring/Spi机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spi机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SPI机制，全称Service Provider Interface，是Java提供的一种标准的服务发现机制。它允许第三方服务提供者扩展某个接口的实现，而无需修改接口的源代码或重新打包。\\r\\n\\r\\nSpring SPI机制常用于 starter 构建和基础库实现。\\r\\n\\r\\n通过 spi 机制，确保自动配置生效的类包含 FileAutoConfiguration\\r\\n\\r\\n\\r\\n\\r\\n使用 SPI可以可插拔的注入配置，比如 `EnableAutoConfiguration`，如果需要 MinIO的配置类，加在类里面即可开启MinIO的功能。\\r\\n\\r\\nwww.jb51.net\\r\\n\\r\\nSPI机制是什么？_java_\"},{\"url\":\"/frame/spring/Spring中Bean加载流程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring中Bean加载流程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"流程图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 创建流程\\r\\n\\r\\n1. 加载 `ApplicationContext` 上下文环境。\\r\\n2. `ApplicationContext` 通过扫描、读取配置，将 Bean对象封装为 `BeanDefinition` 对象，并注册到 `BeanDefinitionMap` 中。\\r\\n3. 在 `ApplicationContext` 执行完成之后会调用对应的后置处理器 `BeanFactoryProcessor` 和其子类 `BeanDefinitionRegistryPostProcessor` 对应方法，可以修改和注册 `BeanDefinition` 到 \"},{\"url\":\"/frame/spring/Spring中Bean的作用域.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring中Bean的作用域\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"作用域类型\\r\\n\\r\\n- singleton\\r\\n    \\r\\n    单例模式。\\r\\n    \\r\\n    使用 `singleton` 定义的 Bean 在 Spring 容器中只有一个实例，是 Bean 默认的作用域。\\r\\n    \\r\\n- prototype\\r\\n    \\r\\n    原型模式\\r\\n    \\r\\n    每次通过 Spring 容器获取 `prototype` 定义的 Bean 时，容器都将创建一个新的 Bean 实例。\\r\\n    \\r\\n- request\\r\\n    \\r\\n    在一次 HTTP 请求中，容器会返回该 Bean 的同一个实例。而对不同的 HTTP 请求，会返回不同的实例，该作用域\"},{\"url\":\"/frame/spring/Spring事务总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring事务总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"编程式事务\\r\\n\\r\\n在代码中硬编码，不推荐使用。\\r\\n\\r\\n 声明式事务\\r\\n\\r\\n- 基于注解的声明式事务\\r\\n- 基于 XML 的声明式事务\\r\\n\\r\\n @Transactional 注解\\r\\n\\r\\nException 分为运行时异常 RuntimeException 和非运行时异常。事务管理能保证出现异常情况的时候保证数据的一致性。\\r\\n\\r\\n默认 `@Transactional` 注解只会在遇到 RuntimeException 类型异常或者 Error时，才会回滚事务。遇到其它异常，Spring 不会回滚事务。\\r\\n\\r\\n 作用范围\\r\\n\\r\\n当 `@Transactional`注解作用于类上的时，该类的所有方法都\"},{\"url\":\"/frame/spring/Spring依赖注入.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring依赖注入\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"依赖注入就是通过spring将bean所需要的一些参数传递到bean实例对象的过程（将依赖关系注入到对象中，不需要每次都new对象）\\r\\n\\r\\n- set方法注入\\r\\n- 构造方法注入\\r\\n- 注解注入\\r\\n\\r\\n 注解注入的区别\\r\\n\\r\\n- @Resource\\r\\n\\r\\n  byName注入\\r\\n\\r\\n  \\r\\n\\r\\n- Autowired\\r\\n\\r\\n  byType注入\"},{\"url\":\"/frame/spring/Spring如何解决循环依赖.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring如何解决循环依赖\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"依赖注入的四种方法\\r\\n\\r\\n- 构造方法注入\\r\\n  \\r\\n    ```java\\r\\n        public HelloA(@Autowired HelloService helloService) {\\r\\n            this.helloService = helloService;\\r\\n        }\\r\\n    ```\\r\\n    \\r\\n- 工厂方法注入\\r\\n  \\r\\n    ```java\\r\\n        @Bean(initMethod = \\\"init\\\", destroyMethod = \\\"destory\\\")\\r\\n        public HelloB helloB(@Auto\"},{\"url\":\"/frame/spring/Spring框架概述.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring框架概述\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、什么是 Spring 框架？\\r\\n\\r\\nSpring 框架指的是 Spring Framework，是一种轻量级的开发框架，主要核心是控制反转 （IOC）和 面向切面编程（AOP）。\\r\\n\\r\\n 二、Spring 的优点\\r\\n\\r\\n1. 方便解耦，简化开发（高内聚低耦合）\\r\\n    - Spring 是一个容器框架，将所有对象创建和依赖关系的维护交给 Spring 管理。\\r\\n    - Spring 工厂用于生成 Bean。\\r\\n2. AOP编程的支持\\r\\n    - Spring 提供面向切面编程，可以方便的实现权限拦截、运行监控等功能\\r\\n    - 日志打印\\r\\n3. 支持声明式事务\\r\\n    - 只需\"},{\"url\":\"/frame/spring/Spring自定义注解扫描.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring自定义注解扫描\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Spring管理的类\\r\\n\\r\\n以下两种方式都可以实现。\\r\\n\\r\\n 使用@ComponentScan + Bean定义\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\n@ComponentScan(basePackages = {\\\"your.package.to.scan\\\"}) // 指定要扫描的包\\r\\npublic class AppConfig {\\r\\n\\r\\n    @Autowired\\r\\n    private ListableBeanFactory beanFactory;\\r\\n\\r\\n    @PostConstruct\\r\\n    public void processAnnotatedBea\"},{\"url\":\"/frame/spring/Spring配置文件加载顺序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring配置文件加载顺序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot配置文件的加载顺序\\r\\n\\r\\nSpringBoot项目启动会扫描以下位置的application.properties或者application.yml文件作为SpringBoot的默认配置文件，具体的目录位置见下图。\\r\\n\\r\\n1. file:./config/ （ 项目根路径下的config文件夹）\\r\\n2. file:./ （项目根路径）\\r\\n3. classpath:/config/ （类路径下的config文件夹）\\r\\n4. classpath:/ （类路径）\\r\\n\\r\\n\\r\\n\\r\\n按照配置文件的优先级，8001\\r\\n\\r\\n&gt; 注意file层是项目的最外层目录，也就是工作目录。\\r\\n&\"},{\"url\":\"/frame/spring/custom/AOP.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AOP\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ByteBuddy\\r\\n\\r\\nAOP即面向切面编程，本质上是一个 Proxy 模式。核心就是拦截核心 Bean 的方法调用。\\r\\n\\r\\n- JDK动态代理\\r\\n- CGLIB动态生成字节码代理。\\r\\n\\r\\n\\r\\n&gt;\\r\\n\\r\\n AOP实现核心\\r\\n\\r\\n- 找到符合AOP要求的原始Bean\\r\\n- 执行指定的拦截器逻辑\\r\\n\\r\\n AOP流程\\r\\n\\r\\n1. 利用 `BeanPostProcessor` 检测每个Bean。\\r\\n2. 扫描每个 Bean 的 @Around 注解。\\r\\n3. 执行 InvocationHandler 的代理方法。\\r\\n\\r\\n 实现 @Before 和 @After\\r\\n\\r\\n基于@Around的模板就\"},{\"url\":\"/frame/spring/custom/Boot.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Boot\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot 内置了 Tomcat，IOC容器和 WebMVC 模块，所以能直接启动。\\r\\n\\r\\n 启动类\\r\\n\\r\\n```java\\r\\n@Slf4j\\r\\npublic class SummerApplication {\\r\\n\\r\\n    static final String CONFIG_APP_YAML = \\\"/application.yml\\\";\\r\\n    static final String CONFIG_APP_PROP = \\\"/application.properties\\\";\\r\\n\\r\\n    public static void run(String webDir, String base\"},{\"url\":\"/frame/spring/custom/IOC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IOC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"其中构造方法注入和工厂方法注入是强依赖，因为Bean创建和属性注入放到一起了。\\r\\n\\r\\n比如构造方法注入，创建对象的同时进行属性注入，这种属于强依赖。\\r\\n\\r\\n而强依赖是解决不了循环依赖的问题的，因为创建对象和属性注入属于一体不可分的。\\r\\n\\r\\n我们解决循环依赖是先创建对象，然后属性注入的时候利用三级缓存解决的。\\r\\n\\r\\n```java\\r\\n    public BeanTest(@Value(\\\"spring.port\\\") String port, String name) {\\r\\n        System.out.println(port);\\r\\n    }\\r\\n```\\r\\n\\r\\nIOC容器有两类，Bean\"},{\"url\":\"/frame/spring/custom/JDBC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JDBC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"DataSource\\r\\n\\r\\n自动注入DataSource\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\npublic class JdbcConfiguration {\\r\\n\\r\\n    /**\\r\\n     * 自动注入HikariDataSource\\r\\n     *\\r\\n     * @param url\\r\\n     * @param username\\r\\n     * @param password\\r\\n     * @param driver\\r\\n     * @param maximumPoolSize\\r\\n     * @param minimumPoolSize\\r\\n     * @pa\"},{\"url\":\"/frame/spring/custom/MVC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MVC实现逻辑\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 应用程序必须配置一个Summer Framework提供的 Listener；\\r\\n2. Tomcat 完成 Servlet 容器的创建后，立刻根据配置创建Listener；\\r\\n    1. Listener初始化时创建 IOC 容器；\\r\\n    2. Listener继续创建DispatcherServlet实例，并向Servlet容器注册；\\r\\n    3. DispatcherServlet初始化时获取到IOC容器中的Controller实例，因此可以根据URL调用不同Controller实例的不同处理方法。\\r\\n    4. 容器中的Controller实例，因此可以根据URL调用不同\"},{\"url\":\"/frame/spring/custom/声明式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"声明式事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"事务传播模型\\r\\n\\r\\n| 传播行为 | 含义 |\\r\\n| --- | --- |\\r\\n| PROPAGATION_REQUIRED | 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。 |\\r\\n| PROPAGATION_SUPPORTS | 支持当前事务，如果当前没有事务，就以非事务方式执行。 |\\r\\n| PROPAGATION_MANDATORY | 支持当前事务，如果当前没有事务，就抛出异常。 |\\r\\n| PROPAGATION_REQUIRED_NEW | 新建事务，如果当前存在事务，把当前事务挂起。 |\\r\\n| PROPAGATION_NOT_SUPPORTED | 以非事务方式\"},{\"url\":\"/frame/spring/custom/手写Spring.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"手写Spring\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- boot模块：实现一个简化版的 `Spring Boot`，用于打包运行。\\r\\n- web模块：实现Web MVC和REST API。\\r\\n\\r\\n Spring主要模块\\r\\n\\r\\n- context模块：实现ApplicationContext容器与Bean的管理；\\r\\n- aop模块：实现AOP功能；\\r\\n- jdbc模块：实现JdbcTemplate，以及声明式事务管理；\\r\\n\\r\\n IOC\\r\\n\\r\\nIOC\\r\\n\\r\\n AOP\\r\\n\\r\\nAOP\\r\\n\\r\\n JDBC\\r\\n\\r\\nJDBC\\r\\n\\r\\n声明式事务\\r\\n\\r\\n1. 由`JdbcConfiguration`创建的`DataSource`，实现了连接池；\\r\\n2. 由`Jdb\"},{\"url\":\"/frame/spring/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Spring框架\\r\\n\\r\\n 一、Spring框架\\r\\n\\r\\n- Spring框架概述\\r\\n- ApplicationContext 和 BeanFactory 区别\\r\\n- BeanFactory 和 FactoryBean 总结\\r\\n- Spring中Bean的作用域\\r\\n- Spring中Bean加载流程\\r\\n- Spring依赖注入\\r\\n- Spring如何解决循环依赖\\r\\n\\r\\n- AOP\\r\\n- Spring事务总结\\r\\n- Aware接口\\r\\n- Spi机制\\r\\n- Spring配置文件加载顺序\\r\\n\\r\\n 二、使用总结\\r\\n\\r\\n- Spring自定义注解扫描\\r\\n- ByteBuddy实现动态代理\\r\\n\\r\\n 三、手写S\"},{\"url\":\"/frame/springboot/SpringBoot使用APO记录操作日志.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot使用APO记录操作日志\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"通过织入自定义注解 @Log，再进行解析记录操作日志。\\r\\n\\r\\n1. 自定义注解 @Log\\r\\n    \\r\\n    ```java\\r\\n    @Target({ElementType.PARAMETER, ElementType.METHOD})\\r\\n    @Retention(RetentionPolicy.RUNTIME)\\r\\n    @Documented\\r\\n    public @interface Log {\\r\\n    \\r\\n        /**\\r\\n         * 模块\\r\\n         */\\r\\n        String title() default \\\"default\\\";\\r\\n\"},{\"url\":\"/frame/springboot/SpringBoot能同时处理多少请求.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot能同时处理多少请求\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot内置了Tomcat，处理请求是 Web 容器处理的。\\r\\n\\r\\n1. 线程池线程数限制\\r\\n\\r\\n   而 Tomcat 的线程池默认最大线程池是 200，所以默认同时最多能处理 200 个请求。\\r\\n\\r\\n   \\r\\n&gt;\\r\\n2. 连接数限制\\r\\n\\r\\n   达到连接池数时，会限制请求数。此时因连接数限制为准，而不是最大线程数。\\r\\n\\r\\n    ```\\r\\n    tomcat最大连接数限制\\r\\n    server.tomcat.max-connections=12\\r\\n    ```\\r\\n\\r\\n\\r\\n---\\r\\n\\r\\n 限制配置\\r\\n\\r\\n```\\r\\ntomcat最大连接数限制\\r\\nserver.tomca\"},{\"url\":\"/frame/springboot/SpringBoot项目自动初始化数据库.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot项目自动初始化数据库\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"背景\\r\\n\\r\\n在 SpringBoot 启动的时候若配置文件中配置的数据库不存在，则自动创建数据库，并执行初始化SQL。\\r\\n\\r\\n 思路\\r\\n\\r\\n1. 判断数据库是否存在。\\r\\n2. 手动注入Datasource。\\r\\n    \\r\\n    在数据库未创建时，启动会报错\\r\\n    \\r\\n3. 初始化表。\\r\\n\\r\\n 解决方式\\r\\n\\r\\n1. 启动类排除 `DataSourceAutoConfiguration.class` ，采用手动注入的方式。\\r\\n    \\r\\n    如果配置的数据库不存在，SpringBoot启动的时候会提示找不到数据库，所以要排除掉，然后手动注入。\\r\\n    \\r\\n    ```java\\r\\n  \"},{\"url\":\"/frame/springboot/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot 框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot 框架\\r\\n\\r\\n\\r\\n 使用总结\\r\\n- SpringBoot能同时处理多少请求\\r\\n- SpringBoot使用APO记录操作日志\\r\\n- SpringBoot项目自动初始化数据库\"},{\"url\":\"/frame/springcloud/Feigh远程调用原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Feigh远程调用原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"思路\\r\\n\\r\\n根据接口地址和 FeignClient构建http请求。\\r\\n\\r\\n1. 构建 http请求模版，包含 header、body、method等参数信息。\\r\\n2. 设置 options，包含超时时间参数配置。\\r\\n3. 根据 clientName 从 nacos（类似map，保存clientName和访问地址的对应关系）中获取访问地址。\\r\\n4. 根据访问地址和http请求参数发起http请求。\\r\\n\\r\\n 代码入口\\r\\n\\r\\n`io/github/openfeign/feign-core/10.4.0/feign-core-10.4.0.jar!/feign/ReflectiveFeign.cla\"},{\"url\":\"/frame/springcloud/Gateway.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Gateway\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"请求流程\\r\\n\\r\\n&lt;img src=\\\"https://s2.loli.net/2025/06/10/RBVjazHT3NinfQe.png\\\" alt=\\\"image.png\\\" style=\\\"zoom:50%;\\\" /\\r\\n\\r\\n- Gateway Handler（网关处理器）：网关处理器是 Spring Cloud Gateway 的核心组件，负责将请求转发到匹配的路由上。它根据路由配置和断言条件进行路由匹配，选择合适的路由进行请求转发。网关处理器还会依次应用配置的过滤器链，对请求进行处理和转换。\\r\\n- Gateway Filter Chain（网关过滤器链）：网关过滤器链由一系列过滤器组成，按照\"},{\"url\":\"/frame/springcloud/Nacos.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Nacos\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"地址\\r\\n\\r\\n GitHub\\r\\n\\r\\nhttps://github.com/alibaba/nacos\\r\\n\\r\\n 文档\\r\\n\\r\\nNacos 快速开始\\r\\n\\r\\n 启动命令\\r\\n\\r\\n```sql\\r\\nsh startup.sh -m standalone\\r\\n```\\r\\n\\r\\n 可视化页面\\r\\n\\r\\n`http://localhost:8848/nacos`\\r\\n\\r\\n\\r\\n\\r\\n 注册中心原理\\r\\n\\r\\n 服务注册\\r\\n\\r\\nNocas Client 在启动的时候会通过 Rest 的方式将自己的元数据（Ip、端口）等信息发给 Nocas Server。\\r\\n\\r\\nNacos Server 收到 Client 的注册请求后，将元数据信息存到\"},{\"url\":\"/frame/springcloud/Seata分布式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Seata分布式事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在分布式情况下，一次业务请求需要调用多个系统操作多个数据源时，针对多个数据源操作会产生分布式事务问题。每个系统能够保证各自数据源的一致性问题，但是全部系统数据的一致性问题没法保证。\\r\\n\\r\\n 官网地址\\r\\n\\r\\nhttps://seata.io/zh-cn/docs/user/quickstart.html\\r\\n\\r\\n 下载地址\\r\\n\\r\\nhttps://seata.io/zh-cn/blog/download.html\\r\\n\\r\\n 基础概念\\r\\n\\r\\n事务ID + 三组件\\r\\n\\r\\n事务ID\\r\\n\\r\\n- Transaction ID(XID)\\r\\n\\r\\n三组件\\r\\n\\r\\n- TC-事务协调者\\r\\n\\r\\n  维护全局和分支事务的状态\"},{\"url\":\"/frame/springcloud/Sentinel原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Sentinel原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Sentinel工作主流程\\r\\n\\r\\n滑动窗口实现原理 · 吾爱开源 · 看云\\r\\n\\r\\n 限流算法\\r\\n\\r\\n 计数器算法\\r\\n\\r\\n计数器算法统计某个时间段的请求量，判断是否超过阈值。\\r\\n\\r\\n\\r\\n\\r\\n存在的问题：\\r\\n\\r\\n如上图中，在时间段的临界处加起来其实QPS 超过了阈值，但是平均到单个时间段未发生。\\r\\n\\r\\n单纯的计数器算法存在 临界统计不准确 的问题。\\r\\n\\r\\n 滑动窗口计数器算法\\r\\n\\r\\n解决滑动窗口存在的问题，引入了滑动窗口计数器。\\r\\n\\r\\n我们将统计时间细分，比如将 1s 统计时长分为 5个 时间窗口，通过 滚动统计所有时间窗口的QPS 作为系统实际的 QPS 的方式，就能解决上述 临界统计 问题。\\r\"},{\"url\":\"/frame/springcloud/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringCloud\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringCloud\\r\\n\\r\\n 使用总结\\r\\n\\r\\n- 注册中心的演进\\r\\n- Nacos\\r\\n- Gateway\\r\\n- Feigh远程调用原理\\r\\n- Sentinel原理\\r\\n- Seata分布式事务\\r\\n\\r\\n\\r\\n\\r\\n 项目\\r\\n\\r\\nSpringCloud总结练习-Gitee\"},{\"url\":\"/frame/springcloud/注册中心的演进.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"注册中心的演进\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 直接远程调用\\r\\n\\r\\n   \\r\\n\\r\\n2. 维护注册表，维护服务调用地址\\r\\n\\r\\n   \\r\\n\\r\\n3. 接入 nginx，利用 nginx 做负载\\r\\n\\r\\n   \\r\\n\\r\\n4. 引入注册机制，提供注册和服务发现功能\\r\\n\\r\\n   \\r\\n\\r\\n5. 引入心跳机制，解决注册中心宕机或者目标服务不可用\"},{\"url\":\"/java/cache/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Cache\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 本地缓存\\r\\n- 多级缓存\\r\\n- 缓存淘汰算法\"},{\"url\":\"/java/cache/多级缓存.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"多级缓存\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"二级缓存\\r\\n\\r\\n二级缓存没有网络开销\\r\\n\\r\\n\\r\\n\\r\\n 优点\\r\\n\\r\\n1. 减少网络请求，提高性能。\\r\\n2. 减少远程缓存的读压力。\\r\\n3. 天然分布式缓存，只存在于当前节点服务。\\r\\n\\r\\n 缺点\\r\\n\\r\\n1. 占用本地内存，空间有限，不支持大数据量。\\r\\n\\r\\n   只存储最热的数据到本地缓存，结合热点服务探测。\\r\\n\\r\\n2. 重启数据会丢失。\\r\\n\\r\\n   重启丢失数据无法避免，但是可以在重启项目的时候把最热的数据加到本地缓存。\\r\\n\\r\\n3. 分布式场景，数据可能不一致。\\r\\n4. 和远程缓存可能存在不一致的问题。\\r\\n\\r\\n   只能保证最终一致性，尽可能让本地缓存过期时间短一点，这样就能加载远程缓存，达到最终\"},{\"url\":\"/java/cache/本地缓存.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"本地缓存\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Guava\\r\\n\\r\\n- 支持最大容量限制\\r\\n- 支持两种过期删除策略\\r\\n- 支持简单的统计功能\\r\\n- 插入时间\\r\\n- 访问时间\\r\\n- 基于LRU算法实现\\r\\n\\r\\n```java\\r\\nLoadingCache&lt;Integer, String\\r\\n        //设置并发级别为8，并发级别是指可以同时写缓存的线程数\\r\\n        .concurrencyLevel(8)\\r\\n        //设置缓存的初始容量为10\\r\\n        .initialCapacity(10)\\r\\n        // 设置缓存最大容量为100，超过100之后就会按照LRU最近最少使用算法来移除缓存\\r\\n    \"},{\"url\":\"/java/cache/缓存淘汰算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"缓存淘汰算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"FIFO-先进先出\\r\\n\\r\\n\\r\\n\\r\\n比较简单，不够灵活。\\r\\n\\r\\n没有跟缓存使用频次和时间等维度联系起来。\\r\\n\\r\\n LRU-最近最少使用\\r\\n\\r\\n核心思想是最近使用的时间。比如最近一小时以内使用缓存的时间。\\r\\n\\r\\n\\r\\n\\r\\n根据数据的历史访问记录来淘汰数据，淘汰最久未被使用的数据。\\r\\n\\r\\n基于如果数据最近被访问过，那么将来访问的记录会更高。优先淘汰最久未被使用的冷数据。\\r\\n\\r\\n LFU-最近最不常用\\r\\n\\r\\n核心思想是最近使用的次数。比如最近一小时内使用缓存的次数。\\r\\n\\r\\n\\r\\n\\r\\nLFU能够提高热点数据的命中率。\\r\\n\\r\\n但是当缓存中数据都是热点数据的时候，将失去该特性。\\r\\n\\r\\n单纯的LFU存在缺陷。\\r\\n\"},{\"url\":\"/java/collection/Collection集合概述.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集合概述\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集合概述\\r\\n\\r\\n 为什么使用集合？\\r\\n\\r\\n当我们需要保存一组类型相同的数据的时候，我们应该用一个容器来保存，这个容器就是数组。\\r\\n\\r\\n但是数组的长度是固定的，当添加的元素超过了数组的长度之后，需要对数组重新定义。而且数组存储的数据是`有序的`、`可重复的`，太过于单一，扩展性不够。\\r\\n\\r\\n于是，引入了集合，Java 内部给我们提供了功能完善的集合框架。能`存储任意对象`，长度可以`动态改变`，提高了数据存储的灵活性。\\r\\n\\r\\n 数组和集合的区别\\r\\n\\r\\n1. 存储类型\\r\\n   - 数组可以存储`基本数据类型`，又可以存储`引用数据类型`。\\r\\n   - 集合只能存储`引用数据类型`。（集合中也可以存\"},{\"url\":\"/java/collection/ConcurrentHashMap1.7.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ConcurrentHashMap - 1.7\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、类简介\\r\\n\\r\\nConcurrentHashMap 是一个线程安全的 HashMap，在 JDK 1.7 HashMap的基础上实现了 `分段锁` 来保证线程安全。在 HashMap 的基础上，默认分为 16 个段，每个段都拥有独立的锁，来保证各个段的线程安全。\\r\\n\\r\\n 扩展 - 线程安全的 HashMap\\r\\n\\r\\nMap实现线程安全的三种方式\\r\\n\\r\\n Unsafe方法总结\\r\\n\\r\\n\\r\\n\\r\\n 二、主要参数\\r\\n\\r\\n```java\\r\\npublic class ConcurrentHashMap&lt;K, V\\r\\n        implements ConcurrentMap&lt;K, V&gt;\"},{\"url\":\"/java/collection/ConcurrentHashMap1.8.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ConcurrentHashMap -1.8\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ConcurrentHashMap 源码分析\\r\\n\\r\\n\\r\\n1.8的ConcurrentHashMap，采用对Node加锁机制。\\r\\n\\r\\n 加锁原理\\r\\n\\r\\n采用CAS+Synchronized组合锁的方法。\\r\\n\\r\\n- CAS\\r\\n\\r\\n  操作Node数组的时候以CAS方式操作。\\r\\n\\r\\n- Synchronized\\r\\n\\r\\n  操作Node对应的数据结构，链表或红黑树的时候加Synchronized。保证操作数据的原子性。\"},{\"url\":\"/java/collection/HashMap1.7.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HashMap - 1.7\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类简介\\r\\n\\r\\nHashMap 是一个用来存储 Key - Value 键值对的集合，每一个键值对也叫做 Entry，这些 Entry 保存在底层数组中。\\r\\n\\r\\n 1. 底层数组\\r\\n\\r\\n底层数组包含的每个元素可以称之为 桶，元素实际保存在每个桶上。\\r\\n\\r\\n```java\\r\\n    static final Entry&lt;?,?\\r\\n\\r\\n    /**\\r\\n     * The table, resized as necessary. Length MUST Always be a power of two.\\r\\n     */\\r\\n    transient Entry&lt;K,V&gt;[] t\"},{\"url\":\"/java/collection/HashMap1.8.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HashMap - 1.8\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类简介\\r\\n\\r\\n 默认参数\\r\\n\\r\\n- 默认长度\\r\\n\\r\\n  ```\\r\\n   static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4\\r\\n  ```\\r\\n\\r\\n- 最大容量\\r\\n\\r\\n  ```\\r\\n  static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;\\r\\n  ```\\r\\n\\r\\n- 默认负载因子\\r\\n\\r\\n  ```\\r\\n   static final float DEFAULT_LOAD_FACTOR = 0.75f;\\r\\n  ```\\r\\n\\r\\n- 默认树化临界点\\r\\n\\r\\n  ```\\r\\n  static final in\"},{\"url\":\"/java/collection/List集合体系.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"List集合体系\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ArrayList\\r\\n\\r\\n 特点\\r\\n\\r\\n- 底层基于数组实现。\\r\\n- 有索引，支持快速访问。\\r\\n- 查询修改快，增删慢。\\r\\n- 线程不安全。\\r\\n\\r\\n 构造方法\\r\\n\\r\\n1. 无参构造\\r\\n\\r\\n   - JDK 1.6 之前，以初始容量 10 创建一个长度为10的数组。\\r\\n   - JDK 1.6 之后，创建一个空数组。\\r\\n\\r\\n   ```java\\r\\n       public ArrayList() {\\r\\n           this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;\\r\\n       }\\r\\n   ```\\r\\n\\r\\n2. 有参构造 - 数\"},{\"url\":\"/java/collection/Set集合体系.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Set集合体系\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HashSet\\r\\n\\r\\n 特点\\r\\n\\r\\n- 底层基于哈希算法实现，使用 `HashMap` 保存数据。\\r\\n- 无序（存取顺序不一致）。\\r\\n- 不可以存储重复元素。\\r\\n- 线程不安全。\\r\\n\\r\\n 构造方法\\r\\n\\r\\n1. 无参构造\\r\\n\\r\\n   底层使用 `HashMap` 保存数据。\\r\\n   \\r\\n```java\\r\\n       public HashSet() {\\r\\n           map = new HashMap&lt;\\r\\n       }\\r\\n```\\r\\n\\r\\n3. 有参构造 - Collection 集合\\r\\n\\r\\n   根据传入的 Collection 集合 初始化底层 `HashMap`。\\r\\n\\r\\n\"},{\"url\":\"/java/collection/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集合\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Collection集合\\r\\n\\r\\n- Collection集合概述\\r\\n- List集合体系\\r\\n- Set集合体系\\r\\n\\r\\n Map集合体系\\r\\n\\r\\n- HashMap - 1.7\\r\\n- ConcurrentHashMap - 1.7\\r\\n- HashMap - 1.8\\r\\n- ConcurrentHashMap -1.8\"},{\"url\":\"/java/concurrent/Java高并发.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Java工程师成长计划-高并发\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java工程师成长计划-高并发\\r\\n\\r\\n```\\r\\n         _______________________________________________        \\r\\n        |   _      __        __                         |       \\r\\n________|  | | /| / / ___   / / ____ ___   __ _  ___    |_______\\r\\n\\\\       |  | |/ |/ / / -_) / / / __// _ \\\\ /  ' \\\\/ -_)   |      /\\r\\n \\\\      |  |\"},{\"url\":\"/java/concurrent/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"高并发\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"思维导图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 参考链接\\r\\n\\r\\n- 深入浅出Java多线程\"},{\"url\":\"/java/concurrent/single/AQS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AQS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"从ReentrantLock的实现看AQS的原理及应用\\r\\n\\r\\nAQS是一种提供了原子式管理同步状态、阻塞和唤醒线程功能以及队列模型的简单框架。\\r\\n\\r\\n 组成\\r\\n\\r\\n1. 共享资源状态维护state。\\r\\n\\r\\n   - AQS使用一个`volatile`修饰的 int 成员变量来表示同步状态，这个状态可以反映锁的当前持有情况。\\r\\n\\r\\n     例如，当状态为 0 时表示无锁状态，而当状态为非零时表示有锁被占用。\\r\\n\\r\\n2. FIFO 队列实现线程排队。\\r\\n\\r\\n   AQS维护了一个FIFO（先入先出）的双向队列，用于管理等待获取锁的线程，当一个线程尝试获取锁但失败时，它会进入这个队列并阻塞，直到锁\"},{\"url\":\"/java/concurrent/single/BlockQueue阻塞队列.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"阻塞队列BlockQueue\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"阻塞队列`BlockQueue`比起传统的`Queue`多了阻塞的功能，适合用于多线程之间的数据共享。阻塞主要发生在队列为空和队列满的情况。\\r\\n\\r\\n- 在队列为空的时候，操作元素出队的线程会进行循环等待，直到队列变为非空。\\r\\n- 在队列满的时候，操作元素入队的线程会进行循环等待，直到队列变为非满。\\r\\n\\r\\n 常见方法\\r\\n\\r\\n`BlockQueue入队`的方法有如下几种：\\r\\n\\r\\n- `offer()`方法，如果队列已满，无法存放，直接返回false。\\r\\n- `add()`方法，实际调用了offer()方法，增加了（Queue Full）的异常信息返回。\\r\\n- `put()`方法，若队列已满，会进行\"},{\"url\":\"/java/concurrent/single/CAS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"悲观和乐观策略\\r\\n\\r\\n锁有着悲观锁和乐观锁之分，悲观锁拥有资源的时候，认为随时会有人来篡改拥有的资源，所以在其拥有资源时不允许其他人访问。而乐观锁在拥有资源的时候不认为会有人来篡改其所拥有的资源，所以在其拥有资源的时候允许其他人访问。悲观锁和乐观锁是一种思想，对应的也是一种策略。\\r\\n\\r\\n加锁和使用 synchronized 其实就是一种悲观的策略，因为总是假设临界区的操作会产生冲突，如果有多个线程需要访问临界区资源，加锁和使用 synchronized 会阻塞其它线程。\\r\\n\\r\\n而无锁其实就是一种乐观的策略，它在操作的时候会假设访问资源不会冲突，所有的线程之间不存在阻塞，也就不存在等待，线程会持\"},{\"url\":\"/java/concurrent/single/ThreadLocal.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ThreadLocal总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ThreadLocal 提供了线程的局部变量，只有当前线程可以操作，不会和其它线程的局部变量产生冲突，实现了变量的线程安全。`ThreadLocal&lt;T\\r\\n\\r\\n 简单例子\\r\\n\\r\\n```java\\r\\npublic class ThreadLocalDemo {\\r\\n\\r\\n    private static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;();\\r\\n\\r\\n    public static void main(String[] args) {\\r\\n        //主线程\\r\\n        threadL\"},{\"url\":\"/java/concurrent/single/synchronized原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"synchronized原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"synchronized原理详解（通俗易懂超级好）-CSDN博客\\r\\n\\r\\n 特性\\r\\n\\r\\n- 原子性\\r\\n\\r\\n  synchronized 修饰的对象或类所有操作都是原子性的。线程需要获取锁，保证整个操作过程的原子性。\\r\\n\\r\\n  比如 i++这种赋值操作。\\r\\n\\r\\n- 可见性\\r\\n\\r\\n  一个线程如果要访问该类或对象必须先获得它的锁，而这个锁的状态对于其他任何线程都是可见的，并且在释放锁之前会将对变量的修改刷新到主存当中，保证资源变量的可见性。\\r\\n\\r\\n  如果某个线程占用了该锁，其他线程就必须在锁池中等待锁的释放。\\r\\n\\r\\n- 有序性\\r\\n\\r\\n  保证只有一个线程访问，确保了有序性。\\r\\n\\r\\n- 可重入性\\r\\n\"},{\"url\":\"/java/concurrent/single/transmittable-thread-local.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"transmittable-thread-local\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"线程池中的线程是可以复用的，假如第一个线程对  ThreadLocal 变量进行了操作，如果没有及时清理，下一个线程就会受到影响。因为 ThreadLocal  是在每个线程上维护了一个 ThreadLocalMap ，所以在线程复用的情况下，之后的线程会获取到  ThreadLocal  里之前线程设置的值。\\r\\n\\r\\n ThreadLocal多线程问题\\r\\n\\r\\n在多线程场景下传递ThreadLocal，如果线程池是池化的话，可能会导致复用ThreadLocal里面的值。\\r\\n\\r\\n\\r\\n\\r\\n 需求场景\\r\\n\\r\\n在使用线程池等池化复用线程的情况下，传递ThreadLoca值。\\r\\n\\r\\n1. 分布式跟踪 tr\"},{\"url\":\"/java/concurrent/single/原子类.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"原子类\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本类型-AtomicInteger\\r\\n\\r\\nAtomicInteger 是无锁的线程安全整数类，基于 `CAS` 实现，位于 `java.util.concurrent.atomic` 包下，该包下实现了一系列使用 `CAS` 操作实现线程安全的类型。其它原子类和 AtomicInteger 非常类似，故只分析 AtomicInteger。\\r\\n\\r\\n\\r\\n\\r\\n 比较 Integer\\r\\n\\r\\nAtomicInteger 是一个整数，与 Integer 不同的是，它是可变的并且是线程安全的。\\r\\n\\r\\n比如在多线程不加锁的情况下，操作 Integer 或者 AtomicInteger ，来比较结果是否正确。\"},{\"url\":\"/java/concurrent/single/死锁活锁和饥饿.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"死锁活锁和饥饿\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在使用锁的时候，可能会因为使用不当产生死锁、活锁和饥饿的现象。\\r\\n\\r\\n在单体应用中，加锁是否能解决所有的线程安全问题？\\r\\n\\r\\n*不能，因为加锁使用不当会有死锁、活锁和饥饿等问题。*\\r\\n\\r\\n 死锁\\r\\n\\r\\n什么是死锁？\\r\\n\\r\\n死锁指的是两个或多个线程之间，互相占用着对方请求的资源，而且不会释放已持有的资源，造成了多线程之间无限等待的现象，就叫做死锁。\\r\\n\\r\\n死锁发生后，会浪费大量的系统资源，并且在高并发下存在严重的安全隐患，甚至导致整个系统崩溃。\\r\\n\\r\\n 死锁产生的条件\\r\\n\\r\\n1. 互斥\\r\\n\\r\\n   某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结\"},{\"url\":\"/java/concurrent/single/线程池的关闭.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程池的关闭\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"线程池的关闭\\r\\n\\r\\n线程池的关闭方式有两种，一种是调用 `shutdown()` 方法，另一种是调用 `shutdownNow()` 方法。\\r\\n\\r\\n- shutdown\\r\\n\\r\\n  调用该方法后，线程池拒绝接受新提交的任务，同时等待线程池里和任务队列中的任务执行完毕再关闭线程。\\r\\n\\r\\n- shutdownNow\\r\\n\\r\\n  调用该方法后，线程池拒绝接受新提交的任务，不再执行任务队列的任务，将线程池任务队列里的任务全部返回。\\r\\n\\r\\n shutdown\\r\\n\\r\\n调用该方法后，线程池拒绝接受新提交的任务，同时等待线程池里和任务队列中的任务执行完毕再关闭线程。\\r\\n\\r\\n```java\\r\\n    public \"},{\"url\":\"/java/concurrent/single/线程池的执行流程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程池的执行\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"执行流程\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n1. 根据初始化参数创建线程池，刚创建时，线程池内没有线程。\\r\\n2. 当有新的任务提交到线程池的时候，会立即新增线程执行任务。\\r\\n3. 若运行线程数 = 核心线程数时，这时进来的任务会被添加到任务队列中，而线程会从任务队列中获取任务执行。\\r\\n4. 运行线程数 = 核心线程数 且 任务队列已满，这时候会在线程池中创建新线程来执行任务。\\r\\n5. 运行线程数 = 最大线程数，且任务队列已满，此时会执行线程池对应的拒绝策略。\\r\\n6. 当任务队列中没有任务，且线程等待时间超过空闲时间，则该线程会被回收。最终线程池中的线程数量会保持在核心线程数的大小。\\r\\n\\r\\n 源码分析\\r\\n\"},{\"url\":\"/java/concurrent/single/线程的生命周期.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程的生命周期\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 Java 中线程从新建到关闭会经过不同的状态，将线程从新建到关闭作为一个生命周期，在 Java 中整个线程的生命周期有 6 种状态。\\r\\n\\r\\n 线程状态类型\\r\\n\\r\\n在 JDK 的 Thread 类，存在 `State` 枚举类，包含了线程的 6 种状态。\\r\\n\\r\\n```java\\r\\n    public enum State {\\r\\n        \\r\\n        NEW,\\r\\n        RUNNABLE,\\r\\n        BLOCKED,\\r\\n        WAITING,\\r\\n        TIMED_WAITING,\\r\\n        TERMINATED;\\r\\n    }\\r\\n```\"},{\"url\":\"/java/distributed/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 分布式事务\\r\\n- 分布式锁\\r\\n- 分布式ID\\r\\n- 幂等性问题\"},{\"url\":\"/java/distributed/分布式ID.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式ID\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"要求\\r\\n\\r\\n1. 分布式全局唯一\\r\\n2. 有序递增\\r\\n\\r\\n 方案\\r\\n\\r\\n\\r\\n\\r\\n 数据库主键自增\\r\\n\\r\\n1. 创建一个全局主键自增的表。\\r\\n2.  从该表查询id使用。\\r\\n    - 效率低下，每次插入之前都要查一次自己的id\\r\\n\\r\\n 数据库号段模式\\r\\n\\r\\n批量从全局自增主键表获取一批主键，放到内存里。（减少数据库访问次数）\\r\\n\\r\\n```bash\\r\\nCREATE TABLE `sequence_id_generator` (\\r\\n  `id` int(10) NOT NULL,\\r\\n  `current_max_id` bigint(20) NOT NULL COMMENT '当前最大id',\\r\\n\"},{\"url\":\"/java/distributed/分布式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在分布式情况下，假如存在 A 同时调用 B、C多个微服务。假如 B 服务事务正常执行并提交，但是 C 事务提交失败，此时 B 和 C都需要回滚。\\r\\n\\r\\n而 MySQL 的事务回滚是通过 redo log 机制来实现的，保证事务的持久化和一致性。\\r\\n\\r\\n但是在分布式，使用了分布式事务的情况下，是通过一条更新SQL，还原原本的数据。\\r\\n\\r\\n\\r\\n\\r\\n一文搞明白分布式事务解决方案！真的 so easy！\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n分布式事务，原理简单，写起来全是坑！ - 掘金\\r\\n\\r\\n\\r\\n\\r\\n 分布式事务解决方案\\r\\n\\r\\n 2PC - 两阶段提交\\r\\n\\r\\n1. prepare - 准备阶段\\r\\n\\r\\n    各个参\"},{\"url\":\"/java/distributed/分布式锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- mysql\\r\\n- redis 的 setnx\\r\\n- redission\\r\\n- redLock\\r\\n- zookeeper\\r\\n- curator\\r\\n\\r\\nredis的分布式锁可用性更高，但是分布式不友好。一般单机的redis实现分布式锁性能就够用。\\r\\n\\r\\n如果非要要求可靠性，可以选择zk，只是zk是cp的，性能要差一点。\\r\\n\\r\\n\\r\\n\\r\\n Reids分布式锁\\r\\n\\r\\nredis实现分布式锁\\r\\n\\r\\n\\r\\n\\r\\n 手写 zk 分布式锁\\r\\n\\r\\nzk 实现分布式锁，是依赖 zk 的临时有序节点。\\r\\n\\r\\n多个线程在 rootPath 下面按顺序创建节点。\\r\\n\\r\\n1. 首先有持久节点lock\\r\\n2. 每个请求获取锁\"},{\"url\":\"/java/distributed/幂等性问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"幂等性问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"常见幂等问题\\r\\n\\r\\n解决常见幂等性问题采用 `一锁、二判、三更新` 就可以解决。\\r\\n\\r\\n- 一锁：锁定需要处理的订单\\r\\n- 二判：订单是否支付\\r\\n- 三更新：更新订单状态\\r\\n\\r\\n 数据库锁-悲观锁\\r\\n\\r\\n- for Update\\r\\n  \\r\\n    `FOR UPDATE` 子句告诉数据库管理系统（DBMS）在检索行的同时锁定这些行，直到当前事务结束。\\r\\n    \\r\\n\\r\\n```java\\r\\nBEGIN;\\r\\n\\r\\nSELECT * FROM orders\\r\\nWHERE order_id = 123\\r\\nFOR UPDATE;\\r\\n\\r\\n-- 进行业务逻辑处理，例如更新订单状态\\r\\nUPDATE orders \"},{\"url\":\"/java/io/BIO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BIO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"JDK 网络编程 BIO，意为阻塞的 IO。\\r\\n\\r\\nBIO 的阻塞体现在两个方面：\\r\\n\\r\\n1. 若一个服务端的服务绑定端口启动后，主线程就会一直等待客户端的连接。\\r\\n2. 客户端和服务端 Socket 端口建立连接之后，在读取到 Socket 信息之前，线程一直处于等待，一直处于阻塞状态。\\r\\n\\r\\n典型的 请求 -应答模型\\r\\n\\r\\n由一个独立的 `Acceptor` 模型监听客户端的请求，收到请求后为每一个客户端创建一个线程去处理，处理完成后将结果返回给客户端。\\r\\n\\r\\nJava BIO：传统的网络通讯模型，就是BIO，同步阻塞IO。\\r\\n\\r\\n其实就是服务端创建一个ServerSocket， 然后就是\"},{\"url\":\"/java/io/IO多路复用.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IO多路复用\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"小白也看得懂的 I/O 多路复用解析（超详细案例）_哔哩哔哩_bilibili\\r\\n\\r\\n 基础概念\\r\\n\\r\\n\\r\\n\\r\\n1. Socket\\r\\n\\r\\n   套接字，在网络通信中，就是客户端和服务端的出入口。\\r\\n\\r\\n   \\r\\n&gt;\\r\\n2. fd\\r\\n\\r\\n   文件描述符，是指向资源文件的索引。\\r\\n\\r\\n\\r\\n Socket通讯的过程\\r\\n\\r\\n\\r\\n\\r\\n1. 服务端通过 bind 绑定机器的端口号， 进程 listen 某个端口。\\r\\n2. 客户端和服务端通过 tcp 三次握手建联。\\r\\n3. 进行数据交互，\\r\\n4. 最后通过 close 断开连接。\\r\\n\\r\\n IO模型\\r\\n\\r\\n\\r\\n\\r\\n 同步阻塞IO - BIO\\r\\n\\r\\n-\"},{\"url\":\"/java/io/NIO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"NIO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NIO 是 JDK1.4 引入，为了解决 BIO 阻塞的问题，又称 `no-blocking io`。\\r\\n\\r\\n同步非阻塞\\r\\n\\r\\n NIO特点\\r\\n\\r\\n- 面向缓冲区\\r\\n  \\r\\n    BIO 是面向流的，NIO 是面向缓冲区的。\\r\\n    \\r\\n    \\r\\n\\r\\n- 非阻塞模式\\r\\n  \\r\\n    NIO 的非阻塞模式，使其线程从 Channel 获取数据时，即使获取不到数据也不会阻塞线程。\\r\\n    \\r\\n\\r\\n NIO 核心组件\\r\\n\\r\\n\\r\\n\\r\\n Selector-轮询选择器\\r\\n\\r\\nJava NIO 的选择器允许一个单独的线程来监视多个输入通道（Channel）。\\r\\n\\r\\n选择器用于检测一个或多个通道的状\"},{\"url\":\"/java/io/Reactor模式.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Reactor模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Reactor模式详解＋源码实现\\r\\n\\r\\n整个 reactor 模式解决的主要问题就是在接收到任务后根据分发器快速进行分发给相应的事件处理器，不需要从开始状态就阻塞。\\r\\n\\r\\n基于事件驱动模型，当接收到请求后会将请求封装成事件，并将事件分发给相应处理事件的Handler，handler处理完成后将事件状态修改为下一个状态，再由Reactor将事件分发给能够处理下一个状态的handler进行处理。\\r\\n\\r\\n\\r\\n\\r\\n1. EventHandler：事件处理器，可以根据事件的不同状态创建处理不同状态的处理器；\\r\\n   \\r\\n    ```java\\r\\n    public abstract class Eve\"},{\"url\":\"/java/io/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- BIO\\r\\n- 基于BIO实现RPC框架\\r\\n- NIO\\r\\n- Reactor模式\\r\\n- IO多路复用\"},{\"url\":\"/java/io/基于BIO实现RPC框架.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"基于BIO实现RPC框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基于bio手写实现简单的rpc_java 手写一个bio-CSDN博客\\r\\n\\r\\n RPC\\r\\n\\r\\n\\r\\n\\r\\n RPC设计\\r\\n\\r\\n\\r\\n\\r\\nRPC 的核心就是让客户端调用远程服务方法，就像调用本地方法一样。\\r\\n\\r\\n- 服务端将自己的类注册到远程服务。\\r\\n- 客户端通过注册中心获取到服务端地址。\\r\\n    - 客户端调用服务端地址，传入类名，调用方法、入参\\r\\n    - 服务端收到方法信息后，本地通过反射执行方法，获取结果返回给客户端。\\r\\n- 客户端需要写一个需要调用的类，和服务端的类保持一致（方法名、入参类型、入参）。\\r\\n    - 客户端需要对这个类进行动态代理，实际访问的是该类的代理对象。\\r\\n   \"},{\"url\":\"/java/jvm/CPU负载过高排查记录.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"CPU负载过高排查记录\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"解决线上微服务容器cpu占用100%问题（java进程占用100%问题）_容器cpu占用高_上树的蜗牛儿的博客-CSDN博客\\r\\n\\r\\n 平台发现问题\\r\\n\\r\\n平台发现集群节点 node219 CPU利用率过高。\\r\\n\\r\\n\\r\\n\\r\\n通过查看该节点下的 pod 发现，bookdemo 使用 CPU 过高。\\r\\n\\r\\n\\r\\n\\r\\n 主机排查\\r\\n\\r\\n top 查看进程情况\\r\\n\\r\\n使用 top 确认占用cpu过高的进程。\\r\\n\\r\\nPID=17177 占用 CPU 最高。\\r\\n\\r\\n\\r\\n\\r\\n 查看进程 PID 对应的容器\\r\\n\\r\\n由于该进程是个POD，需要找到对应容器，进入容器内部排查线程情况。\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 容器内部\"},{\"url\":\"/java/jvm/G1收集器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"G1收集器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- XX:+UseG1GC\\r\\n\\r\\nG1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对 配备多颗处理器及大容量内存的机器，以极高概率满足GC停顿时间要求的同时，还具备高吞吐量性能特征。\\r\\n\\r\\nG1 收集器 在 JDK1.7 正式启用，是 JDK 9以后的默认垃圾收集器，取代了 CMS 以及 Parallel+Parallel Old 的组合，被 Oracle 官方称为“全功能的垃圾收集器”。\\r\\n\\r\\n- 适合大内存机器，具备高吞吐量。\\r\\n- 低 GC 停顿时间。\\r\\n\\r\\n 堆分布\\r\\n\\r\\n 区域分布\\r\\n\\r\\n\\r\\n\\r\\n区分于传统的堆内存分布，G1 是将 JVM 堆内存划分为了多个 \"},{\"url\":\"/java/jvm/JDK调优命令.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JDK调优命令\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"jstack\\r\\n\\r\\n 死锁检测\\r\\n\\r\\n1. 使用 jps 命令查看运行中的 java 进程 Id。\\r\\n   \\r\\n    \\r\\n    \\r\\n2. 使用 jstack 分析线程状态。\\r\\n   \\r\\n    ```\\r\\n    jstack 进程Id\\r\\n    ```\\r\\n    \\r\\n    - 线程状态\\r\\n      \\r\\n        通过分析进程可以得到，`DeadLockTest` 进程的两个线程分别为 `pool-1-thread-2` （简称2）和 `pool-1-thread-1`（简称1）。\\r\\n        \\r\\n        通过打印的线程信息可以发现，线程 2 和 1 的线程状态都是 \"},{\"url\":\"/java/jvm/JVM内存模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JVM内存模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java 内存模型在 JDK1.7 主要包含以下区域。\\r\\n\\r\\n- 程序计数器\\r\\n- 虚拟机栈\\r\\n- 本地方法栈\\r\\n- 方法区\\r\\n- 堆\\r\\n\\r\\n而在 JDK1.8中将运行时数据区中的方法区给取消了，换成了本地内存中的元数据区。\\r\\n\\r\\n- 程序计数器\\r\\n- 虚拟机栈\\r\\n- 本地方法栈\\r\\n- 堆\\r\\n- 元数据区\\r\\n\\r\\n 内存模型图\\r\\n\\r\\n1. JDK 1.7 内存模型图\\r\\n   \\r\\n    \\r\\n    \\r\\n2. JDK 1.8 内存模型图\\r\\n   \\r\\n    JDK1.8中取消了运行时数据区中的方法区，换成了元数据区放到了本地内存里。\\r\\n    \\r\\n    \\r\\n    \\r\\n\\r\\n 运行时数据区\\r\\n\\r\\n\"},{\"url\":\"/java/jvm/Java类加载器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"类加载器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"什么是类加载器\\r\\n\\r\\n类加载器（ClassLoader）就是在系统运行过程中动态的将编译后的.class字节码文件加载到JVM中的工具。在IDE中编写的源代码文件都是`.java`文件，通过编译对应生成`.class`文件。而类加载器就是用来将`.class`文件加载到JVM中的工具。\\r\\n\\r\\n 类加载器类型\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nJava默认提供了三个类加载器，分别是 AppClassLoader、ExtClassLoader、BootstrapClassLoader，除此之外还可以自定义类加载器。类加载器之间是父级的关系，但不是通过继承实现父级关系的，而是通过组合的形式来实现的，在`Clas\"},{\"url\":\"/java/jvm/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JVM\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、类加载器\\r\\n\\r\\n- 类加载器\\r\\n- 对象创建\\r\\n\\r\\n 二、内存模型\\r\\n\\r\\n- JVM内存模型\\r\\n\\r\\n 三、垃圾回收\\r\\n\\r\\n- 垃圾回收算法\\r\\n- 垃圾回收器\\r\\n- G1收集器\\r\\n\\r\\n 四、命令工具\\r\\n\\r\\n- JDK调优命令\\r\\n- 可视化工具\\r\\n\\r\\n 五、排障记录\\r\\n\\r\\n- CPU负载过高排查记录\\r\\n- 内存问题排查总结\\r\\n- 频繁GC排查\\r\\n\\r\\n---\"},{\"url\":\"/java/jvm/内存问题排查总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内存问题排查总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"堆内存dump\\r\\n\\r\\n```\\r\\n1 jmap ‐dump:format=b,file=eureka.hprof 14660\\r\\n```\\r\\n\\r\\n可以配置自动 dump 文件，在内存溢出的时候会自动 dump 文件。\\r\\n\\r\\n```\\r\\n-XX:+HeapDumpOnOutOfMemoryError\\r\\n```\\r\\n\\r\\n比如应用的启动脚本，开启自动 dump 文件。\\r\\n\\r\\n```\\r\\nexec java -classpath $CLASSPATH -Xms1024m -Xmx2048m\\r\\n-XX:+HeapDumpOnOutOfMemoryError\\r\\n-Dquery.type=es\\r\\n-Dfile.enco\"},{\"url\":\"/java/jvm/可视化工具.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可视化工具\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"jconsole\\r\\n\\r\\njconsole是JDK 提供的可视化工具。可以查看内存、线程数量、CPU等资源信息。\\r\\n\\r\\n 使用方式\\r\\n\\r\\n 本地进程\\r\\n\\r\\n直接执行命令\\r\\n\\r\\n```java\\r\\njconsole\\r\\n```\\r\\n\\r\\n 远程进程\\r\\n\\r\\n```java\\r\\n-Djava.rmi.server.hostname=10.10.102.81-Dcom.sun.management.jmxremote.port=9999-Dcom.sun.management.jmxremote-Dcom.sun.management.jmxremote.authenticate=false\\r\\n-Dcom.sun\"},{\"url\":\"/java/jvm/垃圾回收器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"垃圾回收器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"垃圾回收类型\\r\\n\\r\\n1. 串行\\r\\n    - 单线程\\r\\n    - 适合堆内存小的时候。\\r\\n    - STW\\r\\n      \\r\\n        Stop The World 的简称。这是因为串行的机制，在垃圾回收的线程运行的时候，其它工作线程都要阻塞。\\r\\n        \\r\\n        *在垃圾回收过程中，对象的地址会发生改变。如果其它线程不阻塞，则可能会发生对象引用错误的问题。*\\r\\n    \\r\\n2. 吞吐量优先\\r\\n    - 多线程\\r\\n    - 适合堆内存较大，且多核CPU的情况。\\r\\n    - 在单位时间内，STW时间最短。\\r\\n3. 响应时间优先\\r\\n    - 多线程\\r\\n    -\"},{\"url\":\"/java/jvm/垃圾回收算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"垃圾回收算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"如何判断对象可以回收\\r\\n\\r\\n 引用计数法\\r\\n\\r\\n为对象添加引用计数器，如果对象被其它对象引用一次，计数器 +1；对应引用释放，则计数器 -1；只有当计数器为 0 时该对象才会被垃圾回收。\\r\\n\\r\\n- 引用计数法造成的内存泄漏\\r\\n  \\r\\n    像下面这种即使对象不被其它对象引用，这两个对象也一直不会被回收，因为对象A和B之间存在引用关系，引用计数器一直为 1，这样就导致了内存泄露。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n\\r\\n\\r\\n\\r\\n 可达性分析算法\\r\\n\\r\\n&gt; 如果某个对象到GC Roots间没有任何引用链相连， 或者用图论的话来说就是从GC Roots到这个对象不可达时，则证明此\"},{\"url\":\"/java/jvm/对象创建.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"对象创建\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"对象的创建流程\\r\\n\\r\\n\\r\\n\\r\\n 类加载检查\\r\\n\\r\\n判断有无加载过该类，有则直接进入下一步、没有则加载类对象。\\r\\n\\r\\n 分配内存\\r\\n\\r\\n虚拟机为新生对象分配内存。\\r\\n\\r\\n对象所需内存大小在类检查阶段便可确定，为对象分配空间就是将一块确定大小内存从 Java 堆中划分出来。\\r\\n\\r\\n 1. 划分内存的方法\\r\\n\\r\\n- 指针碰撞法\\r\\n  \\r\\n    该方法是JVM中的默认方法。\\r\\n    \\r\\n    它主要就是假设JVM中的内存是绝对规整的，使用过的内存和未使用过的内存分别放在两边，用一个指针来给他们做区分。如果要分配内存，只需要将指针向空闲的那一端移动对象大小的位置就好了。\\r\\n    \\r\\n- 空闲列表\"},{\"url\":\"/java/jvm/类加载器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"类加载器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"什么是类加载器\\r\\n\\r\\n类加载器（ClassLoader）就是在系统运行过程中动态的将编译后的.class字节码文件加载到JVM中的工具。在IDE中编写的源代码文件都是`.java`文件，通过编译对应生成`.class`文件。而类加载器就是用来将`.class`文件加载到JVM中的工具。\\r\\n\\r\\n 类加载器类型\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nJava默认提供了三个类加载器，分别是 AppClassLoader、ExtClassLoader、BootstrapClassLoader，除此之外还可以自定义类加载器。类加载器之间是父级的关系，但不是通过继承实现父级关系的，而是通过组合的形式来实现的，在`Clas\"},{\"url\":\"/java/jvm/频繁GC排查.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"频繁GC排查\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```\\r\\njstat -gcutil 1000\\r\\n```\\r\\n\\r\\n\\r\\n\\r\\n```\\r\\njmap -dump:format=b,file=dumpfile 1000\\r\\n```\\r\\n\\r\\n使用 MAT 工具分析代码\\r\\n\\r\\n---\\r\\n\\r\\n组件消费数据的线程池配置有问题。\"},{\"url\":\"/middleware/es/BulkProcessor死锁问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BulkProcessor死锁问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"问题原因\\r\\n\\r\\n- 定时flush\\r\\n- bulk操作\\r\\n- retryHandler：失败重试\\r\\n1. 定时 flush 和 retryHandler 用的是一个定时线程池，而该线程池只有一个线程。\\r\\n2. 定时 flush 的方法用的锁和 bulk 操作时的锁是同一把锁。都是类对象级别的锁。\\r\\n   \\r\\n    \\r\\n    \\r\\n    \\r\\n    \\r\\n3. 当bluk失败后，会触发默认的重试逻辑。\\r\\n4. 如果重试时候 flush 刚好运行，就会出现这种死锁情况。\\r\\n    1. bulk持有对象锁`BulkProcessor.class`，进行重试逻辑。\\r\\n    2. flush占有线\"},{\"url\":\"/middleware/es/ES分片.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES分片\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"同一个索引会划分为多个分片。分片可以设置副本数量，分为主分片和副本分片。\\r\\n\\r\\n```java\\r\\n 指定索引的主分片和副本分片数\\r\\nPUT /blogs\\r\\n{\\r\\n  \\\"settings\\\": {\\r\\n    \\\"number_of_shards\\\": 3,\\r\\n    \\\"number_of_replicas\\\": 1\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n 主分片\\r\\n\\r\\n- 解决数据水平扩展的问题。同一个索引可以按照分片分配数据，将数据平均分配到所有节点之上。\\r\\n- 主分片数创建好后就不能修改。\\r\\n- 一个分片就是一个运行的 Lucene 实例。\\r\\n\\r\\n 主分片过少\\r\\n\\r\\n- 单个分片数据量过大。查询较慢，利用\"},{\"url\":\"/middleware/es/ES压测记录和esrally使用.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES压测记录和esrally使用\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"环境信息\\r\\n\\r\\n- 压测环境\\r\\n  \\r\\n    ```\\r\\n    http://10.1.11.200:39200/\\r\\n    ```\\r\\n    \\r\\n- 开发环境\\r\\n  \\r\\n    ```java\\r\\n    http://10.10.101.69:39200\\r\\n    ```\\r\\n    \\r\\n- 测试环境\\r\\n  \\r\\n    ```java\\r\\n    http://10.10.103.218:39200/\\r\\n    ```\\r\\n    \\r\\n\\r\\n esrally安装\\r\\n\\r\\n docker安装\\r\\n\\r\\n1. 拉取镜像\\r\\n   \\r\\n    ```\\r\\n    docker pull elastic/rally\"},{\"url\":\"/middleware/es/ES参数调优.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES参数调优\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"预防脑裂\\r\\n\\r\\n\\r\\n\\r\\n重要配置的修改 | Elasticsearch: 权威指南 | Elastic\\r\\n\\r\\n 堆内存设置\\r\\n\\r\\n```\\r\\n -Xms2730m -Xmx2730m -Duser.timezone=Asia/Shanghai\\r\\n```\\r\\n\\r\\nxms和xmx设置一样大小，并设置为略小于pod分配内存的一半。\\r\\n\\r\\n 分片设置\\r\\n\\r\\n分片过小或过多都会影响es的查询速率。\\r\\n\\r\\n一经设置无法修改。\\r\\n\\r\\n目前是10个分片，数据量不大的情况下，设置为5个分片进行测试一下。1个、和node数量一致分片测试。\\r\\n\\r\\n1GB 20个分片\\r\\n\\r\\n1个 20G～40GB\\r\\n\\r\\n 副本数量\\r\\n\\r\"},{\"url\":\"/middleware/es/ES深度分页问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES深度分页问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"from+to分页\\r\\n\\r\\nes在查询时候默认使用的是分页查询，单次只会返回10条数据。\\r\\n\\r\\n可以指定size。\\r\\n\\r\\n\\r\\n\\r\\n- 查询要求默认 from+size 的结果必须不超过10000。\\r\\n  \\r\\n    可以通过修改配置\\r\\n    \\r\\n    ```java\\r\\n    \\\"index.max_result_window\\\":\\\"20000\\\"\\r\\n    ```\\r\\n    \\r\\n    限制单词查询满足条件的结果窗口的大小，由from+size共同决定。\\r\\n    \\r\\n    因为es是先将数据全查出来再做分页，这样做是为了限制内存的消耗。\\r\\n    \\r\\n    ---\\r\\n    \\r\\n    因\"},{\"url\":\"/middleware/es/ES滚动查询-Scroll.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES滚动查询-Scroll\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"原理\\r\\n\\r\\nElasticsearch中的滚动查询是基于 固定的排序规则 来加载一部分数据。\\r\\n\\r\\n当用户刷新时，将从上次加载的最后一条数据的位置再加载同样数量的数据。\\r\\n\\r\\n滚动查询的原理类似于分页查询，但是滚动查询不需要重新执行搜索，只需要继续检索下一批结果。在滚动查询中，每次只加载当前页的数据，而不是一次性加载所有数据。这使得滚动查询比分页查询更高效，因为滚动查询不需要将所有数据都存储在内存中。同时，滚动查询也适用于大量数据的处理，因为它可以分批次地处理数据，而不是一次性处理所有数据。\\r\\n\\r\\n 滚动查询的排序规则\\r\\n\\r\\n滚动查询的排序规则不一定是时间。在Elasticsearch中，滚动\"},{\"url\":\"/middleware/es/ES的log4j2日志自动清理配置.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES的log4j2日志自动清理配置\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"配置\\r\\n\\r\\n```xml\\r\\nappender.rolling.strategy.type = DefaultRolloverStrategy\\r\\nappender.rolling.strategy.fileIndex = nomax\\r\\nappender.rolling.strategy.action.type = Delete\\r\\nappender.rolling.strategy.action.basepath = ${sys:es.logs.base_path}\\r\\nappender.rolling.strategy.action.condition.type = IfFileName\\r\\napp\"},{\"url\":\"/middleware/es/ES聚合查询原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES聚合查询原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES在对海量数据进行聚合分析的时候会损失搜索的精准度来满足实时性的需求。\"},{\"url\":\"/middleware/es/ES集群.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES集群\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集群节点类型\\r\\n\\r\\n1. Master Node - 主节点\\r\\n2. DataNode - 数据节点\\r\\n3. Coordinating Node - 协调节点\\r\\n\\r\\n Master Node\\r\\n\\r\\n- 处理创建，删除索引等请求。\\r\\n- 决定分片被分配到哪个节点。\\r\\n- 维护并更新集群 state。\\r\\n\\r\\n Master Node节点最佳实践\\r\\n\\r\\n- Master节点非常重要，在部署上需要解决单点问题。\\r\\n- 为一个集群设置多个Master节点，而且节点只承担 Master 角色。\\r\\n\\r\\n Data Node\\r\\n\\r\\n保存数据的节点，负责保存分片数据。\\r\\n\\r\\n通过增加数据节点可以解决数据水平扩展\"},{\"url\":\"/middleware/es/Elasticsearch写入原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch写入原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本概念\\r\\n\\r\\n 索引\\r\\n\\r\\nElasticsearch的索引是一个逻辑上的概念，指存储了相同类型的文档集合。\\r\\n\\r\\n 映射\\r\\n\\r\\n映射（mapping）定义索引中有什么字段、进行字段类型确认。类似于数据库中表结构定义。\\r\\n\\r\\nES 默认动态创建索引和索引类型的 映射（mapping），就像是非关系型数据中的，无需定义表结构，更不用指定字段的数据类型。\\r\\n\\r\\n也可以手动指定 mapping 类型，比如通过请求设置索引的映射（mapping）。\\r\\n\\r\\n```java\\r\\ncurl --location --request POST 'localhost:9200/course/_mapping' \"},{\"url\":\"/middleware/es/Elasticsearch基础概念.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch基础概念\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础概念\\r\\n\\r\\n 一、索引库（index）\\r\\n\\r\\nElasticsearch的索引库是一个逻辑上的概念，存储了相同类型的文档内容。类似于 MySQL 数据表，MongoDB 中的集合。\\r\\n\\r\\n1. 新建索引库\\r\\n    - number_of_shards\\r\\n      \\r\\n        设置分片的数量，在集群中通常设置多个分片，表示一个索引库将拆分成多片分别存储不同 的结点，提高了ES的处理能力和高可用性，入门程序使用单机环境，这里设置为 1。\\r\\n        \\r\\n    - number_of_replicas\\r\\n      \\r\\n        设置副本的数量，设置副本是为了提高ES的\"},{\"url\":\"/middleware/es/Elasticsearch查询原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch查询原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES查询原理\\r\\n\\r\\n 查询方式\\r\\n\\r\\n- 根据 doc_id 查询。\\r\\n\\r\\n\\r\\n\\r\\n- 根据条件查询\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引\\r\\n\\r\\n根据文档中的每个字段建立倒排索引。\\r\\n\\r\\n 倒排索引的查询流程\\r\\n\\r\\n\\r\\n\\r\\n1. 查询条件分词。\\r\\n2. 查询单词词典 （term dictionary）。\\r\\n3. 获取对应分词的 doc_id 列表。\\r\\n4. 将查询结果返回。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 倒排索引的组成\\r\\n\\r\\n- postings list\\r\\n  \\r\\n    文档列表。\\r\\n    \\r\\n- term dictionary\\r\\n  \\r\\n    单词字典表。包含文档中所有的单词，es 会将单词排序\"},{\"url\":\"/middleware/es/Elasticsearch检索.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch检索\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"检索方式\\r\\n\\r\\nElasticsearch提供两种检索方式。\\r\\n\\r\\n1. RestAPI 形式通过 URL 参数进行检索。\\r\\n2. 通过 DSL 语句进行查询，通过传递 JSON 为请求体与 Elasticsearch 进行交互，这种方式更强大简洁。\\r\\n\\r\\n URL检索\\r\\n\\r\\n`GET /{index}/{type}/_search?q=*&sort=age:desc&size=5&from=0&_source=name,age,bir`\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\nq=* ：匹配所有文档\\r\\n\\r\\nsort=age：按照指定字段进行排序，默认为升序，:desc 降序排列\\r\\n\\r\\nsize：展示多少\"},{\"url\":\"/middleware/es/Elasticsearch聚合查询.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch聚合查询\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES在对海量数据进行聚合分析的时候会损失搜索的精准度来满足实时性的需求。\\r\\n\\r\\n Elasticsearch聚合查询总结\\r\\n\\r\\n 1. 求和、最大值、最小值、平均值\\r\\n\\r\\n- 求和 - sum\\r\\n- 最大值 - max\\r\\n- 最小值 - min\\r\\n- 平均值 - avg\\r\\n\\r\\n---\\r\\n\\r\\nDSL查询语句\\r\\n\\r\\n```java\\r\\n{\\r\\n    \\\"size\\\": 0,\\r\\n    \\\"query\\\": {\\r\\n        \\\"bool\\\": {\\r\\n            \\\"filter\\\": [\\r\\n                {\\r\\n                    \\\"range\\\": {\\r\\n    \"},{\"url\":\"/middleware/es/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础总结\\r\\n\\r\\n- Elasticsearch基础概念\\r\\n- Elasticsearch检索\\r\\n- Elasticsearch聚合查询\\r\\n\\r\\n\\r\\n- ES滚动查询-Scroll\\r\\n- 批量操作Bulk和BulkProcessor\\r\\n- BulkProcessor死锁问题\\r\\n\\r\\n\\r\\n- 并发场景修改文档\\r\\n- ES深度分页问题\\r\\n\\r\\n\\r\\n- ES集群\\r\\n- ES分片\\r\\n\\r\\n 原理总结\\r\\n\\r\\n- 倒排索引原理\\r\\n- Elasticsearch写入原理\\r\\n- Elasticsearch查询原理\\r\\n- ES聚合查询原理\\r\\n\\r\\n 使用问题\\r\\n- ES参数调优\\r\\n- 集群脑裂-参数配置\\r\\n\\r\\n\\r\\n- ES\"},{\"url\":\"/middleware/es/倒排索引原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"倒排索引图解\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"原理图\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引的搜索过程\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引原理\\r\\n\\r\\nElasticsearch 主要功能就是搜索，为了提高搜索效率，其内部使用了倒排索引。\\r\\n\\r\\n 正排索引\\r\\n\\r\\n在搜索引擎中，每个文件对应一个文件 ID （doc_id），文件内容是关键词的集合。\\r\\n\\r\\n\\r\\n\\r\\n根据 `doc_id` 可以查找到文档详情。\\r\\n\\r\\n*这种方式本质上就是通过文档的 key 查找 value 值。*\\r\\n\\r\\n比如查找 `name=jetty wan` 的文档，只能按照顺序从前向后匹配每个文档的 name 字段。\\r\\n\\r\\n这种查找方式的效率非常低下。\\r\\n\\r\\n 倒排索引\\r\\n\\r\\n倒排索引和正向索引\"},{\"url\":\"/middleware/es/并发场景修改文档.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"并发场景修改文档\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES从7.X版本默认使用的是乐观锁机制修改文档。\\r\\n\\r\\n当在高并发环境下使用乐观锁机制修改文档时，要带上当前文档的_seq_no和_primary_term进行更新：\\r\\n\\r\\n```java\\r\\nPOST /es_db/_doc/2?if_seq_no=21&if_primary_term=6{  \\\"name\\\": \\\"李四xxx\\\"}\\r\\n```\\r\\n\\r\\n如果冲突会提示版本冲突异常。\"},{\"url\":\"/middleware/es/批量操作Bulk和BulkProcessor.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"批量操作Bulk和BulkProcessor\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"es的批量操作，6.x版本的es中high-rest-client中可以用到以下三种。\\r\\n\\r\\n- bulk\\r\\n- bulkAsync\\r\\n- bulkProcessor\\r\\n\\r\\n Bulk\\r\\n\\r\\nbulk api 以此按顺序执行所有的 action（动作）。如果一个单个的动作因任何原因失败，它将继续处理它后面剩余的动作。当 bulk api 返回时，它将提供每个动作的状态（与发送的顺序相同），所以您可以检查是否一个指定的动作是否失败了。\\r\\n\\r\\nes可以通过 _bulk 的API实现批量操作。\\r\\n\\r\\n```java\\r\\nPOST _bulk\\r\\n{\\\"create\\\":{\\\"_index\\\":\\\"article\\\"\"},{\"url\":\"/middleware/es/集群脑裂-参数配置.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集群脑裂-参数配置\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集群脑裂的问题\\r\\n\\r\\n 什么是集群脑裂\\r\\n\\r\\nes 在主节点上产生分歧，产生多个master 节点，从而使集群分裂成多个同名集群，使得集群处于异常状态。\\r\\n\\r\\n当出现多个master节点的时候，可能发生写入请求分配到不同的master节点，而数据只保存在对应的master节点的分片上，不会复制到其它节点。此时若访问不同的节点，会发现查询的结果是不一样的。\\r\\n\\r\\n 举例说明脑裂\\r\\n\\r\\n`discovery.zen.minimum_master_nodes` 参数之前设置为 1（默认值）。\\r\\n\\r\\n这个参数的含义是限制选举master节点的数量。\\r\\n\\r\\n- 当master节点不存在时，至少有几个ma\"},{\"url\":\"/middleware/kafka/Kafka分区机制策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka分区机制策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"分区策略\\r\\n\\r\\n分区策略是决定生产者将消息发送到哪个分区的算法。\\r\\n\\r\\n 轮询策略\\r\\n\\r\\n是 Java 生产者 API 默认提供的分区策略。\\r\\n\\r\\n- 轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。\\r\\n\\r\\n\\r\\n\\r\\n 随机策略\\r\\n\\r\\n将消息随机写入分区\\r\\n\\r\\n key 指定分区\\r\\n\\r\\n当发送消息时指定了key，Kafka会根据key的hash值与分区数取模来决定将数据写入哪个分区。\\r\\n\\r\\n项目中 dr 就是生产这种方式，根据消息类型指定 key，比如 transactionId。这样能保证同一t\"},{\"url\":\"/middleware/kafka/Kafka副本机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka副本机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka 的副本是针对分区来说的，为分区创建副本。\\r\\n\\r\\n副本的作用就是提供数据冗余，在 Leader 副本挂掉之后，转换为 Leader 副本继续工作。\\r\\n\\r\\n不然当 Leader 副本挂掉之后，该分区就会停止对外提供服务。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 副本同步\\r\\n\\r\\n\\r\\n\\r\\n生产者只会往分区的 Leader 发消息，而其它 Follower 会从 Leader 拉取数据进行同步。\\r\\n\\r\\n Follower追随者副本\\r\\n\\r\\nFollower 副本是不对外提供服务的，只是定期地异步拉取领导者副本中的数据而已。\\r\\n\\r\\n LSR副本集合\\r\\n\\r\\nLSR集合里面保存的副本都是与 Leader 副本\"},{\"url\":\"/middleware/kafka/Kafka总控制器Controller.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka总控制器 Controller\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 kafka中会有多个 Broker，其中一个 Broker 会被选举为 Controller，负责管理整个集群中分区和副本的状态。\\r\\n\\r\\n Zookeeper\\r\\n\\r\\nzk 使用的数据模型类似于文件系统的树形结构，根目录也是以“/”开始。该结构上的每个节点被称为 znode，用来保存一些元数据协调信息。\\r\\n\\r\\nZooKeeper 常被用来实现集群成员管理、分布式锁、领导者选举等功能。\\r\\n\\r\\nznode 用来保存元数据信息。\\r\\n\\r\\n- 永久性 znode\\r\\n  \\r\\n    持久性 znode 不会因为 ZooKeeper 集群重启而消失。\\r\\n    \\r\\n- 临时性 znode\\r\\n  \\r\\n   \"},{\"url\":\"/middleware/kafka/Kafka手动重新分区.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka手动重新分区\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka重分配分区_kafka重新分配分区-CSDN博客\\r\\n\\r\\n1. 确定需要重新分区的 topic\\r\\n   \\r\\n    vi topics-to-move.json\\r\\n    \\r\\n    ```java\\r\\n    \\r\\n    {\\r\\n      \\\"topics\\\": [{\\r\\n         \\\"topic\\\": \\\"test-topic\\\"\\r\\n       }],\\r\\n       \\\"version\\\": 1\\r\\n    }\\r\\n    ```\\r\\n    \\r\\n    - topic 可以批量设置\\r\\n2. 根据 topic 生成执行计划\\r\\n   \\r\\n    ```java\\r\\n    bin/kafka-rea\"},{\"url\":\"/middleware/kafka/Kafka消费策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka消费策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka消费者-主动批量拉取\\r\\n\\r\\n\\r\\n&gt; \\r\\n1. kafka配置类\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\n@Slf4j\\r\\npublic class KafkaConfig {\\r\\n\\r\\n    @Bean\\r\\n    public KafkaListenerContainerFactory&lt;?&gt; batchFactory(ConsumerFactory consumerFactory){\\r\\n        ConcurrentKafkaListenerContainerFactory&lt;Integer,String&gt; factory =\\r\\n    \"},{\"url\":\"/middleware/kafka/Kafka生产者参数.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka生产者参数\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- bootstrap.servers： broker的地址\\r\\n- key.serializer：关键字的序列化方式\\r\\n- value.serializer：消息值的序列化方式\\r\\n- acks：指定必须要有多少个分区的副本接收到该消息，服务端才会向生产者发送响应，可选值为：0,1,2，…，all\\r\\n- buffer.memory：生产者的内存缓冲区大小。如果生产者发送消息的速度 \\r\\n- max.block.ms：表示send()方法在抛出异常之前可以阻塞多久的时间，默认是60s\\r\\n- compression.type：消息在发往kafka之前可以进行压缩处理，以此来降低存储开销和网络带宽。默认\"},{\"url\":\"/middleware/kafka/Kafka高性能的原因.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka高性能的原因\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 写数据是按照磁盘顺序读写。\\r\\n   \\r\\n    保证顺序读写，比随机写性能要高很多。\\r\\n    \\r\\n    数据保存在 log 中，并对 log 进行了分段（logSegment）技术，对 logSegment 还增加了日志索引。\\r\\n    \\r\\n2. 数据传输的零拷贝，使的数据在内核空间中就完成了读写操作。\\r\\n   \\r\\n    零拷贝原理：\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 读写数据的批量处理以及压缩传输。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n\\r\\n 零拷贝\\r\\n\\r\\n- 传统数据文件拷贝过程\\r\\n  \\r\\n    整个过程需要在内核空间和应用空间之间拷贝 2 次。\\r\\n    \"},{\"url\":\"/middleware/kafka/Producer发布消息机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Producer发布消息机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"写入机制\\r\\n\\r\\nProducer 通过push模式将消息发给 Broker，每条消息都被追加到对应的 Partition。而且是采用顺序写磁盘的方式（顺序写比随机写效率高，保障 Kafka 高吞吐量）。\\r\\n\\r\\n 消息路由模式\\r\\n\\r\\nProducer 如何确认消息发到哪个 Partition 上？\\r\\n\\r\\n1. 指定了 Partition，直接使用。\\r\\n2. 如果未指定 Partition，指定了 Key。根据 Key 的 Hash 值计算 Partition。\\r\\n   \\r\\n    Hash(key) % num(Partition)\\r\\n    \\r\\n3. 如果未指定 Partition，也未指定 \"},{\"url\":\"/middleware/kafka/__consumer_offsets.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"__consumer_offsets\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"将 Consumer 的位移数据作为一条条普通的 Kafka 消息，提交到 consumer*offsets 中。可以这么说，consumer*offsets 的主要作用是保存 Kafka 消费者的位移信息。\\r\\n\\r\\n_*consumer*offsets也是一个 topic，也有分区。和 kafka 的 topic 基本一致支持自定义写入。但是它是内部的 topic，一般最好不要自动修改。\\r\\n\\r\\n 消息格式\\r\\n\\r\\n1. 分区消费的 offset\\r\\n    \\r\\n    位移主题的 Key 中应该保存 3 部分内容：\\r\\n    \\r\\n    标识某个消费者组里面某个 topic 的某个分区，已经被消费\"},{\"url\":\"/middleware/kafka/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka配置\\r\\n\\r\\n- Kafka消费策略\\r\\n- Kafka生产者参数\\r\\n- kafka的分区副本规划\\r\\n\\r\\n\\r\\n Kafka原理总结\\r\\n- kafka消费模型\\r\\n- kafka-ACK应答机制\\r\\n- kafka解决重复消费\\r\\n\\r\\n\\r\\n- Kafka分区机制策略\\r\\n- kafka保证消息不丢失\\r\\n- 消费者组\\r\\n- __consumer_offsets\\r\\n- Kafka总控制器Controller\\r\\n- Kafka副本机制\\r\\n\\r\\n\\r\\n- Producer发布消息机制\\r\\n- 高水位HW和LEO\\r\\n- 数据日志分段存储\\r\\n\\r\\n\\r\\n- Kafka高性能的原因\\r\\n\\r\\n 使用总结\\r\\n- Kafka手动\"},{\"url\":\"/middleware/kafka/kafka-ACK应答机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka生产者保证消息不丢失-ACK应答机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka 生产者写入数据的时候，引入了 ACK 应答机制。\\r\\n\\r\\n```java\\r\\n            Properties props = new Properties();\\r\\n            props.put(\\\"bootstrap.servers\\\", Configuration.KAFKA_ADDRESS);\\r\\n\\t\\t\\t\\t\\t\\t//1:leader应答就可以发送下一条，确保发送成功。\\r\\n            props.put(\\\"acks\\\", \\\"1\\\");\\r\\n\\t\\t\\t\\t\\t\\t......\\r\\n            props.put(\\\"key.serializer\\\", \\\"org.a\"},{\"url\":\"/middleware/kafka/kafka保证消息不丢失.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka保证消息不丢失\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。\\r\\n\\r\\n 生产者端消息丢失\\r\\n\\r\\n生产者发送消息的时候，如果没有发到 kafka 导致消息丢失（网络抖动），其实这并不是 kafka 的原因。\\r\\n\\r\\nkafka 能保证已经提交到 borker 的数据，不会丢失。\\r\\n\\r\\n默认生产者发数据，采用 `send(msg)`发数据，这样发数据之后生产者并不知道是否发送成功。\\r\\n\\r\\n最好使用 `producer.send(msg, callback)` 发数据，这样通过`callback`能够清楚的知道消息是否发送成功。\\r\\n\\r\\n 消费者端消息丢失\\r\\n\\r\\nConsu\"},{\"url\":\"/middleware/kafka/kafka消费模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka消费模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka消费模型分为两种。\\r\\n\\r\\n1. 消费组消费\\r\\n   \\r\\n    消费组里面的单个消费者消费一个分区的数据。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n    \\r\\n    \\r\\n    \\r\\n2. 消费者-worker进程消费。\\r\\n\\r\\n\\r\\n\\r\\n&gt; 第一种消费模型，每个分区对应一个 consumer。\\r\\n&gt; \\r\\n\\r\\n第二种消费模型，只消费数据不处理，处理的工作单独交给 worker线程池，这样可以避免很多 consumer产生的问题。不要把很重的处理逻辑放到消费者中。\\r\\n\\r\\n&gt; 难以保证 offset 的语义正确性，可能导致重复消费。\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n--\"},{\"url\":\"/middleware/kafka/kafka的分区副本规划.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka的分区副本规划\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. topic划分\\r\\n\\r\\n每个日志对应一个topic。\\r\\n\\r\\ntopic 有自己的分区数量和副本数量。一般根据kafka指定的默认数量自动生成。\\r\\n\\r\\n---\\r\\n\\r\\n 2. 分区数量\\r\\n\\r\\n当生产者发给kafka一条消息时，根据规则分到 topic 的指定分区（partition），所以每个分区的数据是不一样的。\\r\\n\\r\\n 规划分区数量\\r\\n\\r\\n消费者在消费数据的时候，也是从分区中消费的，同一个分区只能被消费组里的一个消费者去消费。\\r\\n\\r\\n比如kafka有3个borker时，假如配置topic有5个分区，分配到3个borker就会出现 2 2 1 的情况。\\r\\n\\r\\n所以在指定topic的分区数量时\"},{\"url\":\"/middleware/kafka/kafka解决重复消费.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka解决重复消费\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"技术干货分享 | Kafka重复消费场景及解决方案\\r\\n\\r\\n 导致重复消费的原因\\r\\n\\r\\n- enable.auto.commit 默认值true，表示消费者会周期性自动提交消费的offset\\r\\n- auto.commit.interval.ms 在enable.auto.commit 为true的情况下， 自动提交的间隔，默认值5000ms\\r\\n- max.poll.records 单次消费者拉取的最大数据条数，默认值 500\\r\\n- max.poll.interval.ms 默认值5分钟，表示若5分钟之内消费者没有消费完上一次poll的消息，那么consumer会主动发起离开group的请求\\r\\n1\"},{\"url\":\"/middleware/kafka/数据日志分段存储.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据日志分段存储\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"数据保存机制\\r\\n\\r\\n\\r\\n\\r\\nKafka 的数据是按照分区存储的，以 topic-partition 为目录保存数据。\\r\\n\\r\\n数据是存到 log 中，而 log 又引入了LogSegment机制。\\r\\n\\r\\n`log.segment.bytes`，默认 1G。当超过1G 之后，日志就会开始分割。\\r\\n\\r\\n而日志分段文件以及索引文件都是以基准偏移量（offset）命名的。\\r\\n\\r\\n基本每段的日志文件包含一个数据文件和两个索引文件。\\r\\n\\r\\n- 以offset 为索引的 `.index`。\\r\\n- 以时间戳为索引的 `.timeindex`。\\r\\n\\r\\n索引里面并不是保留全量的数据索引，而是以稀疏索引的方式保存（方\"},{\"url\":\"/middleware/kafka/消费者组.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"消费者组\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。\\r\\n\\r\\n- 组内的所有消费者协调在一起来消费订阅主题（Subscribed Topics）的所有分区（Partition）。\\r\\n- 每个分区只能由同一个消费者组内的一个 Consumer 实例来消费。\\r\\n\\r\\n比如 topic 有 6 个分区，消费者组里面的消费者数量最理想状态是 6 个，每个消费者消费一个分区。也可以是 3 个或者两个，这样分区能够平均分配。\\r\\n\\r\\n但是最好不要超过 6 个消费者，这样的话会有消费者分不到分区。\\r\\n\\r\\n而 topic 的分区设计时，最好和 broker 的数量成比例。比如 3 个\"},{\"url\":\"/middleware/kafka/高水位HW和LEO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"高水位HW和LEO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"LEO（log_end_offset) 指的是当前分区日志末端的 offset。\\r\\n\\r\\n而 HW 指的是整个 LSR 集合副本中，LEO 最小的。保障 Consumer 只能消费到 HW 的位置。\\r\\n\\r\\n首先Leader 和 Followers 都有自己的 HW和 LEO，当有新消息写入 Leader 时，Consumer 并不能立即消费。\\r\\n\\r\\nFollowers 会 pull leader 最新的消息，同步完之后，发送 ACK 给 Leader。然后 Leader会增加 HW。增加之后，新产生的消息才能被 Consumer 消费掉。\\r\\n\\r\\n这样的目的是为了保证当 Leader 挂掉之后，重\"},{\"url\":\"/middleware/rocketmq/Kakfa和RocketMQ的区别.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kakfa和RocketMQ的区别\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"消费者组\\r\\n\\r\\nRocketMQ和Kafka虽然都使用了Consumer Group的概念来实现消息的分发和负载均衡，但两者在具体实现和一些特性上存在一些差异：\\r\\n\\r\\n1. Rebalance机制：\\r\\n    - RocketMQ：RocketMQ的Consumer Group在成员增减或Topic队列发生变化时会触发Rebalance，旨在重新分配队列到各个消费者实例，确保消息的公平消费。RocketMQ的Rebalance更加灵活，支持多种分配策略，例如平均分配、广播消费等，可以根据业务需求进行配置。\\r\\n    - Kafka：Kafka同样在Consumer Group中进行Rebala\"},{\"url\":\"/middleware/rocketmq/MQ接收消息幂等性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MQ接收消息幂等性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"幂等性\\r\\n\\r\\nMQ的消息幂性，指的是MQ接收消息时候的幂等性。\\r\\n\\r\\n- 最多一次\\r\\n    \\r\\n    消息最多只会被消费一次。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n- 最少一次\\r\\n    \\r\\n    消息最少被消费一次。\\r\\n    \\r\\n    &gt; 同步发送、事务消息。\\r\\n    &gt; \\r\\n- 准确消费一次\\r\\n    \\r\\n    默认RocketMQ保证不了准确消费一次。但是商业版本有。\\r\\n    \\r\\n\\r\\n 消息幂等的必要性\\r\\n\\r\\n- 生产者发送消息时，MQ收到消息，但是网络波动导致ACK没有给到生产者。可能会导致重推消息。\"},{\"url\":\"/middleware/rocketmq/RocketMQ基础学习.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ基础学习\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础架构\\r\\n\\r\\n\\r\\n\\r\\n 生产者\\r\\n\\r\\nRocketMQ提供多种发送方式，同步发送、异步发送、顺序发送、单向发送。\\r\\n\\r\\n同步和异步方式均需要 Broker 返回确认信息，单向发送不需要。\\r\\n\\r\\n生产者中，会把同一类 Producer 组成一个集合，叫做生产者组。同一组的 Producer 被认为是发送同一类消息且发送逻辑一致。\\r\\n\\r\\n 消费者\\r\\n\\r\\n 消费者组\\r\\n\\r\\n消费者组消费同一组数据，消费相同topic，并且消费逻辑一致。消费者组的消费者实例必须订阅完全相同的Topic。\\r\\n\\r\\n 消费模式\\r\\n\\r\\nRocketMQ 支持两种消息模式：集群消费（Clustering）和广播消费（Broad\"},{\"url\":\"/middleware/rocketmq/RocketMQ集群架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ集群架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NameServer：提供Broker的路由服务\\r\\n\\r\\nBroker：负责接收Producer的消息，存储消息，将消息投递给Consumer。\\r\\n\\r\\n- Broker需要管理数据，频繁处理数据，所以需要G1、ZGC这种更先进的垃圾回收器。\\r\\n- 而NameServer类似于Broker的注册中心，提供路由功能，只需要简单的垃圾回收算法就可以，比如CMS。\\r\\n\\r\\nProducer：生产者\\r\\n\\r\\nConsumer：消费者\\r\\n\\r\\n 集群架构说明\\r\\n\\r\\n整个RocketMQ集群里面主要分为两部分，Broker和NameServer。\\r\\n\\r\\n整个RocketMQ遵循的是AP架构，追求可用性。\\r\\n\\r\\n N\"},{\"url\":\"/middleware/rocketmq/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- RocketMQ基础学习\\r\\n- RocketMQ集群架构\\r\\n\\r\\n\\r\\n- 消息样例\\r\\n- 顺序消息\\r\\n- 事务消息\\r\\n\\r\\n\\r\\n- 如何保证发送消息有序\\r\\n- 如何保证消息不丢失\\r\\n- MQ接收消息幂等性\\r\\n\\r\\n\\r\\n- Kakfa和RocketMQ的区别\"},{\"url\":\"/middleware/rocketmq/事务消息.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"事务消息\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"事务消息的流程\\r\\n\\r\\n- 先写half消息到RocketMQ\\r\\n- 再执行本地事务\\r\\n  \\r\\n    本地事务有两个方法，一个是回调执行本地事务，另一个是检查本地事务。\\r\\n    \\r\\n    ```java\\r\\n    /**\\r\\n     * 事务监听器，用来处理本地事务\\r\\n     * @author yangjunwei\\r\\n     * @date 2024/7/4\\r\\n     */\\r\\n    public class TransactionListenerImpl implements TransactionListener {\\r\\n        private AtomicInteger\"},{\"url\":\"/middleware/rocketmq/如何保证发送消息有序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"如何保证发送消息有序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类比Kafka的ParitationKey，RocketMQ是messageQueue。\\r\\n\\r\\n将需要保证顺序的消息发给RocketMQ的messageQueue，被同一个消费者消费，即可保证有序。\\r\\n\\r\\n1. 消费者在发送的时候可以指定selector，指定消息发给哪个messageQueue。\\r\\n2. messageQueue是一个FIFO的队列，能够保证消费时按照写入消息的顺序去消费。\\r\\n\\r\\n所以需要保证有顺序的消息，比如相同产品的订单，可以按照产品 code 设置 selector，保证消息发到同一个 messageQueue，这样就能被同一个消费者消费。\\r\\n\\r\\n```java\\r\\nSe\"},{\"url\":\"/middleware/rocketmq/如何保证消息不丢失.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"如何保证消息不丢失\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"消息丢失场景\\r\\n\\r\\n数据丢失在MQ中比较常见，一般丢失数据都是在跨网络的部分，比如1、2、4。\\r\\n\\r\\n- 生产者发数据\\r\\n- 消费者消费数据\\r\\n- MQ内部主从同步\\r\\n\\r\\n而MQ写数据到磁盘过程也是有丢失数据的可能的。\\r\\n\\r\\n一般写数据到磁盘不会直接去写，而是利用操作系统的缓存，先写数据到缓存中，等待操作系统异步刷进磁盘。\\r\\n\\r\\n比如 Prometheus 的 WAL 机制。\\r\\n\\r\\n\\r\\n\\r\\n 事务消息-生产者\\r\\n\\r\\n使用事务消息能保证本地事务和写入MQ的事务一致性。\\r\\n\\r\\n比如订单场景，只保证本地下订单和向MQ发消息的事务一致性。不会像MySQL一样保证数据库事务。\\r\\n\\r\\n只是保证了业务的分布\"},{\"url\":\"/middleware/rocketmq/消息样例.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"消息样例\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"顺序消息\\r\\n\\r\\nkafka的顺序消息可以指定paritationKey实现，相同paritationKey的消息会被发给同一个paritation。\\r\\n\\r\\nRocketMQ可以通过实现 `MessageQueueSelector` 的 `select` 方法自定义实现消息所发给 MessageQueue的逻辑。\\r\\n\\r\\n```java\\r\\n    @SneakyThrows\\r\\n    @Test\\r\\n    public void orderSend() {\\r\\n        try {\\r\\n            DefaultMQProducer producer = new DefaultMQP\"},{\"url\":\"/middleware/rocketmq/顺序消息.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"顺序消息\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"生产者\\r\\n\\r\\n生产者发送消息到MQ的过程，如果要保证顺序消费。\\r\\n\\r\\n只能采用单线程去生产消息，因为多线程无法控制消息生产顺序。\\r\\n\\r\\n还需要保证 sharding key 相同，保证同一类消息发到同一个 ConsumerQueue。\\r\\n\\r\\n\\r\\n&gt; \\r\\n- 单线程生产消息\\r\\n- 发送到同一个ConsumerQueue\\r\\n\\r\\n 存储\\r\\n\\r\\nRocketMQ的存储是按照时间顺序 append write 到 commitlog 中的，同时它会被分发到 ConsumeQueue中。\\r\\n\\r\\n所以只需要生产时候保证消息采用单线程发送到同一个ConsumerQueue，存储时候就能够顺序存储。\\r\\n\\r\"},{\"url\":\"/other/algorithm/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 时间复杂度\\r\\n- 查找\\r\\n- 排序\\r\\n- 动态规划\"},{\"url\":\"/other/algorithm/动态规划.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"动态规划\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"动态规划重要特性\\r\\n\\r\\n动态规划的核心问题是穷举，因为要求最值，要把所有可行答案找出来，找最值。但是穷举的过程中，会存在【重叠子问题】。\\r\\n\\r\\n 重叠子问题\\r\\n\\r\\n在求解的过程中，存在重复的子问题，若是重复解决这些子问题，存在效率低下的问题。\\r\\n\\r\\n而解决重叠子问题，可以使用【备忘录】或者【DP table】方法来解决。\\r\\n\\r\\n- 备忘录\\r\\n  \\r\\n    备忘录的思想就是将已经解决的子问题结果记录在备忘录中（可以是数组等数据结构）。\\r\\n    \\r\\n\\r\\n\\r\\n&gt; \\r\\n- DP table\\r\\n  \\r\\n    使用 DP table 保存每个子问题的结果，自下向上推算结果。\\r\\n    \\r\\n\\r\\n\"},{\"url\":\"/other/algorithm/排序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"排序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"概念\\r\\n\\r\\n 稳定性\\r\\n\\r\\n稳定性指的是相同的数据所在的位置经过排序后是否发生变化。若是排序后，次序不变，则是稳定的。\\r\\n\\r\\n 内部排序\\r\\n\\r\\n排序记录全部存放在内存中进行排序的过程。\\r\\n\\r\\n 外部排序\\r\\n\\r\\n待排序记录的数量很大，以至于内存不能容纳全部记录，在排序过程中尚需对外存进行访问的排序过程。\\r\\n\\r\\n\\r\\n\\r\\n 选择排序-不稳定\\r\\n\\r\\n每次选择剩余待排序元素中的最小值，放到已排序元素的末尾。\\r\\n\\r\\n原理：每次排序选出最小的元素，替换到对应顺序末尾的位置。\\r\\n思路：第一次排序选出最小的元素，和待排序数组第一位的元素进行交换。\\r\\n\\r\\n```json\\r\\n/**\\r\\n     * 选择排序的思路：\"},{\"url\":\"/other/algorithm/时间复杂度.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"时间复杂度\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"O(1)\\r\\n\\r\\n- 数组下表查询\\r\\n\\r\\n O(n)\\r\\n\\r\\n- 链表元素查询，最坏情况是要查n次。\\r\\n\\r\\n O(logn)\\r\\n\\r\\n- 平衡二叉树\\r\\n- 数组二分法查找指定元素\\r\\n\\r\\n开根号\\r\\n\\r\\n- 比如16长度的数组，想要找到指定元素最多需要4次、\\r\\n  \\r\\n    16→8→4→2→1\\r\\n    \\r\\n- 红黑树（平衡二叉树、完全二叉树）\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n O(log n) \\r\\n\\r\\n复杂度解释：\\r\\n\\r\\n- 在一个理想平衡的二叉搜索树中，每次查找操作从根节点开始，通过比较目标值与当前节点的值来决定是向左还是向右子树进行下一步查找。\\r\\n- 每次比较后，查找范围大致减半，这类似于\"},{\"url\":\"/other/algorithm/查找.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"查找\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"静态查找表\\r\\n\\r\\n 顺序查找\\r\\n\\r\\n线性表查询，查找效率（n+1)/2\\r\\n\\r\\n\\r\\n\\r\\n 折半查找\\r\\n\\r\\n\\r\\n\\r\\n二分查找，仅适用于有序的线性表。\\r\\n\\r\\n折半查找比较次数最多为 [log2n]+1 次。n=2^x，比如8个元素最多需要3次，对应 8=2^3。\\r\\n\\r\\n所以时间复杂度为 O(log2n) 。\\r\\n\\r\\n 分块查找\\r\\n\\r\\n特点是块内无序，但是块间有序。\\r\\n\\r\\n- 先在索引表确定目标所在块。\\r\\n- 在块内顺序查找。\\r\\n\\r\\n\\r\\n\\r\\n比如索引表或者索引文件。\\r\\n\\r\\n 哈希表\\r\\n\\r\\n\\r\\n\\r\\n按照哈希存储元素到哈希表里。\\r\\n\\r\\n 哈希冲突解决方式\\r\\n\\r\\n按照值的哈希值存储会出现哈希冲突的问题，可以通\"},{\"url\":\"/other/datastructure/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据结构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 常用数据结构\\r\\n- 二叉树\"},{\"url\":\"/other/datastructure/二叉树.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"二叉树\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"推荐一个练习数据结构的网站\\r\\n\\r\\nData Structure Visualization\\r\\n\\r\\n 二叉树的遍历（重要）\\r\\n\\r\\n以图示二叉树为例。\\r\\n\\r\\n\\r\\n\\r\\n 中序遍历\\r\\n\\r\\n简化为每个树，都是左中右即可。\\r\\n\\r\\n中序遍历（LDR）是二叉树遍历的一种，也叫做中根遍历、中序周游。在二叉树中，中序遍历首先遍历左子树，然后访问根结点，最后遍历右子树。\\r\\n\\r\\n*左子树 → 根节点 → 右子树*\\r\\n\\r\\n图示二叉树中序遍历结果为：`3、5、6、10、14、15、17、20`；\\r\\n\\r\\n参考代码：Java实现中序遍历\\r\\n\\r\\n 前序遍历\\r\\n\\r\\n前序遍历（VLR）， 1] 是[二叉树遍历的一种，也叫做先根遍历\"},{\"url\":\"/other/datastructure/常用数据结构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"常用数据结构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"存储结构\\r\\n\\r\\n\\r\\n\\r\\n 复杂度\\r\\n\\r\\n时间复杂度\\r\\n\\r\\n空间复杂度\\r\\n\\r\\n 线性表\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 串\\r\\n\\r\\n比如字符串。\\r\\n\\r\\n\\r\\n\\r\\n 数组\\r\\n\\r\\n\\r\\n\\r\\n 矩阵\\r\\n\\r\\n\\r\\n\\r\\n求矩阵元素下标，直接代入即可。\\r\\n\\r\\n\\r\\n\\r\\n代入 A(0,0) 和 A(0,1)，分别对应 M(1) 和 M(2)。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 广义表\\r\\n\\r\\n\\r\\n\\r\\n例1：长度为3，深度为2\\r\\n\\r\\n例2: 先取表尾，再取表头，再取表头。\\r\\n\\r\\nhead (head ( tail(LS1) ) )\\r\\n\\r\\n 广义表的基本运算\\r\\n\\r\\n1. 取表头\\r\\n2. 取表尾\\r\\n\\r\\n 二叉树\\r\\n\\r\\n\\r\\n\\r\\n- 满二叉树\"},{\"url\":\"/other/design/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"设计模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"设计模式的目的\\r\\n\\r\\n* 代码重用性（提取重复代码）\\r\\n* 可读性（代码规范，便于阅读）\\r\\n* 可扩展性（方便增加新功能）\\r\\n* 可靠性（增加新功能，对以前的功能没有影响）\\r\\n* 使程序呈现高内聚、低耦合的特性\\r\\n\\r\\n 设计模式的七大基本原则\\r\\n\\r\\ndesign-principle\\r\\n\\r\\n* 单一职责原则\\r\\n\\r\\n* 接口隔离原则\\r\\n\\r\\n* 依赖倒置原则\\r\\n\\r\\n* 里氏替换原则\\r\\n\\r\\n* 开闭原则\\r\\n\\r\\n* 迪米特法则\\r\\n\\r\\n* 合成复用法则\\r\\n\\r\\n 设计模式三大类型\\r\\n\\r\\n 1. 创建型模式\\r\\n\\r\\ndesign-create\\r\\n\\r\\n* 单例模式\\r\\n\\r\\n    * 序列化和反序列化\\r\\n\\r\\n* 工\"},{\"url\":\"/other/design/七大基本原则.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"七大基本原则\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-principle\\r\\n\\r\\n 单一职责原则\\r\\n\\r\\n1. 一种类只能具有一种职责，降低类的复杂度。\\r\\n2. 提高类的可读性，可维护性。\\r\\n3. 降低变更引起的风险。\\r\\n4. 在类中的方法比较少的时候，可以在方法级别保持单一职责原则。其他情况下，都要保持类的类单一职责原则。\\r\\n\\r\\n 接口隔离原则\\r\\n\\r\\n1. 客户端不应该依赖它不需要的接口。\\r\\n2. 一个类对另一个类的依赖应该建立在最小的接口上。\\r\\n\\r\\n 依赖倒置原则\\r\\n\\r\\n1. 依赖倒置原则的中心思想是面向接口编程。\\r\\n2. 抽象不应该依赖细节，细节应该依赖抽象。抽象是接口或者抽象类，细节即为实现类。\\r\\n3. 对于细节的多变性，抽象的\"},{\"url\":\"/other/design/创建型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"创建型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-create\\r\\n\\r\\n 单例模式\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 饿汉式\\r\\n\\r\\n特点：类创建时创建对象，节省时间，占用内存，`以空间换时间`。\\r\\n\\r\\n1. 静态变量实现\\r\\n    \\r\\n    类加载时创建对象，节省时间，占用内存，`以空间换时间`。`推荐使用`，但是比较浪费空间。\\r\\n    \\r\\n    ```java\\r\\n    \\t\\t/**\\r\\n         * 类加载时创建对象，节省时间，占用内存，以空间换时间\\r\\n         */\\r\\n        private final static SingletonHungryOne INSTANCE = new Singleton\"},{\"url\":\"/other/design/结构型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"结构型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-structural\\r\\n\\r\\n 代理模式\\r\\n\\r\\n代理模式是属于结构型的设计模式,指客户端的请求到达真正的对象之前，做一些额外的操作。\\r\\n\\r\\n 静态代理模式\\r\\n\\r\\n\\r\\n以 AspectJ 为代表。指代理类在编译期生成的，与动态代理相比，效率会很高，但是会生成大量代理类。\\r\\n\\r\\n 动态代理模式\\r\\n\\r\\n以 SpringAOP 为代表为代表，代理类是动态生成的。虽然会效率会低一点，但是大大简化了代码和开发量。\\r\\n\\r\\n- JDK 动态代理\\r\\n- CGlib 动态代理\\r\\n\\r\\n 桥接模式\\r\\n\\r\\n抽象类：定义一个抽象类，作为系统的一部分。\\r\\n\\r\\n实现类：定义一个或多个实现类，与抽象类通过聚合（而非\"},{\"url\":\"/other/design/行为型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"行为型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-behavioral\\r\\n\\r\\n 责任链模式\\r\\n\\r\\n责任链模式——某个请求需要多个对象进行处理，从而避免请求的发送者和接收之间的耦合关系。将这些对象连成一条链子，并沿着这条链子传递该请求，直到有对象处理它为止。主要涉及两个角色：\\r\\n\\r\\n\\r\\n- 抽象处理者角色（Handler）：定义出一个处理请求的接口。这个接口通常由接口或抽象类来实现。\\r\\n- 具体处理者角色（ConcreteHandler）：具体处理者接受到请求后，可以选择将该请求处理掉，或者将请求传给下一个处理者。因此，每个具体处理者需要保存下一个处理者的引用，以便把请求传递下去。\\r\\n\\r\\n 优缺点比较\\r\\n\\r\\n优点\\r\\n\\r\\n- 降低耦\"},{\"url\":\"/other/network/HTTP1x和HTTP2x.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP1x和HTTP2.x\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HTTP1.x\\r\\n\\r\\n 数据格式\\r\\n\\r\\nHTTP1.x基于文本传输。\\r\\n\\r\\n- 请求行\\r\\n- 请求头\\r\\n- 请求体\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 缺点\\r\\n\\r\\n1. 占用字节：在HTTP请求中，包含很多空格和换行符。\\r\\n2. 头部不能压缩：在HTTP1.x中，请求头不能压缩。所以存在请求头比较大的问题，出现大头儿子。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n3. 传输效率低：同一个链接（`Keep-Alive`的情况）同时只能处理一个请求，收到响应才会开始发送下一个请求。\\r\\n    - 如果不设置 `Keep-Alive`，则每一次HTTP请求都会新建一个TCP链接。\\r\\n    \\r\\n    &g\"},{\"url\":\"/other/network/HTTP和HTTPS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP和HTTPS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HTTP 和 HTTPS 的区别\\r\\n\\r\\n- 传输问题。\\r\\n    - HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。\\r\\n    - HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。\\r\\n- 建立连接过程。\\r\\n    - HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。\\r\\n    - HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。\\r\\n- 两者的默认端口不一样。\\r\\n    - HTTP 默认端口号是 80。\\r\\n\"},{\"url\":\"/other/network/HTTP常见字段.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP常见字段\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```json\\r\\nPOST /apmServer-sl/sys-user/login HTTP/1.1\\r\\nAccept: application/json, text/plain, */*\\r\\nAccept-Encoding: gzip, deflate\\r\\nAccept-Language: zh-CN,zh;q=0.9\\r\\nAuthorization: clusterid34\\r\\nConnection: keep-alive\\r\\nContent-Length: 101\\r\\nContent-Type: application/json\\r\\nCookie: apm.name=admin\\r\\nHost: 10.1\"},{\"url\":\"/other/network/Linux如何收发网络包.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Linux如何收发网络包\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"2.3 Linux 系统是如何收发网络包的？\\r\\n\\r\\n 网络协议栈\\r\\n\\r\\n\\r\\n\\r\\n1. 应用程序需要通过系统调用，来和 Socket 进程数据交互。\\r\\n2. Socket 层是介于应用层和传输层之间的抽象层。\\r\\n3. 最下面的一层，则是网卡驱动程序和硬件网卡设备。\\r\\n\\r\\n Linux 接收和发送网络包的流程\"},{\"url\":\"/other/network/OSI七层网络模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"OSI七层网络模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 应用层，负责给应用程序提供统一的接口；\\r\\n- 表示层，负责把数据转换成兼容另一个系统能识别的格式；\\r\\n- 会话层，负责建立、管理和终止表示层实体之间的通信会话；\\r\\n- 传输层，负责端到端的数据传输；\\r\\n- 网络层，负责数据的路由、转发、分片；\\r\\n- 数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址；\\r\\n- 物理层，负责在物理网络中传输数据帧；\"},{\"url\":\"/other/network/RTT和SRTT.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RTT和SRTT\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"RTT\\r\\n\\r\\nRTT 指的是客户端发出数据 → 客户端收到服务端发送的确认数据的时间。\\r\\n\\r\\nRTT 称为往返时延。\\r\\n\\r\\n SRTT\\r\\n\\r\\nSRTT（Smoothed Round Trip Time）是一种用于衡量网络延迟的指标，通常用于评估网络连接的质量和性能。SRTT表示在一系列网络往返（Round Trip）中的平滑往返时间。\\r\\n\\r\\nSRTT是通过在每次往返时间（RTT）的基础上应用加权平均算法来计算得出的。加权平均算法会给最近的RTT值更高的权重，以反映出网络延迟的实时变化。\\r\\n\\r\\nSRTT的值越小，表示网络延迟越低，网络连接的质量越好。较低的SRTT值通常意味着网络响应更快，数据传\"},{\"url\":\"/other/network/Socket.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Socket\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Socket 位于应用层和传输层之前的抽象层，是一组调用接口，TCP/IP网络的API函数。\\r\\n\\r\\n实际上是对 TCP/IP协议的封装，只是为了更方便使用 TCP/IP 协议。\\r\\n\\r\\n\\r\\n这个就像操作系统会提供标准的编程接口，比如win32编程接口一样。\\r\\nTCP/IP也要提供可供程序员做网络开发所用的接口，这就是Socket编程接口。\\r\\n&gt; \\r\\n\\r\\n Socket 通信流程\\r\\n\\r\\n\\r\\n\\r\\nSocket按照四元组来标识不同客户端与服务端之间的连接。\\r\\n\\r\\n四元组「源 IP、源端口、目的 IP、目的端口」\\r\\n\\r\\n- `accept()`\\r\\n  \\r\\n    服务端绑定端口之后，进入 `acc\"},{\"url\":\"/other/network/TCPIP四层网络模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP/IP四层网络模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"为什么要有网络模型\\r\\n\\r\\n进程通信的方式\\r\\n\\r\\n- 本机\\r\\n    - 消息队列\\r\\n    - 共享内存\\r\\n    - 管道（程序用来交换数据的地方）\\r\\n- 不同主机\\r\\n    - 网络通信\\r\\n\\r\\n需要网络通信的设备是多种多样的，所以要兼容，就要设定网络通信之间的网络协议。\\r\\n\\r\\n 应用层\\r\\n\\r\\n应用层定义了应用进程之间通信和交互的规则，应用层交互数据单元为报文。\\r\\n\\r\\n不关心数据如何传输，将报文传给传输层做传输。\\r\\n\\r\\n在这一层有很多熟悉的协议，比如 HTTP、HTTPS、DNS等。\\r\\n\\r\\n【计算机网络】TCP / IP 四层协议_tcp/ip协议包含哪几层_L Jiawen的博客-CSDN\"},{\"url\":\"/other/network/TCP分析工具.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP分析工具\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Wireshark · Go Deep\\r\\n\\r\\n\\r\\n\\r\\n 三次握手\\r\\n\\r\\n\\r\\n\\r\\n 第1次握手\\r\\n\\r\\n\\r\\n\\r\\nsyn设置为1，表明这是一个 SYN包\\r\\n\\r\\n\\r\\n\\r\\nseq = 1390201126\\r\\n\\r\\n\\r\\n\\r\\n 第2次握手\\r\\n\\r\\nsyn=1 同时 ACK=1，表明这是一个 SYN/ACK包\\r\\n\\r\\n\\r\\n\\r\\n服务端返回的 ACK = 客户端第一次发送的 seq+1 = 1390201126+1\\r\\n\\r\\n同时服务端向客户端返回了自己的 seq（如果第三次握手客户端返回的ack=seq+1，代表客户端收到了自己发的seq）\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n 第3次握手\\r\\n\\r\\n可以看到第 3 次握手的\"},{\"url\":\"/other/network/TCP协议.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP协议\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"TCP 协议灵魂 12 问，巩固你的网路底层基础！-腾讯云开发者社区-腾讯云\\r\\n\\r\\n\\r\\n\\r\\n TCP和UDP的区别\\r\\n\\r\\n- 面向连接\\r\\n    - TCP 需要客户端与服务端之间通过三次握手建联，之后才可以发送数据。\\r\\n    - UDP直接向服务端发数据包。\\r\\n- 可靠性\\r\\n    - 有状态\\r\\n        - TCP发数据包时，保证数据包按顺序到达。\\r\\n    - 可控制\\r\\n        - 当TCP协议丢包时，可以控制重发和自己的发送速度，保证数据包完整和有序。\\r\\n    - UDP 是无状态并且不可控的。\\r\\n- 基于字节流\\r\\n    - TCP将数据包通过字节流发送。\\r\\n   \"},{\"url\":\"/other/network/TCP粘包拆包.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP粘包拆包\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"发生粘包的原因\\r\\n\\r\\n- 要发送的数据小于 TCP 发送缓冲区的大小，TCP 将多次写入缓冲区的数据一次发送出去，将会发生粘包；\\r\\n- 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包；\\r\\n- 要发送的数据大于 TCP 发送缓冲区剩余空间大小，将会发生拆包；\\r\\n- 待发送数据大于 MSS（最大报文长度），TCP 在传输前将进行拆包。即 TCP 报文长度 - TCP 头部长度 \\r\\n\\r\\n 解决粘包拆包问题\\r\\n\\r\\n- 定长消息：发送端将每个数据包封装为固定长度\\r\\n- 特殊分隔符：在数据尾部增加特殊字符进行分割\\r\\n- 消息头：将数据分为两部分，一部分是头部，一部分是内容体；其中头部结构大小\"},{\"url\":\"/other/network/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"计算机网络\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础\\r\\n\\r\\n- TCP/IP四层网络模型\\r\\n- OSI七层网络模型\\r\\n- 网址访问页面中间发生了哪些过程\\r\\n- Linux如何收发网络包\\r\\n- 网络包的封装原理\\r\\n- Socket\\r\\n\\r\\n TCP\\r\\n\\r\\n- TCP协议\\r\\n- TCP分析工具\\r\\n\\r\\n\\r\\n- RTT和SRTT\\r\\n- 流量控制-滑动窗口\\r\\n\\r\\n- 拥塞控制\\r\\n- 重传机制\\r\\n- TCP粘包拆包\\r\\n\\r\\n\\r\\n UDP\\r\\n\\r\\nUDP不需要连接，可以单播和广播。\\r\\n\\r\\n HTTP\\r\\n- HTTP常见字段\\r\\n- HTTP和HTTPS\\r\\n- HTTP1x和HTTP2x\\r\\n\\r\\n 参考链接\\r\\n\\r\\n图解网络介绍\"},{\"url\":\"/other/network/拥塞控制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"拥塞控制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"流量控制是避免数据填满发送方的缓冲区。\\r\\n\\r\\n而拥塞控制是避免发送方的数据填满整个网络。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n在⽹络出现拥堵时，如果继续发送⼤量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是⼀重传就会导致⽹络的负担更重，于是会导致更⼤的延迟以及更多的丢包，这个情况就会进⼊恶性循环被不断地放⼤….\\r\\n\\r\\n所以，TCP 不能忽略整个网络中发⽣的事，它被设计成⼀个⽆私的协议，当⽹络发送拥塞时，TCP 会⾃我牺牲，降低发送的数据流。\\r\\n\\r\\n 拥塞窗口\\r\\n\\r\\n拥塞窗⼝ cwnd是发送⽅维护的⼀个的状态变量，它会根据⽹络的拥塞程度动态变化的。\\r\\n\\r\\n发送窗⼝ swnd 和接\"},{\"url\":\"/other/network/流量控制-滑动窗口.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"流量控制-滑动窗口\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在TCP中，滑动窗口用来流量控制。确保发送方不会过快的发送数据导致接收方无法处理数据。\\r\\n\\r\\nTCP拥塞控制是为了解决发送方以过高的速率发送导致网络中出现阻塞，其核心思想就是发生重传时控制发送方滑动窗口（通过控制拥塞窗口cwnd）的大小，从而控制其发送速率。\\r\\n\\r\\n 滑动窗口\\r\\n\\r\\nTCP窗口包括发送窗口和接收窗口，用来限制不同端所能容纳数据的上限，达到控制发送数据的速率。\\r\\n\\r\\n\\r\\n\\r\\nTCP报文里面的窗口大小，作用是告诉对方本端的接受缓冲区还能容纳多少字节的数据。\\r\\n\\r\\n\\r\\n\\r\\n在通信过程中，接收方每次收到数据包，在发送确认报文的时候，还需要告诉发送方自己的缓冲区剩余大小。缓冲区剩余大小，\"},{\"url\":\"/other/network/网址访问页面中间发生了哪些过程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"网址访问页面中间发生了哪些过程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"2.2 键入网址到网页显示，期间发生了什么？\\r\\n\\r\\n URL解析\\r\\n\\r\\n URL组成信息\\r\\n\\r\\nURL实际上就是访问 Web服务器里面的文件资源。\\r\\n\\r\\n\\r\\n\\r\\n 组装HTTP报文\\r\\n\\r\\n根据 URL 解析得到的内容，进行报文组装。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n DNS域名解析\\r\\n\\r\\n解析URL时，如果web服务器是域名，需要走DNS服务器进行域名解析，得到真实访问的IP地址。\\r\\n\\r\\n 域名组成\\r\\n\\r\\n`www.server.com.` 类似树状结构，越右等级越高。\\r\\n\\r\\n域名组成都代表了DNS服务器，里面保存了域名和IP的对应关系。\\r\\n\\r\\n域名服务器就像是一个树状结构。\\r\\n\\r\\n- 根\"},{\"url\":\"/other/network/网络包的封装原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"网络包的封装原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 TCP/IP 四层网络模型中，网络包每层的包装如下：\\r\\n\\r\\n- 传输层，给应用数据前面增加了 TCP 头；\\r\\n- 网络层，给 TCP 数据包前面增加了 IP 头；\\r\\n- 网络接口层，给 IP 数据包前后分别增加了帧头和帧尾；\\r\\n\\r\\n每层增加的头部和尾部，都有每层独特的作用，按照各自的协议填充。\\r\\n\\r\\n在物理链路上并不能传输任意大小的数据包，在以太网中，规定了最大传输单元（MTU）为 1500 字节，规定了单次传输的最大 IP 包的大小。\\r\\n\\r\\n当网络包超过 MTU 时，就会在网络层分片，确保分片后的包不会超过 MTU 大小。\\r\\n\\r\\n- 如果 MTU 越小，网络包分片数越多，那么网络吞吐能力\"},{\"url\":\"/other/network/重传机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"重传机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"超时重传\\r\\n\\r\\n原理是在发送某一个数据以后就开启一个计时器，在一定时间内如果没有得到发送的数据报的 ACK 报文，那么就重新发送数据，直到发送成功为止。\\r\\n\\r\\n RTT\\r\\n\\r\\nRTT（Round-Trip Time，往返时间）。数据包一次的往返时间。\\r\\n\\r\\n\\r\\n\\r\\nSRTT：平均的RTT\\r\\n\\r\\n 缺点\\r\\n\\r\\n- 当一个报文丢失时，会等待一定的超时周期，才重传分组，增加了端到端的时延。\\r\\n- 当一个报文丢失时，在其等待超时的过程中，可能会出现这种情况：其后的报文段已经被接收端接收但却迟迟得不到确认，发送端会认为也丢失了，从而引起不必要的重传，既浪费资源也浪费时间。\\r\\n- 并且，对于 TCP，如果\"},{\"url\":\"/other/observability/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可观测性常见维度\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"可观测性指的是对于系统内部运行状态的全面洞察和理解能力。\\r\\n\\r\\n可观测性项⽬旨在提供⼯具和解决⽅案，帮助开发⼈员和运维团队更好地监视、调试和理解其应⽤程序的行为。\\r\\n\\r\\n 维度\\r\\n\\r\\n- 日志采集 （log）\\r\\n- 指标采集 （Metric）\\r\\n- 链路追踪（Trace）\\r\\n- 告警管理（AlertManager）\\r\\n- 可视化（Visualization）\\r\\n\\r\\n整个可观测项目，维度除了常见的 log、metric、trace之外。还包括告警和可视化。\\r\\n\\r\\n 指标\\r\\n\\r\\n指标又可以分为：\\r\\n\\r\\n- 基础设施\\r\\n\\r\\n  服务器、数据库、MQ的指标。\\r\\n\\r\\n- 应用维度\\r\\n\\r\\n  应用包含模块\"},{\"url\":\"/other/observability/log/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"日志收集全链路\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ELFK\\r\\n\\r\\nELFK 指的是 elasticsearch+logstash+filebeat+kibana\\r\\n\\r\\n 日志管理\\r\\n\\r\\n日志收集→格式化分析→检索和可视化→日志告警\\r\\n\\r\\n\\r\\n\\r\\n 日志架构\\r\\n\\r\\n 小规模环境\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 大规模生产环境\\r\\n\\r\\nELFK + Kafka\\r\\n\\r\\n Logstash\\r\\n\\r\\n从多个来源采集数据，转换数据，然后将数据放到不同的数据库中。\\r\\n\\r\\nda 就很像 logstash 的功能设计。\\r\\n\\r\\n 架构\\r\\n\\r\\n\\r\\n\\r\\nLogstash 接入数据源数据，经过内部 Pipeline，将数据可以写到不同的存储（ES、Kafka）里面。\\r\\n\\r\\nLog\"},{\"url\":\"/other/observability/opentelemetry/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Opentelemetry\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"docs-cn/OT.md at main · open-telemetry/docs-cn\\r\\n\\r\\n OpenTracing&OpenCensus\\r\\n\\r\\n- OpenTracing 制定了一套平台无关、厂商无关的协议标准，使得开发人员能够方便的添加或更换底层 APM 的实现。\\r\\n- OpenCensus支持Metrics、分布式跟踪。\\r\\n\\r\\n OpenTelemetry\\r\\n\\r\\nOpenTelemetry 的核心工作目前主要集中在 3 个部分：\\r\\n\\r\\n1. 规范的制定和协议的统一，规范包含数据传输、API的规范。协议的统一包含：HTTP W3C的标准支持及GRPC 等框架的协议标准。\\r\\n2. 多\"},{\"url\":\"/other/observability/opentelemetry/可观测性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可观测性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"可观测性指的是对于系统内部运行状态的全面洞察和理解能力。\\r\\n\\r\\n可观测性项⽬旨在提供⼯具和解决⽅案，帮助开发⼈员和运维团队更好地监视、调试和理解其应⽤程序的行为。\\r\\n\\r\\n 维度\\r\\n\\r\\n- 日志采集 （log）\\r\\n- 指标采集 （Metric）\\r\\n- 链路追踪（Trace）\\r\\n- 告警管理（AlertManager）\\r\\n- 可视化（Visualization）\\r\\n\\r\\n整个可观测项目，维度除了常见的 log、metric、trace之外。还包括告警和可视化。\\r\\n\\r\\n 指标\\r\\n\\r\\n指标又可以分为：\\r\\n\\r\\n- 基础设施\\r\\n\\r\\n  服务器、数据库、MQ的指标。\\r\\n\\r\\n- 应用维度\\r\\n\\r\\n  应用包含模块\"},{\"url\":\"/other/observability/skywalking/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Skywalking\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Skywalking\\r\\n\\r\\n- 组件安装\\r\\n- 源码学习\"},{\"url\":\"/other/observability/skywalking/源码学习.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"源码学习\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Category: SkyWalking | 芋道源码 —— 纯源码解析博客\\r\\n\\r\\nSkyWalking8.7源码解析\\r\\n\\r\\n 告警组件\\r\\n\\r\\n 初始化Kafka消费者\\r\\n\\r\\n```java\\r\\n@Slf4j\\r\\npublic class KafkaFetcherProvider extends ModuleProvider {\\r\\n    private KafkaFetcherHandlerRegister handlerRegister;\\r\\n    private KafkaFetcherConfig config;\\r\\n\\r\\n    @Override\\r\\n    public String na\"},{\"url\":\"/other/observability/skywalking/组件安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"组件安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"OAP\\r\\n\\r\\n- 配置文件\\r\\n  \\r\\n    ```java\\r\\n    apache-skywalking-apm-bin/config/application.yml\\r\\n    ```\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n- 启动脚本\\r\\n  \\r\\n    ```java\\r\\n    sh bin/oapService.sh\\r\\n    ```\\r\\n    \\r\\n\\r\\n UI\\r\\n\\r\\n- 配置\\r\\n  \\r\\n    ```java\\r\\n    apache-skywalking-apm-bin/webapp/webapp.yml\\r\\n    ```\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n- 启动脚本\\r\\n  \\r\\n    ```java\\r\\n\"},{\"url\":\"/personal/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"personal\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"&lt;div align=\\\"center\\\"\\r\\n  &lt;img src=\\\"https://capsule-render.vercel.app/api?type=waving&color=gradient&height=300&section=header&text=Albert%20Yang&fontSize=90&animation=fadeIn&fontAlignY=38&desc=热爱编程%20|%20追求卓越%20|%20创新思维&descAlignY=55&descAlign=62\\\" /&gt;\\r\\n&lt;/div&gt;\\r\\n&lt;p align=\\\"center\\\" style=\"}],\"groupPostsByYear\":{\"2025 \":[{\"url\":\"/cloudnative/docker/Docker学习总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Docker学习总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本知识\\r\\n\\r\\n 1. Docker 是什么？\\r\\n\\r\\ndocker 是一种容器化虚拟技术，解决了运行环境和配置问题，方便持续集成并有助于项目整体发布。\\r\\n\\r\\n 2. Docker 能干嘛？\\r\\n\\r\\n*一次构建、随处运行。*\\r\\n\\r\\n- 更快速的应用交付和部署。\\r\\n- 更便捷的升级和扩缩容。\\r\\n- 更简单的系统运维。\\r\\n- 更高效的计算源利用。\\r\\n\\r\\n 基本组成\\r\\n\\r\\n 1. 镜像\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 2. 容器\\r\\n\\r\\n&gt; Docker 利用容器（Container）独立运行一个或一组应，容器是用镜像创建的运行实例。\\r\\n&gt; \\r\\n\\r\\n它可以被启动、开始、停止、删除。每个容器都是相\"},{\"url\":\"/cloudnative/docker/docker镜像压缩.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"docker镜像压缩\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"tar包\\r\\n\\r\\n\\r\\n\\r\\n```\\r\\ndocker save tomcat-apm-0915 -o ./tomcat-apm-0915.tar\\r\\n```\\r\\n\\r\\n```\\r\\ndocker load &lt; tomcat-apm-0915.tar\\r\\n```\\r\\n\\r\\nDocker 复制镜像到其他主机 - 彦祚 - 博客园\\r\\n\\r\\n tar.gz包\\r\\n\\r\\n 保存镜像\\r\\n\\r\\n`docker save &lt;myimage\\r\\n\\r\\n```\\r\\ndocker save xxx:xxx| gzip&gt;xxx.tar.gz\\r\\n```\\r\\n\\r\\n 加载镜像\\r\\n\\r\\n`gunzip -c &lt;myimage&gt;_&lt\"},{\"url\":\"/cloudnative/docker/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Docker\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"学习总结\\r\\n- Docker学习总结\\r\\n\\r\\n\\r\\n 使用总结\\r\\n- 容器软件安装\\r\\n- docker镜像压缩\\r\\n- 制作Tomcat镜像\\r\\n- 容器新增bash\"},{\"url\":\"/cloudnative/docker/制作Tomcat镜像.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"制作Tomcat镜像\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"DockerFile文件内容\\r\\n\\r\\n- tomcat 基础镜像\\r\\n  \\r\\n    ```bash\\r\\n    \\r\\n     使用基于 JDK 8 的官方 Tomcat 镜像作为基础镜像\\r\\n    FROM tomcat:8-jdk8\\r\\n    \\r\\n     修改默认的 shell\\r\\n    RUN ln -sf /bin/bash /bin/sh\\r\\n    \\r\\n     暴露 Tomcat 的默认 HTTP 端口\\r\\n    EXPOSE 8080\\r\\n    \\r\\n     设置容器启动时执行的命令\\r\\n    CMD [\\\"catalina.sh\\\", \\\"run\\\"]\\r\\n    ```\\r\\n    \\r\\n- \"},{\"url\":\"/cloudnative/docker/容器新增bash.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"容器新增bash\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"安装方式\\r\\n\\r\\n- wget 下载\\r\\n  \\r\\n    ```bash\\r\\n    from busybox\\r\\n    \\r\\n     下载 bash 二进制文件\\r\\n    RUN wget -O /bin/bash http://ftp.gnu.org/gnu/bash/bash-5.1.tar.gz\\r\\n    \\r\\n     设置可执行权限\\r\\n    RUN chmod +x /bin/bash\\r\\n    \\r\\n     运行命令\\r\\n    CMD [\\\"echo\\\", \\\"Hello, World!\\\"]\\r\\n    ```\\r\\n    \\r\\n- 本地安装\\r\\n  \\r\\n    ```bash\\r\\n    from \"},{\"url\":\"/cloudnative/docker/容器软件安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"容器软件安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"RabbitMQ\\r\\n\\r\\n参考博客\\r\\n\\r\\ndocker安装RabbitMQ\\r\\n\\r\\n---\\r\\n\\r\\n1. 查找镜像\\r\\n   \\r\\n    ```java\\r\\n    docker search rabbitmq\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n2. 拉取镜像\\r\\n   \\r\\n    ```java\\r\\n    docker pull rabbitmq\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 启动镜像\\r\\n   \\r\\n    ```java\\r\\n    docker run -d --hostname my-rabbit --name rabbit -p 15672:15\"},{\"url\":\"/cloudnative/k8s/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"K8s\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- k8s常用命令\\r\\n- k8s问题排查流程图\"},{\"url\":\"/cloudnative/k8s/k8s常用命令.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"k8s常用命令\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"常用命令总结\\r\\n\\r\\n node\\r\\n\\r\\n- 查看所有的node\\r\\n  \\r\\n    ```\\r\\n    kubectl get nodes\\r\\n    ```\\r\\n    \\r\\n- 查看node名与Host文件的相互解析\\r\\n  \\r\\n    ```\\r\\n    cat /etc/hosts\\r\\n    ```\\r\\n    \\r\\n- 查看本机 hostname\\r\\n  \\r\\n    `Plain Text   cat /etc/hostname`\\r\\n    \\r\\n\\r\\n namespace\\r\\n\\r\\n- 查看所有的namespace\\r\\n  \\r\\n    ```\\r\\n    [root@master ~] kubectl  get n\"},{\"url\":\"/cloudnative/k8s/k8s问题排查流程图.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"k8s问题排查流程图\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"深度解密｜基于 eBPF 的 Kubernetes 问题排查全景图发布-阿里云开发者社区\"},{\"url\":\"/cloudnative/prometheus/TSDB.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TSDB\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Prometheus的 TSDB（Time Series Database）作为内置的时序数据库。\\r\\n\\r\\n 存储原理\\r\\n\\r\\nTSDB 既使用内存也使用磁盘进行数据存储。\\r\\n\\r\\n\\r\\n\\r\\n Head\\r\\n\\r\\n在Prometheus中，Head 是数据库的内存部分，用于存储最近写入的数据。\\r\\n\\r\\n当数据在Head中存储2小时后，会被转移到磁盘上的持久块（block）中。这些持久块是不变的，每个块代表一段时间的数据，并且按照时间顺序进行组织和存储。\\r\\n\\r\\n\\r\\n\\r\\n Block块\\r\\n\\r\\nPrometheus中以每2个小时为一个时间窗口，即将2小时内产生的数据存储在一个block中，监控数据会以时间段的形式\"},{\"url\":\"/cloudnative/prometheus/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Prometheus\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 架构\\r\\n- TSDB\\r\\n- 数据模型\\r\\n- node_exporter源码\"},{\"url\":\"/cloudnative/prometheus/node_exporter源码.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"node_exporter源码\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"简单流程\\r\\n\\r\\n1. 定时任务 30s 执行一次\\r\\n    1. 调用采集指标的方法\\r\\n2. 不同 Collector 采集自己的指标\\r\\n    1. 内存\\r\\n        - 读取 `/`@\\r\\n          \\r\\n            `proc/meminfo`文件内容\\r\\n            \\r\\n            ```go\\r\\n            MemTotal:       16267496 kB\\r\\n            MemFree:          803084 kB\\r\\n            MemAvailable:    1507880 kB\\r\\n \"},{\"url\":\"/cloudnative/prometheus/数据模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Prometheus的存储实现上所有的监控样本都是以 time-series 的形式保存在 Prometheus 内置的TSDB（时序数据库）中，而 time-series 所对应的监控指标 (metric) 也是通过 labelset 进行唯一命名的。\\r\\n\\r\\n 样本数据\\r\\n\\r\\n- 指标(metric)：metric name 和描述当前样本特征的 labelsets;\\r\\n- 时间戳(timestamp)：一个精确到毫秒的时间戳;\\r\\n- 样本值(value)： 一个float64的浮点型数据表示当前样本的值。\\r\\n\\r\\n```\\r\\n&lt;--------------- metric -------\"},{\"url\":\"/cloudnative/prometheus/架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Prometheus架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- Promtheus 默认采取主动拉的策略，可以配置各个exporter的拉取间隔。\\r\\n    - Exporter 被动暴露数据，Prometheus 主动拉取。\\r\\n- 但是Promtheus也可以使用 Pushgateway 实现 Push 模型。\\r\\n    - exporter 将数据推给 Pushgateway，Promtheus从Pushgateway拉数据。\"},{\"url\":\"/database/clickhouse/ClickHouse基础.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse基础\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"列式存储\\r\\n\\r\\nclickhouse 是 *列式存储* 数据库\\r\\n\\r\\n在磁盘上按列存储，即按某个字段进行存储。\\r\\n\\r\\n\\r\\n\\r\\n所以列式存储更适合进行查询，比如某一行的聚合、计算、求和等。\\r\\n\\r\\n 列式存储的好处\\r\\n\\r\\n1. 对于某列的聚合、计数、求和等操作要比行式存储更快。\\r\\n   \\r\\n    查询更快。\\r\\n    \\r\\n    - 行式存储，增改删更加方便，因为只需要找到对应的行记录，直接删除即可。但是列式存储对比起来，增改删要更繁琐一点。\\r\\n2. 每一列的数据类型是一样的，这样能更好的进行数据压缩。\\r\\n   \\r\\n    方便数据压缩，节省磁盘\\r\\n    \\r\\n    - 与 es 相比，作为常\"},{\"url\":\"/database/clickhouse/ClickHouse安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"docker下安装clickhouse_docker 安装clickhouse-CSDN博客\\r\\n\\r\\n使用 clickhouse-client 进入 ck\\r\\n\\r\\n mac 安装\\r\\n\\r\\n```java\\r\\ndocker run --rm -d --name=clickhouse \\\\\\r\\n-e CLICKHOUSE_ADMIN_PASSWORD=\\\"123456\\\" \\\\\\r\\n--ulimit nofile=262144:262144 \\\\\\r\\n-p 8123:8123 -p 9009:9009 -p 9090:9000 \\\\\\r\\n-v /Users/yangjunwei/ck/config:/etc/clickhou\"},{\"url\":\"/database/clickhouse/ClickHouse物化列序列化报错.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse物化列序列化报错问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"报错内容\\r\\n\\r\\n```java\\r\\nNo serializer found for column 'date'. Did you forget to register it?\\r\\n\\tat com.clickhouse.client.api.Client.insert(Client.java:1317)\\r\\n\\tat com.clickhouse.client.api.Client.insert(Client.java:1266)\\r\\n```\\r\\n\\r\\n 表结构\\r\\n\\r\\n```java\\r\\nCREATE TABLE IF NOT EXISTS metric_data\\r\\n(\\r\\n    `placeId` UInt3\"},{\"url\":\"/database/clickhouse/ClickHouse高级.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse高级\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MergeTree\\r\\n\\r\\nClickHouse 中最强大的表引擎当属 MergeTree（合并树）引擎及该系列（MergeTree）中的其他引擎，支持索引和分区，地位可以相当于 innodb 之于 Mysql。而且基于 MergeTree，还衍生除了很多小弟，也是非常有特色的引擎。\\r\\n\\r\\n建表语句\\r\\n\\r\\n```sql\\r\\ncreate table t_order_mt(\\r\\n id UInt32,\\r\\n sku_id String,\\r\\n total_amount Decimal(16,2),\\r\\n create_time Datetime\\r\\n) engine = MergeTree\\r\\n partiti\"},{\"url\":\"/database/clickhouse/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- ClickHouse安装\\r\\n- ClickHouse基础\\r\\n- ClickHouse高级\\r\\n- 为什么弃用Elasticsearch\"},{\"url\":\"/database/clickhouse/为什么弃用Elasticsearch.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"对于开发来说：\\r\\n\\r\\n1. 大批量数据查询导致 es 的 CPU 飙升。\\r\\n2. 数据量增大之后，es 的查询效率下降，影响接口性能。\\r\\n3. 聚合效率低。\\r\\n\\r\\n对于运维来说：\\r\\n\\r\\n1. 维护成本很大，在数据量大的情况，es 占用磁盘空间很大，没有很好的压缩手段。\\r\\n2. es 很占内存，内存配置为整体内存的一半。\\r\\n\\r\\n 问题记录\\r\\n\\r\\n- 缓存计算系统评分导致 es 的 cpu 飙升。\\r\\n\\r\\n  系统评分需要查询 es 的流量信息进行计算，实时查询很慢。做了定时任务计算分数信息并作缓存。\\r\\n\\r\\n    - 经常发现 es 的 cpu 会被打满。排查发现随着系统的增多，当定时任务跑的时候\"},{\"url\":\"/database/mysql/B树和B+树.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"B树和B+树\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"B树\\r\\n\\r\\n\\r\\n\\r\\n每个节点是一个磁盘快。每个磁盘快有固定大小，可以存储多个K-V键值对。\\r\\n\\r\\n每个磁盘快包含指向下层节点的指针，方便查找。\\r\\n\\r\\n*由于每个节点存储了更多的键值对数据，可以有效降低查找树的次数，并减少查询磁盘。*\\r\\n\\r\\n- \\r\\n\\r\\n B+树\\r\\n\\r\\n\\r\\n\\r\\n 存储空间\\r\\n\\r\\nB+树是在B树的基础上演进的。\\r\\n\\r\\nB+树的非叶子结点是不保存数据的，仅保存键值。\\r\\n\\r\\n在 InnoDB中页大小是固定的，在只保存键值的情况下，同一个数据页能保存更多的键值。这样就能保证整个树的层级大大降低，减少向下搜索时候的磁盘IO次数，会提高数据的查询效率。\\r\\n\\r\\nInnoDB 中页的默认大小是 \"},{\"url\":\"/database/mysql/InnoDB存储引擎.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"InnoDB存储引擎\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"存储引擎\\r\\n\\r\\n在系统执行 `update` 语句时，经过 `Server层` 的处理，最终要由执行器去调用存储引擎去执行。\\r\\n\\r\\n而 MySQL 存储引擎有很多种，比如 `InnoDB`、`MyISAM`等。\\r\\n\\r\\nMySQL的默认存储引擎已经变更为了 `InnoDB`\\r\\n\\r\\n---\\r\\n\\r\\n`update` 语句操作的数据最终是要写入磁盘中的，但是如果每次都直接操作磁盘，磁盘I/O的开销是很大的。所以需要每次将操作的数据加载到内存中，减少磁盘I/O次数，再在适当时机进行刷盘操作即可。InnoDB 中使用的这块内存叫做 `Buffer Pool`。\\r\\n\\r\\n 缓冲池 - Buffer Pool\\r\"},{\"url\":\"/database/mysql/MySQL基础架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL基础架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL是 `C/S（Client端 / Server端）` 架构。\\r\\n\\r\\n 架构图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nMySQL架构包含 `Server层` 和 `存储引擎层` 。\\r\\n\\r\\n- Server 层包含 `连接器` 、`分析器`、`优化器`、`执行器`。\\r\\n- 存储引擎层包含 `引擎层`、`存储层`。\\r\\n\\r\\n 一、连接器\\r\\n\\r\\n 连接器的作用\\r\\n\\r\\n- 跟客户端建立连接。\\r\\n- 维持和管理连接。\\r\\n- 校验用户和获取用户权限。\\r\\n\\r\\n---\\r\\n\\r\\n 校验用户\\r\\n\\r\\n客户端进行连接MySQL的命令如下：\\r\\n\\r\\n```java\\r\\nmysql -h$ip -P$port -u$user -p\\r\\n`\"},{\"url\":\"/database/mysql/MySQL日志系统.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL日志系统\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"undo.log\\r\\n\\r\\n记录被更新前的数据。\\r\\n\\r\\n\\r\\n\\r\\nInnoDB 支持事务，在事务执行失败回滚时，数据会回到操作前的样子。\\r\\n\\r\\n`undo.log` 就是为了事务回滚，恢复数据的。\\r\\n\\r\\n回滚对应的操作如下：\\r\\n\\r\\n1. insert\\r\\n   \\r\\n    插入一条记录时，将这条记录的主键记录下来，回滚时根据主键删除。\\r\\n    \\r\\n2. update\\r\\n   \\r\\n    更新一条记录时，将更新的列的旧值记录下来，回滚时将这些值更新回去。\\r\\n    \\r\\n3. delete\\r\\n   \\r\\n    删除一条记录时，将这条记录记录下来，回滚时重新插入到表中。\\r\\n    \\r\\n\\r\\n---\\r\\n\\r\\n在\"},{\"url\":\"/database/mysql/MySQL根据idb文件恢复数据.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL根据idb文件恢复数据\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL根据idb文件恢复数据\\r\\n\\r\\n1. MySQl解除表名\\r\\n   \\r\\n    `Plain Text  ALTER TABLE 表名 DISCARD TABLESPACE`\\r\\n    \\r\\n2. 复制 idb 文件到 data目录。\\r\\n   \\r\\n    \\r\\n    \\r\\n3. idb 文件增加权限。\\r\\n   \\r\\n    ```\\r\\n    chown mysql:mysql user_tenant.ibd\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n4. 重新导入表数据文件\\r\\n   \\r\\n    ```\\r\\n    ALTER TABLE 表名 IMPORT TABLESPACE\\r\\n\"},{\"url\":\"/database/mysql/MySQL的binlog日志过期删除.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL的binlog日志过期删除\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"问题\\r\\n\\r\\nmysql的binlog日志过多导致磁盘告警。\\r\\n\\r\\n部署脚本中没有配置 `binlog` 的失效时间，默认是30天。\\r\\n\\r\\n 手动清理\\r\\n\\r\\n1. 查看正在使用的binlog\\r\\n   \\r\\n    ```sql\\r\\n    show master status\\r\\n    ```\\r\\n    \\r\\n2. 删除指定binlog之前的所有binlog\\r\\n   \\r\\n    ```sql\\r\\n    purge binary logs to 'bin.000055'\\r\\n    ```\\r\\n    \\r\\n\\r\\n 配置自动清理\\r\\n\\r\\n 查看日志过期时间\\r\\n\\r\\n```sql\\r\\nshow variables li\"},{\"url\":\"/database/mysql/OrderBy和limit混用的bug.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"OrderBy和limit混用的bug\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"案例\\r\\n\\r\\n```java\\r\\nselect * from table order by month desc limit 0,10\\r\\n```\\r\\n\\r\\nmonth 重复度高的情况下，limt查询会出bug。导致部分数据丢失。可以增加区分度高的字段一起排序，比如id。\\r\\n\\r\\n```java\\r\\nselect * from table order by month desc,id desc limit 0,10\\r\\n```\"},{\"url\":\"/database/mysql/SQL语句的抖动问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SQL语句的抖动问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"有时候在执行 SQL 的时候，突然会变得很慢。这种慢比较随机，看起来像是抖动一样。\\r\\n\\r\\n更新数据流程可以简化一下。\\r\\n\\r\\n1. 内存（buffer pool）中的数据 flush 到磁盘。\\r\\n2. 数据写入到 redo log 中。\\r\\n\\r\\n其中 buffer pool 中的数据页有三种状态：\\r\\n\\r\\n1. 数据页无数据。\\r\\n2. 数据页是干净页。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n3. 数据页是脏页。\\r\\n   \\r\\n    &gt; 脏页指的是内存中的数据被更新，但是没有flush到磁盘。出现内存和磁盘数据不一致的情况，此时该数据页称为脏页面。\\r\\n    &gt; \\r\\n\\r\\n 性能问题\"},{\"url\":\"/database/mysql/explain使用总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"explain使用总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"参数\\r\\n\\r\\n| id | Columns | JSON Name | Meaning |\\r\\n| --- | --- | --- | --- |\\r\\n| 1 | id | select_id | 每个select子句的标识id |\\r\\n| 2 | select_type | None | select语句的类型 |\\r\\n| 3 | table | table_name | 当前表名 |\\r\\n| 4 | partitions | partitions | 匹配的分区 |\\r\\n| 5 | type | access_type | 当前表内访问方式 join type |\\r\\n| 6 | possible_key\"},{\"url\":\"/database/mysql/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL数据库\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL基础\\r\\n\\r\\n- MySQL基础架构\\r\\n- InnoDB存储引擎\\r\\n---\\r\\n- MySQL日志系统\\r\\n---\\r\\n- 一条更新SQL的执行过程\\r\\n---\\r\\n- 事务隔离\\r\\n---\\r\\n- B树和B+树\\r\\n- 索引\\r\\n---\\r\\n- 锁\\r\\n- 行锁\\r\\n\\r\\n\\r\\n\\r\\n MySQL总结\\r\\n\\r\\n- SQL语句的抖动问题\\r\\n- 索引失效的场景\\r\\n- explain使用总结\\r\\n- 慢查询日志\\r\\n\\r\\n\\r\\n 问题总结\\r\\n- OrderBy和limit混用的bug\\r\\n- MySQL的binlog日志过期删除\\r\\n- MySQL根据idb文件恢复数据\"},{\"url\":\"/database/mysql/一条更新SQL的执行过程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"一条更新SQL的执行过程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"juejin.cn\\r\\n\\r\\n```java\\r\\nmysql\\r\\n```\\r\\n\\r\\n 执行流程\\r\\n\\r\\n1. 执行器先找引擎取出 ID=2 这一行记录。\\r\\n    - 如果该行记录在 `Buffer Pool` 中存在，会直接返回数据给执行器。\\r\\n    - 如果该行记录不存在，则会先进行如下操作，再返回数据给执行器。\\r\\n        - 从磁盘中查找数据。\\r\\n        - 将数据写入内存 `Buffer Pool` 中。\\r\\n        - 将数据写入 `undo.log`（记录 insert、update、delete等修改数据的操作）。\\r\\n2. 执行器获取到引擎给的行数据，把这条数据更新 c\"},{\"url\":\"/database/mysql/事务隔离.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"事务隔离\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。\\r\\n\\r\\n在 MySQL 中，事务支持是在`引擎层`实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。\\r\\n\\r\\n比如 MySQL 原生的 `MyISAM 引擎就不支持事务`，这也是 MyISAM 被 InnoDB 取代的重要原因之一。\\r\\n\\r\\n 事务问题\\r\\n\\r\\n 脏读\\r\\n\\r\\n读到了别的事务 修改过 但未提交的数据\\r\\n\\r\\n 不可重复读\\r\\n\\r\\n指的是变没变化的问题。数据被修改了导致前后两次查询结果不一样。\\r\\n\\r\\n原来是 A，现在是 B，就是不可重复读。\\r\\n\\r\\n 幻读\\r\\n\\r\\n指的是存不存在的问题，原来存\"},{\"url\":\"/database/mysql/慢查询日志.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"慢查询日志\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL中，需要查看执行慢的SQL，需要先开启慢查询日志。\\r\\n\\r\\nMySQL的慢查询日志，记录了MySQL中响应时间超过阈值的SQL语句。\\r\\n\\r\\n 参数说明\\r\\n\\r\\n- slow_query_log：是否开启慢查询日志，1表示开启，0表示关闭。\\r\\n- log-slow-queries ：旧版（5.6以下版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name-slow.log\\r\\n- slow-query-log-file：新版（5.6及以上版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name\"},{\"url\":\"/database/mysql/索引.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"索引\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准。\\r\\n\\r\\n InnoDB的索引模型\\r\\n\\r\\n B+树\\r\\n\\r\\n\\r\\n\\r\\nB+树的每个叶子节点存放元素有限，每个叶子节点为一个 page，针对元素的数量会产生页分裂、页合并等现象。\\r\\n\\r\\n什么是B+树？_攻城狮百里的博客-CSDN博客_b+树\\r\\n\\r\\n\\r\\n\\r\\n 聚簇索引和二级索引\\r\\n\\r\\n- 主键索引的叶子结点存的是整行记录。InnoDB 引擎中主键索引又称为聚簇索引。\\r\\n- 非主键索引的叶子结点存的是行记录的ID。在 InnoDB 引擎中非主键索引又称为二级索引。\\r\\n\\r\\n\\r\\n\\r\\n 搜索方式\\r\\n\\r\\n- 根据主键搜索\\r\\n  \\r\\n    `\"},{\"url\":\"/database/mysql/索引失效的场景.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"索引失效的场景\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"查询条件做函数计算\\r\\n\\r\\n```sql\\r\\nselect count(*) from tradelog where month(t_modified)=7;\\r\\n```\\r\\n\\r\\n查询条件做函数计算，在查索引的时候，利用不了索引。因为索引利用的是树的有序性，但是函数计算后的结果在索引的B+树上并不连续。MySQL在查询的时候利用不到树的有序性。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。\\r\\n\\r\\n 隐式类型转换\\r\\n\\r\\n假如 tradeid 字段类型是 varchar ，查询语句\\r\\n\\r\\n```sql\\r\\nexplain   sele\"},{\"url\":\"/database/mysql/行锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"行锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL 中的行锁（row-level locking）并不是单纯指写锁（write lock），而是指锁定机制的粒度。行锁可以是共享锁（也称为读锁，S锁）或排他锁（也称为写锁，X锁），具体取决于事务所使用的隔离级别以及查询类型。\\r\\n\\r\\n- Select for Update：当执行带有 `FOR UPDATE` 子句的 `SELECT` 查询时，InnoDB 会对被选中的行加上排他锁。这确保了在事务提交之前，其他事务不能修改这些行。\\r\\n- Insert Intention Lock：当执行 `INSERT` 操作时，InnoDB 会自动为要插入的行加上意向锁。这是为了避免插入操作与其他事务\"},{\"url\":\"/database/mysql/锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL中加锁是为了处理并发问题，根据锁的粒度可以分为全局锁、表级锁和行锁。\\r\\n\\r\\n 全局锁\\r\\n\\r\\n全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 `Flush tables with read lock` (FTWRL)。\\r\\n\\r\\n加完之后整个数据库处于只读状态。\\r\\n\\r\\n---\\r\\n\\r\\n 应用场景（不推荐）\\r\\n\\r\\n全局锁的经典应用场景 数据库备份。\\r\\n\\r\\n由于加全局锁，会导致整个数据库只读，所以一般不推荐使用。\\r\\n\\r\\n 可重复读进行备份\\r\\n\\r\\n备份数据库一般可以利用可重复读的事务隔离级别来实现，因为可重复读情况开始事务，会生成当前数据库的视图，保证整个事务期间以\"},{\"url\":\"/database/redis/LRU和LFU算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"LRU和LFU算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"LRU算法\\r\\n\\r\\n 简介\\r\\n\\r\\nLRU （Least Recently Used） 算法即最近最久未使用，每次选择最近最久未使用的页面淘汰掉。\\r\\n\\r\\n 实现过程\\r\\n\\r\\n- 新增数据时，元素插入到队列头部。\\r\\n- 访问元素（查询、更新和删除）时，将元素移动到队列头部。\\r\\n- 当超过内存限制，需要淘汰数据时，将已排序队列的最后元素删除。\\r\\n\\r\\n\\r\\n\\r\\n 数据结构\\r\\n\\r\\nLRU 算法内部的数据结构需要根据元素的访问时间排序。还需要查找、插入、删除等效率要高。\\r\\n\\r\\n1. 查找、插入、删除快。\\r\\n2. 支持排序。\\r\\n\\r\\n在常用的集合中，有的是查找更新快或者插入删除快，没有数据结构能同时满足以上条件，所\"},{\"url\":\"/database/redis/Redisson.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Redisson\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还实现了可重入锁（Reentrant Lock）、公平锁（Fair Lock、联锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）等，还提供了许多分布式服务。Redisson提供了使用Redis的最简单和最便捷的方法。Redisson的宗旨是促进使用者对Redis的关注分离（Separation of Concern），从而让使用者能够将精力更集中地放在处理业务逻辑上。\\r\\n\\r\\n Redisson \"},{\"url\":\"/database/redis/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- redis数据类型\\r\\n- redis数据类型原理\\r\\n- redis的持久化\\r\\n\\r\\n\\r\\n- 过期策略\\r\\n- 内存淘汰策略\\r\\n- LRU和LFU算法\\r\\n\\r\\n- redis实现分布式锁\\r\\n- Redisson\\r\\n\\r\\n- redis事务.md\\r\\n- redis集群.md\\r\\n\\r\\n- 缓存问题\\r\\n- 布隆过滤器\"},{\"url\":\"/database/redis/redis事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis的事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis 的事务，可以一次执行多个命令，本质上是一组命令的集合，按照顺序串行化执行而不会被其它命令插入。\\r\\n\\r\\n 常用命令\\r\\n\\r\\n- 开启事务 -`multi`\\r\\n- 执行所有事务 - `exec`\\r\\n- 取消所有事务 - `discard`\\r\\n- 监控一个或多个 key - `watch`\\r\\n- 取消 watch 命令对所有 key 的监控 - `unwatch`\\r\\n  \\r\\n    \\r\\n    \\r\\n\\r\\n watch监控\\r\\n\\r\\nwatch 指令，类似乐观锁，在创建事务之前，使用 watch 指令监控某个值。在事务提交时，如果 key 的值已经被别的客户端改变，那么整个事务队列都不会执行。\\r\\n\"},{\"url\":\"/database/redis/redis实现分布式锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis实现分布式锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"分布式锁简介\\r\\n\\r\\n在分布式环境下，多个系统访问共享资源时会发生线程安全问题，分布式锁就是为了解决分布式环境下访问共享资源的线程安全问题，保证共享资源同一时间只能被一个系统的一个线程访问。\\r\\n\\r\\n 分布式锁具备的条件\\r\\n\\r\\n1. 在分布式环境下，共享资源在同一时间只能被一个系统的一个线程访问。\\r\\n2. 保证设置分布式锁和删除分布式锁操作的原子性。\\r\\n3. 具备可重入特性。\\r\\n4. 防止死锁。\\r\\n5. 具备锁超时失效的机制。\\r\\n6. 具备非阻塞锁特性，不会阻塞等待获取锁。\\r\\n\\r\\n 分布式锁主要实现方式\\r\\n\\r\\n1. zeekeeper 实现分布式锁\\r\\n2. redis 实现分布式锁\\r\\n\\r\\n---\\r\"},{\"url\":\"/database/redis/redis数据类型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis数据类型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis数据类型\\r\\n\\r\\n练习代码地址 redis-practice\\r\\n\\r\\n 键 - key\\r\\n\\r\\n在了解数据类型之前，先了解一下 redis 的键。\\r\\n\\r\\n在 redis 中 命令不区分大小写，但是注意 redis 中的 key 和 value 是区分大小写的。\\r\\n\\r\\n\\r\\n\\r\\n 字符串 - string\\r\\n\\r\\n字符串数据结构是简单的 K-V 模式数据结构。\\r\\n\\r\\n 特点\\r\\n\\r\\n- 单值单 value。\\r\\n- 二进制安全，可以包含任何数据。\\r\\n- 一个键对应 value 值最大能存储数据 512 MB。\\r\\n\\r\\n 常用命令\\r\\n\\r\\n\\r\\n\\r\\n- 设置字符串 - `set test 100`\\r\\n- 查\"},{\"url\":\"/database/redis/redis数据类型原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis数据类型原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. linkedlist (双向链表)\\r\\n    - 当列表元素较多或元素大小超过一定阈值时，Redis 会使用双向链表来存储 `list` 键。\\r\\n    - linkedlist 是一种指针结构，每个节点包含指向前后节点的指针，这使得插入和删除操作非常高效。\\r\\n    - linkedlist 的优点是支持高效的插入和删除操作，但缺点是比 ziplist 更占用内存。\\r\\n\\r\\n 全局哈希表\\r\\n\\r\\n\\r\\n\\r\\nRedis是一个 K-V 数据库，有一个全局的哈希桶存放所有的 key。\\r\\n\\r\\nkey 对应的 entry 包含了实际的 key 和 value。这里的 value 对应着不同的数据类型。\"},{\"url\":\"/database/redis/redis的持久化.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis的持久化\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis 有 RDB 和 AOF 两种持久化方式。\\r\\n\\r\\n RDB\\r\\n\\r\\nRDB 是 *Redis DataBase* 的简称，指的是在指定时间间隔内将内存中的数据集快照写入磁盘文件，也就是 Snapshot 快照，RDB 是默认开启的。\\r\\n\\r\\n RDB的原理\\r\\n\\r\\nRedis 会单独创建 （fork）一个子进程来进行持久化操作，将内存中某一时刻的数据持久化到磁盘文件。这个子进程会先将数据写入到一个临时文件中，等待持久化进程结束后，再用这个临时文件替换掉磁盘文件。\\r\\n\\r\\n\\r\\n\\r\\n在整个过程中，主进程是不进行任何 IO 操作的，这样保证了主进程存取的高性能。\\r\\n\\r\\nRDB 的持久化过程每次都是\"},{\"url\":\"/database/redis/redis集群.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis集群\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Redis集群是一个由多个主从节点群组成的分布式服务集群，它具有复制、高可用和分片特性。\\r\\n\\r\\n 主从模式\\r\\n\\r\\n\\r\\n\\r\\n- 主数据库可以进行读写操作。\\r\\n  \\r\\n    数据会通过主从同步，由主服务器同步给从服务器。\\r\\n    \\r\\n    主服务器将数据\\r\\n    \\r\\n- 从数据库一般是只读的。\\r\\n\\r\\n引入主从复制机制的目的有两个：\\r\\n\\r\\n- 一个是读写分离，分担 “master” 的读写压力\\r\\n- 一个是方便做容灾恢复，避免单点故障。\\r\\n\\r\\n 主从同步的原理\\r\\n\\r\\n\\r\\n\\r\\n- 全量复制\\r\\n  \\r\\n    从数据库在第一次同步的时候会进行全量同步。\\r\\n    \\r\\n    主库执行 bgsav\"},{\"url\":\"/database/redis/内存淘汰策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内存淘汰策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"最大内存设置\\r\\n\\r\\n1. redis 默认内存是多少？\\r\\n   \\r\\n    在 64 位操作系统不限制内存大小，在 32 位操作系统下最多使用 3GB。\\r\\n    \\r\\n2. 查看 redis 最大内存？\\r\\n   \\r\\n    `Plain Text  config get maxmemory`\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 修改 redis 内存大小？\\r\\n    - 修改配置文件\\r\\n      \\r\\n        在 `redis.conf` 第 859 行可以设置最大内存大小（单位是字节）。\\r\\n        \\r\\n        \\r\\n        &gt; \\r\\n        \"},{\"url\":\"/database/redis/布隆过滤器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"布隆过滤器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 什么是布隆过滤器？\\r\\n\\r\\n布隆过滤器（Bloom Filter）是一种数据结构，用来判断一个元素是否在一个集合中。布隆过滤器的本质上使用的是二进制向量和 k 个哈希函数组成。\\r\\n\\r\\n布隆过滤器具有如下优点：\\r\\n\\r\\n- 空间利用率高。\\r\\n  \\r\\n    布隆过滤器底层使用二进制向量保存数据，不需要保存元素本身，只需要在指定 bit 存放标识即可，故空间利用率非常高。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n- 时间效率也较高，插入和查询效率高。\\r\\n  \\r\\n    布隆过滤器的时间复杂度只跟哈希函数的个数 k 有关，插入和查询的时间复杂度均为 O(k)；\\r\\n    \\r\\n    *结合\"},{\"url\":\"/database/redis/缓存问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"缓存问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"前言\\r\\n\\r\\n在使用缓存的时候，简单的缓存处理流程如下。针对如下流程会遇到缓存穿透、缓存击穿、缓存雪崩等问题。\\r\\n\\r\\n\\r\\n\\r\\n 缓存穿透\\r\\n\\r\\n缓存穿透：当用户请求查询某个数据时，先从缓存查询，缓存中没有这个数据。然后向数据库查询数据，数据库中也没有这个数据，导致查询失败。\\r\\n\\r\\n*像一些恶意攻击时，故意查询数据库中不存在的数据，比如查询 id = -1 的数据，会造成数据库压力非常大。*\\r\\n\\r\\n\\r\\n\\r\\n 解决方案\\r\\n\\r\\n1. 对空值做缓存。\\r\\n   \\r\\n    当出现从缓存和数据库都查不到数据的情况时，可以将空值存到缓存中，即 K-V 存为 key-null，缓存过期时间可以设置短点，来防止短\"},{\"url\":\"/database/redis/过期策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"过期策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 Redis 中设置了过期时间的 key，在一定时间后都会被删除。\\r\\n\\r\\n 键的过期时间\\r\\n\\r\\n 配置过期时间\\r\\n\\r\\n1. `setex key seconds value`\\r\\n   \\r\\n    设置 key 时添加过期时间\\r\\n    \\r\\n2. `expire key seconds`\\r\\n   \\r\\n    为某个 key 设置过期时间。\\r\\n    \\r\\n3. 删除 key 的过期时间。\\r\\n   \\r\\n    `persist key`\\r\\n    \\r\\n4. 查看 key 的过期时间\\r\\n   \\r\\n    `ttl key`\\r\\n    \\r\\n\\r\\n redis保存过期时间分析\\r\\n\\r\\n[版权声明：本文为CS\"},{\"url\":\"/frame/mybatis/custom/SQL执行器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SQL执行器-executor\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"将操作数据库的操作从 sqlSession 中解耦，放到 Executor 中。\\r\\n\\r\\n包括事务操作也放到 Executor 中。\\r\\n\\r\\n```java\\r\\npublic interface Executor {\\r\\n\\r\\n    ResultHandler NO_RESULT_HANDLER = null;\\r\\n\\r\\n    &lt;E\\r\\n\\r\\n    Transaction getTransaction();\\r\\n\\r\\n    void commit(boolean required) throws SQLException;\\r\\n\\r\\n    void rollback(boolean required) \"},{\"url\":\"/frame/mybatis/custom/xml解析.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"xml解析\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"\"},{\"url\":\"/frame/mybatis/custom/手写MyBatis.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"手写MyBatis\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"整体流程\\r\\n\\r\\n\\r\\n\\r\\n整个mybatis的功能，就是代理 mapper 然后执行SQL，返回执行结果。\\r\\n\\r\\n\\r\\n\\r\\n1. 解析mybatis配置\\r\\n    - 解析数据源 （Configuration 的 environment）\\r\\n    - 解析mapper文件配置 （路径扫描）\\r\\n2. 解析mapper文件\\r\\n    - 注册mapper到mapperRegistry。（包含mapper的代理类工厂，可以获取代理过的mapper）\\r\\n    - 生成mapper方法对应的mapperStatement。（Configuration 的 mappedStatements）\\r\\n    -\"},{\"url\":\"/frame/mybatis/custom/数据源.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据源\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"数据源解析\\r\\n\\r\\n解析配置文件中的数据源\\r\\n\\r\\n1. 事务模版 - jdbc\\r\\n2. 数据源实现 - druid\\r\\n\\r\\n```xml\\r\\n&lt;configuration\\r\\n\\r\\n    &lt;!--    数据源配置   --&gt;\\r\\n    &lt;environments default=\\\"development\\\"&gt;\\r\\n        &lt;environment id=\\\"development\\\"&gt;\\r\\n            &lt;transactionManager type=\\\"JDBC\\\"/&gt;\\r\\n            &lt;dataSource type=\\\"\"},{\"url\":\"/frame/mybatis/custom/映射器-mapper.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"映射器-mapper\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- SqlSession提供了SqlId。\\r\\n- 而SqlSessionFactroy 提供了开启SqlSession的能力。]\\r\\n- MapperRegistry 包含了所有Mapper的SqlId，包含注册发现Mapper的能力。\\r\\n\\r\\n MapperFactory\\r\\n\\r\\n\\r\\n\\r\\n MapperProxy\\r\\n\\r\\n在mybatis中，调用mapper里面的方法就可以执行SQL。其实是因为mybatis隐藏了实现细节。\\r\\n\\r\\n具体做法是根据mapper里面点的方法生成代理逻辑，在调用该方法时其实是走的代理类的逻辑。\\r\\n\\r\\n而代理类封装了操作数据库的逻辑，代理类即为mapperProxy。\\r\\n\\r\"},{\"url\":\"/frame/mybatis/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MyBatis 框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"手写MyBatis\\r\\n\\r\\n- 手写MyBatis\\r\\n- 映射器-mapper\\r\\n- 数据源\\r\\n- SQL执行器\\r\\n- xml解析\"},{\"url\":\"/frame/netty/ByteBuf.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ByteBuf\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ByteBuf是Netty中用于表示字节序列的数据容器。它是Netty对Java NIO中的ByteBuffer的改进和增强。ByteBuf提供了更灵活、更强大的API，具有许多优势，使得它在网络编程中更加方便和高效。\\r\\n\\r\\n以下是ByteBuf的主要优势：\\r\\n\\r\\n1. 灵活的容量管理： ByteBuf支持动态扩容和收缩，相比Java NIO的ByteBuffer，ByteBuf的容量可以根据实际需求自动调整，无需手动扩容。\\r\\n2. 更丰富的API： ByteBuf提供了丰富的操作API，包括读取、写入、复制、切片、合并等操作。这些API使得对字节数据的操作更加便利，同时提供了更多的功能。\\r\\n\"},{\"url\":\"/frame/netty/HTTP服务和SSL&TLS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP服务和SSL/TLS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"服务端\\r\\n\\r\\n按照 pipline 执行。\\r\\n\\r\\n```java\\r\\n@Override\\r\\n    protected void initChannel(SocketChannel socketChannel) throws Exception {\\r\\n        ChannelPipeline pipeline = socketChannel.pipeline();\\r\\n        //TODO ssl\\r\\n\\r\\n        //服务端\\r\\n        //对请求内容解码\\r\\n        pipeline.addLast(\\\"decoder\\\", new HttpRequestDecode\"},{\"url\":\"/frame/netty/Handler的共享和并发安全性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Handler的共享和并发安全性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"服务端为Channel设置pipeline的时候，可以选择设置共享的还是Channel独有的。\\r\\n\\r\\n```java\\r\\nprivate void start() throws InterruptedException {\\r\\n        final MsgCountHandler msgCountHandler = new MsgCountHandler();\\r\\n        //线程组\\r\\n        EventLoopGroup boss = new NioEventLoopGroup();\\r\\n        EventLoopGroup work = new NioEventLoo\"},{\"url\":\"/frame/netty/Netty实现文件下载.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty实现文件下载\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"实例：如何使用 Netty 下载文件_channelhandlercontext下载文件-CSDN博客\\r\\n\\r\\n ChannelHandler\\r\\n\\r\\n自定义 ChannelHandler ，用来处理 Channel 里面的事件，写数据处理逻辑的。\\r\\n\\r\\n- ChannelInboundHandlerAdapter\\r\\n- SimpleChannelInboundHandler\\r\\n    \\r\\n    是 ChannelInboundHandlerAdapter 的子类，能够指定类型。\\r\\n    \\r\\n\\r\\nNetty 里面预设了很多 ChannelHandler\\r\\n\\r\\n```java\\r\\nch.pipel\"},{\"url\":\"/frame/netty/Netty实现通信框架.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty实现通信框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"功能点\\r\\n\\r\\n1. 基于Netty的NIO通信框架。\\r\\n2. 提供消息的编码解码框架，实现对象的序列化和反序列化。\\r\\n3. 消息内容的放篡改机制。\\r\\n4. 提供基于IP的白名单认证机制。\\r\\n5. 链路的有效性机制（心跳）。\\r\\n6. 链路的断连重连机制。\\r\\n\\r\\n 通信模型\\r\\n\\r\\n\\r\\n\\r\\n 调用链路\\r\\n\\r\\n\\r\\n\\r\\n粘包半包是最前面先要解决的问题。\\r\\n\\r\\n 写空闲检测\\r\\n\\r\\n```java\\r\\npublic class CheckWriteIdleHandler extends IdleStateHandler {\\r\\n\\r\\n    /**\\r\\n     * 0 表示读空闲时间不进行检测，即不对读空闲做任何\"},{\"url\":\"/frame/netty/Netty常用组件.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty常用组件\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Bootstrap\\r\\n\\r\\nNetty的启动类\\r\\n\\r\\n- Bootstrap\\r\\n\\r\\n    客户端启动类\\r\\n\\r\\n- ServerBootstrap\\r\\n\\r\\n    服务端启动类\\r\\n\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n 第一个区别\\r\\n\\r\\n- 客户端需要连接到远程主机和端口即可。\\r\\n\\r\\n- 服务端需要绑定端口。\\r\\n\\r\\n 第二个区别\\r\\n\\r\\n- 服务端需要两个 EventLoopGroup。\\r\\n\\r\\n    原因是使用了多线程主从的Reactor模式。\\r\\n\\r\\n    - 第一个EventLoopGroup，只有一个EventLoop，负责为传入的Accept请求建立连接。一旦建立连接后续，将该 Channel 放到\"},{\"url\":\"/frame/netty/TCP粘包拆包问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP粘包拆包问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"TCP 粘包\\r\\n\\r\\n由于 TCP 协议本身的机制（面向连接的可靠地协议-三次握手机制）客户端与服务器会维持一个连接（Channel），数据在连接不断开的情况下，可以持续不断地将多个数据包发往服务器。\\r\\n\\r\\n但是如果发送的网络数据包太小，那么他本身会启用 Nagle 算法（可配置是否启用）对较小的数据包进行合并（基于此，TCP 的网络延迟要 UDP 的高些）然后再发送（超时或者包大小足够）。\\r\\n\\r\\n那么这样的话，服务器在接收到消息（数据流）的时候就无法区分哪些数据包是客户端自己分开发送的，这样产生了粘包。\\r\\n\\r\\n服务器在接收到数据库后，放到缓冲区中，如果消息没有被及时从缓存区取走，下次在取数据的\"},{\"url\":\"/frame/netty/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础总结\\r\\n\\r\\n- Netty常用组件\\r\\n- Handler的共享和并发安全性\\r\\n- 资源管理和SimpleChannelInboundHandler\\r\\n- 内置通信传输模式\\r\\n- TCP粘包拆包问题\\r\\n- 编解码器\\r\\n\\r\\n\\r\\n- HTTP服务和SSL&TLS\\r\\n- 序列化问题\\r\\n- 写空闲和读空闲\\r\\n\\r\\n\\r\\n- ByteBuf\\r\\n- 线程模型\\r\\n- 零拷贝\\r\\n\\r\\n\\r\\n 练习总结\\r\\n- Netty实现通信框架\\r\\n- 基于Netty实现RPC\\r\\n- Netty实现文件下载\"},{\"url\":\"/frame/netty/内置通信传输模式.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内置通信传输模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```java\\r\\ntry {\\r\\n            //父子EventLoop\\r\\n            serverBootstrap.group(boss,work)\\r\\n                    //指定使用NIO的通信模式\\r\\n                    .channel(NioServerSocketChannel.class)\\r\\n                    .localAddress(new InetSocketAddress(port))\\r\\n                    .childHandler(new ChannelInitia\"},{\"url\":\"/frame/netty/写空闲和读空闲.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"写空闲和读空闲\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在Netty框架中，写空闲（Write Idle） 和 读空闲（Read Idle） 是空闲检测机制中的两个重要概念，它们用于监控网络连接的活跃状态，确保连接的有效性和资源的有效管理。\\r\\n\\r\\n 写空闲（Write Idle）\\r\\n\\r\\n- 定义：写空闲指的是在一段指定时间内，没有数据通过当前的`Channel`被写入到网络中传输给对方。这可能意味着在这段时间内，服务端没有向客户端发送任何数据，或者客户端没有向服务端发送数据。\\r\\n- 应用场景：在某些协议或应用场景中，如果长时间没有数据写入，可能需要触发特定的操作，比如发送心跳包以维持连接活跃，或者是判断连接是否已经失效，进而关闭连接以释放资源。\\r\\n\"},{\"url\":\"/frame/netty/基于Netty实现RPC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"基于netty实现RPC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"源码地址\\r\\n\\r\\nAlbert.Yang/JavaAdvance\\r\\n\\r\\n 服务端\\r\\n\\r\\n ServerBootstrap\\r\\n\\r\\n```java\\r\\n@Service\\r\\n@Slf4j\\r\\npublic class RpcServerFrame implements Runnable {\\r\\n\\r\\n    @Autowired\\r\\n    private ServerInit serverInit;\\r\\n\\r\\n    private EventLoopGroup bossGroup = new NioEventLoopGroup();\\r\\n    private EventLoopGroup workGroup =\"},{\"url\":\"/frame/netty/序列化问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"序列化问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java对象的序列化主要有两个：\\r\\n\\r\\n1. 网络传输\\r\\n   \\r\\n    数据在网络中传输是通过字节流形式的，到服务端需要解码。\\r\\n    \\r\\n2. 对象持久化\\r\\n\\r\\n Java序列化\\r\\n\\r\\nJava序列化机制是基于对象的类结构进行的。\\r\\n\\r\\n当对象需要序列化时，会将对象转换为字节流在网络传输。\\r\\n\\r\\n反序列化时，就是将字节流转换为对象的过程。Java会将字节流转换为对象重新加载到内存中。\\r\\n\\r\\nJava的序列化机制是通过实现`java.io.Serializable`接口来实现的。该接口是一个标记接口，没有任何方法定义。只有实现了`Serializable`接口的类的对象才能被序列化。\\r\\n\"},{\"url\":\"/frame/netty/线程模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Netty的线程模型是什么？为什么它是高效的？\\r\\n\\r\\n1. Netty的线程模型是基于事件驱动的，采用了Reactors设计模式。它的线程模型主要包含以下几个关键组件：\\r\\n2. Boss Group和Worker Group： Netty通过Boss Group和Worker Group来分别管理两类不同的线程。Boss Group负责接收客户端的连接，而Worker Group则负责处理连接后的网络流量。\\r\\n3. Channel： Channel代表了一个网络连接，可以是客户端到服务器的连接，也可以是服务器之间的连接。每个Channel都由一个EventLoop负责处理，而一个EventLo\"},{\"url\":\"/frame/netty/编解码器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"编解码器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在网络传输中，数据是通过字节流传输。\\r\\n\\r\\n对应到客户端和服务端需要进行对应的编码和解码。\\r\\n\\r\\n 解码器\\r\\n\\r\\n- 将字节解码为消息：ByteToMessageDecoder\\r\\n- 将一种消息类型解码为另一种：MessageToMessageDecoder。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 异常处理\\r\\n\\r\\n- TooLongFrameException\\r\\n    \\r\\n    由于 Netty 是一个异步框架，所以需要在字节可以解码之前在内存中缓冲它们。因此，不能让解码器缓冲大量的数据以至于耗尽可用的内存。为了解除这个常见的顾虑，Netty 提供了 TooLongFrameException 类\"},{\"url\":\"/frame/netty/资源管理和SimpleChannelInboundHandler.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"资源管理和SimpleChannelInboundHandler\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NIO中读写Channel数据，都使用了 Buffer，读写数据都是从 Buffer里面读取的。\\r\\n\\r\\n而 Netty在读写网络数据时，同样也需要 Buffer。\\r\\n\\r\\n但是这样就涉及到 Buffer的内存释放，不然会造成内存泄漏。\\r\\n\\r\\n SimpleChannelInboundHandler\\r\\n\\r\\nNetty实现了SimpleChannelInboundHandler类，提供 `channelRead0()` 方法，保证数据被该方法消费后自动释放数据。\\r\\n\\r\\n```java\\r\\n    public void channelRead(ChannelHandlerContext ctx, Ob\"},{\"url\":\"/frame/netty/零拷贝.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"零拷贝\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. ByteBuf 可以直接使用直接内存。\\r\\n    \\r\\n    Socket 通信如果采用堆内存的话，需要将堆里的对象拷贝到堆外，进行一次对象拷贝。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n    \\r\\n    但是 Socket 没有更新对象地址动作，需要的是一个固定的地址。所以堆内存不适合 Socket 使用。只能将对象拷贝到直接内存然后使用。\\r\\n    \\r\\n    而 ByteBuf 直接使用直接内存，减少了对象拷贝。\\r\\n    \\r\\n2. Netty 提供了组合 Buffer，可以将多个 Buffer 合并为一个。\\r\\n    \\r\\n    传统通过内存拷贝的方式将几个小Buffe\"},{\"url\":\"/frame/spring/AOP.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AOP\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"面向切面编程\\r\\n\\r\\n面向切面编程，指的是在运行期间生成代理对象来对类进行增强处理，比如方法执行前和方法执行后进行代码增强。\\r\\n\\r\\n 什么是切面\\r\\n\\r\\n- 切：\\r\\n  \\r\\n    指的是横切逻辑，原有方法代码不动。只能操作横切逻辑代码进行增强。\\r\\n    \\r\\n- 面：\\r\\n  \\r\\n    横切逻辑往往影响很多个方法，每个方法是一个切点，便形成了面。\\r\\n    \\r\\n\\r\\n常用的功能有：\\r\\n\\r\\n- 方法审计日志\\r\\n- 校验权限是否足够\\r\\n\\r\\n\\r\\n\\r\\n AOP体系\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n)连接点 - JoinPoint\\r\\n\\r\\n类里面哪些方法可以被增强，这些方法称为连接点。\\r\\n\\r\\n- 切面\\r\\n\\r\\n    切\"},{\"url\":\"/frame/spring/ApplicationContext和BeanFactory区别.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ApplicationContext和BeanFactory区别\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ApplicationContext 总结\\r\\n\\r\\nApplicationContext 容器上下文，包含了 BeanFactory 的所有功能，还额外提供了以下功能：\\r\\n\\r\\n- MessageSource，提供国际化的消息访问\\r\\n- 资源访问，如 URL 和文件\\r\\n- 事件传播\\r\\n\\r\\n 工具类\\r\\n\\r\\n可以通过实现 `ApplicationContextAware` 接口注入 ApplicationContext\\r\\n\\r\\n```java\\r\\n@Component\\r\\npublic class SpringBeanUtil implements ApplicationContextAware {\\r\\n\\r\\n\"},{\"url\":\"/frame/spring/Aware接口.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Aware接口\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在Spring框架中，`Aware`接口提供了一种机制，允许Bean在初始化过程中获取Spring容器的特定上下文信息或资源。这些接口通常被称作回调接口，因为它们允许Spring容器在特定时刻回调Bean，以便将一些重要的信息注入给Bean。\\r\\n\\r\\n ApplicationContextAware\\r\\n\\r\\n当Spring容器在初始化一个实现了`ApplicationContextAware`接口的Bean时，它会调用`setApplicationContext`方法，将当前的应用上下文传入。\\r\\n\\r\\n```java\\r\\npublic interface ApplicationContextAware\"},{\"url\":\"/frame/spring/BeanFactory和FactoryBean总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BeanFactory和FactoryBean总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"BeanFactory总结\\r\\n\\r\\nBeanFactory 是 Spring 中的一个接口，提供了 IOC 容器最基本的形式，给具体的 IOC 容器实现提供了规范。\\r\\n\\r\\n其本质是一个 IOC 容器或对象工厂，所有的 Bean 都是由 BeanFactory （IOC容器）来进行管理的。Spring 有许多 BeanFactory 的实现类，附件了许多功能。\\r\\n\\r\\n```java\\r\\npublic interface BeanFactory {\\r\\n  \\r\\n  Object getBean(String name) throws BeansException;\\r\\n  \\r\\n\\t&lt;T\\r\\n\\r\\n\\tObj\"},{\"url\":\"/frame/spring/ByteBuddy实现动态代理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ByteBuddy实现动态代理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Byte Buddy - runtime code generation for the Java virtual machine\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n```java\\r\\n&lt;dependency&gt;\\r\\n  &lt;groupId&gt;net.bytebuddy&lt;/groupId&gt;\\r\\n  &lt;artifactId&gt;byte-buddy&lt;/artifactId&gt;\\r\\n  &lt;version&gt;LATEST&lt;/version&gt;\\r\\n&lt;/dependency&gt;\\r\\n```\\r\\n\\r\\n```java\\r\\npublic c\"},{\"url\":\"/frame/spring/Spi机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spi机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SPI机制，全称Service Provider Interface，是Java提供的一种标准的服务发现机制。它允许第三方服务提供者扩展某个接口的实现，而无需修改接口的源代码或重新打包。\\r\\n\\r\\nSpring SPI机制常用于 starter 构建和基础库实现。\\r\\n\\r\\n通过 spi 机制，确保自动配置生效的类包含 FileAutoConfiguration\\r\\n\\r\\n\\r\\n\\r\\n使用 SPI可以可插拔的注入配置，比如 `EnableAutoConfiguration`，如果需要 MinIO的配置类，加在类里面即可开启MinIO的功能。\\r\\n\\r\\nwww.jb51.net\\r\\n\\r\\nSPI机制是什么？_java_\"},{\"url\":\"/frame/spring/Spring中Bean加载流程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring中Bean加载流程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"流程图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 创建流程\\r\\n\\r\\n1. 加载 `ApplicationContext` 上下文环境。\\r\\n2. `ApplicationContext` 通过扫描、读取配置，将 Bean对象封装为 `BeanDefinition` 对象，并注册到 `BeanDefinitionMap` 中。\\r\\n3. 在 `ApplicationContext` 执行完成之后会调用对应的后置处理器 `BeanFactoryProcessor` 和其子类 `BeanDefinitionRegistryPostProcessor` 对应方法，可以修改和注册 `BeanDefinition` 到 \"},{\"url\":\"/frame/spring/Spring中Bean的作用域.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring中Bean的作用域\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"作用域类型\\r\\n\\r\\n- singleton\\r\\n    \\r\\n    单例模式。\\r\\n    \\r\\n    使用 `singleton` 定义的 Bean 在 Spring 容器中只有一个实例，是 Bean 默认的作用域。\\r\\n    \\r\\n- prototype\\r\\n    \\r\\n    原型模式\\r\\n    \\r\\n    每次通过 Spring 容器获取 `prototype` 定义的 Bean 时，容器都将创建一个新的 Bean 实例。\\r\\n    \\r\\n- request\\r\\n    \\r\\n    在一次 HTTP 请求中，容器会返回该 Bean 的同一个实例。而对不同的 HTTP 请求，会返回不同的实例，该作用域\"},{\"url\":\"/frame/spring/Spring事务总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring事务总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"编程式事务\\r\\n\\r\\n在代码中硬编码，不推荐使用。\\r\\n\\r\\n 声明式事务\\r\\n\\r\\n- 基于注解的声明式事务\\r\\n- 基于 XML 的声明式事务\\r\\n\\r\\n @Transactional 注解\\r\\n\\r\\nException 分为运行时异常 RuntimeException 和非运行时异常。事务管理能保证出现异常情况的时候保证数据的一致性。\\r\\n\\r\\n默认 `@Transactional` 注解只会在遇到 RuntimeException 类型异常或者 Error时，才会回滚事务。遇到其它异常，Spring 不会回滚事务。\\r\\n\\r\\n 作用范围\\r\\n\\r\\n当 `@Transactional`注解作用于类上的时，该类的所有方法都\"},{\"url\":\"/frame/spring/Spring依赖注入.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring依赖注入\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"依赖注入就是通过spring将bean所需要的一些参数传递到bean实例对象的过程（将依赖关系注入到对象中，不需要每次都new对象）\\r\\n\\r\\n- set方法注入\\r\\n- 构造方法注入\\r\\n- 注解注入\\r\\n\\r\\n 注解注入的区别\\r\\n\\r\\n- @Resource\\r\\n\\r\\n  byName注入\\r\\n\\r\\n  \\r\\n\\r\\n- Autowired\\r\\n\\r\\n  byType注入\"},{\"url\":\"/frame/spring/Spring如何解决循环依赖.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring如何解决循环依赖\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"依赖注入的四种方法\\r\\n\\r\\n- 构造方法注入\\r\\n  \\r\\n    ```java\\r\\n        public HelloA(@Autowired HelloService helloService) {\\r\\n            this.helloService = helloService;\\r\\n        }\\r\\n    ```\\r\\n    \\r\\n- 工厂方法注入\\r\\n  \\r\\n    ```java\\r\\n        @Bean(initMethod = \\\"init\\\", destroyMethod = \\\"destory\\\")\\r\\n        public HelloB helloB(@Auto\"},{\"url\":\"/frame/spring/Spring框架概述.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring框架概述\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、什么是 Spring 框架？\\r\\n\\r\\nSpring 框架指的是 Spring Framework，是一种轻量级的开发框架，主要核心是控制反转 （IOC）和 面向切面编程（AOP）。\\r\\n\\r\\n 二、Spring 的优点\\r\\n\\r\\n1. 方便解耦，简化开发（高内聚低耦合）\\r\\n    - Spring 是一个容器框架，将所有对象创建和依赖关系的维护交给 Spring 管理。\\r\\n    - Spring 工厂用于生成 Bean。\\r\\n2. AOP编程的支持\\r\\n    - Spring 提供面向切面编程，可以方便的实现权限拦截、运行监控等功能\\r\\n    - 日志打印\\r\\n3. 支持声明式事务\\r\\n    - 只需\"},{\"url\":\"/frame/spring/Spring自定义注解扫描.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring自定义注解扫描\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Spring管理的类\\r\\n\\r\\n以下两种方式都可以实现。\\r\\n\\r\\n 使用@ComponentScan + Bean定义\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\n@ComponentScan(basePackages = {\\\"your.package.to.scan\\\"}) // 指定要扫描的包\\r\\npublic class AppConfig {\\r\\n\\r\\n    @Autowired\\r\\n    private ListableBeanFactory beanFactory;\\r\\n\\r\\n    @PostConstruct\\r\\n    public void processAnnotatedBea\"},{\"url\":\"/frame/spring/Spring配置文件加载顺序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring配置文件加载顺序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot配置文件的加载顺序\\r\\n\\r\\nSpringBoot项目启动会扫描以下位置的application.properties或者application.yml文件作为SpringBoot的默认配置文件，具体的目录位置见下图。\\r\\n\\r\\n1. file:./config/ （ 项目根路径下的config文件夹）\\r\\n2. file:./ （项目根路径）\\r\\n3. classpath:/config/ （类路径下的config文件夹）\\r\\n4. classpath:/ （类路径）\\r\\n\\r\\n\\r\\n\\r\\n按照配置文件的优先级，8001\\r\\n\\r\\n&gt; 注意file层是项目的最外层目录，也就是工作目录。\\r\\n&\"},{\"url\":\"/frame/spring/custom/AOP.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AOP\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ByteBuddy\\r\\n\\r\\nAOP即面向切面编程，本质上是一个 Proxy 模式。核心就是拦截核心 Bean 的方法调用。\\r\\n\\r\\n- JDK动态代理\\r\\n- CGLIB动态生成字节码代理。\\r\\n\\r\\n\\r\\n&gt;\\r\\n\\r\\n AOP实现核心\\r\\n\\r\\n- 找到符合AOP要求的原始Bean\\r\\n- 执行指定的拦截器逻辑\\r\\n\\r\\n AOP流程\\r\\n\\r\\n1. 利用 `BeanPostProcessor` 检测每个Bean。\\r\\n2. 扫描每个 Bean 的 @Around 注解。\\r\\n3. 执行 InvocationHandler 的代理方法。\\r\\n\\r\\n 实现 @Before 和 @After\\r\\n\\r\\n基于@Around的模板就\"},{\"url\":\"/frame/spring/custom/Boot.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Boot\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot 内置了 Tomcat，IOC容器和 WebMVC 模块，所以能直接启动。\\r\\n\\r\\n 启动类\\r\\n\\r\\n```java\\r\\n@Slf4j\\r\\npublic class SummerApplication {\\r\\n\\r\\n    static final String CONFIG_APP_YAML = \\\"/application.yml\\\";\\r\\n    static final String CONFIG_APP_PROP = \\\"/application.properties\\\";\\r\\n\\r\\n    public static void run(String webDir, String base\"},{\"url\":\"/frame/spring/custom/IOC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IOC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"其中构造方法注入和工厂方法注入是强依赖，因为Bean创建和属性注入放到一起了。\\r\\n\\r\\n比如构造方法注入，创建对象的同时进行属性注入，这种属于强依赖。\\r\\n\\r\\n而强依赖是解决不了循环依赖的问题的，因为创建对象和属性注入属于一体不可分的。\\r\\n\\r\\n我们解决循环依赖是先创建对象，然后属性注入的时候利用三级缓存解决的。\\r\\n\\r\\n```java\\r\\n    public BeanTest(@Value(\\\"spring.port\\\") String port, String name) {\\r\\n        System.out.println(port);\\r\\n    }\\r\\n```\\r\\n\\r\\nIOC容器有两类，Bean\"},{\"url\":\"/frame/spring/custom/JDBC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JDBC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"DataSource\\r\\n\\r\\n自动注入DataSource\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\npublic class JdbcConfiguration {\\r\\n\\r\\n    /**\\r\\n     * 自动注入HikariDataSource\\r\\n     *\\r\\n     * @param url\\r\\n     * @param username\\r\\n     * @param password\\r\\n     * @param driver\\r\\n     * @param maximumPoolSize\\r\\n     * @param minimumPoolSize\\r\\n     * @pa\"},{\"url\":\"/frame/spring/custom/MVC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MVC实现逻辑\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 应用程序必须配置一个Summer Framework提供的 Listener；\\r\\n2. Tomcat 完成 Servlet 容器的创建后，立刻根据配置创建Listener；\\r\\n    1. Listener初始化时创建 IOC 容器；\\r\\n    2. Listener继续创建DispatcherServlet实例，并向Servlet容器注册；\\r\\n    3. DispatcherServlet初始化时获取到IOC容器中的Controller实例，因此可以根据URL调用不同Controller实例的不同处理方法。\\r\\n    4. 容器中的Controller实例，因此可以根据URL调用不同\"},{\"url\":\"/frame/spring/custom/声明式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"声明式事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"事务传播模型\\r\\n\\r\\n| 传播行为 | 含义 |\\r\\n| --- | --- |\\r\\n| PROPAGATION_REQUIRED | 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。 |\\r\\n| PROPAGATION_SUPPORTS | 支持当前事务，如果当前没有事务，就以非事务方式执行。 |\\r\\n| PROPAGATION_MANDATORY | 支持当前事务，如果当前没有事务，就抛出异常。 |\\r\\n| PROPAGATION_REQUIRED_NEW | 新建事务，如果当前存在事务，把当前事务挂起。 |\\r\\n| PROPAGATION_NOT_SUPPORTED | 以非事务方式\"},{\"url\":\"/frame/spring/custom/手写Spring.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"手写Spring\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- boot模块：实现一个简化版的 `Spring Boot`，用于打包运行。\\r\\n- web模块：实现Web MVC和REST API。\\r\\n\\r\\n Spring主要模块\\r\\n\\r\\n- context模块：实现ApplicationContext容器与Bean的管理；\\r\\n- aop模块：实现AOP功能；\\r\\n- jdbc模块：实现JdbcTemplate，以及声明式事务管理；\\r\\n\\r\\n IOC\\r\\n\\r\\nIOC\\r\\n\\r\\n AOP\\r\\n\\r\\nAOP\\r\\n\\r\\n JDBC\\r\\n\\r\\nJDBC\\r\\n\\r\\n声明式事务\\r\\n\\r\\n1. 由`JdbcConfiguration`创建的`DataSource`，实现了连接池；\\r\\n2. 由`Jdb\"},{\"url\":\"/frame/spring/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Spring框架\\r\\n\\r\\n 一、Spring框架\\r\\n\\r\\n- Spring框架概述\\r\\n- ApplicationContext 和 BeanFactory 区别\\r\\n- BeanFactory 和 FactoryBean 总结\\r\\n- Spring中Bean的作用域\\r\\n- Spring中Bean加载流程\\r\\n- Spring依赖注入\\r\\n- Spring如何解决循环依赖\\r\\n\\r\\n- AOP\\r\\n- Spring事务总结\\r\\n- Aware接口\\r\\n- Spi机制\\r\\n- Spring配置文件加载顺序\\r\\n\\r\\n 二、使用总结\\r\\n\\r\\n- Spring自定义注解扫描\\r\\n- ByteBuddy实现动态代理\\r\\n\\r\\n 三、手写S\"},{\"url\":\"/frame/springboot/SpringBoot使用APO记录操作日志.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot使用APO记录操作日志\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"通过织入自定义注解 @Log，再进行解析记录操作日志。\\r\\n\\r\\n1. 自定义注解 @Log\\r\\n    \\r\\n    ```java\\r\\n    @Target({ElementType.PARAMETER, ElementType.METHOD})\\r\\n    @Retention(RetentionPolicy.RUNTIME)\\r\\n    @Documented\\r\\n    public @interface Log {\\r\\n    \\r\\n        /**\\r\\n         * 模块\\r\\n         */\\r\\n        String title() default \\\"default\\\";\\r\\n\"},{\"url\":\"/frame/springboot/SpringBoot能同时处理多少请求.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot能同时处理多少请求\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot内置了Tomcat，处理请求是 Web 容器处理的。\\r\\n\\r\\n1. 线程池线程数限制\\r\\n\\r\\n   而 Tomcat 的线程池默认最大线程池是 200，所以默认同时最多能处理 200 个请求。\\r\\n\\r\\n   \\r\\n&gt;\\r\\n2. 连接数限制\\r\\n\\r\\n   达到连接池数时，会限制请求数。此时因连接数限制为准，而不是最大线程数。\\r\\n\\r\\n    ```\\r\\n    tomcat最大连接数限制\\r\\n    server.tomcat.max-connections=12\\r\\n    ```\\r\\n\\r\\n\\r\\n---\\r\\n\\r\\n 限制配置\\r\\n\\r\\n```\\r\\ntomcat最大连接数限制\\r\\nserver.tomca\"},{\"url\":\"/frame/springboot/SpringBoot项目自动初始化数据库.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot项目自动初始化数据库\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"背景\\r\\n\\r\\n在 SpringBoot 启动的时候若配置文件中配置的数据库不存在，则自动创建数据库，并执行初始化SQL。\\r\\n\\r\\n 思路\\r\\n\\r\\n1. 判断数据库是否存在。\\r\\n2. 手动注入Datasource。\\r\\n    \\r\\n    在数据库未创建时，启动会报错\\r\\n    \\r\\n3. 初始化表。\\r\\n\\r\\n 解决方式\\r\\n\\r\\n1. 启动类排除 `DataSourceAutoConfiguration.class` ，采用手动注入的方式。\\r\\n    \\r\\n    如果配置的数据库不存在，SpringBoot启动的时候会提示找不到数据库，所以要排除掉，然后手动注入。\\r\\n    \\r\\n    ```java\\r\\n  \"},{\"url\":\"/frame/springboot/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot 框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot 框架\\r\\n\\r\\n\\r\\n 使用总结\\r\\n- SpringBoot能同时处理多少请求\\r\\n- SpringBoot使用APO记录操作日志\\r\\n- SpringBoot项目自动初始化数据库\"},{\"url\":\"/frame/springcloud/Feigh远程调用原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Feigh远程调用原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"思路\\r\\n\\r\\n根据接口地址和 FeignClient构建http请求。\\r\\n\\r\\n1. 构建 http请求模版，包含 header、body、method等参数信息。\\r\\n2. 设置 options，包含超时时间参数配置。\\r\\n3. 根据 clientName 从 nacos（类似map，保存clientName和访问地址的对应关系）中获取访问地址。\\r\\n4. 根据访问地址和http请求参数发起http请求。\\r\\n\\r\\n 代码入口\\r\\n\\r\\n`io/github/openfeign/feign-core/10.4.0/feign-core-10.4.0.jar!/feign/ReflectiveFeign.cla\"},{\"url\":\"/frame/springcloud/Gateway.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Gateway\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"请求流程\\r\\n\\r\\n&lt;img src=\\\"https://s2.loli.net/2025/06/10/RBVjazHT3NinfQe.png\\\" alt=\\\"image.png\\\" style=\\\"zoom:50%;\\\" /\\r\\n\\r\\n- Gateway Handler（网关处理器）：网关处理器是 Spring Cloud Gateway 的核心组件，负责将请求转发到匹配的路由上。它根据路由配置和断言条件进行路由匹配，选择合适的路由进行请求转发。网关处理器还会依次应用配置的过滤器链，对请求进行处理和转换。\\r\\n- Gateway Filter Chain（网关过滤器链）：网关过滤器链由一系列过滤器组成，按照\"},{\"url\":\"/frame/springcloud/Nacos.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Nacos\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"地址\\r\\n\\r\\n GitHub\\r\\n\\r\\nhttps://github.com/alibaba/nacos\\r\\n\\r\\n 文档\\r\\n\\r\\nNacos 快速开始\\r\\n\\r\\n 启动命令\\r\\n\\r\\n```sql\\r\\nsh startup.sh -m standalone\\r\\n```\\r\\n\\r\\n 可视化页面\\r\\n\\r\\n`http://localhost:8848/nacos`\\r\\n\\r\\n\\r\\n\\r\\n 注册中心原理\\r\\n\\r\\n 服务注册\\r\\n\\r\\nNocas Client 在启动的时候会通过 Rest 的方式将自己的元数据（Ip、端口）等信息发给 Nocas Server。\\r\\n\\r\\nNacos Server 收到 Client 的注册请求后，将元数据信息存到\"},{\"url\":\"/frame/springcloud/Seata分布式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Seata分布式事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在分布式情况下，一次业务请求需要调用多个系统操作多个数据源时，针对多个数据源操作会产生分布式事务问题。每个系统能够保证各自数据源的一致性问题，但是全部系统数据的一致性问题没法保证。\\r\\n\\r\\n 官网地址\\r\\n\\r\\nhttps://seata.io/zh-cn/docs/user/quickstart.html\\r\\n\\r\\n 下载地址\\r\\n\\r\\nhttps://seata.io/zh-cn/blog/download.html\\r\\n\\r\\n 基础概念\\r\\n\\r\\n事务ID + 三组件\\r\\n\\r\\n事务ID\\r\\n\\r\\n- Transaction ID(XID)\\r\\n\\r\\n三组件\\r\\n\\r\\n- TC-事务协调者\\r\\n\\r\\n  维护全局和分支事务的状态\"},{\"url\":\"/frame/springcloud/Sentinel原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Sentinel原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Sentinel工作主流程\\r\\n\\r\\n滑动窗口实现原理 · 吾爱开源 · 看云\\r\\n\\r\\n 限流算法\\r\\n\\r\\n 计数器算法\\r\\n\\r\\n计数器算法统计某个时间段的请求量，判断是否超过阈值。\\r\\n\\r\\n\\r\\n\\r\\n存在的问题：\\r\\n\\r\\n如上图中，在时间段的临界处加起来其实QPS 超过了阈值，但是平均到单个时间段未发生。\\r\\n\\r\\n单纯的计数器算法存在 临界统计不准确 的问题。\\r\\n\\r\\n 滑动窗口计数器算法\\r\\n\\r\\n解决滑动窗口存在的问题，引入了滑动窗口计数器。\\r\\n\\r\\n我们将统计时间细分，比如将 1s 统计时长分为 5个 时间窗口，通过 滚动统计所有时间窗口的QPS 作为系统实际的 QPS 的方式，就能解决上述 临界统计 问题。\\r\"},{\"url\":\"/frame/springcloud/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringCloud\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringCloud\\r\\n\\r\\n 使用总结\\r\\n\\r\\n- 注册中心的演进\\r\\n- Nacos\\r\\n- Gateway\\r\\n- Feigh远程调用原理\\r\\n- Sentinel原理\\r\\n- Seata分布式事务\\r\\n\\r\\n\\r\\n\\r\\n 项目\\r\\n\\r\\nSpringCloud总结练习-Gitee\"},{\"url\":\"/frame/springcloud/注册中心的演进.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"注册中心的演进\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 直接远程调用\\r\\n\\r\\n   \\r\\n\\r\\n2. 维护注册表，维护服务调用地址\\r\\n\\r\\n   \\r\\n\\r\\n3. 接入 nginx，利用 nginx 做负载\\r\\n\\r\\n   \\r\\n\\r\\n4. 引入注册机制，提供注册和服务发现功能\\r\\n\\r\\n   \\r\\n\\r\\n5. 引入心跳机制，解决注册中心宕机或者目标服务不可用\"},{\"url\":\"/java/cache/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Cache\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 本地缓存\\r\\n- 多级缓存\\r\\n- 缓存淘汰算法\"},{\"url\":\"/java/cache/多级缓存.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"多级缓存\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"二级缓存\\r\\n\\r\\n二级缓存没有网络开销\\r\\n\\r\\n\\r\\n\\r\\n 优点\\r\\n\\r\\n1. 减少网络请求，提高性能。\\r\\n2. 减少远程缓存的读压力。\\r\\n3. 天然分布式缓存，只存在于当前节点服务。\\r\\n\\r\\n 缺点\\r\\n\\r\\n1. 占用本地内存，空间有限，不支持大数据量。\\r\\n\\r\\n   只存储最热的数据到本地缓存，结合热点服务探测。\\r\\n\\r\\n2. 重启数据会丢失。\\r\\n\\r\\n   重启丢失数据无法避免，但是可以在重启项目的时候把最热的数据加到本地缓存。\\r\\n\\r\\n3. 分布式场景，数据可能不一致。\\r\\n4. 和远程缓存可能存在不一致的问题。\\r\\n\\r\\n   只能保证最终一致性，尽可能让本地缓存过期时间短一点，这样就能加载远程缓存，达到最终\"},{\"url\":\"/java/cache/本地缓存.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"本地缓存\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Guava\\r\\n\\r\\n- 支持最大容量限制\\r\\n- 支持两种过期删除策略\\r\\n- 支持简单的统计功能\\r\\n- 插入时间\\r\\n- 访问时间\\r\\n- 基于LRU算法实现\\r\\n\\r\\n```java\\r\\nLoadingCache&lt;Integer, String\\r\\n        //设置并发级别为8，并发级别是指可以同时写缓存的线程数\\r\\n        .concurrencyLevel(8)\\r\\n        //设置缓存的初始容量为10\\r\\n        .initialCapacity(10)\\r\\n        // 设置缓存最大容量为100，超过100之后就会按照LRU最近最少使用算法来移除缓存\\r\\n    \"},{\"url\":\"/java/cache/缓存淘汰算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"缓存淘汰算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"FIFO-先进先出\\r\\n\\r\\n\\r\\n\\r\\n比较简单，不够灵活。\\r\\n\\r\\n没有跟缓存使用频次和时间等维度联系起来。\\r\\n\\r\\n LRU-最近最少使用\\r\\n\\r\\n核心思想是最近使用的时间。比如最近一小时以内使用缓存的时间。\\r\\n\\r\\n\\r\\n\\r\\n根据数据的历史访问记录来淘汰数据，淘汰最久未被使用的数据。\\r\\n\\r\\n基于如果数据最近被访问过，那么将来访问的记录会更高。优先淘汰最久未被使用的冷数据。\\r\\n\\r\\n LFU-最近最不常用\\r\\n\\r\\n核心思想是最近使用的次数。比如最近一小时内使用缓存的次数。\\r\\n\\r\\n\\r\\n\\r\\nLFU能够提高热点数据的命中率。\\r\\n\\r\\n但是当缓存中数据都是热点数据的时候，将失去该特性。\\r\\n\\r\\n单纯的LFU存在缺陷。\\r\\n\"},{\"url\":\"/java/collection/Collection集合概述.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集合概述\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集合概述\\r\\n\\r\\n 为什么使用集合？\\r\\n\\r\\n当我们需要保存一组类型相同的数据的时候，我们应该用一个容器来保存，这个容器就是数组。\\r\\n\\r\\n但是数组的长度是固定的，当添加的元素超过了数组的长度之后，需要对数组重新定义。而且数组存储的数据是`有序的`、`可重复的`，太过于单一，扩展性不够。\\r\\n\\r\\n于是，引入了集合，Java 内部给我们提供了功能完善的集合框架。能`存储任意对象`，长度可以`动态改变`，提高了数据存储的灵活性。\\r\\n\\r\\n 数组和集合的区别\\r\\n\\r\\n1. 存储类型\\r\\n   - 数组可以存储`基本数据类型`，又可以存储`引用数据类型`。\\r\\n   - 集合只能存储`引用数据类型`。（集合中也可以存\"},{\"url\":\"/java/collection/ConcurrentHashMap1.7.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ConcurrentHashMap - 1.7\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、类简介\\r\\n\\r\\nConcurrentHashMap 是一个线程安全的 HashMap，在 JDK 1.7 HashMap的基础上实现了 `分段锁` 来保证线程安全。在 HashMap 的基础上，默认分为 16 个段，每个段都拥有独立的锁，来保证各个段的线程安全。\\r\\n\\r\\n 扩展 - 线程安全的 HashMap\\r\\n\\r\\nMap实现线程安全的三种方式\\r\\n\\r\\n Unsafe方法总结\\r\\n\\r\\n\\r\\n\\r\\n 二、主要参数\\r\\n\\r\\n```java\\r\\npublic class ConcurrentHashMap&lt;K, V\\r\\n        implements ConcurrentMap&lt;K, V&gt;\"},{\"url\":\"/java/collection/ConcurrentHashMap1.8.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ConcurrentHashMap -1.8\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ConcurrentHashMap 源码分析\\r\\n\\r\\n\\r\\n1.8的ConcurrentHashMap，采用对Node加锁机制。\\r\\n\\r\\n 加锁原理\\r\\n\\r\\n采用CAS+Synchronized组合锁的方法。\\r\\n\\r\\n- CAS\\r\\n\\r\\n  操作Node数组的时候以CAS方式操作。\\r\\n\\r\\n- Synchronized\\r\\n\\r\\n  操作Node对应的数据结构，链表或红黑树的时候加Synchronized。保证操作数据的原子性。\"},{\"url\":\"/java/collection/HashMap1.7.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HashMap - 1.7\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类简介\\r\\n\\r\\nHashMap 是一个用来存储 Key - Value 键值对的集合，每一个键值对也叫做 Entry，这些 Entry 保存在底层数组中。\\r\\n\\r\\n 1. 底层数组\\r\\n\\r\\n底层数组包含的每个元素可以称之为 桶，元素实际保存在每个桶上。\\r\\n\\r\\n```java\\r\\n    static final Entry&lt;?,?\\r\\n\\r\\n    /**\\r\\n     * The table, resized as necessary. Length MUST Always be a power of two.\\r\\n     */\\r\\n    transient Entry&lt;K,V&gt;[] t\"},{\"url\":\"/java/collection/HashMap1.8.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HashMap - 1.8\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类简介\\r\\n\\r\\n 默认参数\\r\\n\\r\\n- 默认长度\\r\\n\\r\\n  ```\\r\\n   static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4\\r\\n  ```\\r\\n\\r\\n- 最大容量\\r\\n\\r\\n  ```\\r\\n  static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;\\r\\n  ```\\r\\n\\r\\n- 默认负载因子\\r\\n\\r\\n  ```\\r\\n   static final float DEFAULT_LOAD_FACTOR = 0.75f;\\r\\n  ```\\r\\n\\r\\n- 默认树化临界点\\r\\n\\r\\n  ```\\r\\n  static final in\"},{\"url\":\"/java/collection/List集合体系.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"List集合体系\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ArrayList\\r\\n\\r\\n 特点\\r\\n\\r\\n- 底层基于数组实现。\\r\\n- 有索引，支持快速访问。\\r\\n- 查询修改快，增删慢。\\r\\n- 线程不安全。\\r\\n\\r\\n 构造方法\\r\\n\\r\\n1. 无参构造\\r\\n\\r\\n   - JDK 1.6 之前，以初始容量 10 创建一个长度为10的数组。\\r\\n   - JDK 1.6 之后，创建一个空数组。\\r\\n\\r\\n   ```java\\r\\n       public ArrayList() {\\r\\n           this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;\\r\\n       }\\r\\n   ```\\r\\n\\r\\n2. 有参构造 - 数\"},{\"url\":\"/java/collection/Set集合体系.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Set集合体系\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HashSet\\r\\n\\r\\n 特点\\r\\n\\r\\n- 底层基于哈希算法实现，使用 `HashMap` 保存数据。\\r\\n- 无序（存取顺序不一致）。\\r\\n- 不可以存储重复元素。\\r\\n- 线程不安全。\\r\\n\\r\\n 构造方法\\r\\n\\r\\n1. 无参构造\\r\\n\\r\\n   底层使用 `HashMap` 保存数据。\\r\\n   \\r\\n```java\\r\\n       public HashSet() {\\r\\n           map = new HashMap&lt;\\r\\n       }\\r\\n```\\r\\n\\r\\n3. 有参构造 - Collection 集合\\r\\n\\r\\n   根据传入的 Collection 集合 初始化底层 `HashMap`。\\r\\n\\r\\n\"},{\"url\":\"/java/collection/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集合\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Collection集合\\r\\n\\r\\n- Collection集合概述\\r\\n- List集合体系\\r\\n- Set集合体系\\r\\n\\r\\n Map集合体系\\r\\n\\r\\n- HashMap - 1.7\\r\\n- ConcurrentHashMap - 1.7\\r\\n- HashMap - 1.8\\r\\n- ConcurrentHashMap -1.8\"},{\"url\":\"/java/concurrent/Java高并发.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Java工程师成长计划-高并发\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java工程师成长计划-高并发\\r\\n\\r\\n```\\r\\n         _______________________________________________        \\r\\n        |   _      __        __                         |       \\r\\n________|  | | /| / / ___   / / ____ ___   __ _  ___    |_______\\r\\n\\\\       |  | |/ |/ / / -_) / / / __// _ \\\\ /  ' \\\\/ -_)   |      /\\r\\n \\\\      |  |\"},{\"url\":\"/java/concurrent/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"高并发\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"思维导图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 参考链接\\r\\n\\r\\n- 深入浅出Java多线程\"},{\"url\":\"/java/concurrent/single/AQS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AQS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"从ReentrantLock的实现看AQS的原理及应用\\r\\n\\r\\nAQS是一种提供了原子式管理同步状态、阻塞和唤醒线程功能以及队列模型的简单框架。\\r\\n\\r\\n 组成\\r\\n\\r\\n1. 共享资源状态维护state。\\r\\n\\r\\n   - AQS使用一个`volatile`修饰的 int 成员变量来表示同步状态，这个状态可以反映锁的当前持有情况。\\r\\n\\r\\n     例如，当状态为 0 时表示无锁状态，而当状态为非零时表示有锁被占用。\\r\\n\\r\\n2. FIFO 队列实现线程排队。\\r\\n\\r\\n   AQS维护了一个FIFO（先入先出）的双向队列，用于管理等待获取锁的线程，当一个线程尝试获取锁但失败时，它会进入这个队列并阻塞，直到锁\"},{\"url\":\"/java/concurrent/single/BlockQueue阻塞队列.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"阻塞队列BlockQueue\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"阻塞队列`BlockQueue`比起传统的`Queue`多了阻塞的功能，适合用于多线程之间的数据共享。阻塞主要发生在队列为空和队列满的情况。\\r\\n\\r\\n- 在队列为空的时候，操作元素出队的线程会进行循环等待，直到队列变为非空。\\r\\n- 在队列满的时候，操作元素入队的线程会进行循环等待，直到队列变为非满。\\r\\n\\r\\n 常见方法\\r\\n\\r\\n`BlockQueue入队`的方法有如下几种：\\r\\n\\r\\n- `offer()`方法，如果队列已满，无法存放，直接返回false。\\r\\n- `add()`方法，实际调用了offer()方法，增加了（Queue Full）的异常信息返回。\\r\\n- `put()`方法，若队列已满，会进行\"},{\"url\":\"/java/concurrent/single/CAS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"悲观和乐观策略\\r\\n\\r\\n锁有着悲观锁和乐观锁之分，悲观锁拥有资源的时候，认为随时会有人来篡改拥有的资源，所以在其拥有资源时不允许其他人访问。而乐观锁在拥有资源的时候不认为会有人来篡改其所拥有的资源，所以在其拥有资源的时候允许其他人访问。悲观锁和乐观锁是一种思想，对应的也是一种策略。\\r\\n\\r\\n加锁和使用 synchronized 其实就是一种悲观的策略，因为总是假设临界区的操作会产生冲突，如果有多个线程需要访问临界区资源，加锁和使用 synchronized 会阻塞其它线程。\\r\\n\\r\\n而无锁其实就是一种乐观的策略，它在操作的时候会假设访问资源不会冲突，所有的线程之间不存在阻塞，也就不存在等待，线程会持\"},{\"url\":\"/java/concurrent/single/ThreadLocal.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ThreadLocal总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ThreadLocal 提供了线程的局部变量，只有当前线程可以操作，不会和其它线程的局部变量产生冲突，实现了变量的线程安全。`ThreadLocal&lt;T\\r\\n\\r\\n 简单例子\\r\\n\\r\\n```java\\r\\npublic class ThreadLocalDemo {\\r\\n\\r\\n    private static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;();\\r\\n\\r\\n    public static void main(String[] args) {\\r\\n        //主线程\\r\\n        threadL\"},{\"url\":\"/java/concurrent/single/synchronized原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"synchronized原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"synchronized原理详解（通俗易懂超级好）-CSDN博客\\r\\n\\r\\n 特性\\r\\n\\r\\n- 原子性\\r\\n\\r\\n  synchronized 修饰的对象或类所有操作都是原子性的。线程需要获取锁，保证整个操作过程的原子性。\\r\\n\\r\\n  比如 i++这种赋值操作。\\r\\n\\r\\n- 可见性\\r\\n\\r\\n  一个线程如果要访问该类或对象必须先获得它的锁，而这个锁的状态对于其他任何线程都是可见的，并且在释放锁之前会将对变量的修改刷新到主存当中，保证资源变量的可见性。\\r\\n\\r\\n  如果某个线程占用了该锁，其他线程就必须在锁池中等待锁的释放。\\r\\n\\r\\n- 有序性\\r\\n\\r\\n  保证只有一个线程访问，确保了有序性。\\r\\n\\r\\n- 可重入性\\r\\n\"},{\"url\":\"/java/concurrent/single/transmittable-thread-local.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"transmittable-thread-local\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"线程池中的线程是可以复用的，假如第一个线程对  ThreadLocal 变量进行了操作，如果没有及时清理，下一个线程就会受到影响。因为 ThreadLocal  是在每个线程上维护了一个 ThreadLocalMap ，所以在线程复用的情况下，之后的线程会获取到  ThreadLocal  里之前线程设置的值。\\r\\n\\r\\n ThreadLocal多线程问题\\r\\n\\r\\n在多线程场景下传递ThreadLocal，如果线程池是池化的话，可能会导致复用ThreadLocal里面的值。\\r\\n\\r\\n\\r\\n\\r\\n 需求场景\\r\\n\\r\\n在使用线程池等池化复用线程的情况下，传递ThreadLoca值。\\r\\n\\r\\n1. 分布式跟踪 tr\"},{\"url\":\"/java/concurrent/single/原子类.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"原子类\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本类型-AtomicInteger\\r\\n\\r\\nAtomicInteger 是无锁的线程安全整数类，基于 `CAS` 实现，位于 `java.util.concurrent.atomic` 包下，该包下实现了一系列使用 `CAS` 操作实现线程安全的类型。其它原子类和 AtomicInteger 非常类似，故只分析 AtomicInteger。\\r\\n\\r\\n\\r\\n\\r\\n 比较 Integer\\r\\n\\r\\nAtomicInteger 是一个整数，与 Integer 不同的是，它是可变的并且是线程安全的。\\r\\n\\r\\n比如在多线程不加锁的情况下，操作 Integer 或者 AtomicInteger ，来比较结果是否正确。\"},{\"url\":\"/java/concurrent/single/死锁活锁和饥饿.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"死锁活锁和饥饿\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在使用锁的时候，可能会因为使用不当产生死锁、活锁和饥饿的现象。\\r\\n\\r\\n在单体应用中，加锁是否能解决所有的线程安全问题？\\r\\n\\r\\n*不能，因为加锁使用不当会有死锁、活锁和饥饿等问题。*\\r\\n\\r\\n 死锁\\r\\n\\r\\n什么是死锁？\\r\\n\\r\\n死锁指的是两个或多个线程之间，互相占用着对方请求的资源，而且不会释放已持有的资源，造成了多线程之间无限等待的现象，就叫做死锁。\\r\\n\\r\\n死锁发生后，会浪费大量的系统资源，并且在高并发下存在严重的安全隐患，甚至导致整个系统崩溃。\\r\\n\\r\\n 死锁产生的条件\\r\\n\\r\\n1. 互斥\\r\\n\\r\\n   某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结\"},{\"url\":\"/java/concurrent/single/线程池的关闭.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程池的关闭\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"线程池的关闭\\r\\n\\r\\n线程池的关闭方式有两种，一种是调用 `shutdown()` 方法，另一种是调用 `shutdownNow()` 方法。\\r\\n\\r\\n- shutdown\\r\\n\\r\\n  调用该方法后，线程池拒绝接受新提交的任务，同时等待线程池里和任务队列中的任务执行完毕再关闭线程。\\r\\n\\r\\n- shutdownNow\\r\\n\\r\\n  调用该方法后，线程池拒绝接受新提交的任务，不再执行任务队列的任务，将线程池任务队列里的任务全部返回。\\r\\n\\r\\n shutdown\\r\\n\\r\\n调用该方法后，线程池拒绝接受新提交的任务，同时等待线程池里和任务队列中的任务执行完毕再关闭线程。\\r\\n\\r\\n```java\\r\\n    public \"},{\"url\":\"/java/concurrent/single/线程池的执行流程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程池的执行\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"执行流程\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n1. 根据初始化参数创建线程池，刚创建时，线程池内没有线程。\\r\\n2. 当有新的任务提交到线程池的时候，会立即新增线程执行任务。\\r\\n3. 若运行线程数 = 核心线程数时，这时进来的任务会被添加到任务队列中，而线程会从任务队列中获取任务执行。\\r\\n4. 运行线程数 = 核心线程数 且 任务队列已满，这时候会在线程池中创建新线程来执行任务。\\r\\n5. 运行线程数 = 最大线程数，且任务队列已满，此时会执行线程池对应的拒绝策略。\\r\\n6. 当任务队列中没有任务，且线程等待时间超过空闲时间，则该线程会被回收。最终线程池中的线程数量会保持在核心线程数的大小。\\r\\n\\r\\n 源码分析\\r\\n\"},{\"url\":\"/java/concurrent/single/线程的生命周期.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程的生命周期\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 Java 中线程从新建到关闭会经过不同的状态，将线程从新建到关闭作为一个生命周期，在 Java 中整个线程的生命周期有 6 种状态。\\r\\n\\r\\n 线程状态类型\\r\\n\\r\\n在 JDK 的 Thread 类，存在 `State` 枚举类，包含了线程的 6 种状态。\\r\\n\\r\\n```java\\r\\n    public enum State {\\r\\n        \\r\\n        NEW,\\r\\n        RUNNABLE,\\r\\n        BLOCKED,\\r\\n        WAITING,\\r\\n        TIMED_WAITING,\\r\\n        TERMINATED;\\r\\n    }\\r\\n```\"},{\"url\":\"/java/distributed/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 分布式事务\\r\\n- 分布式锁\\r\\n- 分布式ID\\r\\n- 幂等性问题\"},{\"url\":\"/java/distributed/分布式ID.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式ID\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"要求\\r\\n\\r\\n1. 分布式全局唯一\\r\\n2. 有序递增\\r\\n\\r\\n 方案\\r\\n\\r\\n\\r\\n\\r\\n 数据库主键自增\\r\\n\\r\\n1. 创建一个全局主键自增的表。\\r\\n2.  从该表查询id使用。\\r\\n    - 效率低下，每次插入之前都要查一次自己的id\\r\\n\\r\\n 数据库号段模式\\r\\n\\r\\n批量从全局自增主键表获取一批主键，放到内存里。（减少数据库访问次数）\\r\\n\\r\\n```bash\\r\\nCREATE TABLE `sequence_id_generator` (\\r\\n  `id` int(10) NOT NULL,\\r\\n  `current_max_id` bigint(20) NOT NULL COMMENT '当前最大id',\\r\\n\"},{\"url\":\"/java/distributed/分布式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在分布式情况下，假如存在 A 同时调用 B、C多个微服务。假如 B 服务事务正常执行并提交，但是 C 事务提交失败，此时 B 和 C都需要回滚。\\r\\n\\r\\n而 MySQL 的事务回滚是通过 redo log 机制来实现的，保证事务的持久化和一致性。\\r\\n\\r\\n但是在分布式，使用了分布式事务的情况下，是通过一条更新SQL，还原原本的数据。\\r\\n\\r\\n\\r\\n\\r\\n一文搞明白分布式事务解决方案！真的 so easy！\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n分布式事务，原理简单，写起来全是坑！ - 掘金\\r\\n\\r\\n\\r\\n\\r\\n 分布式事务解决方案\\r\\n\\r\\n 2PC - 两阶段提交\\r\\n\\r\\n1. prepare - 准备阶段\\r\\n\\r\\n    各个参\"},{\"url\":\"/java/distributed/分布式锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- mysql\\r\\n- redis 的 setnx\\r\\n- redission\\r\\n- redLock\\r\\n- zookeeper\\r\\n- curator\\r\\n\\r\\nredis的分布式锁可用性更高，但是分布式不友好。一般单机的redis实现分布式锁性能就够用。\\r\\n\\r\\n如果非要要求可靠性，可以选择zk，只是zk是cp的，性能要差一点。\\r\\n\\r\\n\\r\\n\\r\\n Reids分布式锁\\r\\n\\r\\nredis实现分布式锁\\r\\n\\r\\n\\r\\n\\r\\n 手写 zk 分布式锁\\r\\n\\r\\nzk 实现分布式锁，是依赖 zk 的临时有序节点。\\r\\n\\r\\n多个线程在 rootPath 下面按顺序创建节点。\\r\\n\\r\\n1. 首先有持久节点lock\\r\\n2. 每个请求获取锁\"},{\"url\":\"/java/distributed/幂等性问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"幂等性问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"常见幂等问题\\r\\n\\r\\n解决常见幂等性问题采用 `一锁、二判、三更新` 就可以解决。\\r\\n\\r\\n- 一锁：锁定需要处理的订单\\r\\n- 二判：订单是否支付\\r\\n- 三更新：更新订单状态\\r\\n\\r\\n 数据库锁-悲观锁\\r\\n\\r\\n- for Update\\r\\n  \\r\\n    `FOR UPDATE` 子句告诉数据库管理系统（DBMS）在检索行的同时锁定这些行，直到当前事务结束。\\r\\n    \\r\\n\\r\\n```java\\r\\nBEGIN;\\r\\n\\r\\nSELECT * FROM orders\\r\\nWHERE order_id = 123\\r\\nFOR UPDATE;\\r\\n\\r\\n-- 进行业务逻辑处理，例如更新订单状态\\r\\nUPDATE orders \"},{\"url\":\"/java/io/BIO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BIO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"JDK 网络编程 BIO，意为阻塞的 IO。\\r\\n\\r\\nBIO 的阻塞体现在两个方面：\\r\\n\\r\\n1. 若一个服务端的服务绑定端口启动后，主线程就会一直等待客户端的连接。\\r\\n2. 客户端和服务端 Socket 端口建立连接之后，在读取到 Socket 信息之前，线程一直处于等待，一直处于阻塞状态。\\r\\n\\r\\n典型的 请求 -应答模型\\r\\n\\r\\n由一个独立的 `Acceptor` 模型监听客户端的请求，收到请求后为每一个客户端创建一个线程去处理，处理完成后将结果返回给客户端。\\r\\n\\r\\nJava BIO：传统的网络通讯模型，就是BIO，同步阻塞IO。\\r\\n\\r\\n其实就是服务端创建一个ServerSocket， 然后就是\"},{\"url\":\"/java/io/IO多路复用.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IO多路复用\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"小白也看得懂的 I/O 多路复用解析（超详细案例）_哔哩哔哩_bilibili\\r\\n\\r\\n 基础概念\\r\\n\\r\\n\\r\\n\\r\\n1. Socket\\r\\n\\r\\n   套接字，在网络通信中，就是客户端和服务端的出入口。\\r\\n\\r\\n   \\r\\n&gt;\\r\\n2. fd\\r\\n\\r\\n   文件描述符，是指向资源文件的索引。\\r\\n\\r\\n\\r\\n Socket通讯的过程\\r\\n\\r\\n\\r\\n\\r\\n1. 服务端通过 bind 绑定机器的端口号， 进程 listen 某个端口。\\r\\n2. 客户端和服务端通过 tcp 三次握手建联。\\r\\n3. 进行数据交互，\\r\\n4. 最后通过 close 断开连接。\\r\\n\\r\\n IO模型\\r\\n\\r\\n\\r\\n\\r\\n 同步阻塞IO - BIO\\r\\n\\r\\n-\"},{\"url\":\"/java/io/NIO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"NIO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NIO 是 JDK1.4 引入，为了解决 BIO 阻塞的问题，又称 `no-blocking io`。\\r\\n\\r\\n同步非阻塞\\r\\n\\r\\n NIO特点\\r\\n\\r\\n- 面向缓冲区\\r\\n  \\r\\n    BIO 是面向流的，NIO 是面向缓冲区的。\\r\\n    \\r\\n    \\r\\n\\r\\n- 非阻塞模式\\r\\n  \\r\\n    NIO 的非阻塞模式，使其线程从 Channel 获取数据时，即使获取不到数据也不会阻塞线程。\\r\\n    \\r\\n\\r\\n NIO 核心组件\\r\\n\\r\\n\\r\\n\\r\\n Selector-轮询选择器\\r\\n\\r\\nJava NIO 的选择器允许一个单独的线程来监视多个输入通道（Channel）。\\r\\n\\r\\n选择器用于检测一个或多个通道的状\"},{\"url\":\"/java/io/Reactor模式.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Reactor模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Reactor模式详解＋源码实现\\r\\n\\r\\n整个 reactor 模式解决的主要问题就是在接收到任务后根据分发器快速进行分发给相应的事件处理器，不需要从开始状态就阻塞。\\r\\n\\r\\n基于事件驱动模型，当接收到请求后会将请求封装成事件，并将事件分发给相应处理事件的Handler，handler处理完成后将事件状态修改为下一个状态，再由Reactor将事件分发给能够处理下一个状态的handler进行处理。\\r\\n\\r\\n\\r\\n\\r\\n1. EventHandler：事件处理器，可以根据事件的不同状态创建处理不同状态的处理器；\\r\\n   \\r\\n    ```java\\r\\n    public abstract class Eve\"},{\"url\":\"/java/io/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- BIO\\r\\n- 基于BIO实现RPC框架\\r\\n- NIO\\r\\n- Reactor模式\\r\\n- IO多路复用\"},{\"url\":\"/java/io/基于BIO实现RPC框架.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"基于BIO实现RPC框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基于bio手写实现简单的rpc_java 手写一个bio-CSDN博客\\r\\n\\r\\n RPC\\r\\n\\r\\n\\r\\n\\r\\n RPC设计\\r\\n\\r\\n\\r\\n\\r\\nRPC 的核心就是让客户端调用远程服务方法，就像调用本地方法一样。\\r\\n\\r\\n- 服务端将自己的类注册到远程服务。\\r\\n- 客户端通过注册中心获取到服务端地址。\\r\\n    - 客户端调用服务端地址，传入类名，调用方法、入参\\r\\n    - 服务端收到方法信息后，本地通过反射执行方法，获取结果返回给客户端。\\r\\n- 客户端需要写一个需要调用的类，和服务端的类保持一致（方法名、入参类型、入参）。\\r\\n    - 客户端需要对这个类进行动态代理，实际访问的是该类的代理对象。\\r\\n   \"},{\"url\":\"/java/jvm/CPU负载过高排查记录.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"CPU负载过高排查记录\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"解决线上微服务容器cpu占用100%问题（java进程占用100%问题）_容器cpu占用高_上树的蜗牛儿的博客-CSDN博客\\r\\n\\r\\n 平台发现问题\\r\\n\\r\\n平台发现集群节点 node219 CPU利用率过高。\\r\\n\\r\\n\\r\\n\\r\\n通过查看该节点下的 pod 发现，bookdemo 使用 CPU 过高。\\r\\n\\r\\n\\r\\n\\r\\n 主机排查\\r\\n\\r\\n top 查看进程情况\\r\\n\\r\\n使用 top 确认占用cpu过高的进程。\\r\\n\\r\\nPID=17177 占用 CPU 最高。\\r\\n\\r\\n\\r\\n\\r\\n 查看进程 PID 对应的容器\\r\\n\\r\\n由于该进程是个POD，需要找到对应容器，进入容器内部排查线程情况。\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 容器内部\"},{\"url\":\"/java/jvm/G1收集器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"G1收集器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- XX:+UseG1GC\\r\\n\\r\\nG1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对 配备多颗处理器及大容量内存的机器，以极高概率满足GC停顿时间要求的同时，还具备高吞吐量性能特征。\\r\\n\\r\\nG1 收集器 在 JDK1.7 正式启用，是 JDK 9以后的默认垃圾收集器，取代了 CMS 以及 Parallel+Parallel Old 的组合，被 Oracle 官方称为“全功能的垃圾收集器”。\\r\\n\\r\\n- 适合大内存机器，具备高吞吐量。\\r\\n- 低 GC 停顿时间。\\r\\n\\r\\n 堆分布\\r\\n\\r\\n 区域分布\\r\\n\\r\\n\\r\\n\\r\\n区分于传统的堆内存分布，G1 是将 JVM 堆内存划分为了多个 \"},{\"url\":\"/java/jvm/JDK调优命令.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JDK调优命令\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"jstack\\r\\n\\r\\n 死锁检测\\r\\n\\r\\n1. 使用 jps 命令查看运行中的 java 进程 Id。\\r\\n   \\r\\n    \\r\\n    \\r\\n2. 使用 jstack 分析线程状态。\\r\\n   \\r\\n    ```\\r\\n    jstack 进程Id\\r\\n    ```\\r\\n    \\r\\n    - 线程状态\\r\\n      \\r\\n        通过分析进程可以得到，`DeadLockTest` 进程的两个线程分别为 `pool-1-thread-2` （简称2）和 `pool-1-thread-1`（简称1）。\\r\\n        \\r\\n        通过打印的线程信息可以发现，线程 2 和 1 的线程状态都是 \"},{\"url\":\"/java/jvm/JVM内存模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JVM内存模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java 内存模型在 JDK1.7 主要包含以下区域。\\r\\n\\r\\n- 程序计数器\\r\\n- 虚拟机栈\\r\\n- 本地方法栈\\r\\n- 方法区\\r\\n- 堆\\r\\n\\r\\n而在 JDK1.8中将运行时数据区中的方法区给取消了，换成了本地内存中的元数据区。\\r\\n\\r\\n- 程序计数器\\r\\n- 虚拟机栈\\r\\n- 本地方法栈\\r\\n- 堆\\r\\n- 元数据区\\r\\n\\r\\n 内存模型图\\r\\n\\r\\n1. JDK 1.7 内存模型图\\r\\n   \\r\\n    \\r\\n    \\r\\n2. JDK 1.8 内存模型图\\r\\n   \\r\\n    JDK1.8中取消了运行时数据区中的方法区，换成了元数据区放到了本地内存里。\\r\\n    \\r\\n    \\r\\n    \\r\\n\\r\\n 运行时数据区\\r\\n\\r\\n\"},{\"url\":\"/java/jvm/Java类加载器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"类加载器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"什么是类加载器\\r\\n\\r\\n类加载器（ClassLoader）就是在系统运行过程中动态的将编译后的.class字节码文件加载到JVM中的工具。在IDE中编写的源代码文件都是`.java`文件，通过编译对应生成`.class`文件。而类加载器就是用来将`.class`文件加载到JVM中的工具。\\r\\n\\r\\n 类加载器类型\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nJava默认提供了三个类加载器，分别是 AppClassLoader、ExtClassLoader、BootstrapClassLoader，除此之外还可以自定义类加载器。类加载器之间是父级的关系，但不是通过继承实现父级关系的，而是通过组合的形式来实现的，在`Clas\"},{\"url\":\"/java/jvm/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JVM\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、类加载器\\r\\n\\r\\n- 类加载器\\r\\n- 对象创建\\r\\n\\r\\n 二、内存模型\\r\\n\\r\\n- JVM内存模型\\r\\n\\r\\n 三、垃圾回收\\r\\n\\r\\n- 垃圾回收算法\\r\\n- 垃圾回收器\\r\\n- G1收集器\\r\\n\\r\\n 四、命令工具\\r\\n\\r\\n- JDK调优命令\\r\\n- 可视化工具\\r\\n\\r\\n 五、排障记录\\r\\n\\r\\n- CPU负载过高排查记录\\r\\n- 内存问题排查总结\\r\\n- 频繁GC排查\\r\\n\\r\\n---\"},{\"url\":\"/java/jvm/内存问题排查总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内存问题排查总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"堆内存dump\\r\\n\\r\\n```\\r\\n1 jmap ‐dump:format=b,file=eureka.hprof 14660\\r\\n```\\r\\n\\r\\n可以配置自动 dump 文件，在内存溢出的时候会自动 dump 文件。\\r\\n\\r\\n```\\r\\n-XX:+HeapDumpOnOutOfMemoryError\\r\\n```\\r\\n\\r\\n比如应用的启动脚本，开启自动 dump 文件。\\r\\n\\r\\n```\\r\\nexec java -classpath $CLASSPATH -Xms1024m -Xmx2048m\\r\\n-XX:+HeapDumpOnOutOfMemoryError\\r\\n-Dquery.type=es\\r\\n-Dfile.enco\"},{\"url\":\"/java/jvm/可视化工具.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可视化工具\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"jconsole\\r\\n\\r\\njconsole是JDK 提供的可视化工具。可以查看内存、线程数量、CPU等资源信息。\\r\\n\\r\\n 使用方式\\r\\n\\r\\n 本地进程\\r\\n\\r\\n直接执行命令\\r\\n\\r\\n```java\\r\\njconsole\\r\\n```\\r\\n\\r\\n 远程进程\\r\\n\\r\\n```java\\r\\n-Djava.rmi.server.hostname=10.10.102.81-Dcom.sun.management.jmxremote.port=9999-Dcom.sun.management.jmxremote-Dcom.sun.management.jmxremote.authenticate=false\\r\\n-Dcom.sun\"},{\"url\":\"/java/jvm/垃圾回收器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"垃圾回收器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"垃圾回收类型\\r\\n\\r\\n1. 串行\\r\\n    - 单线程\\r\\n    - 适合堆内存小的时候。\\r\\n    - STW\\r\\n      \\r\\n        Stop The World 的简称。这是因为串行的机制，在垃圾回收的线程运行的时候，其它工作线程都要阻塞。\\r\\n        \\r\\n        *在垃圾回收过程中，对象的地址会发生改变。如果其它线程不阻塞，则可能会发生对象引用错误的问题。*\\r\\n    \\r\\n2. 吞吐量优先\\r\\n    - 多线程\\r\\n    - 适合堆内存较大，且多核CPU的情况。\\r\\n    - 在单位时间内，STW时间最短。\\r\\n3. 响应时间优先\\r\\n    - 多线程\\r\\n    -\"},{\"url\":\"/java/jvm/垃圾回收算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"垃圾回收算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"如何判断对象可以回收\\r\\n\\r\\n 引用计数法\\r\\n\\r\\n为对象添加引用计数器，如果对象被其它对象引用一次，计数器 +1；对应引用释放，则计数器 -1；只有当计数器为 0 时该对象才会被垃圾回收。\\r\\n\\r\\n- 引用计数法造成的内存泄漏\\r\\n  \\r\\n    像下面这种即使对象不被其它对象引用，这两个对象也一直不会被回收，因为对象A和B之间存在引用关系，引用计数器一直为 1，这样就导致了内存泄露。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n\\r\\n\\r\\n\\r\\n 可达性分析算法\\r\\n\\r\\n&gt; 如果某个对象到GC Roots间没有任何引用链相连， 或者用图论的话来说就是从GC Roots到这个对象不可达时，则证明此\"},{\"url\":\"/java/jvm/对象创建.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"对象创建\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"对象的创建流程\\r\\n\\r\\n\\r\\n\\r\\n 类加载检查\\r\\n\\r\\n判断有无加载过该类，有则直接进入下一步、没有则加载类对象。\\r\\n\\r\\n 分配内存\\r\\n\\r\\n虚拟机为新生对象分配内存。\\r\\n\\r\\n对象所需内存大小在类检查阶段便可确定，为对象分配空间就是将一块确定大小内存从 Java 堆中划分出来。\\r\\n\\r\\n 1. 划分内存的方法\\r\\n\\r\\n- 指针碰撞法\\r\\n  \\r\\n    该方法是JVM中的默认方法。\\r\\n    \\r\\n    它主要就是假设JVM中的内存是绝对规整的，使用过的内存和未使用过的内存分别放在两边，用一个指针来给他们做区分。如果要分配内存，只需要将指针向空闲的那一端移动对象大小的位置就好了。\\r\\n    \\r\\n- 空闲列表\"},{\"url\":\"/java/jvm/类加载器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"类加载器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"什么是类加载器\\r\\n\\r\\n类加载器（ClassLoader）就是在系统运行过程中动态的将编译后的.class字节码文件加载到JVM中的工具。在IDE中编写的源代码文件都是`.java`文件，通过编译对应生成`.class`文件。而类加载器就是用来将`.class`文件加载到JVM中的工具。\\r\\n\\r\\n 类加载器类型\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nJava默认提供了三个类加载器，分别是 AppClassLoader、ExtClassLoader、BootstrapClassLoader，除此之外还可以自定义类加载器。类加载器之间是父级的关系，但不是通过继承实现父级关系的，而是通过组合的形式来实现的，在`Clas\"},{\"url\":\"/java/jvm/频繁GC排查.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"频繁GC排查\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```\\r\\njstat -gcutil 1000\\r\\n```\\r\\n\\r\\n\\r\\n\\r\\n```\\r\\njmap -dump:format=b,file=dumpfile 1000\\r\\n```\\r\\n\\r\\n使用 MAT 工具分析代码\\r\\n\\r\\n---\\r\\n\\r\\n组件消费数据的线程池配置有问题。\"},{\"url\":\"/middleware/es/BulkProcessor死锁问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BulkProcessor死锁问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"问题原因\\r\\n\\r\\n- 定时flush\\r\\n- bulk操作\\r\\n- retryHandler：失败重试\\r\\n1. 定时 flush 和 retryHandler 用的是一个定时线程池，而该线程池只有一个线程。\\r\\n2. 定时 flush 的方法用的锁和 bulk 操作时的锁是同一把锁。都是类对象级别的锁。\\r\\n   \\r\\n    \\r\\n    \\r\\n    \\r\\n    \\r\\n3. 当bluk失败后，会触发默认的重试逻辑。\\r\\n4. 如果重试时候 flush 刚好运行，就会出现这种死锁情况。\\r\\n    1. bulk持有对象锁`BulkProcessor.class`，进行重试逻辑。\\r\\n    2. flush占有线\"},{\"url\":\"/middleware/es/ES分片.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES分片\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"同一个索引会划分为多个分片。分片可以设置副本数量，分为主分片和副本分片。\\r\\n\\r\\n```java\\r\\n 指定索引的主分片和副本分片数\\r\\nPUT /blogs\\r\\n{\\r\\n  \\\"settings\\\": {\\r\\n    \\\"number_of_shards\\\": 3,\\r\\n    \\\"number_of_replicas\\\": 1\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n 主分片\\r\\n\\r\\n- 解决数据水平扩展的问题。同一个索引可以按照分片分配数据，将数据平均分配到所有节点之上。\\r\\n- 主分片数创建好后就不能修改。\\r\\n- 一个分片就是一个运行的 Lucene 实例。\\r\\n\\r\\n 主分片过少\\r\\n\\r\\n- 单个分片数据量过大。查询较慢，利用\"},{\"url\":\"/middleware/es/ES压测记录和esrally使用.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES压测记录和esrally使用\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"环境信息\\r\\n\\r\\n- 压测环境\\r\\n  \\r\\n    ```\\r\\n    http://10.1.11.200:39200/\\r\\n    ```\\r\\n    \\r\\n- 开发环境\\r\\n  \\r\\n    ```java\\r\\n    http://10.10.101.69:39200\\r\\n    ```\\r\\n    \\r\\n- 测试环境\\r\\n  \\r\\n    ```java\\r\\n    http://10.10.103.218:39200/\\r\\n    ```\\r\\n    \\r\\n\\r\\n esrally安装\\r\\n\\r\\n docker安装\\r\\n\\r\\n1. 拉取镜像\\r\\n   \\r\\n    ```\\r\\n    docker pull elastic/rally\"},{\"url\":\"/middleware/es/ES参数调优.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES参数调优\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"预防脑裂\\r\\n\\r\\n\\r\\n\\r\\n重要配置的修改 | Elasticsearch: 权威指南 | Elastic\\r\\n\\r\\n 堆内存设置\\r\\n\\r\\n```\\r\\n -Xms2730m -Xmx2730m -Duser.timezone=Asia/Shanghai\\r\\n```\\r\\n\\r\\nxms和xmx设置一样大小，并设置为略小于pod分配内存的一半。\\r\\n\\r\\n 分片设置\\r\\n\\r\\n分片过小或过多都会影响es的查询速率。\\r\\n\\r\\n一经设置无法修改。\\r\\n\\r\\n目前是10个分片，数据量不大的情况下，设置为5个分片进行测试一下。1个、和node数量一致分片测试。\\r\\n\\r\\n1GB 20个分片\\r\\n\\r\\n1个 20G～40GB\\r\\n\\r\\n 副本数量\\r\\n\\r\"},{\"url\":\"/middleware/es/ES深度分页问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES深度分页问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"from+to分页\\r\\n\\r\\nes在查询时候默认使用的是分页查询，单次只会返回10条数据。\\r\\n\\r\\n可以指定size。\\r\\n\\r\\n\\r\\n\\r\\n- 查询要求默认 from+size 的结果必须不超过10000。\\r\\n  \\r\\n    可以通过修改配置\\r\\n    \\r\\n    ```java\\r\\n    \\\"index.max_result_window\\\":\\\"20000\\\"\\r\\n    ```\\r\\n    \\r\\n    限制单词查询满足条件的结果窗口的大小，由from+size共同决定。\\r\\n    \\r\\n    因为es是先将数据全查出来再做分页，这样做是为了限制内存的消耗。\\r\\n    \\r\\n    ---\\r\\n    \\r\\n    因\"},{\"url\":\"/middleware/es/ES滚动查询-Scroll.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES滚动查询-Scroll\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"原理\\r\\n\\r\\nElasticsearch中的滚动查询是基于 固定的排序规则 来加载一部分数据。\\r\\n\\r\\n当用户刷新时，将从上次加载的最后一条数据的位置再加载同样数量的数据。\\r\\n\\r\\n滚动查询的原理类似于分页查询，但是滚动查询不需要重新执行搜索，只需要继续检索下一批结果。在滚动查询中，每次只加载当前页的数据，而不是一次性加载所有数据。这使得滚动查询比分页查询更高效，因为滚动查询不需要将所有数据都存储在内存中。同时，滚动查询也适用于大量数据的处理，因为它可以分批次地处理数据，而不是一次性处理所有数据。\\r\\n\\r\\n 滚动查询的排序规则\\r\\n\\r\\n滚动查询的排序规则不一定是时间。在Elasticsearch中，滚动\"},{\"url\":\"/middleware/es/ES的log4j2日志自动清理配置.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES的log4j2日志自动清理配置\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"配置\\r\\n\\r\\n```xml\\r\\nappender.rolling.strategy.type = DefaultRolloverStrategy\\r\\nappender.rolling.strategy.fileIndex = nomax\\r\\nappender.rolling.strategy.action.type = Delete\\r\\nappender.rolling.strategy.action.basepath = ${sys:es.logs.base_path}\\r\\nappender.rolling.strategy.action.condition.type = IfFileName\\r\\napp\"},{\"url\":\"/middleware/es/ES聚合查询原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES聚合查询原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES在对海量数据进行聚合分析的时候会损失搜索的精准度来满足实时性的需求。\"},{\"url\":\"/middleware/es/ES集群.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES集群\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集群节点类型\\r\\n\\r\\n1. Master Node - 主节点\\r\\n2. DataNode - 数据节点\\r\\n3. Coordinating Node - 协调节点\\r\\n\\r\\n Master Node\\r\\n\\r\\n- 处理创建，删除索引等请求。\\r\\n- 决定分片被分配到哪个节点。\\r\\n- 维护并更新集群 state。\\r\\n\\r\\n Master Node节点最佳实践\\r\\n\\r\\n- Master节点非常重要，在部署上需要解决单点问题。\\r\\n- 为一个集群设置多个Master节点，而且节点只承担 Master 角色。\\r\\n\\r\\n Data Node\\r\\n\\r\\n保存数据的节点，负责保存分片数据。\\r\\n\\r\\n通过增加数据节点可以解决数据水平扩展\"},{\"url\":\"/middleware/es/Elasticsearch写入原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch写入原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本概念\\r\\n\\r\\n 索引\\r\\n\\r\\nElasticsearch的索引是一个逻辑上的概念，指存储了相同类型的文档集合。\\r\\n\\r\\n 映射\\r\\n\\r\\n映射（mapping）定义索引中有什么字段、进行字段类型确认。类似于数据库中表结构定义。\\r\\n\\r\\nES 默认动态创建索引和索引类型的 映射（mapping），就像是非关系型数据中的，无需定义表结构，更不用指定字段的数据类型。\\r\\n\\r\\n也可以手动指定 mapping 类型，比如通过请求设置索引的映射（mapping）。\\r\\n\\r\\n```java\\r\\ncurl --location --request POST 'localhost:9200/course/_mapping' \"},{\"url\":\"/middleware/es/Elasticsearch基础概念.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch基础概念\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础概念\\r\\n\\r\\n 一、索引库（index）\\r\\n\\r\\nElasticsearch的索引库是一个逻辑上的概念，存储了相同类型的文档内容。类似于 MySQL 数据表，MongoDB 中的集合。\\r\\n\\r\\n1. 新建索引库\\r\\n    - number_of_shards\\r\\n      \\r\\n        设置分片的数量，在集群中通常设置多个分片，表示一个索引库将拆分成多片分别存储不同 的结点，提高了ES的处理能力和高可用性，入门程序使用单机环境，这里设置为 1。\\r\\n        \\r\\n    - number_of_replicas\\r\\n      \\r\\n        设置副本的数量，设置副本是为了提高ES的\"},{\"url\":\"/middleware/es/Elasticsearch查询原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch查询原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES查询原理\\r\\n\\r\\n 查询方式\\r\\n\\r\\n- 根据 doc_id 查询。\\r\\n\\r\\n\\r\\n\\r\\n- 根据条件查询\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引\\r\\n\\r\\n根据文档中的每个字段建立倒排索引。\\r\\n\\r\\n 倒排索引的查询流程\\r\\n\\r\\n\\r\\n\\r\\n1. 查询条件分词。\\r\\n2. 查询单词词典 （term dictionary）。\\r\\n3. 获取对应分词的 doc_id 列表。\\r\\n4. 将查询结果返回。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 倒排索引的组成\\r\\n\\r\\n- postings list\\r\\n  \\r\\n    文档列表。\\r\\n    \\r\\n- term dictionary\\r\\n  \\r\\n    单词字典表。包含文档中所有的单词，es 会将单词排序\"},{\"url\":\"/middleware/es/Elasticsearch检索.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch检索\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"检索方式\\r\\n\\r\\nElasticsearch提供两种检索方式。\\r\\n\\r\\n1. RestAPI 形式通过 URL 参数进行检索。\\r\\n2. 通过 DSL 语句进行查询，通过传递 JSON 为请求体与 Elasticsearch 进行交互，这种方式更强大简洁。\\r\\n\\r\\n URL检索\\r\\n\\r\\n`GET /{index}/{type}/_search?q=*&sort=age:desc&size=5&from=0&_source=name,age,bir`\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\nq=* ：匹配所有文档\\r\\n\\r\\nsort=age：按照指定字段进行排序，默认为升序，:desc 降序排列\\r\\n\\r\\nsize：展示多少\"},{\"url\":\"/middleware/es/Elasticsearch聚合查询.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch聚合查询\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES在对海量数据进行聚合分析的时候会损失搜索的精准度来满足实时性的需求。\\r\\n\\r\\n Elasticsearch聚合查询总结\\r\\n\\r\\n 1. 求和、最大值、最小值、平均值\\r\\n\\r\\n- 求和 - sum\\r\\n- 最大值 - max\\r\\n- 最小值 - min\\r\\n- 平均值 - avg\\r\\n\\r\\n---\\r\\n\\r\\nDSL查询语句\\r\\n\\r\\n```java\\r\\n{\\r\\n    \\\"size\\\": 0,\\r\\n    \\\"query\\\": {\\r\\n        \\\"bool\\\": {\\r\\n            \\\"filter\\\": [\\r\\n                {\\r\\n                    \\\"range\\\": {\\r\\n    \"},{\"url\":\"/middleware/es/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础总结\\r\\n\\r\\n- Elasticsearch基础概念\\r\\n- Elasticsearch检索\\r\\n- Elasticsearch聚合查询\\r\\n\\r\\n\\r\\n- ES滚动查询-Scroll\\r\\n- 批量操作Bulk和BulkProcessor\\r\\n- BulkProcessor死锁问题\\r\\n\\r\\n\\r\\n- 并发场景修改文档\\r\\n- ES深度分页问题\\r\\n\\r\\n\\r\\n- ES集群\\r\\n- ES分片\\r\\n\\r\\n 原理总结\\r\\n\\r\\n- 倒排索引原理\\r\\n- Elasticsearch写入原理\\r\\n- Elasticsearch查询原理\\r\\n- ES聚合查询原理\\r\\n\\r\\n 使用问题\\r\\n- ES参数调优\\r\\n- 集群脑裂-参数配置\\r\\n\\r\\n\\r\\n- ES\"},{\"url\":\"/middleware/es/倒排索引原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"倒排索引图解\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"原理图\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引的搜索过程\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引原理\\r\\n\\r\\nElasticsearch 主要功能就是搜索，为了提高搜索效率，其内部使用了倒排索引。\\r\\n\\r\\n 正排索引\\r\\n\\r\\n在搜索引擎中，每个文件对应一个文件 ID （doc_id），文件内容是关键词的集合。\\r\\n\\r\\n\\r\\n\\r\\n根据 `doc_id` 可以查找到文档详情。\\r\\n\\r\\n*这种方式本质上就是通过文档的 key 查找 value 值。*\\r\\n\\r\\n比如查找 `name=jetty wan` 的文档，只能按照顺序从前向后匹配每个文档的 name 字段。\\r\\n\\r\\n这种查找方式的效率非常低下。\\r\\n\\r\\n 倒排索引\\r\\n\\r\\n倒排索引和正向索引\"},{\"url\":\"/middleware/es/并发场景修改文档.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"并发场景修改文档\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES从7.X版本默认使用的是乐观锁机制修改文档。\\r\\n\\r\\n当在高并发环境下使用乐观锁机制修改文档时，要带上当前文档的_seq_no和_primary_term进行更新：\\r\\n\\r\\n```java\\r\\nPOST /es_db/_doc/2?if_seq_no=21&if_primary_term=6{  \\\"name\\\": \\\"李四xxx\\\"}\\r\\n```\\r\\n\\r\\n如果冲突会提示版本冲突异常。\"},{\"url\":\"/middleware/es/批量操作Bulk和BulkProcessor.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"批量操作Bulk和BulkProcessor\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"es的批量操作，6.x版本的es中high-rest-client中可以用到以下三种。\\r\\n\\r\\n- bulk\\r\\n- bulkAsync\\r\\n- bulkProcessor\\r\\n\\r\\n Bulk\\r\\n\\r\\nbulk api 以此按顺序执行所有的 action（动作）。如果一个单个的动作因任何原因失败，它将继续处理它后面剩余的动作。当 bulk api 返回时，它将提供每个动作的状态（与发送的顺序相同），所以您可以检查是否一个指定的动作是否失败了。\\r\\n\\r\\nes可以通过 _bulk 的API实现批量操作。\\r\\n\\r\\n```java\\r\\nPOST _bulk\\r\\n{\\\"create\\\":{\\\"_index\\\":\\\"article\\\"\"},{\"url\":\"/middleware/es/集群脑裂-参数配置.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集群脑裂-参数配置\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集群脑裂的问题\\r\\n\\r\\n 什么是集群脑裂\\r\\n\\r\\nes 在主节点上产生分歧，产生多个master 节点，从而使集群分裂成多个同名集群，使得集群处于异常状态。\\r\\n\\r\\n当出现多个master节点的时候，可能发生写入请求分配到不同的master节点，而数据只保存在对应的master节点的分片上，不会复制到其它节点。此时若访问不同的节点，会发现查询的结果是不一样的。\\r\\n\\r\\n 举例说明脑裂\\r\\n\\r\\n`discovery.zen.minimum_master_nodes` 参数之前设置为 1（默认值）。\\r\\n\\r\\n这个参数的含义是限制选举master节点的数量。\\r\\n\\r\\n- 当master节点不存在时，至少有几个ma\"},{\"url\":\"/middleware/kafka/Kafka分区机制策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka分区机制策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"分区策略\\r\\n\\r\\n分区策略是决定生产者将消息发送到哪个分区的算法。\\r\\n\\r\\n 轮询策略\\r\\n\\r\\n是 Java 生产者 API 默认提供的分区策略。\\r\\n\\r\\n- 轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。\\r\\n\\r\\n\\r\\n\\r\\n 随机策略\\r\\n\\r\\n将消息随机写入分区\\r\\n\\r\\n key 指定分区\\r\\n\\r\\n当发送消息时指定了key，Kafka会根据key的hash值与分区数取模来决定将数据写入哪个分区。\\r\\n\\r\\n项目中 dr 就是生产这种方式，根据消息类型指定 key，比如 transactionId。这样能保证同一t\"},{\"url\":\"/middleware/kafka/Kafka副本机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka副本机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka 的副本是针对分区来说的，为分区创建副本。\\r\\n\\r\\n副本的作用就是提供数据冗余，在 Leader 副本挂掉之后，转换为 Leader 副本继续工作。\\r\\n\\r\\n不然当 Leader 副本挂掉之后，该分区就会停止对外提供服务。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 副本同步\\r\\n\\r\\n\\r\\n\\r\\n生产者只会往分区的 Leader 发消息，而其它 Follower 会从 Leader 拉取数据进行同步。\\r\\n\\r\\n Follower追随者副本\\r\\n\\r\\nFollower 副本是不对外提供服务的，只是定期地异步拉取领导者副本中的数据而已。\\r\\n\\r\\n LSR副本集合\\r\\n\\r\\nLSR集合里面保存的副本都是与 Leader 副本\"},{\"url\":\"/middleware/kafka/Kafka总控制器Controller.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka总控制器 Controller\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 kafka中会有多个 Broker，其中一个 Broker 会被选举为 Controller，负责管理整个集群中分区和副本的状态。\\r\\n\\r\\n Zookeeper\\r\\n\\r\\nzk 使用的数据模型类似于文件系统的树形结构，根目录也是以“/”开始。该结构上的每个节点被称为 znode，用来保存一些元数据协调信息。\\r\\n\\r\\nZooKeeper 常被用来实现集群成员管理、分布式锁、领导者选举等功能。\\r\\n\\r\\nznode 用来保存元数据信息。\\r\\n\\r\\n- 永久性 znode\\r\\n  \\r\\n    持久性 znode 不会因为 ZooKeeper 集群重启而消失。\\r\\n    \\r\\n- 临时性 znode\\r\\n  \\r\\n   \"},{\"url\":\"/middleware/kafka/Kafka手动重新分区.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka手动重新分区\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka重分配分区_kafka重新分配分区-CSDN博客\\r\\n\\r\\n1. 确定需要重新分区的 topic\\r\\n   \\r\\n    vi topics-to-move.json\\r\\n    \\r\\n    ```java\\r\\n    \\r\\n    {\\r\\n      \\\"topics\\\": [{\\r\\n         \\\"topic\\\": \\\"test-topic\\\"\\r\\n       }],\\r\\n       \\\"version\\\": 1\\r\\n    }\\r\\n    ```\\r\\n    \\r\\n    - topic 可以批量设置\\r\\n2. 根据 topic 生成执行计划\\r\\n   \\r\\n    ```java\\r\\n    bin/kafka-rea\"},{\"url\":\"/middleware/kafka/Kafka消费策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka消费策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka消费者-主动批量拉取\\r\\n\\r\\n\\r\\n&gt; \\r\\n1. kafka配置类\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\n@Slf4j\\r\\npublic class KafkaConfig {\\r\\n\\r\\n    @Bean\\r\\n    public KafkaListenerContainerFactory&lt;?&gt; batchFactory(ConsumerFactory consumerFactory){\\r\\n        ConcurrentKafkaListenerContainerFactory&lt;Integer,String&gt; factory =\\r\\n    \"},{\"url\":\"/middleware/kafka/Kafka生产者参数.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka生产者参数\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- bootstrap.servers： broker的地址\\r\\n- key.serializer：关键字的序列化方式\\r\\n- value.serializer：消息值的序列化方式\\r\\n- acks：指定必须要有多少个分区的副本接收到该消息，服务端才会向生产者发送响应，可选值为：0,1,2，…，all\\r\\n- buffer.memory：生产者的内存缓冲区大小。如果生产者发送消息的速度 \\r\\n- max.block.ms：表示send()方法在抛出异常之前可以阻塞多久的时间，默认是60s\\r\\n- compression.type：消息在发往kafka之前可以进行压缩处理，以此来降低存储开销和网络带宽。默认\"},{\"url\":\"/middleware/kafka/Kafka高性能的原因.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka高性能的原因\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 写数据是按照磁盘顺序读写。\\r\\n   \\r\\n    保证顺序读写，比随机写性能要高很多。\\r\\n    \\r\\n    数据保存在 log 中，并对 log 进行了分段（logSegment）技术，对 logSegment 还增加了日志索引。\\r\\n    \\r\\n2. 数据传输的零拷贝，使的数据在内核空间中就完成了读写操作。\\r\\n   \\r\\n    零拷贝原理：\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 读写数据的批量处理以及压缩传输。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n\\r\\n 零拷贝\\r\\n\\r\\n- 传统数据文件拷贝过程\\r\\n  \\r\\n    整个过程需要在内核空间和应用空间之间拷贝 2 次。\\r\\n    \"},{\"url\":\"/middleware/kafka/Producer发布消息机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Producer发布消息机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"写入机制\\r\\n\\r\\nProducer 通过push模式将消息发给 Broker，每条消息都被追加到对应的 Partition。而且是采用顺序写磁盘的方式（顺序写比随机写效率高，保障 Kafka 高吞吐量）。\\r\\n\\r\\n 消息路由模式\\r\\n\\r\\nProducer 如何确认消息发到哪个 Partition 上？\\r\\n\\r\\n1. 指定了 Partition，直接使用。\\r\\n2. 如果未指定 Partition，指定了 Key。根据 Key 的 Hash 值计算 Partition。\\r\\n   \\r\\n    Hash(key) % num(Partition)\\r\\n    \\r\\n3. 如果未指定 Partition，也未指定 \"},{\"url\":\"/middleware/kafka/__consumer_offsets.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"__consumer_offsets\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"将 Consumer 的位移数据作为一条条普通的 Kafka 消息，提交到 consumer*offsets 中。可以这么说，consumer*offsets 的主要作用是保存 Kafka 消费者的位移信息。\\r\\n\\r\\n_*consumer*offsets也是一个 topic，也有分区。和 kafka 的 topic 基本一致支持自定义写入。但是它是内部的 topic，一般最好不要自动修改。\\r\\n\\r\\n 消息格式\\r\\n\\r\\n1. 分区消费的 offset\\r\\n    \\r\\n    位移主题的 Key 中应该保存 3 部分内容：\\r\\n    \\r\\n    标识某个消费者组里面某个 topic 的某个分区，已经被消费\"},{\"url\":\"/middleware/kafka/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka配置\\r\\n\\r\\n- Kafka消费策略\\r\\n- Kafka生产者参数\\r\\n- kafka的分区副本规划\\r\\n\\r\\n\\r\\n Kafka原理总结\\r\\n- kafka消费模型\\r\\n- kafka-ACK应答机制\\r\\n- kafka解决重复消费\\r\\n\\r\\n\\r\\n- Kafka分区机制策略\\r\\n- kafka保证消息不丢失\\r\\n- 消费者组\\r\\n- __consumer_offsets\\r\\n- Kafka总控制器Controller\\r\\n- Kafka副本机制\\r\\n\\r\\n\\r\\n- Producer发布消息机制\\r\\n- 高水位HW和LEO\\r\\n- 数据日志分段存储\\r\\n\\r\\n\\r\\n- Kafka高性能的原因\\r\\n\\r\\n 使用总结\\r\\n- Kafka手动\"},{\"url\":\"/middleware/kafka/kafka-ACK应答机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka生产者保证消息不丢失-ACK应答机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka 生产者写入数据的时候，引入了 ACK 应答机制。\\r\\n\\r\\n```java\\r\\n            Properties props = new Properties();\\r\\n            props.put(\\\"bootstrap.servers\\\", Configuration.KAFKA_ADDRESS);\\r\\n\\t\\t\\t\\t\\t\\t//1:leader应答就可以发送下一条，确保发送成功。\\r\\n            props.put(\\\"acks\\\", \\\"1\\\");\\r\\n\\t\\t\\t\\t\\t\\t......\\r\\n            props.put(\\\"key.serializer\\\", \\\"org.a\"},{\"url\":\"/middleware/kafka/kafka保证消息不丢失.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka保证消息不丢失\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。\\r\\n\\r\\n 生产者端消息丢失\\r\\n\\r\\n生产者发送消息的时候，如果没有发到 kafka 导致消息丢失（网络抖动），其实这并不是 kafka 的原因。\\r\\n\\r\\nkafka 能保证已经提交到 borker 的数据，不会丢失。\\r\\n\\r\\n默认生产者发数据，采用 `send(msg)`发数据，这样发数据之后生产者并不知道是否发送成功。\\r\\n\\r\\n最好使用 `producer.send(msg, callback)` 发数据，这样通过`callback`能够清楚的知道消息是否发送成功。\\r\\n\\r\\n 消费者端消息丢失\\r\\n\\r\\nConsu\"},{\"url\":\"/middleware/kafka/kafka消费模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka消费模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka消费模型分为两种。\\r\\n\\r\\n1. 消费组消费\\r\\n   \\r\\n    消费组里面的单个消费者消费一个分区的数据。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n    \\r\\n    \\r\\n    \\r\\n2. 消费者-worker进程消费。\\r\\n\\r\\n\\r\\n\\r\\n&gt; 第一种消费模型，每个分区对应一个 consumer。\\r\\n&gt; \\r\\n\\r\\n第二种消费模型，只消费数据不处理，处理的工作单独交给 worker线程池，这样可以避免很多 consumer产生的问题。不要把很重的处理逻辑放到消费者中。\\r\\n\\r\\n&gt; 难以保证 offset 的语义正确性，可能导致重复消费。\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n--\"},{\"url\":\"/middleware/kafka/kafka的分区副本规划.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka的分区副本规划\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. topic划分\\r\\n\\r\\n每个日志对应一个topic。\\r\\n\\r\\ntopic 有自己的分区数量和副本数量。一般根据kafka指定的默认数量自动生成。\\r\\n\\r\\n---\\r\\n\\r\\n 2. 分区数量\\r\\n\\r\\n当生产者发给kafka一条消息时，根据规则分到 topic 的指定分区（partition），所以每个分区的数据是不一样的。\\r\\n\\r\\n 规划分区数量\\r\\n\\r\\n消费者在消费数据的时候，也是从分区中消费的，同一个分区只能被消费组里的一个消费者去消费。\\r\\n\\r\\n比如kafka有3个borker时，假如配置topic有5个分区，分配到3个borker就会出现 2 2 1 的情况。\\r\\n\\r\\n所以在指定topic的分区数量时\"},{\"url\":\"/middleware/kafka/kafka解决重复消费.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka解决重复消费\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"技术干货分享 | Kafka重复消费场景及解决方案\\r\\n\\r\\n 导致重复消费的原因\\r\\n\\r\\n- enable.auto.commit 默认值true，表示消费者会周期性自动提交消费的offset\\r\\n- auto.commit.interval.ms 在enable.auto.commit 为true的情况下， 自动提交的间隔，默认值5000ms\\r\\n- max.poll.records 单次消费者拉取的最大数据条数，默认值 500\\r\\n- max.poll.interval.ms 默认值5分钟，表示若5分钟之内消费者没有消费完上一次poll的消息，那么consumer会主动发起离开group的请求\\r\\n1\"},{\"url\":\"/middleware/kafka/数据日志分段存储.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据日志分段存储\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"数据保存机制\\r\\n\\r\\n\\r\\n\\r\\nKafka 的数据是按照分区存储的，以 topic-partition 为目录保存数据。\\r\\n\\r\\n数据是存到 log 中，而 log 又引入了LogSegment机制。\\r\\n\\r\\n`log.segment.bytes`，默认 1G。当超过1G 之后，日志就会开始分割。\\r\\n\\r\\n而日志分段文件以及索引文件都是以基准偏移量（offset）命名的。\\r\\n\\r\\n基本每段的日志文件包含一个数据文件和两个索引文件。\\r\\n\\r\\n- 以offset 为索引的 `.index`。\\r\\n- 以时间戳为索引的 `.timeindex`。\\r\\n\\r\\n索引里面并不是保留全量的数据索引，而是以稀疏索引的方式保存（方\"},{\"url\":\"/middleware/kafka/消费者组.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"消费者组\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。\\r\\n\\r\\n- 组内的所有消费者协调在一起来消费订阅主题（Subscribed Topics）的所有分区（Partition）。\\r\\n- 每个分区只能由同一个消费者组内的一个 Consumer 实例来消费。\\r\\n\\r\\n比如 topic 有 6 个分区，消费者组里面的消费者数量最理想状态是 6 个，每个消费者消费一个分区。也可以是 3 个或者两个，这样分区能够平均分配。\\r\\n\\r\\n但是最好不要超过 6 个消费者，这样的话会有消费者分不到分区。\\r\\n\\r\\n而 topic 的分区设计时，最好和 broker 的数量成比例。比如 3 个\"},{\"url\":\"/middleware/kafka/高水位HW和LEO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"高水位HW和LEO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"LEO（log_end_offset) 指的是当前分区日志末端的 offset。\\r\\n\\r\\n而 HW 指的是整个 LSR 集合副本中，LEO 最小的。保障 Consumer 只能消费到 HW 的位置。\\r\\n\\r\\n首先Leader 和 Followers 都有自己的 HW和 LEO，当有新消息写入 Leader 时，Consumer 并不能立即消费。\\r\\n\\r\\nFollowers 会 pull leader 最新的消息，同步完之后，发送 ACK 给 Leader。然后 Leader会增加 HW。增加之后，新产生的消息才能被 Consumer 消费掉。\\r\\n\\r\\n这样的目的是为了保证当 Leader 挂掉之后，重\"},{\"url\":\"/middleware/rocketmq/Kakfa和RocketMQ的区别.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kakfa和RocketMQ的区别\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"消费者组\\r\\n\\r\\nRocketMQ和Kafka虽然都使用了Consumer Group的概念来实现消息的分发和负载均衡，但两者在具体实现和一些特性上存在一些差异：\\r\\n\\r\\n1. Rebalance机制：\\r\\n    - RocketMQ：RocketMQ的Consumer Group在成员增减或Topic队列发生变化时会触发Rebalance，旨在重新分配队列到各个消费者实例，确保消息的公平消费。RocketMQ的Rebalance更加灵活，支持多种分配策略，例如平均分配、广播消费等，可以根据业务需求进行配置。\\r\\n    - Kafka：Kafka同样在Consumer Group中进行Rebala\"},{\"url\":\"/middleware/rocketmq/MQ接收消息幂等性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MQ接收消息幂等性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"幂等性\\r\\n\\r\\nMQ的消息幂性，指的是MQ接收消息时候的幂等性。\\r\\n\\r\\n- 最多一次\\r\\n    \\r\\n    消息最多只会被消费一次。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n- 最少一次\\r\\n    \\r\\n    消息最少被消费一次。\\r\\n    \\r\\n    &gt; 同步发送、事务消息。\\r\\n    &gt; \\r\\n- 准确消费一次\\r\\n    \\r\\n    默认RocketMQ保证不了准确消费一次。但是商业版本有。\\r\\n    \\r\\n\\r\\n 消息幂等的必要性\\r\\n\\r\\n- 生产者发送消息时，MQ收到消息，但是网络波动导致ACK没有给到生产者。可能会导致重推消息。\"},{\"url\":\"/middleware/rocketmq/RocketMQ基础学习.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ基础学习\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础架构\\r\\n\\r\\n\\r\\n\\r\\n 生产者\\r\\n\\r\\nRocketMQ提供多种发送方式，同步发送、异步发送、顺序发送、单向发送。\\r\\n\\r\\n同步和异步方式均需要 Broker 返回确认信息，单向发送不需要。\\r\\n\\r\\n生产者中，会把同一类 Producer 组成一个集合，叫做生产者组。同一组的 Producer 被认为是发送同一类消息且发送逻辑一致。\\r\\n\\r\\n 消费者\\r\\n\\r\\n 消费者组\\r\\n\\r\\n消费者组消费同一组数据，消费相同topic，并且消费逻辑一致。消费者组的消费者实例必须订阅完全相同的Topic。\\r\\n\\r\\n 消费模式\\r\\n\\r\\nRocketMQ 支持两种消息模式：集群消费（Clustering）和广播消费（Broad\"},{\"url\":\"/middleware/rocketmq/RocketMQ集群架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ集群架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NameServer：提供Broker的路由服务\\r\\n\\r\\nBroker：负责接收Producer的消息，存储消息，将消息投递给Consumer。\\r\\n\\r\\n- Broker需要管理数据，频繁处理数据，所以需要G1、ZGC这种更先进的垃圾回收器。\\r\\n- 而NameServer类似于Broker的注册中心，提供路由功能，只需要简单的垃圾回收算法就可以，比如CMS。\\r\\n\\r\\nProducer：生产者\\r\\n\\r\\nConsumer：消费者\\r\\n\\r\\n 集群架构说明\\r\\n\\r\\n整个RocketMQ集群里面主要分为两部分，Broker和NameServer。\\r\\n\\r\\n整个RocketMQ遵循的是AP架构，追求可用性。\\r\\n\\r\\n N\"},{\"url\":\"/middleware/rocketmq/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- RocketMQ基础学习\\r\\n- RocketMQ集群架构\\r\\n\\r\\n\\r\\n- 消息样例\\r\\n- 顺序消息\\r\\n- 事务消息\\r\\n\\r\\n\\r\\n- 如何保证发送消息有序\\r\\n- 如何保证消息不丢失\\r\\n- MQ接收消息幂等性\\r\\n\\r\\n\\r\\n- Kakfa和RocketMQ的区别\"},{\"url\":\"/middleware/rocketmq/事务消息.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"事务消息\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"事务消息的流程\\r\\n\\r\\n- 先写half消息到RocketMQ\\r\\n- 再执行本地事务\\r\\n  \\r\\n    本地事务有两个方法，一个是回调执行本地事务，另一个是检查本地事务。\\r\\n    \\r\\n    ```java\\r\\n    /**\\r\\n     * 事务监听器，用来处理本地事务\\r\\n     * @author yangjunwei\\r\\n     * @date 2024/7/4\\r\\n     */\\r\\n    public class TransactionListenerImpl implements TransactionListener {\\r\\n        private AtomicInteger\"},{\"url\":\"/middleware/rocketmq/如何保证发送消息有序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"如何保证发送消息有序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类比Kafka的ParitationKey，RocketMQ是messageQueue。\\r\\n\\r\\n将需要保证顺序的消息发给RocketMQ的messageQueue，被同一个消费者消费，即可保证有序。\\r\\n\\r\\n1. 消费者在发送的时候可以指定selector，指定消息发给哪个messageQueue。\\r\\n2. messageQueue是一个FIFO的队列，能够保证消费时按照写入消息的顺序去消费。\\r\\n\\r\\n所以需要保证有顺序的消息，比如相同产品的订单，可以按照产品 code 设置 selector，保证消息发到同一个 messageQueue，这样就能被同一个消费者消费。\\r\\n\\r\\n```java\\r\\nSe\"},{\"url\":\"/middleware/rocketmq/如何保证消息不丢失.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"如何保证消息不丢失\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"消息丢失场景\\r\\n\\r\\n数据丢失在MQ中比较常见，一般丢失数据都是在跨网络的部分，比如1、2、4。\\r\\n\\r\\n- 生产者发数据\\r\\n- 消费者消费数据\\r\\n- MQ内部主从同步\\r\\n\\r\\n而MQ写数据到磁盘过程也是有丢失数据的可能的。\\r\\n\\r\\n一般写数据到磁盘不会直接去写，而是利用操作系统的缓存，先写数据到缓存中，等待操作系统异步刷进磁盘。\\r\\n\\r\\n比如 Prometheus 的 WAL 机制。\\r\\n\\r\\n\\r\\n\\r\\n 事务消息-生产者\\r\\n\\r\\n使用事务消息能保证本地事务和写入MQ的事务一致性。\\r\\n\\r\\n比如订单场景，只保证本地下订单和向MQ发消息的事务一致性。不会像MySQL一样保证数据库事务。\\r\\n\\r\\n只是保证了业务的分布\"},{\"url\":\"/middleware/rocketmq/消息样例.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"消息样例\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"顺序消息\\r\\n\\r\\nkafka的顺序消息可以指定paritationKey实现，相同paritationKey的消息会被发给同一个paritation。\\r\\n\\r\\nRocketMQ可以通过实现 `MessageQueueSelector` 的 `select` 方法自定义实现消息所发给 MessageQueue的逻辑。\\r\\n\\r\\n```java\\r\\n    @SneakyThrows\\r\\n    @Test\\r\\n    public void orderSend() {\\r\\n        try {\\r\\n            DefaultMQProducer producer = new DefaultMQP\"},{\"url\":\"/middleware/rocketmq/顺序消息.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"顺序消息\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"生产者\\r\\n\\r\\n生产者发送消息到MQ的过程，如果要保证顺序消费。\\r\\n\\r\\n只能采用单线程去生产消息，因为多线程无法控制消息生产顺序。\\r\\n\\r\\n还需要保证 sharding key 相同，保证同一类消息发到同一个 ConsumerQueue。\\r\\n\\r\\n\\r\\n&gt; \\r\\n- 单线程生产消息\\r\\n- 发送到同一个ConsumerQueue\\r\\n\\r\\n 存储\\r\\n\\r\\nRocketMQ的存储是按照时间顺序 append write 到 commitlog 中的，同时它会被分发到 ConsumeQueue中。\\r\\n\\r\\n所以只需要生产时候保证消息采用单线程发送到同一个ConsumerQueue，存储时候就能够顺序存储。\\r\\n\\r\"},{\"url\":\"/other/algorithm/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 时间复杂度\\r\\n- 查找\\r\\n- 排序\\r\\n- 动态规划\"},{\"url\":\"/other/algorithm/动态规划.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"动态规划\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"动态规划重要特性\\r\\n\\r\\n动态规划的核心问题是穷举，因为要求最值，要把所有可行答案找出来，找最值。但是穷举的过程中，会存在【重叠子问题】。\\r\\n\\r\\n 重叠子问题\\r\\n\\r\\n在求解的过程中，存在重复的子问题，若是重复解决这些子问题，存在效率低下的问题。\\r\\n\\r\\n而解决重叠子问题，可以使用【备忘录】或者【DP table】方法来解决。\\r\\n\\r\\n- 备忘录\\r\\n  \\r\\n    备忘录的思想就是将已经解决的子问题结果记录在备忘录中（可以是数组等数据结构）。\\r\\n    \\r\\n\\r\\n\\r\\n&gt; \\r\\n- DP table\\r\\n  \\r\\n    使用 DP table 保存每个子问题的结果，自下向上推算结果。\\r\\n    \\r\\n\\r\\n\"},{\"url\":\"/other/algorithm/排序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"排序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"概念\\r\\n\\r\\n 稳定性\\r\\n\\r\\n稳定性指的是相同的数据所在的位置经过排序后是否发生变化。若是排序后，次序不变，则是稳定的。\\r\\n\\r\\n 内部排序\\r\\n\\r\\n排序记录全部存放在内存中进行排序的过程。\\r\\n\\r\\n 外部排序\\r\\n\\r\\n待排序记录的数量很大，以至于内存不能容纳全部记录，在排序过程中尚需对外存进行访问的排序过程。\\r\\n\\r\\n\\r\\n\\r\\n 选择排序-不稳定\\r\\n\\r\\n每次选择剩余待排序元素中的最小值，放到已排序元素的末尾。\\r\\n\\r\\n原理：每次排序选出最小的元素，替换到对应顺序末尾的位置。\\r\\n思路：第一次排序选出最小的元素，和待排序数组第一位的元素进行交换。\\r\\n\\r\\n```json\\r\\n/**\\r\\n     * 选择排序的思路：\"},{\"url\":\"/other/algorithm/时间复杂度.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"时间复杂度\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"O(1)\\r\\n\\r\\n- 数组下表查询\\r\\n\\r\\n O(n)\\r\\n\\r\\n- 链表元素查询，最坏情况是要查n次。\\r\\n\\r\\n O(logn)\\r\\n\\r\\n- 平衡二叉树\\r\\n- 数组二分法查找指定元素\\r\\n\\r\\n开根号\\r\\n\\r\\n- 比如16长度的数组，想要找到指定元素最多需要4次、\\r\\n  \\r\\n    16→8→4→2→1\\r\\n    \\r\\n- 红黑树（平衡二叉树、完全二叉树）\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n O(log n) \\r\\n\\r\\n复杂度解释：\\r\\n\\r\\n- 在一个理想平衡的二叉搜索树中，每次查找操作从根节点开始，通过比较目标值与当前节点的值来决定是向左还是向右子树进行下一步查找。\\r\\n- 每次比较后，查找范围大致减半，这类似于\"},{\"url\":\"/other/algorithm/查找.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"查找\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"静态查找表\\r\\n\\r\\n 顺序查找\\r\\n\\r\\n线性表查询，查找效率（n+1)/2\\r\\n\\r\\n\\r\\n\\r\\n 折半查找\\r\\n\\r\\n\\r\\n\\r\\n二分查找，仅适用于有序的线性表。\\r\\n\\r\\n折半查找比较次数最多为 [log2n]+1 次。n=2^x，比如8个元素最多需要3次，对应 8=2^3。\\r\\n\\r\\n所以时间复杂度为 O(log2n) 。\\r\\n\\r\\n 分块查找\\r\\n\\r\\n特点是块内无序，但是块间有序。\\r\\n\\r\\n- 先在索引表确定目标所在块。\\r\\n- 在块内顺序查找。\\r\\n\\r\\n\\r\\n\\r\\n比如索引表或者索引文件。\\r\\n\\r\\n 哈希表\\r\\n\\r\\n\\r\\n\\r\\n按照哈希存储元素到哈希表里。\\r\\n\\r\\n 哈希冲突解决方式\\r\\n\\r\\n按照值的哈希值存储会出现哈希冲突的问题，可以通\"},{\"url\":\"/other/datastructure/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据结构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 常用数据结构\\r\\n- 二叉树\"},{\"url\":\"/other/datastructure/二叉树.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"二叉树\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"推荐一个练习数据结构的网站\\r\\n\\r\\nData Structure Visualization\\r\\n\\r\\n 二叉树的遍历（重要）\\r\\n\\r\\n以图示二叉树为例。\\r\\n\\r\\n\\r\\n\\r\\n 中序遍历\\r\\n\\r\\n简化为每个树，都是左中右即可。\\r\\n\\r\\n中序遍历（LDR）是二叉树遍历的一种，也叫做中根遍历、中序周游。在二叉树中，中序遍历首先遍历左子树，然后访问根结点，最后遍历右子树。\\r\\n\\r\\n*左子树 → 根节点 → 右子树*\\r\\n\\r\\n图示二叉树中序遍历结果为：`3、5、6、10、14、15、17、20`；\\r\\n\\r\\n参考代码：Java实现中序遍历\\r\\n\\r\\n 前序遍历\\r\\n\\r\\n前序遍历（VLR）， 1] 是[二叉树遍历的一种，也叫做先根遍历\"},{\"url\":\"/other/datastructure/常用数据结构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"常用数据结构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"存储结构\\r\\n\\r\\n\\r\\n\\r\\n 复杂度\\r\\n\\r\\n时间复杂度\\r\\n\\r\\n空间复杂度\\r\\n\\r\\n 线性表\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 串\\r\\n\\r\\n比如字符串。\\r\\n\\r\\n\\r\\n\\r\\n 数组\\r\\n\\r\\n\\r\\n\\r\\n 矩阵\\r\\n\\r\\n\\r\\n\\r\\n求矩阵元素下标，直接代入即可。\\r\\n\\r\\n\\r\\n\\r\\n代入 A(0,0) 和 A(0,1)，分别对应 M(1) 和 M(2)。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 广义表\\r\\n\\r\\n\\r\\n\\r\\n例1：长度为3，深度为2\\r\\n\\r\\n例2: 先取表尾，再取表头，再取表头。\\r\\n\\r\\nhead (head ( tail(LS1) ) )\\r\\n\\r\\n 广义表的基本运算\\r\\n\\r\\n1. 取表头\\r\\n2. 取表尾\\r\\n\\r\\n 二叉树\\r\\n\\r\\n\\r\\n\\r\\n- 满二叉树\"},{\"url\":\"/other/design/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"设计模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"设计模式的目的\\r\\n\\r\\n* 代码重用性（提取重复代码）\\r\\n* 可读性（代码规范，便于阅读）\\r\\n* 可扩展性（方便增加新功能）\\r\\n* 可靠性（增加新功能，对以前的功能没有影响）\\r\\n* 使程序呈现高内聚、低耦合的特性\\r\\n\\r\\n 设计模式的七大基本原则\\r\\n\\r\\ndesign-principle\\r\\n\\r\\n* 单一职责原则\\r\\n\\r\\n* 接口隔离原则\\r\\n\\r\\n* 依赖倒置原则\\r\\n\\r\\n* 里氏替换原则\\r\\n\\r\\n* 开闭原则\\r\\n\\r\\n* 迪米特法则\\r\\n\\r\\n* 合成复用法则\\r\\n\\r\\n 设计模式三大类型\\r\\n\\r\\n 1. 创建型模式\\r\\n\\r\\ndesign-create\\r\\n\\r\\n* 单例模式\\r\\n\\r\\n    * 序列化和反序列化\\r\\n\\r\\n* 工\"},{\"url\":\"/other/design/七大基本原则.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"七大基本原则\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-principle\\r\\n\\r\\n 单一职责原则\\r\\n\\r\\n1. 一种类只能具有一种职责，降低类的复杂度。\\r\\n2. 提高类的可读性，可维护性。\\r\\n3. 降低变更引起的风险。\\r\\n4. 在类中的方法比较少的时候，可以在方法级别保持单一职责原则。其他情况下，都要保持类的类单一职责原则。\\r\\n\\r\\n 接口隔离原则\\r\\n\\r\\n1. 客户端不应该依赖它不需要的接口。\\r\\n2. 一个类对另一个类的依赖应该建立在最小的接口上。\\r\\n\\r\\n 依赖倒置原则\\r\\n\\r\\n1. 依赖倒置原则的中心思想是面向接口编程。\\r\\n2. 抽象不应该依赖细节，细节应该依赖抽象。抽象是接口或者抽象类，细节即为实现类。\\r\\n3. 对于细节的多变性，抽象的\"},{\"url\":\"/other/design/创建型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"创建型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-create\\r\\n\\r\\n 单例模式\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 饿汉式\\r\\n\\r\\n特点：类创建时创建对象，节省时间，占用内存，`以空间换时间`。\\r\\n\\r\\n1. 静态变量实现\\r\\n    \\r\\n    类加载时创建对象，节省时间，占用内存，`以空间换时间`。`推荐使用`，但是比较浪费空间。\\r\\n    \\r\\n    ```java\\r\\n    \\t\\t/**\\r\\n         * 类加载时创建对象，节省时间，占用内存，以空间换时间\\r\\n         */\\r\\n        private final static SingletonHungryOne INSTANCE = new Singleton\"},{\"url\":\"/other/design/结构型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"结构型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-structural\\r\\n\\r\\n 代理模式\\r\\n\\r\\n代理模式是属于结构型的设计模式,指客户端的请求到达真正的对象之前，做一些额外的操作。\\r\\n\\r\\n 静态代理模式\\r\\n\\r\\n\\r\\n以 AspectJ 为代表。指代理类在编译期生成的，与动态代理相比，效率会很高，但是会生成大量代理类。\\r\\n\\r\\n 动态代理模式\\r\\n\\r\\n以 SpringAOP 为代表为代表，代理类是动态生成的。虽然会效率会低一点，但是大大简化了代码和开发量。\\r\\n\\r\\n- JDK 动态代理\\r\\n- CGlib 动态代理\\r\\n\\r\\n 桥接模式\\r\\n\\r\\n抽象类：定义一个抽象类，作为系统的一部分。\\r\\n\\r\\n实现类：定义一个或多个实现类，与抽象类通过聚合（而非\"},{\"url\":\"/other/design/行为型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"行为型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-behavioral\\r\\n\\r\\n 责任链模式\\r\\n\\r\\n责任链模式——某个请求需要多个对象进行处理，从而避免请求的发送者和接收之间的耦合关系。将这些对象连成一条链子，并沿着这条链子传递该请求，直到有对象处理它为止。主要涉及两个角色：\\r\\n\\r\\n\\r\\n- 抽象处理者角色（Handler）：定义出一个处理请求的接口。这个接口通常由接口或抽象类来实现。\\r\\n- 具体处理者角色（ConcreteHandler）：具体处理者接受到请求后，可以选择将该请求处理掉，或者将请求传给下一个处理者。因此，每个具体处理者需要保存下一个处理者的引用，以便把请求传递下去。\\r\\n\\r\\n 优缺点比较\\r\\n\\r\\n优点\\r\\n\\r\\n- 降低耦\"},{\"url\":\"/other/network/HTTP1x和HTTP2x.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP1x和HTTP2.x\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HTTP1.x\\r\\n\\r\\n 数据格式\\r\\n\\r\\nHTTP1.x基于文本传输。\\r\\n\\r\\n- 请求行\\r\\n- 请求头\\r\\n- 请求体\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 缺点\\r\\n\\r\\n1. 占用字节：在HTTP请求中，包含很多空格和换行符。\\r\\n2. 头部不能压缩：在HTTP1.x中，请求头不能压缩。所以存在请求头比较大的问题，出现大头儿子。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n3. 传输效率低：同一个链接（`Keep-Alive`的情况）同时只能处理一个请求，收到响应才会开始发送下一个请求。\\r\\n    - 如果不设置 `Keep-Alive`，则每一次HTTP请求都会新建一个TCP链接。\\r\\n    \\r\\n    &g\"},{\"url\":\"/other/network/HTTP和HTTPS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP和HTTPS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HTTP 和 HTTPS 的区别\\r\\n\\r\\n- 传输问题。\\r\\n    - HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。\\r\\n    - HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。\\r\\n- 建立连接过程。\\r\\n    - HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。\\r\\n    - HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。\\r\\n- 两者的默认端口不一样。\\r\\n    - HTTP 默认端口号是 80。\\r\\n\"},{\"url\":\"/other/network/HTTP常见字段.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP常见字段\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```json\\r\\nPOST /apmServer-sl/sys-user/login HTTP/1.1\\r\\nAccept: application/json, text/plain, */*\\r\\nAccept-Encoding: gzip, deflate\\r\\nAccept-Language: zh-CN,zh;q=0.9\\r\\nAuthorization: clusterid34\\r\\nConnection: keep-alive\\r\\nContent-Length: 101\\r\\nContent-Type: application/json\\r\\nCookie: apm.name=admin\\r\\nHost: 10.1\"},{\"url\":\"/other/network/Linux如何收发网络包.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Linux如何收发网络包\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"2.3 Linux 系统是如何收发网络包的？\\r\\n\\r\\n 网络协议栈\\r\\n\\r\\n\\r\\n\\r\\n1. 应用程序需要通过系统调用，来和 Socket 进程数据交互。\\r\\n2. Socket 层是介于应用层和传输层之间的抽象层。\\r\\n3. 最下面的一层，则是网卡驱动程序和硬件网卡设备。\\r\\n\\r\\n Linux 接收和发送网络包的流程\"},{\"url\":\"/other/network/OSI七层网络模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"OSI七层网络模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 应用层，负责给应用程序提供统一的接口；\\r\\n- 表示层，负责把数据转换成兼容另一个系统能识别的格式；\\r\\n- 会话层，负责建立、管理和终止表示层实体之间的通信会话；\\r\\n- 传输层，负责端到端的数据传输；\\r\\n- 网络层，负责数据的路由、转发、分片；\\r\\n- 数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址；\\r\\n- 物理层，负责在物理网络中传输数据帧；\"},{\"url\":\"/other/network/RTT和SRTT.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RTT和SRTT\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"RTT\\r\\n\\r\\nRTT 指的是客户端发出数据 → 客户端收到服务端发送的确认数据的时间。\\r\\n\\r\\nRTT 称为往返时延。\\r\\n\\r\\n SRTT\\r\\n\\r\\nSRTT（Smoothed Round Trip Time）是一种用于衡量网络延迟的指标，通常用于评估网络连接的质量和性能。SRTT表示在一系列网络往返（Round Trip）中的平滑往返时间。\\r\\n\\r\\nSRTT是通过在每次往返时间（RTT）的基础上应用加权平均算法来计算得出的。加权平均算法会给最近的RTT值更高的权重，以反映出网络延迟的实时变化。\\r\\n\\r\\nSRTT的值越小，表示网络延迟越低，网络连接的质量越好。较低的SRTT值通常意味着网络响应更快，数据传\"},{\"url\":\"/other/network/Socket.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Socket\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Socket 位于应用层和传输层之前的抽象层，是一组调用接口，TCP/IP网络的API函数。\\r\\n\\r\\n实际上是对 TCP/IP协议的封装，只是为了更方便使用 TCP/IP 协议。\\r\\n\\r\\n\\r\\n这个就像操作系统会提供标准的编程接口，比如win32编程接口一样。\\r\\nTCP/IP也要提供可供程序员做网络开发所用的接口，这就是Socket编程接口。\\r\\n&gt; \\r\\n\\r\\n Socket 通信流程\\r\\n\\r\\n\\r\\n\\r\\nSocket按照四元组来标识不同客户端与服务端之间的连接。\\r\\n\\r\\n四元组「源 IP、源端口、目的 IP、目的端口」\\r\\n\\r\\n- `accept()`\\r\\n  \\r\\n    服务端绑定端口之后，进入 `acc\"},{\"url\":\"/other/network/TCPIP四层网络模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP/IP四层网络模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"为什么要有网络模型\\r\\n\\r\\n进程通信的方式\\r\\n\\r\\n- 本机\\r\\n    - 消息队列\\r\\n    - 共享内存\\r\\n    - 管道（程序用来交换数据的地方）\\r\\n- 不同主机\\r\\n    - 网络通信\\r\\n\\r\\n需要网络通信的设备是多种多样的，所以要兼容，就要设定网络通信之间的网络协议。\\r\\n\\r\\n 应用层\\r\\n\\r\\n应用层定义了应用进程之间通信和交互的规则，应用层交互数据单元为报文。\\r\\n\\r\\n不关心数据如何传输，将报文传给传输层做传输。\\r\\n\\r\\n在这一层有很多熟悉的协议，比如 HTTP、HTTPS、DNS等。\\r\\n\\r\\n【计算机网络】TCP / IP 四层协议_tcp/ip协议包含哪几层_L Jiawen的博客-CSDN\"},{\"url\":\"/other/network/TCP分析工具.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP分析工具\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Wireshark · Go Deep\\r\\n\\r\\n\\r\\n\\r\\n 三次握手\\r\\n\\r\\n\\r\\n\\r\\n 第1次握手\\r\\n\\r\\n\\r\\n\\r\\nsyn设置为1，表明这是一个 SYN包\\r\\n\\r\\n\\r\\n\\r\\nseq = 1390201126\\r\\n\\r\\n\\r\\n\\r\\n 第2次握手\\r\\n\\r\\nsyn=1 同时 ACK=1，表明这是一个 SYN/ACK包\\r\\n\\r\\n\\r\\n\\r\\n服务端返回的 ACK = 客户端第一次发送的 seq+1 = 1390201126+1\\r\\n\\r\\n同时服务端向客户端返回了自己的 seq（如果第三次握手客户端返回的ack=seq+1，代表客户端收到了自己发的seq）\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n 第3次握手\\r\\n\\r\\n可以看到第 3 次握手的\"},{\"url\":\"/other/network/TCP协议.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP协议\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"TCP 协议灵魂 12 问，巩固你的网路底层基础！-腾讯云开发者社区-腾讯云\\r\\n\\r\\n\\r\\n\\r\\n TCP和UDP的区别\\r\\n\\r\\n- 面向连接\\r\\n    - TCP 需要客户端与服务端之间通过三次握手建联，之后才可以发送数据。\\r\\n    - UDP直接向服务端发数据包。\\r\\n- 可靠性\\r\\n    - 有状态\\r\\n        - TCP发数据包时，保证数据包按顺序到达。\\r\\n    - 可控制\\r\\n        - 当TCP协议丢包时，可以控制重发和自己的发送速度，保证数据包完整和有序。\\r\\n    - UDP 是无状态并且不可控的。\\r\\n- 基于字节流\\r\\n    - TCP将数据包通过字节流发送。\\r\\n   \"},{\"url\":\"/other/network/TCP粘包拆包.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP粘包拆包\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"发生粘包的原因\\r\\n\\r\\n- 要发送的数据小于 TCP 发送缓冲区的大小，TCP 将多次写入缓冲区的数据一次发送出去，将会发生粘包；\\r\\n- 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包；\\r\\n- 要发送的数据大于 TCP 发送缓冲区剩余空间大小，将会发生拆包；\\r\\n- 待发送数据大于 MSS（最大报文长度），TCP 在传输前将进行拆包。即 TCP 报文长度 - TCP 头部长度 \\r\\n\\r\\n 解决粘包拆包问题\\r\\n\\r\\n- 定长消息：发送端将每个数据包封装为固定长度\\r\\n- 特殊分隔符：在数据尾部增加特殊字符进行分割\\r\\n- 消息头：将数据分为两部分，一部分是头部，一部分是内容体；其中头部结构大小\"},{\"url\":\"/other/network/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"计算机网络\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础\\r\\n\\r\\n- TCP/IP四层网络模型\\r\\n- OSI七层网络模型\\r\\n- 网址访问页面中间发生了哪些过程\\r\\n- Linux如何收发网络包\\r\\n- 网络包的封装原理\\r\\n- Socket\\r\\n\\r\\n TCP\\r\\n\\r\\n- TCP协议\\r\\n- TCP分析工具\\r\\n\\r\\n\\r\\n- RTT和SRTT\\r\\n- 流量控制-滑动窗口\\r\\n\\r\\n- 拥塞控制\\r\\n- 重传机制\\r\\n- TCP粘包拆包\\r\\n\\r\\n\\r\\n UDP\\r\\n\\r\\nUDP不需要连接，可以单播和广播。\\r\\n\\r\\n HTTP\\r\\n- HTTP常见字段\\r\\n- HTTP和HTTPS\\r\\n- HTTP1x和HTTP2x\\r\\n\\r\\n 参考链接\\r\\n\\r\\n图解网络介绍\"},{\"url\":\"/other/network/拥塞控制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"拥塞控制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"流量控制是避免数据填满发送方的缓冲区。\\r\\n\\r\\n而拥塞控制是避免发送方的数据填满整个网络。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n在⽹络出现拥堵时，如果继续发送⼤量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是⼀重传就会导致⽹络的负担更重，于是会导致更⼤的延迟以及更多的丢包，这个情况就会进⼊恶性循环被不断地放⼤….\\r\\n\\r\\n所以，TCP 不能忽略整个网络中发⽣的事，它被设计成⼀个⽆私的协议，当⽹络发送拥塞时，TCP 会⾃我牺牲，降低发送的数据流。\\r\\n\\r\\n 拥塞窗口\\r\\n\\r\\n拥塞窗⼝ cwnd是发送⽅维护的⼀个的状态变量，它会根据⽹络的拥塞程度动态变化的。\\r\\n\\r\\n发送窗⼝ swnd 和接\"},{\"url\":\"/other/network/流量控制-滑动窗口.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"流量控制-滑动窗口\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在TCP中，滑动窗口用来流量控制。确保发送方不会过快的发送数据导致接收方无法处理数据。\\r\\n\\r\\nTCP拥塞控制是为了解决发送方以过高的速率发送导致网络中出现阻塞，其核心思想就是发生重传时控制发送方滑动窗口（通过控制拥塞窗口cwnd）的大小，从而控制其发送速率。\\r\\n\\r\\n 滑动窗口\\r\\n\\r\\nTCP窗口包括发送窗口和接收窗口，用来限制不同端所能容纳数据的上限，达到控制发送数据的速率。\\r\\n\\r\\n\\r\\n\\r\\nTCP报文里面的窗口大小，作用是告诉对方本端的接受缓冲区还能容纳多少字节的数据。\\r\\n\\r\\n\\r\\n\\r\\n在通信过程中，接收方每次收到数据包，在发送确认报文的时候，还需要告诉发送方自己的缓冲区剩余大小。缓冲区剩余大小，\"},{\"url\":\"/other/network/网址访问页面中间发生了哪些过程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"网址访问页面中间发生了哪些过程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"2.2 键入网址到网页显示，期间发生了什么？\\r\\n\\r\\n URL解析\\r\\n\\r\\n URL组成信息\\r\\n\\r\\nURL实际上就是访问 Web服务器里面的文件资源。\\r\\n\\r\\n\\r\\n\\r\\n 组装HTTP报文\\r\\n\\r\\n根据 URL 解析得到的内容，进行报文组装。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n DNS域名解析\\r\\n\\r\\n解析URL时，如果web服务器是域名，需要走DNS服务器进行域名解析，得到真实访问的IP地址。\\r\\n\\r\\n 域名组成\\r\\n\\r\\n`www.server.com.` 类似树状结构，越右等级越高。\\r\\n\\r\\n域名组成都代表了DNS服务器，里面保存了域名和IP的对应关系。\\r\\n\\r\\n域名服务器就像是一个树状结构。\\r\\n\\r\\n- 根\"},{\"url\":\"/other/network/网络包的封装原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"网络包的封装原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 TCP/IP 四层网络模型中，网络包每层的包装如下：\\r\\n\\r\\n- 传输层，给应用数据前面增加了 TCP 头；\\r\\n- 网络层，给 TCP 数据包前面增加了 IP 头；\\r\\n- 网络接口层，给 IP 数据包前后分别增加了帧头和帧尾；\\r\\n\\r\\n每层增加的头部和尾部，都有每层独特的作用，按照各自的协议填充。\\r\\n\\r\\n在物理链路上并不能传输任意大小的数据包，在以太网中，规定了最大传输单元（MTU）为 1500 字节，规定了单次传输的最大 IP 包的大小。\\r\\n\\r\\n当网络包超过 MTU 时，就会在网络层分片，确保分片后的包不会超过 MTU 大小。\\r\\n\\r\\n- 如果 MTU 越小，网络包分片数越多，那么网络吞吐能力\"},{\"url\":\"/other/network/重传机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"重传机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"超时重传\\r\\n\\r\\n原理是在发送某一个数据以后就开启一个计时器，在一定时间内如果没有得到发送的数据报的 ACK 报文，那么就重新发送数据，直到发送成功为止。\\r\\n\\r\\n RTT\\r\\n\\r\\nRTT（Round-Trip Time，往返时间）。数据包一次的往返时间。\\r\\n\\r\\n\\r\\n\\r\\nSRTT：平均的RTT\\r\\n\\r\\n 缺点\\r\\n\\r\\n- 当一个报文丢失时，会等待一定的超时周期，才重传分组，增加了端到端的时延。\\r\\n- 当一个报文丢失时，在其等待超时的过程中，可能会出现这种情况：其后的报文段已经被接收端接收但却迟迟得不到确认，发送端会认为也丢失了，从而引起不必要的重传，既浪费资源也浪费时间。\\r\\n- 并且，对于 TCP，如果\"},{\"url\":\"/other/observability/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可观测性常见维度\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"可观测性指的是对于系统内部运行状态的全面洞察和理解能力。\\r\\n\\r\\n可观测性项⽬旨在提供⼯具和解决⽅案，帮助开发⼈员和运维团队更好地监视、调试和理解其应⽤程序的行为。\\r\\n\\r\\n 维度\\r\\n\\r\\n- 日志采集 （log）\\r\\n- 指标采集 （Metric）\\r\\n- 链路追踪（Trace）\\r\\n- 告警管理（AlertManager）\\r\\n- 可视化（Visualization）\\r\\n\\r\\n整个可观测项目，维度除了常见的 log、metric、trace之外。还包括告警和可视化。\\r\\n\\r\\n 指标\\r\\n\\r\\n指标又可以分为：\\r\\n\\r\\n- 基础设施\\r\\n\\r\\n  服务器、数据库、MQ的指标。\\r\\n\\r\\n- 应用维度\\r\\n\\r\\n  应用包含模块\"},{\"url\":\"/other/observability/log/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"日志收集全链路\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ELFK\\r\\n\\r\\nELFK 指的是 elasticsearch+logstash+filebeat+kibana\\r\\n\\r\\n 日志管理\\r\\n\\r\\n日志收集→格式化分析→检索和可视化→日志告警\\r\\n\\r\\n\\r\\n\\r\\n 日志架构\\r\\n\\r\\n 小规模环境\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 大规模生产环境\\r\\n\\r\\nELFK + Kafka\\r\\n\\r\\n Logstash\\r\\n\\r\\n从多个来源采集数据，转换数据，然后将数据放到不同的数据库中。\\r\\n\\r\\nda 就很像 logstash 的功能设计。\\r\\n\\r\\n 架构\\r\\n\\r\\n\\r\\n\\r\\nLogstash 接入数据源数据，经过内部 Pipeline，将数据可以写到不同的存储（ES、Kafka）里面。\\r\\n\\r\\nLog\"},{\"url\":\"/other/observability/opentelemetry/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Opentelemetry\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"docs-cn/OT.md at main · open-telemetry/docs-cn\\r\\n\\r\\n OpenTracing&OpenCensus\\r\\n\\r\\n- OpenTracing 制定了一套平台无关、厂商无关的协议标准，使得开发人员能够方便的添加或更换底层 APM 的实现。\\r\\n- OpenCensus支持Metrics、分布式跟踪。\\r\\n\\r\\n OpenTelemetry\\r\\n\\r\\nOpenTelemetry 的核心工作目前主要集中在 3 个部分：\\r\\n\\r\\n1. 规范的制定和协议的统一，规范包含数据传输、API的规范。协议的统一包含：HTTP W3C的标准支持及GRPC 等框架的协议标准。\\r\\n2. 多\"},{\"url\":\"/other/observability/opentelemetry/可观测性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可观测性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"可观测性指的是对于系统内部运行状态的全面洞察和理解能力。\\r\\n\\r\\n可观测性项⽬旨在提供⼯具和解决⽅案，帮助开发⼈员和运维团队更好地监视、调试和理解其应⽤程序的行为。\\r\\n\\r\\n 维度\\r\\n\\r\\n- 日志采集 （log）\\r\\n- 指标采集 （Metric）\\r\\n- 链路追踪（Trace）\\r\\n- 告警管理（AlertManager）\\r\\n- 可视化（Visualization）\\r\\n\\r\\n整个可观测项目，维度除了常见的 log、metric、trace之外。还包括告警和可视化。\\r\\n\\r\\n 指标\\r\\n\\r\\n指标又可以分为：\\r\\n\\r\\n- 基础设施\\r\\n\\r\\n  服务器、数据库、MQ的指标。\\r\\n\\r\\n- 应用维度\\r\\n\\r\\n  应用包含模块\"},{\"url\":\"/other/observability/skywalking/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Skywalking\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Skywalking\\r\\n\\r\\n- 组件安装\\r\\n- 源码学习\"},{\"url\":\"/other/observability/skywalking/源码学习.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"源码学习\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Category: SkyWalking | 芋道源码 —— 纯源码解析博客\\r\\n\\r\\nSkyWalking8.7源码解析\\r\\n\\r\\n 告警组件\\r\\n\\r\\n 初始化Kafka消费者\\r\\n\\r\\n```java\\r\\n@Slf4j\\r\\npublic class KafkaFetcherProvider extends ModuleProvider {\\r\\n    private KafkaFetcherHandlerRegister handlerRegister;\\r\\n    private KafkaFetcherConfig config;\\r\\n\\r\\n    @Override\\r\\n    public String na\"},{\"url\":\"/other/observability/skywalking/组件安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"组件安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"OAP\\r\\n\\r\\n- 配置文件\\r\\n  \\r\\n    ```java\\r\\n    apache-skywalking-apm-bin/config/application.yml\\r\\n    ```\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n- 启动脚本\\r\\n  \\r\\n    ```java\\r\\n    sh bin/oapService.sh\\r\\n    ```\\r\\n    \\r\\n\\r\\n UI\\r\\n\\r\\n- 配置\\r\\n  \\r\\n    ```java\\r\\n    apache-skywalking-apm-bin/webapp/webapp.yml\\r\\n    ```\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n- 启动脚本\\r\\n  \\r\\n    ```java\\r\\n\"},{\"url\":\"/personal/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"personal\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"&lt;div align=\\\"center\\\"\\r\\n  &lt;img src=\\\"https://capsule-render.vercel.app/api?type=waving&color=gradient&height=300&section=header&text=Albert%20Yang&fontSize=90&animation=fadeIn&fontAlignY=38&desc=热爱编程%20|%20追求卓越%20|%20创新思维&descAlignY=55&descAlign=62\\\" /&gt;\\r\\n&lt;/div&gt;\\r\\n&lt;p align=\\\"center\\\" style=\"}]},\"groupPostsByYearMonth\":{\"2025 \":{\"08\":[{\"url\":\"/cloudnative/docker/Docker学习总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Docker学习总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本知识\\r\\n\\r\\n 1. Docker 是什么？\\r\\n\\r\\ndocker 是一种容器化虚拟技术，解决了运行环境和配置问题，方便持续集成并有助于项目整体发布。\\r\\n\\r\\n 2. Docker 能干嘛？\\r\\n\\r\\n*一次构建、随处运行。*\\r\\n\\r\\n- 更快速的应用交付和部署。\\r\\n- 更便捷的升级和扩缩容。\\r\\n- 更简单的系统运维。\\r\\n- 更高效的计算源利用。\\r\\n\\r\\n 基本组成\\r\\n\\r\\n 1. 镜像\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 2. 容器\\r\\n\\r\\n&gt; Docker 利用容器（Container）独立运行一个或一组应，容器是用镜像创建的运行实例。\\r\\n&gt; \\r\\n\\r\\n它可以被启动、开始、停止、删除。每个容器都是相\"},{\"url\":\"/cloudnative/docker/docker镜像压缩.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"docker镜像压缩\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"tar包\\r\\n\\r\\n\\r\\n\\r\\n```\\r\\ndocker save tomcat-apm-0915 -o ./tomcat-apm-0915.tar\\r\\n```\\r\\n\\r\\n```\\r\\ndocker load &lt; tomcat-apm-0915.tar\\r\\n```\\r\\n\\r\\nDocker 复制镜像到其他主机 - 彦祚 - 博客园\\r\\n\\r\\n tar.gz包\\r\\n\\r\\n 保存镜像\\r\\n\\r\\n`docker save &lt;myimage\\r\\n\\r\\n```\\r\\ndocker save xxx:xxx| gzip&gt;xxx.tar.gz\\r\\n```\\r\\n\\r\\n 加载镜像\\r\\n\\r\\n`gunzip -c &lt;myimage&gt;_&lt\"},{\"url\":\"/cloudnative/docker/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Docker\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"学习总结\\r\\n- Docker学习总结\\r\\n\\r\\n\\r\\n 使用总结\\r\\n- 容器软件安装\\r\\n- docker镜像压缩\\r\\n- 制作Tomcat镜像\\r\\n- 容器新增bash\"},{\"url\":\"/cloudnative/docker/制作Tomcat镜像.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"制作Tomcat镜像\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"DockerFile文件内容\\r\\n\\r\\n- tomcat 基础镜像\\r\\n  \\r\\n    ```bash\\r\\n    \\r\\n     使用基于 JDK 8 的官方 Tomcat 镜像作为基础镜像\\r\\n    FROM tomcat:8-jdk8\\r\\n    \\r\\n     修改默认的 shell\\r\\n    RUN ln -sf /bin/bash /bin/sh\\r\\n    \\r\\n     暴露 Tomcat 的默认 HTTP 端口\\r\\n    EXPOSE 8080\\r\\n    \\r\\n     设置容器启动时执行的命令\\r\\n    CMD [\\\"catalina.sh\\\", \\\"run\\\"]\\r\\n    ```\\r\\n    \\r\\n- \"},{\"url\":\"/cloudnative/docker/容器新增bash.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"容器新增bash\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"安装方式\\r\\n\\r\\n- wget 下载\\r\\n  \\r\\n    ```bash\\r\\n    from busybox\\r\\n    \\r\\n     下载 bash 二进制文件\\r\\n    RUN wget -O /bin/bash http://ftp.gnu.org/gnu/bash/bash-5.1.tar.gz\\r\\n    \\r\\n     设置可执行权限\\r\\n    RUN chmod +x /bin/bash\\r\\n    \\r\\n     运行命令\\r\\n    CMD [\\\"echo\\\", \\\"Hello, World!\\\"]\\r\\n    ```\\r\\n    \\r\\n- 本地安装\\r\\n  \\r\\n    ```bash\\r\\n    from \"},{\"url\":\"/cloudnative/docker/容器软件安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"容器软件安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"RabbitMQ\\r\\n\\r\\n参考博客\\r\\n\\r\\ndocker安装RabbitMQ\\r\\n\\r\\n---\\r\\n\\r\\n1. 查找镜像\\r\\n   \\r\\n    ```java\\r\\n    docker search rabbitmq\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n2. 拉取镜像\\r\\n   \\r\\n    ```java\\r\\n    docker pull rabbitmq\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 启动镜像\\r\\n   \\r\\n    ```java\\r\\n    docker run -d --hostname my-rabbit --name rabbit -p 15672:15\"},{\"url\":\"/cloudnative/k8s/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"K8s\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- k8s常用命令\\r\\n- k8s问题排查流程图\"},{\"url\":\"/cloudnative/k8s/k8s常用命令.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"k8s常用命令\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"常用命令总结\\r\\n\\r\\n node\\r\\n\\r\\n- 查看所有的node\\r\\n  \\r\\n    ```\\r\\n    kubectl get nodes\\r\\n    ```\\r\\n    \\r\\n- 查看node名与Host文件的相互解析\\r\\n  \\r\\n    ```\\r\\n    cat /etc/hosts\\r\\n    ```\\r\\n    \\r\\n- 查看本机 hostname\\r\\n  \\r\\n    `Plain Text   cat /etc/hostname`\\r\\n    \\r\\n\\r\\n namespace\\r\\n\\r\\n- 查看所有的namespace\\r\\n  \\r\\n    ```\\r\\n    [root@master ~] kubectl  get n\"},{\"url\":\"/cloudnative/k8s/k8s问题排查流程图.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"k8s问题排查流程图\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"深度解密｜基于 eBPF 的 Kubernetes 问题排查全景图发布-阿里云开发者社区\"},{\"url\":\"/cloudnative/prometheus/TSDB.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TSDB\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Prometheus的 TSDB（Time Series Database）作为内置的时序数据库。\\r\\n\\r\\n 存储原理\\r\\n\\r\\nTSDB 既使用内存也使用磁盘进行数据存储。\\r\\n\\r\\n\\r\\n\\r\\n Head\\r\\n\\r\\n在Prometheus中，Head 是数据库的内存部分，用于存储最近写入的数据。\\r\\n\\r\\n当数据在Head中存储2小时后，会被转移到磁盘上的持久块（block）中。这些持久块是不变的，每个块代表一段时间的数据，并且按照时间顺序进行组织和存储。\\r\\n\\r\\n\\r\\n\\r\\n Block块\\r\\n\\r\\nPrometheus中以每2个小时为一个时间窗口，即将2小时内产生的数据存储在一个block中，监控数据会以时间段的形式\"},{\"url\":\"/cloudnative/prometheus/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Prometheus\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 架构\\r\\n- TSDB\\r\\n- 数据模型\\r\\n- node_exporter源码\"},{\"url\":\"/cloudnative/prometheus/node_exporter源码.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"node_exporter源码\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"简单流程\\r\\n\\r\\n1. 定时任务 30s 执行一次\\r\\n    1. 调用采集指标的方法\\r\\n2. 不同 Collector 采集自己的指标\\r\\n    1. 内存\\r\\n        - 读取 `/`@\\r\\n          \\r\\n            `proc/meminfo`文件内容\\r\\n            \\r\\n            ```go\\r\\n            MemTotal:       16267496 kB\\r\\n            MemFree:          803084 kB\\r\\n            MemAvailable:    1507880 kB\\r\\n \"},{\"url\":\"/cloudnative/prometheus/数据模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Prometheus的存储实现上所有的监控样本都是以 time-series 的形式保存在 Prometheus 内置的TSDB（时序数据库）中，而 time-series 所对应的监控指标 (metric) 也是通过 labelset 进行唯一命名的。\\r\\n\\r\\n 样本数据\\r\\n\\r\\n- 指标(metric)：metric name 和描述当前样本特征的 labelsets;\\r\\n- 时间戳(timestamp)：一个精确到毫秒的时间戳;\\r\\n- 样本值(value)： 一个float64的浮点型数据表示当前样本的值。\\r\\n\\r\\n```\\r\\n&lt;--------------- metric -------\"},{\"url\":\"/cloudnative/prometheus/架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Prometheus架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- Promtheus 默认采取主动拉的策略，可以配置各个exporter的拉取间隔。\\r\\n    - Exporter 被动暴露数据，Prometheus 主动拉取。\\r\\n- 但是Promtheus也可以使用 Pushgateway 实现 Push 模型。\\r\\n    - exporter 将数据推给 Pushgateway，Promtheus从Pushgateway拉数据。\"},{\"url\":\"/database/clickhouse/ClickHouse基础.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse基础\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"列式存储\\r\\n\\r\\nclickhouse 是 *列式存储* 数据库\\r\\n\\r\\n在磁盘上按列存储，即按某个字段进行存储。\\r\\n\\r\\n\\r\\n\\r\\n所以列式存储更适合进行查询，比如某一行的聚合、计算、求和等。\\r\\n\\r\\n 列式存储的好处\\r\\n\\r\\n1. 对于某列的聚合、计数、求和等操作要比行式存储更快。\\r\\n   \\r\\n    查询更快。\\r\\n    \\r\\n    - 行式存储，增改删更加方便，因为只需要找到对应的行记录，直接删除即可。但是列式存储对比起来，增改删要更繁琐一点。\\r\\n2. 每一列的数据类型是一样的，这样能更好的进行数据压缩。\\r\\n   \\r\\n    方便数据压缩，节省磁盘\\r\\n    \\r\\n    - 与 es 相比，作为常\"},{\"url\":\"/database/clickhouse/ClickHouse安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"docker下安装clickhouse_docker 安装clickhouse-CSDN博客\\r\\n\\r\\n使用 clickhouse-client 进入 ck\\r\\n\\r\\n mac 安装\\r\\n\\r\\n```java\\r\\ndocker run --rm -d --name=clickhouse \\\\\\r\\n-e CLICKHOUSE_ADMIN_PASSWORD=\\\"123456\\\" \\\\\\r\\n--ulimit nofile=262144:262144 \\\\\\r\\n-p 8123:8123 -p 9009:9009 -p 9090:9000 \\\\\\r\\n-v /Users/yangjunwei/ck/config:/etc/clickhou\"},{\"url\":\"/database/clickhouse/ClickHouse物化列序列化报错.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse物化列序列化报错问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"报错内容\\r\\n\\r\\n```java\\r\\nNo serializer found for column 'date'. Did you forget to register it?\\r\\n\\tat com.clickhouse.client.api.Client.insert(Client.java:1317)\\r\\n\\tat com.clickhouse.client.api.Client.insert(Client.java:1266)\\r\\n```\\r\\n\\r\\n 表结构\\r\\n\\r\\n```java\\r\\nCREATE TABLE IF NOT EXISTS metric_data\\r\\n(\\r\\n    `placeId` UInt3\"},{\"url\":\"/database/clickhouse/ClickHouse高级.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse高级\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MergeTree\\r\\n\\r\\nClickHouse 中最强大的表引擎当属 MergeTree（合并树）引擎及该系列（MergeTree）中的其他引擎，支持索引和分区，地位可以相当于 innodb 之于 Mysql。而且基于 MergeTree，还衍生除了很多小弟，也是非常有特色的引擎。\\r\\n\\r\\n建表语句\\r\\n\\r\\n```sql\\r\\ncreate table t_order_mt(\\r\\n id UInt32,\\r\\n sku_id String,\\r\\n total_amount Decimal(16,2),\\r\\n create_time Datetime\\r\\n) engine = MergeTree\\r\\n partiti\"},{\"url\":\"/database/clickhouse/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ClickHouse\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- ClickHouse安装\\r\\n- ClickHouse基础\\r\\n- ClickHouse高级\\r\\n- 为什么弃用Elasticsearch\"},{\"url\":\"/database/clickhouse/为什么弃用Elasticsearch.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"对于开发来说：\\r\\n\\r\\n1. 大批量数据查询导致 es 的 CPU 飙升。\\r\\n2. 数据量增大之后，es 的查询效率下降，影响接口性能。\\r\\n3. 聚合效率低。\\r\\n\\r\\n对于运维来说：\\r\\n\\r\\n1. 维护成本很大，在数据量大的情况，es 占用磁盘空间很大，没有很好的压缩手段。\\r\\n2. es 很占内存，内存配置为整体内存的一半。\\r\\n\\r\\n 问题记录\\r\\n\\r\\n- 缓存计算系统评分导致 es 的 cpu 飙升。\\r\\n\\r\\n  系统评分需要查询 es 的流量信息进行计算，实时查询很慢。做了定时任务计算分数信息并作缓存。\\r\\n\\r\\n    - 经常发现 es 的 cpu 会被打满。排查发现随着系统的增多，当定时任务跑的时候\"},{\"url\":\"/database/mysql/B树和B+树.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"B树和B+树\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"B树\\r\\n\\r\\n\\r\\n\\r\\n每个节点是一个磁盘快。每个磁盘快有固定大小，可以存储多个K-V键值对。\\r\\n\\r\\n每个磁盘快包含指向下层节点的指针，方便查找。\\r\\n\\r\\n*由于每个节点存储了更多的键值对数据，可以有效降低查找树的次数，并减少查询磁盘。*\\r\\n\\r\\n- \\r\\n\\r\\n B+树\\r\\n\\r\\n\\r\\n\\r\\n 存储空间\\r\\n\\r\\nB+树是在B树的基础上演进的。\\r\\n\\r\\nB+树的非叶子结点是不保存数据的，仅保存键值。\\r\\n\\r\\n在 InnoDB中页大小是固定的，在只保存键值的情况下，同一个数据页能保存更多的键值。这样就能保证整个树的层级大大降低，减少向下搜索时候的磁盘IO次数，会提高数据的查询效率。\\r\\n\\r\\nInnoDB 中页的默认大小是 \"},{\"url\":\"/database/mysql/InnoDB存储引擎.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"InnoDB存储引擎\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"存储引擎\\r\\n\\r\\n在系统执行 `update` 语句时，经过 `Server层` 的处理，最终要由执行器去调用存储引擎去执行。\\r\\n\\r\\n而 MySQL 存储引擎有很多种，比如 `InnoDB`、`MyISAM`等。\\r\\n\\r\\nMySQL的默认存储引擎已经变更为了 `InnoDB`\\r\\n\\r\\n---\\r\\n\\r\\n`update` 语句操作的数据最终是要写入磁盘中的，但是如果每次都直接操作磁盘，磁盘I/O的开销是很大的。所以需要每次将操作的数据加载到内存中，减少磁盘I/O次数，再在适当时机进行刷盘操作即可。InnoDB 中使用的这块内存叫做 `Buffer Pool`。\\r\\n\\r\\n 缓冲池 - Buffer Pool\\r\"},{\"url\":\"/database/mysql/MySQL基础架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL基础架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL是 `C/S（Client端 / Server端）` 架构。\\r\\n\\r\\n 架构图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nMySQL架构包含 `Server层` 和 `存储引擎层` 。\\r\\n\\r\\n- Server 层包含 `连接器` 、`分析器`、`优化器`、`执行器`。\\r\\n- 存储引擎层包含 `引擎层`、`存储层`。\\r\\n\\r\\n 一、连接器\\r\\n\\r\\n 连接器的作用\\r\\n\\r\\n- 跟客户端建立连接。\\r\\n- 维持和管理连接。\\r\\n- 校验用户和获取用户权限。\\r\\n\\r\\n---\\r\\n\\r\\n 校验用户\\r\\n\\r\\n客户端进行连接MySQL的命令如下：\\r\\n\\r\\n```java\\r\\nmysql -h$ip -P$port -u$user -p\\r\\n`\"},{\"url\":\"/database/mysql/MySQL日志系统.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL日志系统\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"undo.log\\r\\n\\r\\n记录被更新前的数据。\\r\\n\\r\\n\\r\\n\\r\\nInnoDB 支持事务，在事务执行失败回滚时，数据会回到操作前的样子。\\r\\n\\r\\n`undo.log` 就是为了事务回滚，恢复数据的。\\r\\n\\r\\n回滚对应的操作如下：\\r\\n\\r\\n1. insert\\r\\n   \\r\\n    插入一条记录时，将这条记录的主键记录下来，回滚时根据主键删除。\\r\\n    \\r\\n2. update\\r\\n   \\r\\n    更新一条记录时，将更新的列的旧值记录下来，回滚时将这些值更新回去。\\r\\n    \\r\\n3. delete\\r\\n   \\r\\n    删除一条记录时，将这条记录记录下来，回滚时重新插入到表中。\\r\\n    \\r\\n\\r\\n---\\r\\n\\r\\n在\"},{\"url\":\"/database/mysql/MySQL根据idb文件恢复数据.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL根据idb文件恢复数据\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL根据idb文件恢复数据\\r\\n\\r\\n1. MySQl解除表名\\r\\n   \\r\\n    `Plain Text  ALTER TABLE 表名 DISCARD TABLESPACE`\\r\\n    \\r\\n2. 复制 idb 文件到 data目录。\\r\\n   \\r\\n    \\r\\n    \\r\\n3. idb 文件增加权限。\\r\\n   \\r\\n    ```\\r\\n    chown mysql:mysql user_tenant.ibd\\r\\n    ```\\r\\n    \\r\\n    \\r\\n    \\r\\n4. 重新导入表数据文件\\r\\n   \\r\\n    ```\\r\\n    ALTER TABLE 表名 IMPORT TABLESPACE\\r\\n\"},{\"url\":\"/database/mysql/MySQL的binlog日志过期删除.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL的binlog日志过期删除\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"问题\\r\\n\\r\\nmysql的binlog日志过多导致磁盘告警。\\r\\n\\r\\n部署脚本中没有配置 `binlog` 的失效时间，默认是30天。\\r\\n\\r\\n 手动清理\\r\\n\\r\\n1. 查看正在使用的binlog\\r\\n   \\r\\n    ```sql\\r\\n    show master status\\r\\n    ```\\r\\n    \\r\\n2. 删除指定binlog之前的所有binlog\\r\\n   \\r\\n    ```sql\\r\\n    purge binary logs to 'bin.000055'\\r\\n    ```\\r\\n    \\r\\n\\r\\n 配置自动清理\\r\\n\\r\\n 查看日志过期时间\\r\\n\\r\\n```sql\\r\\nshow variables li\"},{\"url\":\"/database/mysql/OrderBy和limit混用的bug.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"OrderBy和limit混用的bug\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"案例\\r\\n\\r\\n```java\\r\\nselect * from table order by month desc limit 0,10\\r\\n```\\r\\n\\r\\nmonth 重复度高的情况下，limt查询会出bug。导致部分数据丢失。可以增加区分度高的字段一起排序，比如id。\\r\\n\\r\\n```java\\r\\nselect * from table order by month desc,id desc limit 0,10\\r\\n```\"},{\"url\":\"/database/mysql/SQL语句的抖动问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SQL语句的抖动问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"有时候在执行 SQL 的时候，突然会变得很慢。这种慢比较随机，看起来像是抖动一样。\\r\\n\\r\\n更新数据流程可以简化一下。\\r\\n\\r\\n1. 内存（buffer pool）中的数据 flush 到磁盘。\\r\\n2. 数据写入到 redo log 中。\\r\\n\\r\\n其中 buffer pool 中的数据页有三种状态：\\r\\n\\r\\n1. 数据页无数据。\\r\\n2. 数据页是干净页。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n3. 数据页是脏页。\\r\\n   \\r\\n    &gt; 脏页指的是内存中的数据被更新，但是没有flush到磁盘。出现内存和磁盘数据不一致的情况，此时该数据页称为脏页面。\\r\\n    &gt; \\r\\n\\r\\n 性能问题\"},{\"url\":\"/database/mysql/explain使用总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"explain使用总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"参数\\r\\n\\r\\n| id | Columns | JSON Name | Meaning |\\r\\n| --- | --- | --- | --- |\\r\\n| 1 | id | select_id | 每个select子句的标识id |\\r\\n| 2 | select_type | None | select语句的类型 |\\r\\n| 3 | table | table_name | 当前表名 |\\r\\n| 4 | partitions | partitions | 匹配的分区 |\\r\\n| 5 | type | access_type | 当前表内访问方式 join type |\\r\\n| 6 | possible_key\"},{\"url\":\"/database/mysql/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MySQL数据库\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL基础\\r\\n\\r\\n- MySQL基础架构\\r\\n- InnoDB存储引擎\\r\\n---\\r\\n- MySQL日志系统\\r\\n---\\r\\n- 一条更新SQL的执行过程\\r\\n---\\r\\n- 事务隔离\\r\\n---\\r\\n- B树和B+树\\r\\n- 索引\\r\\n---\\r\\n- 锁\\r\\n- 行锁\\r\\n\\r\\n\\r\\n\\r\\n MySQL总结\\r\\n\\r\\n- SQL语句的抖动问题\\r\\n- 索引失效的场景\\r\\n- explain使用总结\\r\\n- 慢查询日志\\r\\n\\r\\n\\r\\n 问题总结\\r\\n- OrderBy和limit混用的bug\\r\\n- MySQL的binlog日志过期删除\\r\\n- MySQL根据idb文件恢复数据\"},{\"url\":\"/database/mysql/一条更新SQL的执行过程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"一条更新SQL的执行过程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"juejin.cn\\r\\n\\r\\n```java\\r\\nmysql\\r\\n```\\r\\n\\r\\n 执行流程\\r\\n\\r\\n1. 执行器先找引擎取出 ID=2 这一行记录。\\r\\n    - 如果该行记录在 `Buffer Pool` 中存在，会直接返回数据给执行器。\\r\\n    - 如果该行记录不存在，则会先进行如下操作，再返回数据给执行器。\\r\\n        - 从磁盘中查找数据。\\r\\n        - 将数据写入内存 `Buffer Pool` 中。\\r\\n        - 将数据写入 `undo.log`（记录 insert、update、delete等修改数据的操作）。\\r\\n2. 执行器获取到引擎给的行数据，把这条数据更新 c\"},{\"url\":\"/database/mysql/事务隔离.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"事务隔离\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"简单来说，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。\\r\\n\\r\\n在 MySQL 中，事务支持是在`引擎层`实现的。你现在知道，MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。\\r\\n\\r\\n比如 MySQL 原生的 `MyISAM 引擎就不支持事务`，这也是 MyISAM 被 InnoDB 取代的重要原因之一。\\r\\n\\r\\n 事务问题\\r\\n\\r\\n 脏读\\r\\n\\r\\n读到了别的事务 修改过 但未提交的数据\\r\\n\\r\\n 不可重复读\\r\\n\\r\\n指的是变没变化的问题。数据被修改了导致前后两次查询结果不一样。\\r\\n\\r\\n原来是 A，现在是 B，就是不可重复读。\\r\\n\\r\\n 幻读\\r\\n\\r\\n指的是存不存在的问题，原来存\"},{\"url\":\"/database/mysql/慢查询日志.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"慢查询日志\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL中，需要查看执行慢的SQL，需要先开启慢查询日志。\\r\\n\\r\\nMySQL的慢查询日志，记录了MySQL中响应时间超过阈值的SQL语句。\\r\\n\\r\\n 参数说明\\r\\n\\r\\n- slow_query_log：是否开启慢查询日志，1表示开启，0表示关闭。\\r\\n- log-slow-queries ：旧版（5.6以下版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name-slow.log\\r\\n- slow-query-log-file：新版（5.6及以上版本）MySQL数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件host_name\"},{\"url\":\"/database/mysql/索引.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"索引\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准。\\r\\n\\r\\n InnoDB的索引模型\\r\\n\\r\\n B+树\\r\\n\\r\\n\\r\\n\\r\\nB+树的每个叶子节点存放元素有限，每个叶子节点为一个 page，针对元素的数量会产生页分裂、页合并等现象。\\r\\n\\r\\n什么是B+树？_攻城狮百里的博客-CSDN博客_b+树\\r\\n\\r\\n\\r\\n\\r\\n 聚簇索引和二级索引\\r\\n\\r\\n- 主键索引的叶子结点存的是整行记录。InnoDB 引擎中主键索引又称为聚簇索引。\\r\\n- 非主键索引的叶子结点存的是行记录的ID。在 InnoDB 引擎中非主键索引又称为二级索引。\\r\\n\\r\\n\\r\\n\\r\\n 搜索方式\\r\\n\\r\\n- 根据主键搜索\\r\\n  \\r\\n    `\"},{\"url\":\"/database/mysql/索引失效的场景.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"索引失效的场景\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"查询条件做函数计算\\r\\n\\r\\n```sql\\r\\nselect count(*) from tradelog where month(t_modified)=7;\\r\\n```\\r\\n\\r\\n查询条件做函数计算，在查索引的时候，利用不了索引。因为索引利用的是树的有序性，但是函数计算后的结果在索引的B+树上并不连续。MySQL在查询的时候利用不到树的有序性。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。\\r\\n\\r\\n 隐式类型转换\\r\\n\\r\\n假如 tradeid 字段类型是 varchar ，查询语句\\r\\n\\r\\n```sql\\r\\nexplain   sele\"},{\"url\":\"/database/mysql/行锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"行锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL 中的行锁（row-level locking）并不是单纯指写锁（write lock），而是指锁定机制的粒度。行锁可以是共享锁（也称为读锁，S锁）或排他锁（也称为写锁，X锁），具体取决于事务所使用的隔离级别以及查询类型。\\r\\n\\r\\n- Select for Update：当执行带有 `FOR UPDATE` 子句的 `SELECT` 查询时，InnoDB 会对被选中的行加上排他锁。这确保了在事务提交之前，其他事务不能修改这些行。\\r\\n- Insert Intention Lock：当执行 `INSERT` 操作时，InnoDB 会自动为要插入的行加上意向锁。这是为了避免插入操作与其他事务\"},{\"url\":\"/database/mysql/锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"MySQL中加锁是为了处理并发问题，根据锁的粒度可以分为全局锁、表级锁和行锁。\\r\\n\\r\\n 全局锁\\r\\n\\r\\n全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 `Flush tables with read lock` (FTWRL)。\\r\\n\\r\\n加完之后整个数据库处于只读状态。\\r\\n\\r\\n---\\r\\n\\r\\n 应用场景（不推荐）\\r\\n\\r\\n全局锁的经典应用场景 数据库备份。\\r\\n\\r\\n由于加全局锁，会导致整个数据库只读，所以一般不推荐使用。\\r\\n\\r\\n 可重复读进行备份\\r\\n\\r\\n备份数据库一般可以利用可重复读的事务隔离级别来实现，因为可重复读情况开始事务，会生成当前数据库的视图，保证整个事务期间以\"},{\"url\":\"/database/redis/LRU和LFU算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"LRU和LFU算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"LRU算法\\r\\n\\r\\n 简介\\r\\n\\r\\nLRU （Least Recently Used） 算法即最近最久未使用，每次选择最近最久未使用的页面淘汰掉。\\r\\n\\r\\n 实现过程\\r\\n\\r\\n- 新增数据时，元素插入到队列头部。\\r\\n- 访问元素（查询、更新和删除）时，将元素移动到队列头部。\\r\\n- 当超过内存限制，需要淘汰数据时，将已排序队列的最后元素删除。\\r\\n\\r\\n\\r\\n\\r\\n 数据结构\\r\\n\\r\\nLRU 算法内部的数据结构需要根据元素的访问时间排序。还需要查找、插入、删除等效率要高。\\r\\n\\r\\n1. 查找、插入、删除快。\\r\\n2. 支持排序。\\r\\n\\r\\n在常用的集合中，有的是查找更新快或者插入删除快，没有数据结构能同时满足以上条件，所\"},{\"url\":\"/database/redis/Redisson.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Redisson\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还实现了可重入锁（Reentrant Lock）、公平锁（Fair Lock、联锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）等，还提供了许多分布式服务。Redisson提供了使用Redis的最简单和最便捷的方法。Redisson的宗旨是促进使用者对Redis的关注分离（Separation of Concern），从而让使用者能够将精力更集中地放在处理业务逻辑上。\\r\\n\\r\\n Redisson \"},{\"url\":\"/database/redis/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- redis数据类型\\r\\n- redis数据类型原理\\r\\n- redis的持久化\\r\\n\\r\\n\\r\\n- 过期策略\\r\\n- 内存淘汰策略\\r\\n- LRU和LFU算法\\r\\n\\r\\n- redis实现分布式锁\\r\\n- Redisson\\r\\n\\r\\n- redis事务.md\\r\\n- redis集群.md\\r\\n\\r\\n- 缓存问题\\r\\n- 布隆过滤器\"},{\"url\":\"/database/redis/redis事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis的事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis 的事务，可以一次执行多个命令，本质上是一组命令的集合，按照顺序串行化执行而不会被其它命令插入。\\r\\n\\r\\n 常用命令\\r\\n\\r\\n- 开启事务 -`multi`\\r\\n- 执行所有事务 - `exec`\\r\\n- 取消所有事务 - `discard`\\r\\n- 监控一个或多个 key - `watch`\\r\\n- 取消 watch 命令对所有 key 的监控 - `unwatch`\\r\\n  \\r\\n    \\r\\n    \\r\\n\\r\\n watch监控\\r\\n\\r\\nwatch 指令，类似乐观锁，在创建事务之前，使用 watch 指令监控某个值。在事务提交时，如果 key 的值已经被别的客户端改变，那么整个事务队列都不会执行。\\r\\n\"},{\"url\":\"/database/redis/redis实现分布式锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis实现分布式锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"分布式锁简介\\r\\n\\r\\n在分布式环境下，多个系统访问共享资源时会发生线程安全问题，分布式锁就是为了解决分布式环境下访问共享资源的线程安全问题，保证共享资源同一时间只能被一个系统的一个线程访问。\\r\\n\\r\\n 分布式锁具备的条件\\r\\n\\r\\n1. 在分布式环境下，共享资源在同一时间只能被一个系统的一个线程访问。\\r\\n2. 保证设置分布式锁和删除分布式锁操作的原子性。\\r\\n3. 具备可重入特性。\\r\\n4. 防止死锁。\\r\\n5. 具备锁超时失效的机制。\\r\\n6. 具备非阻塞锁特性，不会阻塞等待获取锁。\\r\\n\\r\\n 分布式锁主要实现方式\\r\\n\\r\\n1. zeekeeper 实现分布式锁\\r\\n2. redis 实现分布式锁\\r\\n\\r\\n---\\r\"},{\"url\":\"/database/redis/redis数据类型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis数据类型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis数据类型\\r\\n\\r\\n练习代码地址 redis-practice\\r\\n\\r\\n 键 - key\\r\\n\\r\\n在了解数据类型之前，先了解一下 redis 的键。\\r\\n\\r\\n在 redis 中 命令不区分大小写，但是注意 redis 中的 key 和 value 是区分大小写的。\\r\\n\\r\\n\\r\\n\\r\\n 字符串 - string\\r\\n\\r\\n字符串数据结构是简单的 K-V 模式数据结构。\\r\\n\\r\\n 特点\\r\\n\\r\\n- 单值单 value。\\r\\n- 二进制安全，可以包含任何数据。\\r\\n- 一个键对应 value 值最大能存储数据 512 MB。\\r\\n\\r\\n 常用命令\\r\\n\\r\\n\\r\\n\\r\\n- 设置字符串 - `set test 100`\\r\\n- 查\"},{\"url\":\"/database/redis/redis数据类型原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis数据类型原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. linkedlist (双向链表)\\r\\n    - 当列表元素较多或元素大小超过一定阈值时，Redis 会使用双向链表来存储 `list` 键。\\r\\n    - linkedlist 是一种指针结构，每个节点包含指向前后节点的指针，这使得插入和删除操作非常高效。\\r\\n    - linkedlist 的优点是支持高效的插入和删除操作，但缺点是比 ziplist 更占用内存。\\r\\n\\r\\n 全局哈希表\\r\\n\\r\\n\\r\\n\\r\\nRedis是一个 K-V 数据库，有一个全局的哈希桶存放所有的 key。\\r\\n\\r\\nkey 对应的 entry 包含了实际的 key 和 value。这里的 value 对应着不同的数据类型。\"},{\"url\":\"/database/redis/redis的持久化.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis的持久化\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"redis 有 RDB 和 AOF 两种持久化方式。\\r\\n\\r\\n RDB\\r\\n\\r\\nRDB 是 *Redis DataBase* 的简称，指的是在指定时间间隔内将内存中的数据集快照写入磁盘文件，也就是 Snapshot 快照，RDB 是默认开启的。\\r\\n\\r\\n RDB的原理\\r\\n\\r\\nRedis 会单独创建 （fork）一个子进程来进行持久化操作，将内存中某一时刻的数据持久化到磁盘文件。这个子进程会先将数据写入到一个临时文件中，等待持久化进程结束后，再用这个临时文件替换掉磁盘文件。\\r\\n\\r\\n\\r\\n\\r\\n在整个过程中，主进程是不进行任何 IO 操作的，这样保证了主进程存取的高性能。\\r\\n\\r\\nRDB 的持久化过程每次都是\"},{\"url\":\"/database/redis/redis集群.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"redis集群\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Redis集群是一个由多个主从节点群组成的分布式服务集群，它具有复制、高可用和分片特性。\\r\\n\\r\\n 主从模式\\r\\n\\r\\n\\r\\n\\r\\n- 主数据库可以进行读写操作。\\r\\n  \\r\\n    数据会通过主从同步，由主服务器同步给从服务器。\\r\\n    \\r\\n    主服务器将数据\\r\\n    \\r\\n- 从数据库一般是只读的。\\r\\n\\r\\n引入主从复制机制的目的有两个：\\r\\n\\r\\n- 一个是读写分离，分担 “master” 的读写压力\\r\\n- 一个是方便做容灾恢复，避免单点故障。\\r\\n\\r\\n 主从同步的原理\\r\\n\\r\\n\\r\\n\\r\\n- 全量复制\\r\\n  \\r\\n    从数据库在第一次同步的时候会进行全量同步。\\r\\n    \\r\\n    主库执行 bgsav\"},{\"url\":\"/database/redis/内存淘汰策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内存淘汰策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"最大内存设置\\r\\n\\r\\n1. redis 默认内存是多少？\\r\\n   \\r\\n    在 64 位操作系统不限制内存大小，在 32 位操作系统下最多使用 3GB。\\r\\n    \\r\\n2. 查看 redis 最大内存？\\r\\n   \\r\\n    `Plain Text  config get maxmemory`\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 修改 redis 内存大小？\\r\\n    - 修改配置文件\\r\\n      \\r\\n        在 `redis.conf` 第 859 行可以设置最大内存大小（单位是字节）。\\r\\n        \\r\\n        \\r\\n        &gt; \\r\\n        \"},{\"url\":\"/database/redis/布隆过滤器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"布隆过滤器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 什么是布隆过滤器？\\r\\n\\r\\n布隆过滤器（Bloom Filter）是一种数据结构，用来判断一个元素是否在一个集合中。布隆过滤器的本质上使用的是二进制向量和 k 个哈希函数组成。\\r\\n\\r\\n布隆过滤器具有如下优点：\\r\\n\\r\\n- 空间利用率高。\\r\\n  \\r\\n    布隆过滤器底层使用二进制向量保存数据，不需要保存元素本身，只需要在指定 bit 存放标识即可，故空间利用率非常高。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n- 时间效率也较高，插入和查询效率高。\\r\\n  \\r\\n    布隆过滤器的时间复杂度只跟哈希函数的个数 k 有关，插入和查询的时间复杂度均为 O(k)；\\r\\n    \\r\\n    *结合\"},{\"url\":\"/database/redis/缓存问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"缓存问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"前言\\r\\n\\r\\n在使用缓存的时候，简单的缓存处理流程如下。针对如下流程会遇到缓存穿透、缓存击穿、缓存雪崩等问题。\\r\\n\\r\\n\\r\\n\\r\\n 缓存穿透\\r\\n\\r\\n缓存穿透：当用户请求查询某个数据时，先从缓存查询，缓存中没有这个数据。然后向数据库查询数据，数据库中也没有这个数据，导致查询失败。\\r\\n\\r\\n*像一些恶意攻击时，故意查询数据库中不存在的数据，比如查询 id = -1 的数据，会造成数据库压力非常大。*\\r\\n\\r\\n\\r\\n\\r\\n 解决方案\\r\\n\\r\\n1. 对空值做缓存。\\r\\n   \\r\\n    当出现从缓存和数据库都查不到数据的情况时，可以将空值存到缓存中，即 K-V 存为 key-null，缓存过期时间可以设置短点，来防止短\"},{\"url\":\"/database/redis/过期策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"过期策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 Redis 中设置了过期时间的 key，在一定时间后都会被删除。\\r\\n\\r\\n 键的过期时间\\r\\n\\r\\n 配置过期时间\\r\\n\\r\\n1. `setex key seconds value`\\r\\n   \\r\\n    设置 key 时添加过期时间\\r\\n    \\r\\n2. `expire key seconds`\\r\\n   \\r\\n    为某个 key 设置过期时间。\\r\\n    \\r\\n3. 删除 key 的过期时间。\\r\\n   \\r\\n    `persist key`\\r\\n    \\r\\n4. 查看 key 的过期时间\\r\\n   \\r\\n    `ttl key`\\r\\n    \\r\\n\\r\\n redis保存过期时间分析\\r\\n\\r\\n[版权声明：本文为CS\"},{\"url\":\"/frame/mybatis/custom/SQL执行器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SQL执行器-executor\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"将操作数据库的操作从 sqlSession 中解耦，放到 Executor 中。\\r\\n\\r\\n包括事务操作也放到 Executor 中。\\r\\n\\r\\n```java\\r\\npublic interface Executor {\\r\\n\\r\\n    ResultHandler NO_RESULT_HANDLER = null;\\r\\n\\r\\n    &lt;E\\r\\n\\r\\n    Transaction getTransaction();\\r\\n\\r\\n    void commit(boolean required) throws SQLException;\\r\\n\\r\\n    void rollback(boolean required) \"},{\"url\":\"/frame/mybatis/custom/xml解析.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"xml解析\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"\"},{\"url\":\"/frame/mybatis/custom/手写MyBatis.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"手写MyBatis\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"整体流程\\r\\n\\r\\n\\r\\n\\r\\n整个mybatis的功能，就是代理 mapper 然后执行SQL，返回执行结果。\\r\\n\\r\\n\\r\\n\\r\\n1. 解析mybatis配置\\r\\n    - 解析数据源 （Configuration 的 environment）\\r\\n    - 解析mapper文件配置 （路径扫描）\\r\\n2. 解析mapper文件\\r\\n    - 注册mapper到mapperRegistry。（包含mapper的代理类工厂，可以获取代理过的mapper）\\r\\n    - 生成mapper方法对应的mapperStatement。（Configuration 的 mappedStatements）\\r\\n    -\"},{\"url\":\"/frame/mybatis/custom/数据源.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据源\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"数据源解析\\r\\n\\r\\n解析配置文件中的数据源\\r\\n\\r\\n1. 事务模版 - jdbc\\r\\n2. 数据源实现 - druid\\r\\n\\r\\n```xml\\r\\n&lt;configuration\\r\\n\\r\\n    &lt;!--    数据源配置   --&gt;\\r\\n    &lt;environments default=\\\"development\\\"&gt;\\r\\n        &lt;environment id=\\\"development\\\"&gt;\\r\\n            &lt;transactionManager type=\\\"JDBC\\\"/&gt;\\r\\n            &lt;dataSource type=\\\"\"},{\"url\":\"/frame/mybatis/custom/映射器-mapper.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"映射器-mapper\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- SqlSession提供了SqlId。\\r\\n- 而SqlSessionFactroy 提供了开启SqlSession的能力。]\\r\\n- MapperRegistry 包含了所有Mapper的SqlId，包含注册发现Mapper的能力。\\r\\n\\r\\n MapperFactory\\r\\n\\r\\n\\r\\n\\r\\n MapperProxy\\r\\n\\r\\n在mybatis中，调用mapper里面的方法就可以执行SQL。其实是因为mybatis隐藏了实现细节。\\r\\n\\r\\n具体做法是根据mapper里面点的方法生成代理逻辑，在调用该方法时其实是走的代理类的逻辑。\\r\\n\\r\\n而代理类封装了操作数据库的逻辑，代理类即为mapperProxy。\\r\\n\\r\"},{\"url\":\"/frame/mybatis/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MyBatis 框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"手写MyBatis\\r\\n\\r\\n- 手写MyBatis\\r\\n- 映射器-mapper\\r\\n- 数据源\\r\\n- SQL执行器\\r\\n- xml解析\"},{\"url\":\"/frame/netty/ByteBuf.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ByteBuf\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ByteBuf是Netty中用于表示字节序列的数据容器。它是Netty对Java NIO中的ByteBuffer的改进和增强。ByteBuf提供了更灵活、更强大的API，具有许多优势，使得它在网络编程中更加方便和高效。\\r\\n\\r\\n以下是ByteBuf的主要优势：\\r\\n\\r\\n1. 灵活的容量管理： ByteBuf支持动态扩容和收缩，相比Java NIO的ByteBuffer，ByteBuf的容量可以根据实际需求自动调整，无需手动扩容。\\r\\n2. 更丰富的API： ByteBuf提供了丰富的操作API，包括读取、写入、复制、切片、合并等操作。这些API使得对字节数据的操作更加便利，同时提供了更多的功能。\\r\\n\"},{\"url\":\"/frame/netty/HTTP服务和SSL&TLS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP服务和SSL/TLS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"服务端\\r\\n\\r\\n按照 pipline 执行。\\r\\n\\r\\n```java\\r\\n@Override\\r\\n    protected void initChannel(SocketChannel socketChannel) throws Exception {\\r\\n        ChannelPipeline pipeline = socketChannel.pipeline();\\r\\n        //TODO ssl\\r\\n\\r\\n        //服务端\\r\\n        //对请求内容解码\\r\\n        pipeline.addLast(\\\"decoder\\\", new HttpRequestDecode\"},{\"url\":\"/frame/netty/Handler的共享和并发安全性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Handler的共享和并发安全性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"服务端为Channel设置pipeline的时候，可以选择设置共享的还是Channel独有的。\\r\\n\\r\\n```java\\r\\nprivate void start() throws InterruptedException {\\r\\n        final MsgCountHandler msgCountHandler = new MsgCountHandler();\\r\\n        //线程组\\r\\n        EventLoopGroup boss = new NioEventLoopGroup();\\r\\n        EventLoopGroup work = new NioEventLoo\"},{\"url\":\"/frame/netty/Netty实现文件下载.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty实现文件下载\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"实例：如何使用 Netty 下载文件_channelhandlercontext下载文件-CSDN博客\\r\\n\\r\\n ChannelHandler\\r\\n\\r\\n自定义 ChannelHandler ，用来处理 Channel 里面的事件，写数据处理逻辑的。\\r\\n\\r\\n- ChannelInboundHandlerAdapter\\r\\n- SimpleChannelInboundHandler\\r\\n    \\r\\n    是 ChannelInboundHandlerAdapter 的子类，能够指定类型。\\r\\n    \\r\\n\\r\\nNetty 里面预设了很多 ChannelHandler\\r\\n\\r\\n```java\\r\\nch.pipel\"},{\"url\":\"/frame/netty/Netty实现通信框架.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty实现通信框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"功能点\\r\\n\\r\\n1. 基于Netty的NIO通信框架。\\r\\n2. 提供消息的编码解码框架，实现对象的序列化和反序列化。\\r\\n3. 消息内容的放篡改机制。\\r\\n4. 提供基于IP的白名单认证机制。\\r\\n5. 链路的有效性机制（心跳）。\\r\\n6. 链路的断连重连机制。\\r\\n\\r\\n 通信模型\\r\\n\\r\\n\\r\\n\\r\\n 调用链路\\r\\n\\r\\n\\r\\n\\r\\n粘包半包是最前面先要解决的问题。\\r\\n\\r\\n 写空闲检测\\r\\n\\r\\n```java\\r\\npublic class CheckWriteIdleHandler extends IdleStateHandler {\\r\\n\\r\\n    /**\\r\\n     * 0 表示读空闲时间不进行检测，即不对读空闲做任何\"},{\"url\":\"/frame/netty/Netty常用组件.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty常用组件\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Bootstrap\\r\\n\\r\\nNetty的启动类\\r\\n\\r\\n- Bootstrap\\r\\n\\r\\n    客户端启动类\\r\\n\\r\\n- ServerBootstrap\\r\\n\\r\\n    服务端启动类\\r\\n\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n 第一个区别\\r\\n\\r\\n- 客户端需要连接到远程主机和端口即可。\\r\\n\\r\\n- 服务端需要绑定端口。\\r\\n\\r\\n 第二个区别\\r\\n\\r\\n- 服务端需要两个 EventLoopGroup。\\r\\n\\r\\n    原因是使用了多线程主从的Reactor模式。\\r\\n\\r\\n    - 第一个EventLoopGroup，只有一个EventLoop，负责为传入的Accept请求建立连接。一旦建立连接后续，将该 Channel 放到\"},{\"url\":\"/frame/netty/TCP粘包拆包问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP粘包拆包问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"TCP 粘包\\r\\n\\r\\n由于 TCP 协议本身的机制（面向连接的可靠地协议-三次握手机制）客户端与服务器会维持一个连接（Channel），数据在连接不断开的情况下，可以持续不断地将多个数据包发往服务器。\\r\\n\\r\\n但是如果发送的网络数据包太小，那么他本身会启用 Nagle 算法（可配置是否启用）对较小的数据包进行合并（基于此，TCP 的网络延迟要 UDP 的高些）然后再发送（超时或者包大小足够）。\\r\\n\\r\\n那么这样的话，服务器在接收到消息（数据流）的时候就无法区分哪些数据包是客户端自己分开发送的，这样产生了粘包。\\r\\n\\r\\n服务器在接收到数据库后，放到缓冲区中，如果消息没有被及时从缓存区取走，下次在取数据的\"},{\"url\":\"/frame/netty/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Netty\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础总结\\r\\n\\r\\n- Netty常用组件\\r\\n- Handler的共享和并发安全性\\r\\n- 资源管理和SimpleChannelInboundHandler\\r\\n- 内置通信传输模式\\r\\n- TCP粘包拆包问题\\r\\n- 编解码器\\r\\n\\r\\n\\r\\n- HTTP服务和SSL&TLS\\r\\n- 序列化问题\\r\\n- 写空闲和读空闲\\r\\n\\r\\n\\r\\n- ByteBuf\\r\\n- 线程模型\\r\\n- 零拷贝\\r\\n\\r\\n\\r\\n 练习总结\\r\\n- Netty实现通信框架\\r\\n- 基于Netty实现RPC\\r\\n- Netty实现文件下载\"},{\"url\":\"/frame/netty/内置通信传输模式.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内置通信传输模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```java\\r\\ntry {\\r\\n            //父子EventLoop\\r\\n            serverBootstrap.group(boss,work)\\r\\n                    //指定使用NIO的通信模式\\r\\n                    .channel(NioServerSocketChannel.class)\\r\\n                    .localAddress(new InetSocketAddress(port))\\r\\n                    .childHandler(new ChannelInitia\"},{\"url\":\"/frame/netty/写空闲和读空闲.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"写空闲和读空闲\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在Netty框架中，写空闲（Write Idle） 和 读空闲（Read Idle） 是空闲检测机制中的两个重要概念，它们用于监控网络连接的活跃状态，确保连接的有效性和资源的有效管理。\\r\\n\\r\\n 写空闲（Write Idle）\\r\\n\\r\\n- 定义：写空闲指的是在一段指定时间内，没有数据通过当前的`Channel`被写入到网络中传输给对方。这可能意味着在这段时间内，服务端没有向客户端发送任何数据，或者客户端没有向服务端发送数据。\\r\\n- 应用场景：在某些协议或应用场景中，如果长时间没有数据写入，可能需要触发特定的操作，比如发送心跳包以维持连接活跃，或者是判断连接是否已经失效，进而关闭连接以释放资源。\\r\\n\"},{\"url\":\"/frame/netty/基于Netty实现RPC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"基于netty实现RPC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"源码地址\\r\\n\\r\\nAlbert.Yang/JavaAdvance\\r\\n\\r\\n 服务端\\r\\n\\r\\n ServerBootstrap\\r\\n\\r\\n```java\\r\\n@Service\\r\\n@Slf4j\\r\\npublic class RpcServerFrame implements Runnable {\\r\\n\\r\\n    @Autowired\\r\\n    private ServerInit serverInit;\\r\\n\\r\\n    private EventLoopGroup bossGroup = new NioEventLoopGroup();\\r\\n    private EventLoopGroup workGroup =\"},{\"url\":\"/frame/netty/序列化问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"序列化问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java对象的序列化主要有两个：\\r\\n\\r\\n1. 网络传输\\r\\n   \\r\\n    数据在网络中传输是通过字节流形式的，到服务端需要解码。\\r\\n    \\r\\n2. 对象持久化\\r\\n\\r\\n Java序列化\\r\\n\\r\\nJava序列化机制是基于对象的类结构进行的。\\r\\n\\r\\n当对象需要序列化时，会将对象转换为字节流在网络传输。\\r\\n\\r\\n反序列化时，就是将字节流转换为对象的过程。Java会将字节流转换为对象重新加载到内存中。\\r\\n\\r\\nJava的序列化机制是通过实现`java.io.Serializable`接口来实现的。该接口是一个标记接口，没有任何方法定义。只有实现了`Serializable`接口的类的对象才能被序列化。\\r\\n\"},{\"url\":\"/frame/netty/线程模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Netty的线程模型是什么？为什么它是高效的？\\r\\n\\r\\n1. Netty的线程模型是基于事件驱动的，采用了Reactors设计模式。它的线程模型主要包含以下几个关键组件：\\r\\n2. Boss Group和Worker Group： Netty通过Boss Group和Worker Group来分别管理两类不同的线程。Boss Group负责接收客户端的连接，而Worker Group则负责处理连接后的网络流量。\\r\\n3. Channel： Channel代表了一个网络连接，可以是客户端到服务器的连接，也可以是服务器之间的连接。每个Channel都由一个EventLoop负责处理，而一个EventLo\"},{\"url\":\"/frame/netty/编解码器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"编解码器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在网络传输中，数据是通过字节流传输。\\r\\n\\r\\n对应到客户端和服务端需要进行对应的编码和解码。\\r\\n\\r\\n 解码器\\r\\n\\r\\n- 将字节解码为消息：ByteToMessageDecoder\\r\\n- 将一种消息类型解码为另一种：MessageToMessageDecoder。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 异常处理\\r\\n\\r\\n- TooLongFrameException\\r\\n    \\r\\n    由于 Netty 是一个异步框架，所以需要在字节可以解码之前在内存中缓冲它们。因此，不能让解码器缓冲大量的数据以至于耗尽可用的内存。为了解除这个常见的顾虑，Netty 提供了 TooLongFrameException 类\"},{\"url\":\"/frame/netty/资源管理和SimpleChannelInboundHandler.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"资源管理和SimpleChannelInboundHandler\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NIO中读写Channel数据，都使用了 Buffer，读写数据都是从 Buffer里面读取的。\\r\\n\\r\\n而 Netty在读写网络数据时，同样也需要 Buffer。\\r\\n\\r\\n但是这样就涉及到 Buffer的内存释放，不然会造成内存泄漏。\\r\\n\\r\\n SimpleChannelInboundHandler\\r\\n\\r\\nNetty实现了SimpleChannelInboundHandler类，提供 `channelRead0()` 方法，保证数据被该方法消费后自动释放数据。\\r\\n\\r\\n```java\\r\\n    public void channelRead(ChannelHandlerContext ctx, Ob\"},{\"url\":\"/frame/netty/零拷贝.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"零拷贝\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. ByteBuf 可以直接使用直接内存。\\r\\n    \\r\\n    Socket 通信如果采用堆内存的话，需要将堆里的对象拷贝到堆外，进行一次对象拷贝。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n    \\r\\n    但是 Socket 没有更新对象地址动作，需要的是一个固定的地址。所以堆内存不适合 Socket 使用。只能将对象拷贝到直接内存然后使用。\\r\\n    \\r\\n    而 ByteBuf 直接使用直接内存，减少了对象拷贝。\\r\\n    \\r\\n2. Netty 提供了组合 Buffer，可以将多个 Buffer 合并为一个。\\r\\n    \\r\\n    传统通过内存拷贝的方式将几个小Buffe\"},{\"url\":\"/frame/spring/AOP.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AOP\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"面向切面编程\\r\\n\\r\\n面向切面编程，指的是在运行期间生成代理对象来对类进行增强处理，比如方法执行前和方法执行后进行代码增强。\\r\\n\\r\\n 什么是切面\\r\\n\\r\\n- 切：\\r\\n  \\r\\n    指的是横切逻辑，原有方法代码不动。只能操作横切逻辑代码进行增强。\\r\\n    \\r\\n- 面：\\r\\n  \\r\\n    横切逻辑往往影响很多个方法，每个方法是一个切点，便形成了面。\\r\\n    \\r\\n\\r\\n常用的功能有：\\r\\n\\r\\n- 方法审计日志\\r\\n- 校验权限是否足够\\r\\n\\r\\n\\r\\n\\r\\n AOP体系\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n)连接点 - JoinPoint\\r\\n\\r\\n类里面哪些方法可以被增强，这些方法称为连接点。\\r\\n\\r\\n- 切面\\r\\n\\r\\n    切\"},{\"url\":\"/frame/spring/ApplicationContext和BeanFactory区别.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ApplicationContext和BeanFactory区别\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ApplicationContext 总结\\r\\n\\r\\nApplicationContext 容器上下文，包含了 BeanFactory 的所有功能，还额外提供了以下功能：\\r\\n\\r\\n- MessageSource，提供国际化的消息访问\\r\\n- 资源访问，如 URL 和文件\\r\\n- 事件传播\\r\\n\\r\\n 工具类\\r\\n\\r\\n可以通过实现 `ApplicationContextAware` 接口注入 ApplicationContext\\r\\n\\r\\n```java\\r\\n@Component\\r\\npublic class SpringBeanUtil implements ApplicationContextAware {\\r\\n\\r\\n\"},{\"url\":\"/frame/spring/Aware接口.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Aware接口\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在Spring框架中，`Aware`接口提供了一种机制，允许Bean在初始化过程中获取Spring容器的特定上下文信息或资源。这些接口通常被称作回调接口，因为它们允许Spring容器在特定时刻回调Bean，以便将一些重要的信息注入给Bean。\\r\\n\\r\\n ApplicationContextAware\\r\\n\\r\\n当Spring容器在初始化一个实现了`ApplicationContextAware`接口的Bean时，它会调用`setApplicationContext`方法，将当前的应用上下文传入。\\r\\n\\r\\n```java\\r\\npublic interface ApplicationContextAware\"},{\"url\":\"/frame/spring/BeanFactory和FactoryBean总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BeanFactory和FactoryBean总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"BeanFactory总结\\r\\n\\r\\nBeanFactory 是 Spring 中的一个接口，提供了 IOC 容器最基本的形式，给具体的 IOC 容器实现提供了规范。\\r\\n\\r\\n其本质是一个 IOC 容器或对象工厂，所有的 Bean 都是由 BeanFactory （IOC容器）来进行管理的。Spring 有许多 BeanFactory 的实现类，附件了许多功能。\\r\\n\\r\\n```java\\r\\npublic interface BeanFactory {\\r\\n  \\r\\n  Object getBean(String name) throws BeansException;\\r\\n  \\r\\n\\t&lt;T\\r\\n\\r\\n\\tObj\"},{\"url\":\"/frame/spring/ByteBuddy实现动态代理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ByteBuddy实现动态代理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Byte Buddy - runtime code generation for the Java virtual machine\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n```java\\r\\n&lt;dependency&gt;\\r\\n  &lt;groupId&gt;net.bytebuddy&lt;/groupId&gt;\\r\\n  &lt;artifactId&gt;byte-buddy&lt;/artifactId&gt;\\r\\n  &lt;version&gt;LATEST&lt;/version&gt;\\r\\n&lt;/dependency&gt;\\r\\n```\\r\\n\\r\\n```java\\r\\npublic c\"},{\"url\":\"/frame/spring/Spi机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spi机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SPI机制，全称Service Provider Interface，是Java提供的一种标准的服务发现机制。它允许第三方服务提供者扩展某个接口的实现，而无需修改接口的源代码或重新打包。\\r\\n\\r\\nSpring SPI机制常用于 starter 构建和基础库实现。\\r\\n\\r\\n通过 spi 机制，确保自动配置生效的类包含 FileAutoConfiguration\\r\\n\\r\\n\\r\\n\\r\\n使用 SPI可以可插拔的注入配置，比如 `EnableAutoConfiguration`，如果需要 MinIO的配置类，加在类里面即可开启MinIO的功能。\\r\\n\\r\\nwww.jb51.net\\r\\n\\r\\nSPI机制是什么？_java_\"},{\"url\":\"/frame/spring/Spring中Bean加载流程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring中Bean加载流程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"流程图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 创建流程\\r\\n\\r\\n1. 加载 `ApplicationContext` 上下文环境。\\r\\n2. `ApplicationContext` 通过扫描、读取配置，将 Bean对象封装为 `BeanDefinition` 对象，并注册到 `BeanDefinitionMap` 中。\\r\\n3. 在 `ApplicationContext` 执行完成之后会调用对应的后置处理器 `BeanFactoryProcessor` 和其子类 `BeanDefinitionRegistryPostProcessor` 对应方法，可以修改和注册 `BeanDefinition` 到 \"},{\"url\":\"/frame/spring/Spring中Bean的作用域.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring中Bean的作用域\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"作用域类型\\r\\n\\r\\n- singleton\\r\\n    \\r\\n    单例模式。\\r\\n    \\r\\n    使用 `singleton` 定义的 Bean 在 Spring 容器中只有一个实例，是 Bean 默认的作用域。\\r\\n    \\r\\n- prototype\\r\\n    \\r\\n    原型模式\\r\\n    \\r\\n    每次通过 Spring 容器获取 `prototype` 定义的 Bean 时，容器都将创建一个新的 Bean 实例。\\r\\n    \\r\\n- request\\r\\n    \\r\\n    在一次 HTTP 请求中，容器会返回该 Bean 的同一个实例。而对不同的 HTTP 请求，会返回不同的实例，该作用域\"},{\"url\":\"/frame/spring/Spring事务总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring事务总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"编程式事务\\r\\n\\r\\n在代码中硬编码，不推荐使用。\\r\\n\\r\\n 声明式事务\\r\\n\\r\\n- 基于注解的声明式事务\\r\\n- 基于 XML 的声明式事务\\r\\n\\r\\n @Transactional 注解\\r\\n\\r\\nException 分为运行时异常 RuntimeException 和非运行时异常。事务管理能保证出现异常情况的时候保证数据的一致性。\\r\\n\\r\\n默认 `@Transactional` 注解只会在遇到 RuntimeException 类型异常或者 Error时，才会回滚事务。遇到其它异常，Spring 不会回滚事务。\\r\\n\\r\\n 作用范围\\r\\n\\r\\n当 `@Transactional`注解作用于类上的时，该类的所有方法都\"},{\"url\":\"/frame/spring/Spring依赖注入.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring依赖注入\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"依赖注入就是通过spring将bean所需要的一些参数传递到bean实例对象的过程（将依赖关系注入到对象中，不需要每次都new对象）\\r\\n\\r\\n- set方法注入\\r\\n- 构造方法注入\\r\\n- 注解注入\\r\\n\\r\\n 注解注入的区别\\r\\n\\r\\n- @Resource\\r\\n\\r\\n  byName注入\\r\\n\\r\\n  \\r\\n\\r\\n- Autowired\\r\\n\\r\\n  byType注入\"},{\"url\":\"/frame/spring/Spring如何解决循环依赖.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring如何解决循环依赖\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"依赖注入的四种方法\\r\\n\\r\\n- 构造方法注入\\r\\n  \\r\\n    ```java\\r\\n        public HelloA(@Autowired HelloService helloService) {\\r\\n            this.helloService = helloService;\\r\\n        }\\r\\n    ```\\r\\n    \\r\\n- 工厂方法注入\\r\\n  \\r\\n    ```java\\r\\n        @Bean(initMethod = \\\"init\\\", destroyMethod = \\\"destory\\\")\\r\\n        public HelloB helloB(@Auto\"},{\"url\":\"/frame/spring/Spring框架概述.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring框架概述\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、什么是 Spring 框架？\\r\\n\\r\\nSpring 框架指的是 Spring Framework，是一种轻量级的开发框架，主要核心是控制反转 （IOC）和 面向切面编程（AOP）。\\r\\n\\r\\n 二、Spring 的优点\\r\\n\\r\\n1. 方便解耦，简化开发（高内聚低耦合）\\r\\n    - Spring 是一个容器框架，将所有对象创建和依赖关系的维护交给 Spring 管理。\\r\\n    - Spring 工厂用于生成 Bean。\\r\\n2. AOP编程的支持\\r\\n    - Spring 提供面向切面编程，可以方便的实现权限拦截、运行监控等功能\\r\\n    - 日志打印\\r\\n3. 支持声明式事务\\r\\n    - 只需\"},{\"url\":\"/frame/spring/Spring自定义注解扫描.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring自定义注解扫描\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Spring管理的类\\r\\n\\r\\n以下两种方式都可以实现。\\r\\n\\r\\n 使用@ComponentScan + Bean定义\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\n@ComponentScan(basePackages = {\\\"your.package.to.scan\\\"}) // 指定要扫描的包\\r\\npublic class AppConfig {\\r\\n\\r\\n    @Autowired\\r\\n    private ListableBeanFactory beanFactory;\\r\\n\\r\\n    @PostConstruct\\r\\n    public void processAnnotatedBea\"},{\"url\":\"/frame/spring/Spring配置文件加载顺序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring配置文件加载顺序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot配置文件的加载顺序\\r\\n\\r\\nSpringBoot项目启动会扫描以下位置的application.properties或者application.yml文件作为SpringBoot的默认配置文件，具体的目录位置见下图。\\r\\n\\r\\n1. file:./config/ （ 项目根路径下的config文件夹）\\r\\n2. file:./ （项目根路径）\\r\\n3. classpath:/config/ （类路径下的config文件夹）\\r\\n4. classpath:/ （类路径）\\r\\n\\r\\n\\r\\n\\r\\n按照配置文件的优先级，8001\\r\\n\\r\\n&gt; 注意file层是项目的最外层目录，也就是工作目录。\\r\\n&\"},{\"url\":\"/frame/spring/custom/AOP.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AOP\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ByteBuddy\\r\\n\\r\\nAOP即面向切面编程，本质上是一个 Proxy 模式。核心就是拦截核心 Bean 的方法调用。\\r\\n\\r\\n- JDK动态代理\\r\\n- CGLIB动态生成字节码代理。\\r\\n\\r\\n\\r\\n&gt;\\r\\n\\r\\n AOP实现核心\\r\\n\\r\\n- 找到符合AOP要求的原始Bean\\r\\n- 执行指定的拦截器逻辑\\r\\n\\r\\n AOP流程\\r\\n\\r\\n1. 利用 `BeanPostProcessor` 检测每个Bean。\\r\\n2. 扫描每个 Bean 的 @Around 注解。\\r\\n3. 执行 InvocationHandler 的代理方法。\\r\\n\\r\\n 实现 @Before 和 @After\\r\\n\\r\\n基于@Around的模板就\"},{\"url\":\"/frame/spring/custom/Boot.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Boot\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot 内置了 Tomcat，IOC容器和 WebMVC 模块，所以能直接启动。\\r\\n\\r\\n 启动类\\r\\n\\r\\n```java\\r\\n@Slf4j\\r\\npublic class SummerApplication {\\r\\n\\r\\n    static final String CONFIG_APP_YAML = \\\"/application.yml\\\";\\r\\n    static final String CONFIG_APP_PROP = \\\"/application.properties\\\";\\r\\n\\r\\n    public static void run(String webDir, String base\"},{\"url\":\"/frame/spring/custom/IOC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IOC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"其中构造方法注入和工厂方法注入是强依赖，因为Bean创建和属性注入放到一起了。\\r\\n\\r\\n比如构造方法注入，创建对象的同时进行属性注入，这种属于强依赖。\\r\\n\\r\\n而强依赖是解决不了循环依赖的问题的，因为创建对象和属性注入属于一体不可分的。\\r\\n\\r\\n我们解决循环依赖是先创建对象，然后属性注入的时候利用三级缓存解决的。\\r\\n\\r\\n```java\\r\\n    public BeanTest(@Value(\\\"spring.port\\\") String port, String name) {\\r\\n        System.out.println(port);\\r\\n    }\\r\\n```\\r\\n\\r\\nIOC容器有两类，Bean\"},{\"url\":\"/frame/spring/custom/JDBC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JDBC\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"DataSource\\r\\n\\r\\n自动注入DataSource\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\npublic class JdbcConfiguration {\\r\\n\\r\\n    /**\\r\\n     * 自动注入HikariDataSource\\r\\n     *\\r\\n     * @param url\\r\\n     * @param username\\r\\n     * @param password\\r\\n     * @param driver\\r\\n     * @param maximumPoolSize\\r\\n     * @param minimumPoolSize\\r\\n     * @pa\"},{\"url\":\"/frame/spring/custom/MVC.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MVC实现逻辑\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 应用程序必须配置一个Summer Framework提供的 Listener；\\r\\n2. Tomcat 完成 Servlet 容器的创建后，立刻根据配置创建Listener；\\r\\n    1. Listener初始化时创建 IOC 容器；\\r\\n    2. Listener继续创建DispatcherServlet实例，并向Servlet容器注册；\\r\\n    3. DispatcherServlet初始化时获取到IOC容器中的Controller实例，因此可以根据URL调用不同Controller实例的不同处理方法。\\r\\n    4. 容器中的Controller实例，因此可以根据URL调用不同\"},{\"url\":\"/frame/spring/custom/声明式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"声明式事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"事务传播模型\\r\\n\\r\\n| 传播行为 | 含义 |\\r\\n| --- | --- |\\r\\n| PROPAGATION_REQUIRED | 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择。 |\\r\\n| PROPAGATION_SUPPORTS | 支持当前事务，如果当前没有事务，就以非事务方式执行。 |\\r\\n| PROPAGATION_MANDATORY | 支持当前事务，如果当前没有事务，就抛出异常。 |\\r\\n| PROPAGATION_REQUIRED_NEW | 新建事务，如果当前存在事务，把当前事务挂起。 |\\r\\n| PROPAGATION_NOT_SUPPORTED | 以非事务方式\"},{\"url\":\"/frame/spring/custom/手写Spring.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"手写Spring\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- boot模块：实现一个简化版的 `Spring Boot`，用于打包运行。\\r\\n- web模块：实现Web MVC和REST API。\\r\\n\\r\\n Spring主要模块\\r\\n\\r\\n- context模块：实现ApplicationContext容器与Bean的管理；\\r\\n- aop模块：实现AOP功能；\\r\\n- jdbc模块：实现JdbcTemplate，以及声明式事务管理；\\r\\n\\r\\n IOC\\r\\n\\r\\nIOC\\r\\n\\r\\n AOP\\r\\n\\r\\nAOP\\r\\n\\r\\n JDBC\\r\\n\\r\\nJDBC\\r\\n\\r\\n声明式事务\\r\\n\\r\\n1. 由`JdbcConfiguration`创建的`DataSource`，实现了连接池；\\r\\n2. 由`Jdb\"},{\"url\":\"/frame/spring/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Spring框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Spring框架\\r\\n\\r\\n 一、Spring框架\\r\\n\\r\\n- Spring框架概述\\r\\n- ApplicationContext 和 BeanFactory 区别\\r\\n- BeanFactory 和 FactoryBean 总结\\r\\n- Spring中Bean的作用域\\r\\n- Spring中Bean加载流程\\r\\n- Spring依赖注入\\r\\n- Spring如何解决循环依赖\\r\\n\\r\\n- AOP\\r\\n- Spring事务总结\\r\\n- Aware接口\\r\\n- Spi机制\\r\\n- Spring配置文件加载顺序\\r\\n\\r\\n 二、使用总结\\r\\n\\r\\n- Spring自定义注解扫描\\r\\n- ByteBuddy实现动态代理\\r\\n\\r\\n 三、手写S\"},{\"url\":\"/frame/springboot/SpringBoot使用APO记录操作日志.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot使用APO记录操作日志\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"通过织入自定义注解 @Log，再进行解析记录操作日志。\\r\\n\\r\\n1. 自定义注解 @Log\\r\\n    \\r\\n    ```java\\r\\n    @Target({ElementType.PARAMETER, ElementType.METHOD})\\r\\n    @Retention(RetentionPolicy.RUNTIME)\\r\\n    @Documented\\r\\n    public @interface Log {\\r\\n    \\r\\n        /**\\r\\n         * 模块\\r\\n         */\\r\\n        String title() default \\\"default\\\";\\r\\n\"},{\"url\":\"/frame/springboot/SpringBoot能同时处理多少请求.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot能同时处理多少请求\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot内置了Tomcat，处理请求是 Web 容器处理的。\\r\\n\\r\\n1. 线程池线程数限制\\r\\n\\r\\n   而 Tomcat 的线程池默认最大线程池是 200，所以默认同时最多能处理 200 个请求。\\r\\n\\r\\n   \\r\\n&gt;\\r\\n2. 连接数限制\\r\\n\\r\\n   达到连接池数时，会限制请求数。此时因连接数限制为准，而不是最大线程数。\\r\\n\\r\\n    ```\\r\\n    tomcat最大连接数限制\\r\\n    server.tomcat.max-connections=12\\r\\n    ```\\r\\n\\r\\n\\r\\n---\\r\\n\\r\\n 限制配置\\r\\n\\r\\n```\\r\\ntomcat最大连接数限制\\r\\nserver.tomca\"},{\"url\":\"/frame/springboot/SpringBoot项目自动初始化数据库.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot项目自动初始化数据库\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"背景\\r\\n\\r\\n在 SpringBoot 启动的时候若配置文件中配置的数据库不存在，则自动创建数据库，并执行初始化SQL。\\r\\n\\r\\n 思路\\r\\n\\r\\n1. 判断数据库是否存在。\\r\\n2. 手动注入Datasource。\\r\\n    \\r\\n    在数据库未创建时，启动会报错\\r\\n    \\r\\n3. 初始化表。\\r\\n\\r\\n 解决方式\\r\\n\\r\\n1. 启动类排除 `DataSourceAutoConfiguration.class` ，采用手动注入的方式。\\r\\n    \\r\\n    如果配置的数据库不存在，SpringBoot启动的时候会提示找不到数据库，所以要排除掉，然后手动注入。\\r\\n    \\r\\n    ```java\\r\\n  \"},{\"url\":\"/frame/springboot/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringBoot 框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringBoot 框架\\r\\n\\r\\n\\r\\n 使用总结\\r\\n- SpringBoot能同时处理多少请求\\r\\n- SpringBoot使用APO记录操作日志\\r\\n- SpringBoot项目自动初始化数据库\"},{\"url\":\"/frame/springcloud/Feigh远程调用原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Feigh远程调用原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"思路\\r\\n\\r\\n根据接口地址和 FeignClient构建http请求。\\r\\n\\r\\n1. 构建 http请求模版，包含 header、body、method等参数信息。\\r\\n2. 设置 options，包含超时时间参数配置。\\r\\n3. 根据 clientName 从 nacos（类似map，保存clientName和访问地址的对应关系）中获取访问地址。\\r\\n4. 根据访问地址和http请求参数发起http请求。\\r\\n\\r\\n 代码入口\\r\\n\\r\\n`io/github/openfeign/feign-core/10.4.0/feign-core-10.4.0.jar!/feign/ReflectiveFeign.cla\"},{\"url\":\"/frame/springcloud/Gateway.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Gateway\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"请求流程\\r\\n\\r\\n&lt;img src=\\\"https://s2.loli.net/2025/06/10/RBVjazHT3NinfQe.png\\\" alt=\\\"image.png\\\" style=\\\"zoom:50%;\\\" /\\r\\n\\r\\n- Gateway Handler（网关处理器）：网关处理器是 Spring Cloud Gateway 的核心组件，负责将请求转发到匹配的路由上。它根据路由配置和断言条件进行路由匹配，选择合适的路由进行请求转发。网关处理器还会依次应用配置的过滤器链，对请求进行处理和转换。\\r\\n- Gateway Filter Chain（网关过滤器链）：网关过滤器链由一系列过滤器组成，按照\"},{\"url\":\"/frame/springcloud/Nacos.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Nacos\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"地址\\r\\n\\r\\n GitHub\\r\\n\\r\\nhttps://github.com/alibaba/nacos\\r\\n\\r\\n 文档\\r\\n\\r\\nNacos 快速开始\\r\\n\\r\\n 启动命令\\r\\n\\r\\n```sql\\r\\nsh startup.sh -m standalone\\r\\n```\\r\\n\\r\\n 可视化页面\\r\\n\\r\\n`http://localhost:8848/nacos`\\r\\n\\r\\n\\r\\n\\r\\n 注册中心原理\\r\\n\\r\\n 服务注册\\r\\n\\r\\nNocas Client 在启动的时候会通过 Rest 的方式将自己的元数据（Ip、端口）等信息发给 Nocas Server。\\r\\n\\r\\nNacos Server 收到 Client 的注册请求后，将元数据信息存到\"},{\"url\":\"/frame/springcloud/Seata分布式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Seata分布式事务\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在分布式情况下，一次业务请求需要调用多个系统操作多个数据源时，针对多个数据源操作会产生分布式事务问题。每个系统能够保证各自数据源的一致性问题，但是全部系统数据的一致性问题没法保证。\\r\\n\\r\\n 官网地址\\r\\n\\r\\nhttps://seata.io/zh-cn/docs/user/quickstart.html\\r\\n\\r\\n 下载地址\\r\\n\\r\\nhttps://seata.io/zh-cn/blog/download.html\\r\\n\\r\\n 基础概念\\r\\n\\r\\n事务ID + 三组件\\r\\n\\r\\n事务ID\\r\\n\\r\\n- Transaction ID(XID)\\r\\n\\r\\n三组件\\r\\n\\r\\n- TC-事务协调者\\r\\n\\r\\n  维护全局和分支事务的状态\"},{\"url\":\"/frame/springcloud/Sentinel原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Sentinel原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Sentinel工作主流程\\r\\n\\r\\n滑动窗口实现原理 · 吾爱开源 · 看云\\r\\n\\r\\n 限流算法\\r\\n\\r\\n 计数器算法\\r\\n\\r\\n计数器算法统计某个时间段的请求量，判断是否超过阈值。\\r\\n\\r\\n\\r\\n\\r\\n存在的问题：\\r\\n\\r\\n如上图中，在时间段的临界处加起来其实QPS 超过了阈值，但是平均到单个时间段未发生。\\r\\n\\r\\n单纯的计数器算法存在 临界统计不准确 的问题。\\r\\n\\r\\n 滑动窗口计数器算法\\r\\n\\r\\n解决滑动窗口存在的问题，引入了滑动窗口计数器。\\r\\n\\r\\n我们将统计时间细分，比如将 1s 统计时长分为 5个 时间窗口，通过 滚动统计所有时间窗口的QPS 作为系统实际的 QPS 的方式，就能解决上述 临界统计 问题。\\r\"},{\"url\":\"/frame/springcloud/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"SpringCloud\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"SpringCloud\\r\\n\\r\\n 使用总结\\r\\n\\r\\n- 注册中心的演进\\r\\n- Nacos\\r\\n- Gateway\\r\\n- Feigh远程调用原理\\r\\n- Sentinel原理\\r\\n- Seata分布式事务\\r\\n\\r\\n\\r\\n\\r\\n 项目\\r\\n\\r\\nSpringCloud总结练习-Gitee\"},{\"url\":\"/frame/springcloud/注册中心的演进.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"注册中心的演进\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 直接远程调用\\r\\n\\r\\n   \\r\\n\\r\\n2. 维护注册表，维护服务调用地址\\r\\n\\r\\n   \\r\\n\\r\\n3. 接入 nginx，利用 nginx 做负载\\r\\n\\r\\n   \\r\\n\\r\\n4. 引入注册机制，提供注册和服务发现功能\\r\\n\\r\\n   \\r\\n\\r\\n5. 引入心跳机制，解决注册中心宕机或者目标服务不可用\"},{\"url\":\"/java/cache/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Cache\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 本地缓存\\r\\n- 多级缓存\\r\\n- 缓存淘汰算法\"},{\"url\":\"/java/cache/多级缓存.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"多级缓存\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"二级缓存\\r\\n\\r\\n二级缓存没有网络开销\\r\\n\\r\\n\\r\\n\\r\\n 优点\\r\\n\\r\\n1. 减少网络请求，提高性能。\\r\\n2. 减少远程缓存的读压力。\\r\\n3. 天然分布式缓存，只存在于当前节点服务。\\r\\n\\r\\n 缺点\\r\\n\\r\\n1. 占用本地内存，空间有限，不支持大数据量。\\r\\n\\r\\n   只存储最热的数据到本地缓存，结合热点服务探测。\\r\\n\\r\\n2. 重启数据会丢失。\\r\\n\\r\\n   重启丢失数据无法避免，但是可以在重启项目的时候把最热的数据加到本地缓存。\\r\\n\\r\\n3. 分布式场景，数据可能不一致。\\r\\n4. 和远程缓存可能存在不一致的问题。\\r\\n\\r\\n   只能保证最终一致性，尽可能让本地缓存过期时间短一点，这样就能加载远程缓存，达到最终\"},{\"url\":\"/java/cache/本地缓存.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"本地缓存\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Guava\\r\\n\\r\\n- 支持最大容量限制\\r\\n- 支持两种过期删除策略\\r\\n- 支持简单的统计功能\\r\\n- 插入时间\\r\\n- 访问时间\\r\\n- 基于LRU算法实现\\r\\n\\r\\n```java\\r\\nLoadingCache&lt;Integer, String\\r\\n        //设置并发级别为8，并发级别是指可以同时写缓存的线程数\\r\\n        .concurrencyLevel(8)\\r\\n        //设置缓存的初始容量为10\\r\\n        .initialCapacity(10)\\r\\n        // 设置缓存最大容量为100，超过100之后就会按照LRU最近最少使用算法来移除缓存\\r\\n    \"},{\"url\":\"/java/cache/缓存淘汰算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"缓存淘汰算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"FIFO-先进先出\\r\\n\\r\\n\\r\\n\\r\\n比较简单，不够灵活。\\r\\n\\r\\n没有跟缓存使用频次和时间等维度联系起来。\\r\\n\\r\\n LRU-最近最少使用\\r\\n\\r\\n核心思想是最近使用的时间。比如最近一小时以内使用缓存的时间。\\r\\n\\r\\n\\r\\n\\r\\n根据数据的历史访问记录来淘汰数据，淘汰最久未被使用的数据。\\r\\n\\r\\n基于如果数据最近被访问过，那么将来访问的记录会更高。优先淘汰最久未被使用的冷数据。\\r\\n\\r\\n LFU-最近最不常用\\r\\n\\r\\n核心思想是最近使用的次数。比如最近一小时内使用缓存的次数。\\r\\n\\r\\n\\r\\n\\r\\nLFU能够提高热点数据的命中率。\\r\\n\\r\\n但是当缓存中数据都是热点数据的时候，将失去该特性。\\r\\n\\r\\n单纯的LFU存在缺陷。\\r\\n\"},{\"url\":\"/java/collection/Collection集合概述.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集合概述\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集合概述\\r\\n\\r\\n 为什么使用集合？\\r\\n\\r\\n当我们需要保存一组类型相同的数据的时候，我们应该用一个容器来保存，这个容器就是数组。\\r\\n\\r\\n但是数组的长度是固定的，当添加的元素超过了数组的长度之后，需要对数组重新定义。而且数组存储的数据是`有序的`、`可重复的`，太过于单一，扩展性不够。\\r\\n\\r\\n于是，引入了集合，Java 内部给我们提供了功能完善的集合框架。能`存储任意对象`，长度可以`动态改变`，提高了数据存储的灵活性。\\r\\n\\r\\n 数组和集合的区别\\r\\n\\r\\n1. 存储类型\\r\\n   - 数组可以存储`基本数据类型`，又可以存储`引用数据类型`。\\r\\n   - 集合只能存储`引用数据类型`。（集合中也可以存\"},{\"url\":\"/java/collection/ConcurrentHashMap1.7.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ConcurrentHashMap - 1.7\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、类简介\\r\\n\\r\\nConcurrentHashMap 是一个线程安全的 HashMap，在 JDK 1.7 HashMap的基础上实现了 `分段锁` 来保证线程安全。在 HashMap 的基础上，默认分为 16 个段，每个段都拥有独立的锁，来保证各个段的线程安全。\\r\\n\\r\\n 扩展 - 线程安全的 HashMap\\r\\n\\r\\nMap实现线程安全的三种方式\\r\\n\\r\\n Unsafe方法总结\\r\\n\\r\\n\\r\\n\\r\\n 二、主要参数\\r\\n\\r\\n```java\\r\\npublic class ConcurrentHashMap&lt;K, V\\r\\n        implements ConcurrentMap&lt;K, V&gt;\"},{\"url\":\"/java/collection/ConcurrentHashMap1.8.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ConcurrentHashMap -1.8\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ConcurrentHashMap 源码分析\\r\\n\\r\\n\\r\\n1.8的ConcurrentHashMap，采用对Node加锁机制。\\r\\n\\r\\n 加锁原理\\r\\n\\r\\n采用CAS+Synchronized组合锁的方法。\\r\\n\\r\\n- CAS\\r\\n\\r\\n  操作Node数组的时候以CAS方式操作。\\r\\n\\r\\n- Synchronized\\r\\n\\r\\n  操作Node对应的数据结构，链表或红黑树的时候加Synchronized。保证操作数据的原子性。\"},{\"url\":\"/java/collection/HashMap1.7.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HashMap - 1.7\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类简介\\r\\n\\r\\nHashMap 是一个用来存储 Key - Value 键值对的集合，每一个键值对也叫做 Entry，这些 Entry 保存在底层数组中。\\r\\n\\r\\n 1. 底层数组\\r\\n\\r\\n底层数组包含的每个元素可以称之为 桶，元素实际保存在每个桶上。\\r\\n\\r\\n```java\\r\\n    static final Entry&lt;?,?\\r\\n\\r\\n    /**\\r\\n     * The table, resized as necessary. Length MUST Always be a power of two.\\r\\n     */\\r\\n    transient Entry&lt;K,V&gt;[] t\"},{\"url\":\"/java/collection/HashMap1.8.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HashMap - 1.8\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类简介\\r\\n\\r\\n 默认参数\\r\\n\\r\\n- 默认长度\\r\\n\\r\\n  ```\\r\\n   static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4\\r\\n  ```\\r\\n\\r\\n- 最大容量\\r\\n\\r\\n  ```\\r\\n  static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;\\r\\n  ```\\r\\n\\r\\n- 默认负载因子\\r\\n\\r\\n  ```\\r\\n   static final float DEFAULT_LOAD_FACTOR = 0.75f;\\r\\n  ```\\r\\n\\r\\n- 默认树化临界点\\r\\n\\r\\n  ```\\r\\n  static final in\"},{\"url\":\"/java/collection/List集合体系.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"List集合体系\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ArrayList\\r\\n\\r\\n 特点\\r\\n\\r\\n- 底层基于数组实现。\\r\\n- 有索引，支持快速访问。\\r\\n- 查询修改快，增删慢。\\r\\n- 线程不安全。\\r\\n\\r\\n 构造方法\\r\\n\\r\\n1. 无参构造\\r\\n\\r\\n   - JDK 1.6 之前，以初始容量 10 创建一个长度为10的数组。\\r\\n   - JDK 1.6 之后，创建一个空数组。\\r\\n\\r\\n   ```java\\r\\n       public ArrayList() {\\r\\n           this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;\\r\\n       }\\r\\n   ```\\r\\n\\r\\n2. 有参构造 - 数\"},{\"url\":\"/java/collection/Set集合体系.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Set集合体系\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HashSet\\r\\n\\r\\n 特点\\r\\n\\r\\n- 底层基于哈希算法实现，使用 `HashMap` 保存数据。\\r\\n- 无序（存取顺序不一致）。\\r\\n- 不可以存储重复元素。\\r\\n- 线程不安全。\\r\\n\\r\\n 构造方法\\r\\n\\r\\n1. 无参构造\\r\\n\\r\\n   底层使用 `HashMap` 保存数据。\\r\\n   \\r\\n```java\\r\\n       public HashSet() {\\r\\n           map = new HashMap&lt;\\r\\n       }\\r\\n```\\r\\n\\r\\n3. 有参构造 - Collection 集合\\r\\n\\r\\n   根据传入的 Collection 集合 初始化底层 `HashMap`。\\r\\n\\r\\n\"},{\"url\":\"/java/collection/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集合\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Collection集合\\r\\n\\r\\n- Collection集合概述\\r\\n- List集合体系\\r\\n- Set集合体系\\r\\n\\r\\n Map集合体系\\r\\n\\r\\n- HashMap - 1.7\\r\\n- ConcurrentHashMap - 1.7\\r\\n- HashMap - 1.8\\r\\n- ConcurrentHashMap -1.8\"},{\"url\":\"/java/concurrent/Java高并发.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Java工程师成长计划-高并发\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java工程师成长计划-高并发\\r\\n\\r\\n```\\r\\n         _______________________________________________        \\r\\n        |   _      __        __                         |       \\r\\n________|  | | /| / / ___   / / ____ ___   __ _  ___    |_______\\r\\n\\\\       |  | |/ |/ / / -_) / / / __// _ \\\\ /  ' \\\\/ -_)   |      /\\r\\n \\\\      |  |\"},{\"url\":\"/java/concurrent/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"高并发\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"思维导图\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 参考链接\\r\\n\\r\\n- 深入浅出Java多线程\"},{\"url\":\"/java/concurrent/single/AQS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"AQS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"从ReentrantLock的实现看AQS的原理及应用\\r\\n\\r\\nAQS是一种提供了原子式管理同步状态、阻塞和唤醒线程功能以及队列模型的简单框架。\\r\\n\\r\\n 组成\\r\\n\\r\\n1. 共享资源状态维护state。\\r\\n\\r\\n   - AQS使用一个`volatile`修饰的 int 成员变量来表示同步状态，这个状态可以反映锁的当前持有情况。\\r\\n\\r\\n     例如，当状态为 0 时表示无锁状态，而当状态为非零时表示有锁被占用。\\r\\n\\r\\n2. FIFO 队列实现线程排队。\\r\\n\\r\\n   AQS维护了一个FIFO（先入先出）的双向队列，用于管理等待获取锁的线程，当一个线程尝试获取锁但失败时，它会进入这个队列并阻塞，直到锁\"},{\"url\":\"/java/concurrent/single/BlockQueue阻塞队列.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"阻塞队列BlockQueue\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"阻塞队列`BlockQueue`比起传统的`Queue`多了阻塞的功能，适合用于多线程之间的数据共享。阻塞主要发生在队列为空和队列满的情况。\\r\\n\\r\\n- 在队列为空的时候，操作元素出队的线程会进行循环等待，直到队列变为非空。\\r\\n- 在队列满的时候，操作元素入队的线程会进行循环等待，直到队列变为非满。\\r\\n\\r\\n 常见方法\\r\\n\\r\\n`BlockQueue入队`的方法有如下几种：\\r\\n\\r\\n- `offer()`方法，如果队列已满，无法存放，直接返回false。\\r\\n- `add()`方法，实际调用了offer()方法，增加了（Queue Full）的异常信息返回。\\r\\n- `put()`方法，若队列已满，会进行\"},{\"url\":\"/java/concurrent/single/CAS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"悲观和乐观策略\\r\\n\\r\\n锁有着悲观锁和乐观锁之分，悲观锁拥有资源的时候，认为随时会有人来篡改拥有的资源，所以在其拥有资源时不允许其他人访问。而乐观锁在拥有资源的时候不认为会有人来篡改其所拥有的资源，所以在其拥有资源的时候允许其他人访问。悲观锁和乐观锁是一种思想，对应的也是一种策略。\\r\\n\\r\\n加锁和使用 synchronized 其实就是一种悲观的策略，因为总是假设临界区的操作会产生冲突，如果有多个线程需要访问临界区资源，加锁和使用 synchronized 会阻塞其它线程。\\r\\n\\r\\n而无锁其实就是一种乐观的策略，它在操作的时候会假设访问资源不会冲突，所有的线程之间不存在阻塞，也就不存在等待，线程会持\"},{\"url\":\"/java/concurrent/single/ThreadLocal.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ThreadLocal总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ThreadLocal 提供了线程的局部变量，只有当前线程可以操作，不会和其它线程的局部变量产生冲突，实现了变量的线程安全。`ThreadLocal&lt;T\\r\\n\\r\\n 简单例子\\r\\n\\r\\n```java\\r\\npublic class ThreadLocalDemo {\\r\\n\\r\\n    private static ThreadLocal&lt;String&gt; threadLocal = new ThreadLocal&lt;&gt;();\\r\\n\\r\\n    public static void main(String[] args) {\\r\\n        //主线程\\r\\n        threadL\"},{\"url\":\"/java/concurrent/single/synchronized原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"synchronized原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"synchronized原理详解（通俗易懂超级好）-CSDN博客\\r\\n\\r\\n 特性\\r\\n\\r\\n- 原子性\\r\\n\\r\\n  synchronized 修饰的对象或类所有操作都是原子性的。线程需要获取锁，保证整个操作过程的原子性。\\r\\n\\r\\n  比如 i++这种赋值操作。\\r\\n\\r\\n- 可见性\\r\\n\\r\\n  一个线程如果要访问该类或对象必须先获得它的锁，而这个锁的状态对于其他任何线程都是可见的，并且在释放锁之前会将对变量的修改刷新到主存当中，保证资源变量的可见性。\\r\\n\\r\\n  如果某个线程占用了该锁，其他线程就必须在锁池中等待锁的释放。\\r\\n\\r\\n- 有序性\\r\\n\\r\\n  保证只有一个线程访问，确保了有序性。\\r\\n\\r\\n- 可重入性\\r\\n\"},{\"url\":\"/java/concurrent/single/transmittable-thread-local.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"transmittable-thread-local\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"线程池中的线程是可以复用的，假如第一个线程对  ThreadLocal 变量进行了操作，如果没有及时清理，下一个线程就会受到影响。因为 ThreadLocal  是在每个线程上维护了一个 ThreadLocalMap ，所以在线程复用的情况下，之后的线程会获取到  ThreadLocal  里之前线程设置的值。\\r\\n\\r\\n ThreadLocal多线程问题\\r\\n\\r\\n在多线程场景下传递ThreadLocal，如果线程池是池化的话，可能会导致复用ThreadLocal里面的值。\\r\\n\\r\\n\\r\\n\\r\\n 需求场景\\r\\n\\r\\n在使用线程池等池化复用线程的情况下，传递ThreadLoca值。\\r\\n\\r\\n1. 分布式跟踪 tr\"},{\"url\":\"/java/concurrent/single/原子类.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"原子类\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本类型-AtomicInteger\\r\\n\\r\\nAtomicInteger 是无锁的线程安全整数类，基于 `CAS` 实现，位于 `java.util.concurrent.atomic` 包下，该包下实现了一系列使用 `CAS` 操作实现线程安全的类型。其它原子类和 AtomicInteger 非常类似，故只分析 AtomicInteger。\\r\\n\\r\\n\\r\\n\\r\\n 比较 Integer\\r\\n\\r\\nAtomicInteger 是一个整数，与 Integer 不同的是，它是可变的并且是线程安全的。\\r\\n\\r\\n比如在多线程不加锁的情况下，操作 Integer 或者 AtomicInteger ，来比较结果是否正确。\"},{\"url\":\"/java/concurrent/single/死锁活锁和饥饿.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"死锁活锁和饥饿\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在使用锁的时候，可能会因为使用不当产生死锁、活锁和饥饿的现象。\\r\\n\\r\\n在单体应用中，加锁是否能解决所有的线程安全问题？\\r\\n\\r\\n*不能，因为加锁使用不当会有死锁、活锁和饥饿等问题。*\\r\\n\\r\\n 死锁\\r\\n\\r\\n什么是死锁？\\r\\n\\r\\n死锁指的是两个或多个线程之间，互相占用着对方请求的资源，而且不会释放已持有的资源，造成了多线程之间无限等待的现象，就叫做死锁。\\r\\n\\r\\n死锁发生后，会浪费大量的系统资源，并且在高并发下存在严重的安全隐患，甚至导致整个系统崩溃。\\r\\n\\r\\n 死锁产生的条件\\r\\n\\r\\n1. 互斥\\r\\n\\r\\n   某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结\"},{\"url\":\"/java/concurrent/single/线程池的关闭.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程池的关闭\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"线程池的关闭\\r\\n\\r\\n线程池的关闭方式有两种，一种是调用 `shutdown()` 方法，另一种是调用 `shutdownNow()` 方法。\\r\\n\\r\\n- shutdown\\r\\n\\r\\n  调用该方法后，线程池拒绝接受新提交的任务，同时等待线程池里和任务队列中的任务执行完毕再关闭线程。\\r\\n\\r\\n- shutdownNow\\r\\n\\r\\n  调用该方法后，线程池拒绝接受新提交的任务，不再执行任务队列的任务，将线程池任务队列里的任务全部返回。\\r\\n\\r\\n shutdown\\r\\n\\r\\n调用该方法后，线程池拒绝接受新提交的任务，同时等待线程池里和任务队列中的任务执行完毕再关闭线程。\\r\\n\\r\\n```java\\r\\n    public \"},{\"url\":\"/java/concurrent/single/线程池的执行流程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程池的执行\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"执行流程\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n1. 根据初始化参数创建线程池，刚创建时，线程池内没有线程。\\r\\n2. 当有新的任务提交到线程池的时候，会立即新增线程执行任务。\\r\\n3. 若运行线程数 = 核心线程数时，这时进来的任务会被添加到任务队列中，而线程会从任务队列中获取任务执行。\\r\\n4. 运行线程数 = 核心线程数 且 任务队列已满，这时候会在线程池中创建新线程来执行任务。\\r\\n5. 运行线程数 = 最大线程数，且任务队列已满，此时会执行线程池对应的拒绝策略。\\r\\n6. 当任务队列中没有任务，且线程等待时间超过空闲时间，则该线程会被回收。最终线程池中的线程数量会保持在核心线程数的大小。\\r\\n\\r\\n 源码分析\\r\\n\"},{\"url\":\"/java/concurrent/single/线程的生命周期.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"线程的生命周期\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 Java 中线程从新建到关闭会经过不同的状态，将线程从新建到关闭作为一个生命周期，在 Java 中整个线程的生命周期有 6 种状态。\\r\\n\\r\\n 线程状态类型\\r\\n\\r\\n在 JDK 的 Thread 类，存在 `State` 枚举类，包含了线程的 6 种状态。\\r\\n\\r\\n```java\\r\\n    public enum State {\\r\\n        \\r\\n        NEW,\\r\\n        RUNNABLE,\\r\\n        BLOCKED,\\r\\n        WAITING,\\r\\n        TIMED_WAITING,\\r\\n        TERMINATED;\\r\\n    }\\r\\n```\"},{\"url\":\"/java/distributed/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 分布式事务\\r\\n- 分布式锁\\r\\n- 分布式ID\\r\\n- 幂等性问题\"},{\"url\":\"/java/distributed/分布式ID.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式ID\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"要求\\r\\n\\r\\n1. 分布式全局唯一\\r\\n2. 有序递增\\r\\n\\r\\n 方案\\r\\n\\r\\n\\r\\n\\r\\n 数据库主键自增\\r\\n\\r\\n1. 创建一个全局主键自增的表。\\r\\n2.  从该表查询id使用。\\r\\n    - 效率低下，每次插入之前都要查一次自己的id\\r\\n\\r\\n 数据库号段模式\\r\\n\\r\\n批量从全局自增主键表获取一批主键，放到内存里。（减少数据库访问次数）\\r\\n\\r\\n```bash\\r\\nCREATE TABLE `sequence_id_generator` (\\r\\n  `id` int(10) NOT NULL,\\r\\n  `current_max_id` bigint(20) NOT NULL COMMENT '当前最大id',\\r\\n\"},{\"url\":\"/java/distributed/分布式事务.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"html\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在分布式情况下，假如存在 A 同时调用 B、C多个微服务。假如 B 服务事务正常执行并提交，但是 C 事务提交失败，此时 B 和 C都需要回滚。\\r\\n\\r\\n而 MySQL 的事务回滚是通过 redo log 机制来实现的，保证事务的持久化和一致性。\\r\\n\\r\\n但是在分布式，使用了分布式事务的情况下，是通过一条更新SQL，还原原本的数据。\\r\\n\\r\\n\\r\\n\\r\\n一文搞明白分布式事务解决方案！真的 so easy！\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n分布式事务，原理简单，写起来全是坑！ - 掘金\\r\\n\\r\\n\\r\\n\\r\\n 分布式事务解决方案\\r\\n\\r\\n 2PC - 两阶段提交\\r\\n\\r\\n1. prepare - 准备阶段\\r\\n\\r\\n    各个参\"},{\"url\":\"/java/distributed/分布式锁.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"分布式锁\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- mysql\\r\\n- redis 的 setnx\\r\\n- redission\\r\\n- redLock\\r\\n- zookeeper\\r\\n- curator\\r\\n\\r\\nredis的分布式锁可用性更高，但是分布式不友好。一般单机的redis实现分布式锁性能就够用。\\r\\n\\r\\n如果非要要求可靠性，可以选择zk，只是zk是cp的，性能要差一点。\\r\\n\\r\\n\\r\\n\\r\\n Reids分布式锁\\r\\n\\r\\nredis实现分布式锁\\r\\n\\r\\n\\r\\n\\r\\n 手写 zk 分布式锁\\r\\n\\r\\nzk 实现分布式锁，是依赖 zk 的临时有序节点。\\r\\n\\r\\n多个线程在 rootPath 下面按顺序创建节点。\\r\\n\\r\\n1. 首先有持久节点lock\\r\\n2. 每个请求获取锁\"},{\"url\":\"/java/distributed/幂等性问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"幂等性问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"常见幂等问题\\r\\n\\r\\n解决常见幂等性问题采用 `一锁、二判、三更新` 就可以解决。\\r\\n\\r\\n- 一锁：锁定需要处理的订单\\r\\n- 二判：订单是否支付\\r\\n- 三更新：更新订单状态\\r\\n\\r\\n 数据库锁-悲观锁\\r\\n\\r\\n- for Update\\r\\n  \\r\\n    `FOR UPDATE` 子句告诉数据库管理系统（DBMS）在检索行的同时锁定这些行，直到当前事务结束。\\r\\n    \\r\\n\\r\\n```java\\r\\nBEGIN;\\r\\n\\r\\nSELECT * FROM orders\\r\\nWHERE order_id = 123\\r\\nFOR UPDATE;\\r\\n\\r\\n-- 进行业务逻辑处理，例如更新订单状态\\r\\nUPDATE orders \"},{\"url\":\"/java/io/BIO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BIO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"JDK 网络编程 BIO，意为阻塞的 IO。\\r\\n\\r\\nBIO 的阻塞体现在两个方面：\\r\\n\\r\\n1. 若一个服务端的服务绑定端口启动后，主线程就会一直等待客户端的连接。\\r\\n2. 客户端和服务端 Socket 端口建立连接之后，在读取到 Socket 信息之前，线程一直处于等待，一直处于阻塞状态。\\r\\n\\r\\n典型的 请求 -应答模型\\r\\n\\r\\n由一个独立的 `Acceptor` 模型监听客户端的请求，收到请求后为每一个客户端创建一个线程去处理，处理完成后将结果返回给客户端。\\r\\n\\r\\nJava BIO：传统的网络通讯模型，就是BIO，同步阻塞IO。\\r\\n\\r\\n其实就是服务端创建一个ServerSocket， 然后就是\"},{\"url\":\"/java/io/IO多路复用.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IO多路复用\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"小白也看得懂的 I/O 多路复用解析（超详细案例）_哔哩哔哩_bilibili\\r\\n\\r\\n 基础概念\\r\\n\\r\\n\\r\\n\\r\\n1. Socket\\r\\n\\r\\n   套接字，在网络通信中，就是客户端和服务端的出入口。\\r\\n\\r\\n   \\r\\n&gt;\\r\\n2. fd\\r\\n\\r\\n   文件描述符，是指向资源文件的索引。\\r\\n\\r\\n\\r\\n Socket通讯的过程\\r\\n\\r\\n\\r\\n\\r\\n1. 服务端通过 bind 绑定机器的端口号， 进程 listen 某个端口。\\r\\n2. 客户端和服务端通过 tcp 三次握手建联。\\r\\n3. 进行数据交互，\\r\\n4. 最后通过 close 断开连接。\\r\\n\\r\\n IO模型\\r\\n\\r\\n\\r\\n\\r\\n 同步阻塞IO - BIO\\r\\n\\r\\n-\"},{\"url\":\"/java/io/NIO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"NIO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NIO 是 JDK1.4 引入，为了解决 BIO 阻塞的问题，又称 `no-blocking io`。\\r\\n\\r\\n同步非阻塞\\r\\n\\r\\n NIO特点\\r\\n\\r\\n- 面向缓冲区\\r\\n  \\r\\n    BIO 是面向流的，NIO 是面向缓冲区的。\\r\\n    \\r\\n    \\r\\n\\r\\n- 非阻塞模式\\r\\n  \\r\\n    NIO 的非阻塞模式，使其线程从 Channel 获取数据时，即使获取不到数据也不会阻塞线程。\\r\\n    \\r\\n\\r\\n NIO 核心组件\\r\\n\\r\\n\\r\\n\\r\\n Selector-轮询选择器\\r\\n\\r\\nJava NIO 的选择器允许一个单独的线程来监视多个输入通道（Channel）。\\r\\n\\r\\n选择器用于检测一个或多个通道的状\"},{\"url\":\"/java/io/Reactor模式.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Reactor模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Reactor模式详解＋源码实现\\r\\n\\r\\n整个 reactor 模式解决的主要问题就是在接收到任务后根据分发器快速进行分发给相应的事件处理器，不需要从开始状态就阻塞。\\r\\n\\r\\n基于事件驱动模型，当接收到请求后会将请求封装成事件，并将事件分发给相应处理事件的Handler，handler处理完成后将事件状态修改为下一个状态，再由Reactor将事件分发给能够处理下一个状态的handler进行处理。\\r\\n\\r\\n\\r\\n\\r\\n1. EventHandler：事件处理器，可以根据事件的不同状态创建处理不同状态的处理器；\\r\\n   \\r\\n    ```java\\r\\n    public abstract class Eve\"},{\"url\":\"/java/io/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"IO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- BIO\\r\\n- 基于BIO实现RPC框架\\r\\n- NIO\\r\\n- Reactor模式\\r\\n- IO多路复用\"},{\"url\":\"/java/io/基于BIO实现RPC框架.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"基于BIO实现RPC框架\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基于bio手写实现简单的rpc_java 手写一个bio-CSDN博客\\r\\n\\r\\n RPC\\r\\n\\r\\n\\r\\n\\r\\n RPC设计\\r\\n\\r\\n\\r\\n\\r\\nRPC 的核心就是让客户端调用远程服务方法，就像调用本地方法一样。\\r\\n\\r\\n- 服务端将自己的类注册到远程服务。\\r\\n- 客户端通过注册中心获取到服务端地址。\\r\\n    - 客户端调用服务端地址，传入类名，调用方法、入参\\r\\n    - 服务端收到方法信息后，本地通过反射执行方法，获取结果返回给客户端。\\r\\n- 客户端需要写一个需要调用的类，和服务端的类保持一致（方法名、入参类型、入参）。\\r\\n    - 客户端需要对这个类进行动态代理，实际访问的是该类的代理对象。\\r\\n   \"},{\"url\":\"/java/jvm/CPU负载过高排查记录.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"CPU负载过高排查记录\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"解决线上微服务容器cpu占用100%问题（java进程占用100%问题）_容器cpu占用高_上树的蜗牛儿的博客-CSDN博客\\r\\n\\r\\n 平台发现问题\\r\\n\\r\\n平台发现集群节点 node219 CPU利用率过高。\\r\\n\\r\\n\\r\\n\\r\\n通过查看该节点下的 pod 发现，bookdemo 使用 CPU 过高。\\r\\n\\r\\n\\r\\n\\r\\n 主机排查\\r\\n\\r\\n top 查看进程情况\\r\\n\\r\\n使用 top 确认占用cpu过高的进程。\\r\\n\\r\\nPID=17177 占用 CPU 最高。\\r\\n\\r\\n\\r\\n\\r\\n 查看进程 PID 对应的容器\\r\\n\\r\\n由于该进程是个POD，需要找到对应容器，进入容器内部排查线程情况。\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 容器内部\"},{\"url\":\"/java/jvm/G1收集器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"G1收集器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- XX:+UseG1GC\\r\\n\\r\\nG1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对 配备多颗处理器及大容量内存的机器，以极高概率满足GC停顿时间要求的同时，还具备高吞吐量性能特征。\\r\\n\\r\\nG1 收集器 在 JDK1.7 正式启用，是 JDK 9以后的默认垃圾收集器，取代了 CMS 以及 Parallel+Parallel Old 的组合，被 Oracle 官方称为“全功能的垃圾收集器”。\\r\\n\\r\\n- 适合大内存机器，具备高吞吐量。\\r\\n- 低 GC 停顿时间。\\r\\n\\r\\n 堆分布\\r\\n\\r\\n 区域分布\\r\\n\\r\\n\\r\\n\\r\\n区分于传统的堆内存分布，G1 是将 JVM 堆内存划分为了多个 \"},{\"url\":\"/java/jvm/JDK调优命令.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JDK调优命令\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"jstack\\r\\n\\r\\n 死锁检测\\r\\n\\r\\n1. 使用 jps 命令查看运行中的 java 进程 Id。\\r\\n   \\r\\n    \\r\\n    \\r\\n2. 使用 jstack 分析线程状态。\\r\\n   \\r\\n    ```\\r\\n    jstack 进程Id\\r\\n    ```\\r\\n    \\r\\n    - 线程状态\\r\\n      \\r\\n        通过分析进程可以得到，`DeadLockTest` 进程的两个线程分别为 `pool-1-thread-2` （简称2）和 `pool-1-thread-1`（简称1）。\\r\\n        \\r\\n        通过打印的线程信息可以发现，线程 2 和 1 的线程状态都是 \"},{\"url\":\"/java/jvm/JVM内存模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JVM内存模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Java 内存模型在 JDK1.7 主要包含以下区域。\\r\\n\\r\\n- 程序计数器\\r\\n- 虚拟机栈\\r\\n- 本地方法栈\\r\\n- 方法区\\r\\n- 堆\\r\\n\\r\\n而在 JDK1.8中将运行时数据区中的方法区给取消了，换成了本地内存中的元数据区。\\r\\n\\r\\n- 程序计数器\\r\\n- 虚拟机栈\\r\\n- 本地方法栈\\r\\n- 堆\\r\\n- 元数据区\\r\\n\\r\\n 内存模型图\\r\\n\\r\\n1. JDK 1.7 内存模型图\\r\\n   \\r\\n    \\r\\n    \\r\\n2. JDK 1.8 内存模型图\\r\\n   \\r\\n    JDK1.8中取消了运行时数据区中的方法区，换成了元数据区放到了本地内存里。\\r\\n    \\r\\n    \\r\\n    \\r\\n\\r\\n 运行时数据区\\r\\n\\r\\n\"},{\"url\":\"/java/jvm/Java类加载器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"类加载器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"什么是类加载器\\r\\n\\r\\n类加载器（ClassLoader）就是在系统运行过程中动态的将编译后的.class字节码文件加载到JVM中的工具。在IDE中编写的源代码文件都是`.java`文件，通过编译对应生成`.class`文件。而类加载器就是用来将`.class`文件加载到JVM中的工具。\\r\\n\\r\\n 类加载器类型\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nJava默认提供了三个类加载器，分别是 AppClassLoader、ExtClassLoader、BootstrapClassLoader，除此之外还可以自定义类加载器。类加载器之间是父级的关系，但不是通过继承实现父级关系的，而是通过组合的形式来实现的，在`Clas\"},{\"url\":\"/java/jvm/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"JVM\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"一、类加载器\\r\\n\\r\\n- 类加载器\\r\\n- 对象创建\\r\\n\\r\\n 二、内存模型\\r\\n\\r\\n- JVM内存模型\\r\\n\\r\\n 三、垃圾回收\\r\\n\\r\\n- 垃圾回收算法\\r\\n- 垃圾回收器\\r\\n- G1收集器\\r\\n\\r\\n 四、命令工具\\r\\n\\r\\n- JDK调优命令\\r\\n- 可视化工具\\r\\n\\r\\n 五、排障记录\\r\\n\\r\\n- CPU负载过高排查记录\\r\\n- 内存问题排查总结\\r\\n- 频繁GC排查\\r\\n\\r\\n---\"},{\"url\":\"/java/jvm/内存问题排查总结.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"内存问题排查总结\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"堆内存dump\\r\\n\\r\\n```\\r\\n1 jmap ‐dump:format=b,file=eureka.hprof 14660\\r\\n```\\r\\n\\r\\n可以配置自动 dump 文件，在内存溢出的时候会自动 dump 文件。\\r\\n\\r\\n```\\r\\n-XX:+HeapDumpOnOutOfMemoryError\\r\\n```\\r\\n\\r\\n比如应用的启动脚本，开启自动 dump 文件。\\r\\n\\r\\n```\\r\\nexec java -classpath $CLASSPATH -Xms1024m -Xmx2048m\\r\\n-XX:+HeapDumpOnOutOfMemoryError\\r\\n-Dquery.type=es\\r\\n-Dfile.enco\"},{\"url\":\"/java/jvm/可视化工具.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可视化工具\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"jconsole\\r\\n\\r\\njconsole是JDK 提供的可视化工具。可以查看内存、线程数量、CPU等资源信息。\\r\\n\\r\\n 使用方式\\r\\n\\r\\n 本地进程\\r\\n\\r\\n直接执行命令\\r\\n\\r\\n```java\\r\\njconsole\\r\\n```\\r\\n\\r\\n 远程进程\\r\\n\\r\\n```java\\r\\n-Djava.rmi.server.hostname=10.10.102.81-Dcom.sun.management.jmxremote.port=9999-Dcom.sun.management.jmxremote-Dcom.sun.management.jmxremote.authenticate=false\\r\\n-Dcom.sun\"},{\"url\":\"/java/jvm/垃圾回收器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"垃圾回收器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"垃圾回收类型\\r\\n\\r\\n1. 串行\\r\\n    - 单线程\\r\\n    - 适合堆内存小的时候。\\r\\n    - STW\\r\\n      \\r\\n        Stop The World 的简称。这是因为串行的机制，在垃圾回收的线程运行的时候，其它工作线程都要阻塞。\\r\\n        \\r\\n        *在垃圾回收过程中，对象的地址会发生改变。如果其它线程不阻塞，则可能会发生对象引用错误的问题。*\\r\\n    \\r\\n2. 吞吐量优先\\r\\n    - 多线程\\r\\n    - 适合堆内存较大，且多核CPU的情况。\\r\\n    - 在单位时间内，STW时间最短。\\r\\n3. 响应时间优先\\r\\n    - 多线程\\r\\n    -\"},{\"url\":\"/java/jvm/垃圾回收算法.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"垃圾回收算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"如何判断对象可以回收\\r\\n\\r\\n 引用计数法\\r\\n\\r\\n为对象添加引用计数器，如果对象被其它对象引用一次，计数器 +1；对应引用释放，则计数器 -1；只有当计数器为 0 时该对象才会被垃圾回收。\\r\\n\\r\\n- 引用计数法造成的内存泄漏\\r\\n  \\r\\n    像下面这种即使对象不被其它对象引用，这两个对象也一直不会被回收，因为对象A和B之间存在引用关系，引用计数器一直为 1，这样就导致了内存泄露。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n\\r\\n\\r\\n\\r\\n 可达性分析算法\\r\\n\\r\\n&gt; 如果某个对象到GC Roots间没有任何引用链相连， 或者用图论的话来说就是从GC Roots到这个对象不可达时，则证明此\"},{\"url\":\"/java/jvm/对象创建.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"对象创建\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"对象的创建流程\\r\\n\\r\\n\\r\\n\\r\\n 类加载检查\\r\\n\\r\\n判断有无加载过该类，有则直接进入下一步、没有则加载类对象。\\r\\n\\r\\n 分配内存\\r\\n\\r\\n虚拟机为新生对象分配内存。\\r\\n\\r\\n对象所需内存大小在类检查阶段便可确定，为对象分配空间就是将一块确定大小内存从 Java 堆中划分出来。\\r\\n\\r\\n 1. 划分内存的方法\\r\\n\\r\\n- 指针碰撞法\\r\\n  \\r\\n    该方法是JVM中的默认方法。\\r\\n    \\r\\n    它主要就是假设JVM中的内存是绝对规整的，使用过的内存和未使用过的内存分别放在两边，用一个指针来给他们做区分。如果要分配内存，只需要将指针向空闲的那一端移动对象大小的位置就好了。\\r\\n    \\r\\n- 空闲列表\"},{\"url\":\"/java/jvm/类加载器.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"类加载器\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"什么是类加载器\\r\\n\\r\\n类加载器（ClassLoader）就是在系统运行过程中动态的将编译后的.class字节码文件加载到JVM中的工具。在IDE中编写的源代码文件都是`.java`文件，通过编译对应生成`.class`文件。而类加载器就是用来将`.class`文件加载到JVM中的工具。\\r\\n\\r\\n 类加载器类型\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nJava默认提供了三个类加载器，分别是 AppClassLoader、ExtClassLoader、BootstrapClassLoader，除此之外还可以自定义类加载器。类加载器之间是父级的关系，但不是通过继承实现父级关系的，而是通过组合的形式来实现的，在`Clas\"},{\"url\":\"/java/jvm/频繁GC排查.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"频繁GC排查\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```\\r\\njstat -gcutil 1000\\r\\n```\\r\\n\\r\\n\\r\\n\\r\\n```\\r\\njmap -dump:format=b,file=dumpfile 1000\\r\\n```\\r\\n\\r\\n使用 MAT 工具分析代码\\r\\n\\r\\n---\\r\\n\\r\\n组件消费数据的线程池配置有问题。\"},{\"url\":\"/middleware/es/BulkProcessor死锁问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"BulkProcessor死锁问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"问题原因\\r\\n\\r\\n- 定时flush\\r\\n- bulk操作\\r\\n- retryHandler：失败重试\\r\\n1. 定时 flush 和 retryHandler 用的是一个定时线程池，而该线程池只有一个线程。\\r\\n2. 定时 flush 的方法用的锁和 bulk 操作时的锁是同一把锁。都是类对象级别的锁。\\r\\n   \\r\\n    \\r\\n    \\r\\n    \\r\\n    \\r\\n3. 当bluk失败后，会触发默认的重试逻辑。\\r\\n4. 如果重试时候 flush 刚好运行，就会出现这种死锁情况。\\r\\n    1. bulk持有对象锁`BulkProcessor.class`，进行重试逻辑。\\r\\n    2. flush占有线\"},{\"url\":\"/middleware/es/ES分片.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES分片\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"同一个索引会划分为多个分片。分片可以设置副本数量，分为主分片和副本分片。\\r\\n\\r\\n```java\\r\\n 指定索引的主分片和副本分片数\\r\\nPUT /blogs\\r\\n{\\r\\n  \\\"settings\\\": {\\r\\n    \\\"number_of_shards\\\": 3,\\r\\n    \\\"number_of_replicas\\\": 1\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n 主分片\\r\\n\\r\\n- 解决数据水平扩展的问题。同一个索引可以按照分片分配数据，将数据平均分配到所有节点之上。\\r\\n- 主分片数创建好后就不能修改。\\r\\n- 一个分片就是一个运行的 Lucene 实例。\\r\\n\\r\\n 主分片过少\\r\\n\\r\\n- 单个分片数据量过大。查询较慢，利用\"},{\"url\":\"/middleware/es/ES压测记录和esrally使用.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES压测记录和esrally使用\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"环境信息\\r\\n\\r\\n- 压测环境\\r\\n  \\r\\n    ```\\r\\n    http://10.1.11.200:39200/\\r\\n    ```\\r\\n    \\r\\n- 开发环境\\r\\n  \\r\\n    ```java\\r\\n    http://10.10.101.69:39200\\r\\n    ```\\r\\n    \\r\\n- 测试环境\\r\\n  \\r\\n    ```java\\r\\n    http://10.10.103.218:39200/\\r\\n    ```\\r\\n    \\r\\n\\r\\n esrally安装\\r\\n\\r\\n docker安装\\r\\n\\r\\n1. 拉取镜像\\r\\n   \\r\\n    ```\\r\\n    docker pull elastic/rally\"},{\"url\":\"/middleware/es/ES参数调优.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES参数调优\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"预防脑裂\\r\\n\\r\\n\\r\\n\\r\\n重要配置的修改 | Elasticsearch: 权威指南 | Elastic\\r\\n\\r\\n 堆内存设置\\r\\n\\r\\n```\\r\\n -Xms2730m -Xmx2730m -Duser.timezone=Asia/Shanghai\\r\\n```\\r\\n\\r\\nxms和xmx设置一样大小，并设置为略小于pod分配内存的一半。\\r\\n\\r\\n 分片设置\\r\\n\\r\\n分片过小或过多都会影响es的查询速率。\\r\\n\\r\\n一经设置无法修改。\\r\\n\\r\\n目前是10个分片，数据量不大的情况下，设置为5个分片进行测试一下。1个、和node数量一致分片测试。\\r\\n\\r\\n1GB 20个分片\\r\\n\\r\\n1个 20G～40GB\\r\\n\\r\\n 副本数量\\r\\n\\r\"},{\"url\":\"/middleware/es/ES深度分页问题.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES深度分页问题\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"from+to分页\\r\\n\\r\\nes在查询时候默认使用的是分页查询，单次只会返回10条数据。\\r\\n\\r\\n可以指定size。\\r\\n\\r\\n\\r\\n\\r\\n- 查询要求默认 from+size 的结果必须不超过10000。\\r\\n  \\r\\n    可以通过修改配置\\r\\n    \\r\\n    ```java\\r\\n    \\\"index.max_result_window\\\":\\\"20000\\\"\\r\\n    ```\\r\\n    \\r\\n    限制单词查询满足条件的结果窗口的大小，由from+size共同决定。\\r\\n    \\r\\n    因为es是先将数据全查出来再做分页，这样做是为了限制内存的消耗。\\r\\n    \\r\\n    ---\\r\\n    \\r\\n    因\"},{\"url\":\"/middleware/es/ES滚动查询-Scroll.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES滚动查询-Scroll\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"原理\\r\\n\\r\\nElasticsearch中的滚动查询是基于 固定的排序规则 来加载一部分数据。\\r\\n\\r\\n当用户刷新时，将从上次加载的最后一条数据的位置再加载同样数量的数据。\\r\\n\\r\\n滚动查询的原理类似于分页查询，但是滚动查询不需要重新执行搜索，只需要继续检索下一批结果。在滚动查询中，每次只加载当前页的数据，而不是一次性加载所有数据。这使得滚动查询比分页查询更高效，因为滚动查询不需要将所有数据都存储在内存中。同时，滚动查询也适用于大量数据的处理，因为它可以分批次地处理数据，而不是一次性处理所有数据。\\r\\n\\r\\n 滚动查询的排序规则\\r\\n\\r\\n滚动查询的排序规则不一定是时间。在Elasticsearch中，滚动\"},{\"url\":\"/middleware/es/ES的log4j2日志自动清理配置.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES的log4j2日志自动清理配置\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"配置\\r\\n\\r\\n```xml\\r\\nappender.rolling.strategy.type = DefaultRolloverStrategy\\r\\nappender.rolling.strategy.fileIndex = nomax\\r\\nappender.rolling.strategy.action.type = Delete\\r\\nappender.rolling.strategy.action.basepath = ${sys:es.logs.base_path}\\r\\nappender.rolling.strategy.action.condition.type = IfFileName\\r\\napp\"},{\"url\":\"/middleware/es/ES聚合查询原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES聚合查询原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES在对海量数据进行聚合分析的时候会损失搜索的精准度来满足实时性的需求。\"},{\"url\":\"/middleware/es/ES集群.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"ES集群\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集群节点类型\\r\\n\\r\\n1. Master Node - 主节点\\r\\n2. DataNode - 数据节点\\r\\n3. Coordinating Node - 协调节点\\r\\n\\r\\n Master Node\\r\\n\\r\\n- 处理创建，删除索引等请求。\\r\\n- 决定分片被分配到哪个节点。\\r\\n- 维护并更新集群 state。\\r\\n\\r\\n Master Node节点最佳实践\\r\\n\\r\\n- Master节点非常重要，在部署上需要解决单点问题。\\r\\n- 为一个集群设置多个Master节点，而且节点只承担 Master 角色。\\r\\n\\r\\n Data Node\\r\\n\\r\\n保存数据的节点，负责保存分片数据。\\r\\n\\r\\n通过增加数据节点可以解决数据水平扩展\"},{\"url\":\"/middleware/es/Elasticsearch写入原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch写入原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基本概念\\r\\n\\r\\n 索引\\r\\n\\r\\nElasticsearch的索引是一个逻辑上的概念，指存储了相同类型的文档集合。\\r\\n\\r\\n 映射\\r\\n\\r\\n映射（mapping）定义索引中有什么字段、进行字段类型确认。类似于数据库中表结构定义。\\r\\n\\r\\nES 默认动态创建索引和索引类型的 映射（mapping），就像是非关系型数据中的，无需定义表结构，更不用指定字段的数据类型。\\r\\n\\r\\n也可以手动指定 mapping 类型，比如通过请求设置索引的映射（mapping）。\\r\\n\\r\\n```java\\r\\ncurl --location --request POST 'localhost:9200/course/_mapping' \"},{\"url\":\"/middleware/es/Elasticsearch基础概念.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch基础概念\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础概念\\r\\n\\r\\n 一、索引库（index）\\r\\n\\r\\nElasticsearch的索引库是一个逻辑上的概念，存储了相同类型的文档内容。类似于 MySQL 数据表，MongoDB 中的集合。\\r\\n\\r\\n1. 新建索引库\\r\\n    - number_of_shards\\r\\n      \\r\\n        设置分片的数量，在集群中通常设置多个分片，表示一个索引库将拆分成多片分别存储不同 的结点，提高了ES的处理能力和高可用性，入门程序使用单机环境，这里设置为 1。\\r\\n        \\r\\n    - number_of_replicas\\r\\n      \\r\\n        设置副本的数量，设置副本是为了提高ES的\"},{\"url\":\"/middleware/es/Elasticsearch查询原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch查询原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES查询原理\\r\\n\\r\\n 查询方式\\r\\n\\r\\n- 根据 doc_id 查询。\\r\\n\\r\\n\\r\\n\\r\\n- 根据条件查询\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引\\r\\n\\r\\n根据文档中的每个字段建立倒排索引。\\r\\n\\r\\n 倒排索引的查询流程\\r\\n\\r\\n\\r\\n\\r\\n1. 查询条件分词。\\r\\n2. 查询单词词典 （term dictionary）。\\r\\n3. 获取对应分词的 doc_id 列表。\\r\\n4. 将查询结果返回。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 倒排索引的组成\\r\\n\\r\\n- postings list\\r\\n  \\r\\n    文档列表。\\r\\n    \\r\\n- term dictionary\\r\\n  \\r\\n    单词字典表。包含文档中所有的单词，es 会将单词排序\"},{\"url\":\"/middleware/es/Elasticsearch检索.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch检索\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"检索方式\\r\\n\\r\\nElasticsearch提供两种检索方式。\\r\\n\\r\\n1. RestAPI 形式通过 URL 参数进行检索。\\r\\n2. 通过 DSL 语句进行查询，通过传递 JSON 为请求体与 Elasticsearch 进行交互，这种方式更强大简洁。\\r\\n\\r\\n URL检索\\r\\n\\r\\n`GET /{index}/{type}/_search?q=*&sort=age:desc&size=5&from=0&_source=name,age,bir`\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\nq=* ：匹配所有文档\\r\\n\\r\\nsort=age：按照指定字段进行排序，默认为升序，:desc 降序排列\\r\\n\\r\\nsize：展示多少\"},{\"url\":\"/middleware/es/Elasticsearch聚合查询.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch聚合查询\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES在对海量数据进行聚合分析的时候会损失搜索的精准度来满足实时性的需求。\\r\\n\\r\\n Elasticsearch聚合查询总结\\r\\n\\r\\n 1. 求和、最大值、最小值、平均值\\r\\n\\r\\n- 求和 - sum\\r\\n- 最大值 - max\\r\\n- 最小值 - min\\r\\n- 平均值 - avg\\r\\n\\r\\n---\\r\\n\\r\\nDSL查询语句\\r\\n\\r\\n```java\\r\\n{\\r\\n    \\\"size\\\": 0,\\r\\n    \\\"query\\\": {\\r\\n        \\\"bool\\\": {\\r\\n            \\\"filter\\\": [\\r\\n                {\\r\\n                    \\\"range\\\": {\\r\\n    \"},{\"url\":\"/middleware/es/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Elasticsearch\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础总结\\r\\n\\r\\n- Elasticsearch基础概念\\r\\n- Elasticsearch检索\\r\\n- Elasticsearch聚合查询\\r\\n\\r\\n\\r\\n- ES滚动查询-Scroll\\r\\n- 批量操作Bulk和BulkProcessor\\r\\n- BulkProcessor死锁问题\\r\\n\\r\\n\\r\\n- 并发场景修改文档\\r\\n- ES深度分页问题\\r\\n\\r\\n\\r\\n- ES集群\\r\\n- ES分片\\r\\n\\r\\n 原理总结\\r\\n\\r\\n- 倒排索引原理\\r\\n- Elasticsearch写入原理\\r\\n- Elasticsearch查询原理\\r\\n- ES聚合查询原理\\r\\n\\r\\n 使用问题\\r\\n- ES参数调优\\r\\n- 集群脑裂-参数配置\\r\\n\\r\\n\\r\\n- ES\"},{\"url\":\"/middleware/es/倒排索引原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"倒排索引图解\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"原理图\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引的搜索过程\\r\\n\\r\\n\\r\\n\\r\\n 倒排索引原理\\r\\n\\r\\nElasticsearch 主要功能就是搜索，为了提高搜索效率，其内部使用了倒排索引。\\r\\n\\r\\n 正排索引\\r\\n\\r\\n在搜索引擎中，每个文件对应一个文件 ID （doc_id），文件内容是关键词的集合。\\r\\n\\r\\n\\r\\n\\r\\n根据 `doc_id` 可以查找到文档详情。\\r\\n\\r\\n*这种方式本质上就是通过文档的 key 查找 value 值。*\\r\\n\\r\\n比如查找 `name=jetty wan` 的文档，只能按照顺序从前向后匹配每个文档的 name 字段。\\r\\n\\r\\n这种查找方式的效率非常低下。\\r\\n\\r\\n 倒排索引\\r\\n\\r\\n倒排索引和正向索引\"},{\"url\":\"/middleware/es/并发场景修改文档.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"并发场景修改文档\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ES从7.X版本默认使用的是乐观锁机制修改文档。\\r\\n\\r\\n当在高并发环境下使用乐观锁机制修改文档时，要带上当前文档的_seq_no和_primary_term进行更新：\\r\\n\\r\\n```java\\r\\nPOST /es_db/_doc/2?if_seq_no=21&if_primary_term=6{  \\\"name\\\": \\\"李四xxx\\\"}\\r\\n```\\r\\n\\r\\n如果冲突会提示版本冲突异常。\"},{\"url\":\"/middleware/es/批量操作Bulk和BulkProcessor.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"批量操作Bulk和BulkProcessor\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"es的批量操作，6.x版本的es中high-rest-client中可以用到以下三种。\\r\\n\\r\\n- bulk\\r\\n- bulkAsync\\r\\n- bulkProcessor\\r\\n\\r\\n Bulk\\r\\n\\r\\nbulk api 以此按顺序执行所有的 action（动作）。如果一个单个的动作因任何原因失败，它将继续处理它后面剩余的动作。当 bulk api 返回时，它将提供每个动作的状态（与发送的顺序相同），所以您可以检查是否一个指定的动作是否失败了。\\r\\n\\r\\nes可以通过 _bulk 的API实现批量操作。\\r\\n\\r\\n```java\\r\\nPOST _bulk\\r\\n{\\\"create\\\":{\\\"_index\\\":\\\"article\\\"\"},{\"url\":\"/middleware/es/集群脑裂-参数配置.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"集群脑裂-参数配置\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"集群脑裂的问题\\r\\n\\r\\n 什么是集群脑裂\\r\\n\\r\\nes 在主节点上产生分歧，产生多个master 节点，从而使集群分裂成多个同名集群，使得集群处于异常状态。\\r\\n\\r\\n当出现多个master节点的时候，可能发生写入请求分配到不同的master节点，而数据只保存在对应的master节点的分片上，不会复制到其它节点。此时若访问不同的节点，会发现查询的结果是不一样的。\\r\\n\\r\\n 举例说明脑裂\\r\\n\\r\\n`discovery.zen.minimum_master_nodes` 参数之前设置为 1（默认值）。\\r\\n\\r\\n这个参数的含义是限制选举master节点的数量。\\r\\n\\r\\n- 当master节点不存在时，至少有几个ma\"},{\"url\":\"/middleware/kafka/Kafka分区机制策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka分区机制策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"分区策略\\r\\n\\r\\n分区策略是决定生产者将消息发送到哪个分区的算法。\\r\\n\\r\\n 轮询策略\\r\\n\\r\\n是 Java 生产者 API 默认提供的分区策略。\\r\\n\\r\\n- 轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一。\\r\\n\\r\\n\\r\\n\\r\\n 随机策略\\r\\n\\r\\n将消息随机写入分区\\r\\n\\r\\n key 指定分区\\r\\n\\r\\n当发送消息时指定了key，Kafka会根据key的hash值与分区数取模来决定将数据写入哪个分区。\\r\\n\\r\\n项目中 dr 就是生产这种方式，根据消息类型指定 key，比如 transactionId。这样能保证同一t\"},{\"url\":\"/middleware/kafka/Kafka副本机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka副本机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka 的副本是针对分区来说的，为分区创建副本。\\r\\n\\r\\n副本的作用就是提供数据冗余，在 Leader 副本挂掉之后，转换为 Leader 副本继续工作。\\r\\n\\r\\n不然当 Leader 副本挂掉之后，该分区就会停止对外提供服务。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 副本同步\\r\\n\\r\\n\\r\\n\\r\\n生产者只会往分区的 Leader 发消息，而其它 Follower 会从 Leader 拉取数据进行同步。\\r\\n\\r\\n Follower追随者副本\\r\\n\\r\\nFollower 副本是不对外提供服务的，只是定期地异步拉取领导者副本中的数据而已。\\r\\n\\r\\n LSR副本集合\\r\\n\\r\\nLSR集合里面保存的副本都是与 Leader 副本\"},{\"url\":\"/middleware/kafka/Kafka总控制器Controller.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka总控制器 Controller\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 kafka中会有多个 Broker，其中一个 Broker 会被选举为 Controller，负责管理整个集群中分区和副本的状态。\\r\\n\\r\\n Zookeeper\\r\\n\\r\\nzk 使用的数据模型类似于文件系统的树形结构，根目录也是以“/”开始。该结构上的每个节点被称为 znode，用来保存一些元数据协调信息。\\r\\n\\r\\nZooKeeper 常被用来实现集群成员管理、分布式锁、领导者选举等功能。\\r\\n\\r\\nznode 用来保存元数据信息。\\r\\n\\r\\n- 永久性 znode\\r\\n  \\r\\n    持久性 znode 不会因为 ZooKeeper 集群重启而消失。\\r\\n    \\r\\n- 临时性 znode\\r\\n  \\r\\n   \"},{\"url\":\"/middleware/kafka/Kafka手动重新分区.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka手动重新分区\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka重分配分区_kafka重新分配分区-CSDN博客\\r\\n\\r\\n1. 确定需要重新分区的 topic\\r\\n   \\r\\n    vi topics-to-move.json\\r\\n    \\r\\n    ```java\\r\\n    \\r\\n    {\\r\\n      \\\"topics\\\": [{\\r\\n         \\\"topic\\\": \\\"test-topic\\\"\\r\\n       }],\\r\\n       \\\"version\\\": 1\\r\\n    }\\r\\n    ```\\r\\n    \\r\\n    - topic 可以批量设置\\r\\n2. 根据 topic 生成执行计划\\r\\n   \\r\\n    ```java\\r\\n    bin/kafka-rea\"},{\"url\":\"/middleware/kafka/Kafka消费策略.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka消费策略\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka消费者-主动批量拉取\\r\\n\\r\\n\\r\\n&gt; \\r\\n1. kafka配置类\\r\\n\\r\\n```java\\r\\n@Configuration\\r\\n@Slf4j\\r\\npublic class KafkaConfig {\\r\\n\\r\\n    @Bean\\r\\n    public KafkaListenerContainerFactory&lt;?&gt; batchFactory(ConsumerFactory consumerFactory){\\r\\n        ConcurrentKafkaListenerContainerFactory&lt;Integer,String&gt; factory =\\r\\n    \"},{\"url\":\"/middleware/kafka/Kafka生产者参数.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka生产者参数\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- bootstrap.servers： broker的地址\\r\\n- key.serializer：关键字的序列化方式\\r\\n- value.serializer：消息值的序列化方式\\r\\n- acks：指定必须要有多少个分区的副本接收到该消息，服务端才会向生产者发送响应，可选值为：0,1,2，…，all\\r\\n- buffer.memory：生产者的内存缓冲区大小。如果生产者发送消息的速度 \\r\\n- max.block.ms：表示send()方法在抛出异常之前可以阻塞多久的时间，默认是60s\\r\\n- compression.type：消息在发往kafka之前可以进行压缩处理，以此来降低存储开销和网络带宽。默认\"},{\"url\":\"/middleware/kafka/Kafka高性能的原因.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka高性能的原因\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. 写数据是按照磁盘顺序读写。\\r\\n   \\r\\n    保证顺序读写，比随机写性能要高很多。\\r\\n    \\r\\n    数据保存在 log 中，并对 log 进行了分段（logSegment）技术，对 logSegment 还增加了日志索引。\\r\\n    \\r\\n2. 数据传输的零拷贝，使的数据在内核空间中就完成了读写操作。\\r\\n   \\r\\n    零拷贝原理：\\r\\n    \\r\\n    \\r\\n    \\r\\n3. 读写数据的批量处理以及压缩传输。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n\\r\\n 零拷贝\\r\\n\\r\\n- 传统数据文件拷贝过程\\r\\n  \\r\\n    整个过程需要在内核空间和应用空间之间拷贝 2 次。\\r\\n    \"},{\"url\":\"/middleware/kafka/Producer发布消息机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Producer发布消息机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"写入机制\\r\\n\\r\\nProducer 通过push模式将消息发给 Broker，每条消息都被追加到对应的 Partition。而且是采用顺序写磁盘的方式（顺序写比随机写效率高，保障 Kafka 高吞吐量）。\\r\\n\\r\\n 消息路由模式\\r\\n\\r\\nProducer 如何确认消息发到哪个 Partition 上？\\r\\n\\r\\n1. 指定了 Partition，直接使用。\\r\\n2. 如果未指定 Partition，指定了 Key。根据 Key 的 Hash 值计算 Partition。\\r\\n   \\r\\n    Hash(key) % num(Partition)\\r\\n    \\r\\n3. 如果未指定 Partition，也未指定 \"},{\"url\":\"/middleware/kafka/__consumer_offsets.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"__consumer_offsets\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"将 Consumer 的位移数据作为一条条普通的 Kafka 消息，提交到 consumer*offsets 中。可以这么说，consumer*offsets 的主要作用是保存 Kafka 消费者的位移信息。\\r\\n\\r\\n_*consumer*offsets也是一个 topic，也有分区。和 kafka 的 topic 基本一致支持自定义写入。但是它是内部的 topic，一般最好不要自动修改。\\r\\n\\r\\n 消息格式\\r\\n\\r\\n1. 分区消费的 offset\\r\\n    \\r\\n    位移主题的 Key 中应该保存 3 部分内容：\\r\\n    \\r\\n    标识某个消费者组里面某个 topic 的某个分区，已经被消费\"},{\"url\":\"/middleware/kafka/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kafka\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka配置\\r\\n\\r\\n- Kafka消费策略\\r\\n- Kafka生产者参数\\r\\n- kafka的分区副本规划\\r\\n\\r\\n\\r\\n Kafka原理总结\\r\\n- kafka消费模型\\r\\n- kafka-ACK应答机制\\r\\n- kafka解决重复消费\\r\\n\\r\\n\\r\\n- Kafka分区机制策略\\r\\n- kafka保证消息不丢失\\r\\n- 消费者组\\r\\n- __consumer_offsets\\r\\n- Kafka总控制器Controller\\r\\n- Kafka副本机制\\r\\n\\r\\n\\r\\n- Producer发布消息机制\\r\\n- 高水位HW和LEO\\r\\n- 数据日志分段存储\\r\\n\\r\\n\\r\\n- Kafka高性能的原因\\r\\n\\r\\n 使用总结\\r\\n- Kafka手动\"},{\"url\":\"/middleware/kafka/kafka-ACK应答机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka生产者保证消息不丢失-ACK应答机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka 生产者写入数据的时候，引入了 ACK 应答机制。\\r\\n\\r\\n```java\\r\\n            Properties props = new Properties();\\r\\n            props.put(\\\"bootstrap.servers\\\", Configuration.KAFKA_ADDRESS);\\r\\n\\t\\t\\t\\t\\t\\t//1:leader应答就可以发送下一条，确保发送成功。\\r\\n            props.put(\\\"acks\\\", \\\"1\\\");\\r\\n\\t\\t\\t\\t\\t\\t......\\r\\n            props.put(\\\"key.serializer\\\", \\\"org.a\"},{\"url\":\"/middleware/kafka/kafka保证消息不丢失.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka保证消息不丢失\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。\\r\\n\\r\\n 生产者端消息丢失\\r\\n\\r\\n生产者发送消息的时候，如果没有发到 kafka 导致消息丢失（网络抖动），其实这并不是 kafka 的原因。\\r\\n\\r\\nkafka 能保证已经提交到 borker 的数据，不会丢失。\\r\\n\\r\\n默认生产者发数据，采用 `send(msg)`发数据，这样发数据之后生产者并不知道是否发送成功。\\r\\n\\r\\n最好使用 `producer.send(msg, callback)` 发数据，这样通过`callback`能够清楚的知道消息是否发送成功。\\r\\n\\r\\n 消费者端消息丢失\\r\\n\\r\\nConsu\"},{\"url\":\"/middleware/kafka/kafka消费模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka消费模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"kafka消费模型分为两种。\\r\\n\\r\\n1. 消费组消费\\r\\n   \\r\\n    消费组里面的单个消费者消费一个分区的数据。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n    \\r\\n    \\r\\n    \\r\\n2. 消费者-worker进程消费。\\r\\n\\r\\n\\r\\n\\r\\n&gt; 第一种消费模型，每个分区对应一个 consumer。\\r\\n&gt; \\r\\n\\r\\n第二种消费模型，只消费数据不处理，处理的工作单独交给 worker线程池，这样可以避免很多 consumer产生的问题。不要把很重的处理逻辑放到消费者中。\\r\\n\\r\\n&gt; 难以保证 offset 的语义正确性，可能导致重复消费。\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n--\"},{\"url\":\"/middleware/kafka/kafka的分区副本规划.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka的分区副本规划\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"1. topic划分\\r\\n\\r\\n每个日志对应一个topic。\\r\\n\\r\\ntopic 有自己的分区数量和副本数量。一般根据kafka指定的默认数量自动生成。\\r\\n\\r\\n---\\r\\n\\r\\n 2. 分区数量\\r\\n\\r\\n当生产者发给kafka一条消息时，根据规则分到 topic 的指定分区（partition），所以每个分区的数据是不一样的。\\r\\n\\r\\n 规划分区数量\\r\\n\\r\\n消费者在消费数据的时候，也是从分区中消费的，同一个分区只能被消费组里的一个消费者去消费。\\r\\n\\r\\n比如kafka有3个borker时，假如配置topic有5个分区，分配到3个borker就会出现 2 2 1 的情况。\\r\\n\\r\\n所以在指定topic的分区数量时\"},{\"url\":\"/middleware/kafka/kafka解决重复消费.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"kafka解决重复消费\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"技术干货分享 | Kafka重复消费场景及解决方案\\r\\n\\r\\n 导致重复消费的原因\\r\\n\\r\\n- enable.auto.commit 默认值true，表示消费者会周期性自动提交消费的offset\\r\\n- auto.commit.interval.ms 在enable.auto.commit 为true的情况下， 自动提交的间隔，默认值5000ms\\r\\n- max.poll.records 单次消费者拉取的最大数据条数，默认值 500\\r\\n- max.poll.interval.ms 默认值5分钟，表示若5分钟之内消费者没有消费完上一次poll的消息，那么consumer会主动发起离开group的请求\\r\\n1\"},{\"url\":\"/middleware/kafka/数据日志分段存储.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据日志分段存储\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"数据保存机制\\r\\n\\r\\n\\r\\n\\r\\nKafka 的数据是按照分区存储的，以 topic-partition 为目录保存数据。\\r\\n\\r\\n数据是存到 log 中，而 log 又引入了LogSegment机制。\\r\\n\\r\\n`log.segment.bytes`，默认 1G。当超过1G 之后，日志就会开始分割。\\r\\n\\r\\n而日志分段文件以及索引文件都是以基准偏移量（offset）命名的。\\r\\n\\r\\n基本每段的日志文件包含一个数据文件和两个索引文件。\\r\\n\\r\\n- 以offset 为索引的 `.index`。\\r\\n- 以时间戳为索引的 `.timeindex`。\\r\\n\\r\\n索引里面并不是保留全量的数据索引，而是以稀疏索引的方式保存（方\"},{\"url\":\"/middleware/kafka/消费者组.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"消费者组\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者机制。\\r\\n\\r\\n- 组内的所有消费者协调在一起来消费订阅主题（Subscribed Topics）的所有分区（Partition）。\\r\\n- 每个分区只能由同一个消费者组内的一个 Consumer 实例来消费。\\r\\n\\r\\n比如 topic 有 6 个分区，消费者组里面的消费者数量最理想状态是 6 个，每个消费者消费一个分区。也可以是 3 个或者两个，这样分区能够平均分配。\\r\\n\\r\\n但是最好不要超过 6 个消费者，这样的话会有消费者分不到分区。\\r\\n\\r\\n而 topic 的分区设计时，最好和 broker 的数量成比例。比如 3 个\"},{\"url\":\"/middleware/kafka/高水位HW和LEO.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"高水位HW和LEO\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"LEO（log_end_offset) 指的是当前分区日志末端的 offset。\\r\\n\\r\\n而 HW 指的是整个 LSR 集合副本中，LEO 最小的。保障 Consumer 只能消费到 HW 的位置。\\r\\n\\r\\n首先Leader 和 Followers 都有自己的 HW和 LEO，当有新消息写入 Leader 时，Consumer 并不能立即消费。\\r\\n\\r\\nFollowers 会 pull leader 最新的消息，同步完之后，发送 ACK 给 Leader。然后 Leader会增加 HW。增加之后，新产生的消息才能被 Consumer 消费掉。\\r\\n\\r\\n这样的目的是为了保证当 Leader 挂掉之后，重\"},{\"url\":\"/middleware/rocketmq/Kakfa和RocketMQ的区别.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Kakfa和RocketMQ的区别\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"消费者组\\r\\n\\r\\nRocketMQ和Kafka虽然都使用了Consumer Group的概念来实现消息的分发和负载均衡，但两者在具体实现和一些特性上存在一些差异：\\r\\n\\r\\n1. Rebalance机制：\\r\\n    - RocketMQ：RocketMQ的Consumer Group在成员增减或Topic队列发生变化时会触发Rebalance，旨在重新分配队列到各个消费者实例，确保消息的公平消费。RocketMQ的Rebalance更加灵活，支持多种分配策略，例如平均分配、广播消费等，可以根据业务需求进行配置。\\r\\n    - Kafka：Kafka同样在Consumer Group中进行Rebala\"},{\"url\":\"/middleware/rocketmq/MQ接收消息幂等性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"MQ接收消息幂等性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"幂等性\\r\\n\\r\\nMQ的消息幂性，指的是MQ接收消息时候的幂等性。\\r\\n\\r\\n- 最多一次\\r\\n    \\r\\n    消息最多只会被消费一次。\\r\\n    \\r\\n    \\r\\n    &gt; \\r\\n- 最少一次\\r\\n    \\r\\n    消息最少被消费一次。\\r\\n    \\r\\n    &gt; 同步发送、事务消息。\\r\\n    &gt; \\r\\n- 准确消费一次\\r\\n    \\r\\n    默认RocketMQ保证不了准确消费一次。但是商业版本有。\\r\\n    \\r\\n\\r\\n 消息幂等的必要性\\r\\n\\r\\n- 生产者发送消息时，MQ收到消息，但是网络波动导致ACK没有给到生产者。可能会导致重推消息。\"},{\"url\":\"/middleware/rocketmq/RocketMQ基础学习.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ基础学习\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础架构\\r\\n\\r\\n\\r\\n\\r\\n 生产者\\r\\n\\r\\nRocketMQ提供多种发送方式，同步发送、异步发送、顺序发送、单向发送。\\r\\n\\r\\n同步和异步方式均需要 Broker 返回确认信息，单向发送不需要。\\r\\n\\r\\n生产者中，会把同一类 Producer 组成一个集合，叫做生产者组。同一组的 Producer 被认为是发送同一类消息且发送逻辑一致。\\r\\n\\r\\n 消费者\\r\\n\\r\\n 消费者组\\r\\n\\r\\n消费者组消费同一组数据，消费相同topic，并且消费逻辑一致。消费者组的消费者实例必须订阅完全相同的Topic。\\r\\n\\r\\n 消费模式\\r\\n\\r\\nRocketMQ 支持两种消息模式：集群消费（Clustering）和广播消费（Broad\"},{\"url\":\"/middleware/rocketmq/RocketMQ集群架构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ集群架构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"NameServer：提供Broker的路由服务\\r\\n\\r\\nBroker：负责接收Producer的消息，存储消息，将消息投递给Consumer。\\r\\n\\r\\n- Broker需要管理数据，频繁处理数据，所以需要G1、ZGC这种更先进的垃圾回收器。\\r\\n- 而NameServer类似于Broker的注册中心，提供路由功能，只需要简单的垃圾回收算法就可以，比如CMS。\\r\\n\\r\\nProducer：生产者\\r\\n\\r\\nConsumer：消费者\\r\\n\\r\\n 集群架构说明\\r\\n\\r\\n整个RocketMQ集群里面主要分为两部分，Broker和NameServer。\\r\\n\\r\\n整个RocketMQ遵循的是AP架构，追求可用性。\\r\\n\\r\\n N\"},{\"url\":\"/middleware/rocketmq/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RocketMQ\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- RocketMQ基础学习\\r\\n- RocketMQ集群架构\\r\\n\\r\\n\\r\\n- 消息样例\\r\\n- 顺序消息\\r\\n- 事务消息\\r\\n\\r\\n\\r\\n- 如何保证发送消息有序\\r\\n- 如何保证消息不丢失\\r\\n- MQ接收消息幂等性\\r\\n\\r\\n\\r\\n- Kakfa和RocketMQ的区别\"},{\"url\":\"/middleware/rocketmq/事务消息.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"事务消息\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"事务消息的流程\\r\\n\\r\\n- 先写half消息到RocketMQ\\r\\n- 再执行本地事务\\r\\n  \\r\\n    本地事务有两个方法，一个是回调执行本地事务，另一个是检查本地事务。\\r\\n    \\r\\n    ```java\\r\\n    /**\\r\\n     * 事务监听器，用来处理本地事务\\r\\n     * @author yangjunwei\\r\\n     * @date 2024/7/4\\r\\n     */\\r\\n    public class TransactionListenerImpl implements TransactionListener {\\r\\n        private AtomicInteger\"},{\"url\":\"/middleware/rocketmq/如何保证发送消息有序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"如何保证发送消息有序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"类比Kafka的ParitationKey，RocketMQ是messageQueue。\\r\\n\\r\\n将需要保证顺序的消息发给RocketMQ的messageQueue，被同一个消费者消费，即可保证有序。\\r\\n\\r\\n1. 消费者在发送的时候可以指定selector，指定消息发给哪个messageQueue。\\r\\n2. messageQueue是一个FIFO的队列，能够保证消费时按照写入消息的顺序去消费。\\r\\n\\r\\n所以需要保证有顺序的消息，比如相同产品的订单，可以按照产品 code 设置 selector，保证消息发到同一个 messageQueue，这样就能被同一个消费者消费。\\r\\n\\r\\n```java\\r\\nSe\"},{\"url\":\"/middleware/rocketmq/如何保证消息不丢失.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"如何保证消息不丢失\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"消息丢失场景\\r\\n\\r\\n数据丢失在MQ中比较常见，一般丢失数据都是在跨网络的部分，比如1、2、4。\\r\\n\\r\\n- 生产者发数据\\r\\n- 消费者消费数据\\r\\n- MQ内部主从同步\\r\\n\\r\\n而MQ写数据到磁盘过程也是有丢失数据的可能的。\\r\\n\\r\\n一般写数据到磁盘不会直接去写，而是利用操作系统的缓存，先写数据到缓存中，等待操作系统异步刷进磁盘。\\r\\n\\r\\n比如 Prometheus 的 WAL 机制。\\r\\n\\r\\n\\r\\n\\r\\n 事务消息-生产者\\r\\n\\r\\n使用事务消息能保证本地事务和写入MQ的事务一致性。\\r\\n\\r\\n比如订单场景，只保证本地下订单和向MQ发消息的事务一致性。不会像MySQL一样保证数据库事务。\\r\\n\\r\\n只是保证了业务的分布\"},{\"url\":\"/middleware/rocketmq/消息样例.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"消息样例\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"顺序消息\\r\\n\\r\\nkafka的顺序消息可以指定paritationKey实现，相同paritationKey的消息会被发给同一个paritation。\\r\\n\\r\\nRocketMQ可以通过实现 `MessageQueueSelector` 的 `select` 方法自定义实现消息所发给 MessageQueue的逻辑。\\r\\n\\r\\n```java\\r\\n    @SneakyThrows\\r\\n    @Test\\r\\n    public void orderSend() {\\r\\n        try {\\r\\n            DefaultMQProducer producer = new DefaultMQP\"},{\"url\":\"/middleware/rocketmq/顺序消息.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"顺序消息\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"生产者\\r\\n\\r\\n生产者发送消息到MQ的过程，如果要保证顺序消费。\\r\\n\\r\\n只能采用单线程去生产消息，因为多线程无法控制消息生产顺序。\\r\\n\\r\\n还需要保证 sharding key 相同，保证同一类消息发到同一个 ConsumerQueue。\\r\\n\\r\\n\\r\\n&gt; \\r\\n- 单线程生产消息\\r\\n- 发送到同一个ConsumerQueue\\r\\n\\r\\n 存储\\r\\n\\r\\nRocketMQ的存储是按照时间顺序 append write 到 commitlog 中的，同时它会被分发到 ConsumeQueue中。\\r\\n\\r\\n所以只需要生产时候保证消息采用单线程发送到同一个ConsumerQueue，存储时候就能够顺序存储。\\r\\n\\r\"},{\"url\":\"/other/algorithm/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"算法\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 时间复杂度\\r\\n- 查找\\r\\n- 排序\\r\\n- 动态规划\"},{\"url\":\"/other/algorithm/动态规划.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"动态规划\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"动态规划重要特性\\r\\n\\r\\n动态规划的核心问题是穷举，因为要求最值，要把所有可行答案找出来，找最值。但是穷举的过程中，会存在【重叠子问题】。\\r\\n\\r\\n 重叠子问题\\r\\n\\r\\n在求解的过程中，存在重复的子问题，若是重复解决这些子问题，存在效率低下的问题。\\r\\n\\r\\n而解决重叠子问题，可以使用【备忘录】或者【DP table】方法来解决。\\r\\n\\r\\n- 备忘录\\r\\n  \\r\\n    备忘录的思想就是将已经解决的子问题结果记录在备忘录中（可以是数组等数据结构）。\\r\\n    \\r\\n\\r\\n\\r\\n&gt; \\r\\n- DP table\\r\\n  \\r\\n    使用 DP table 保存每个子问题的结果，自下向上推算结果。\\r\\n    \\r\\n\\r\\n\"},{\"url\":\"/other/algorithm/排序.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"排序\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"概念\\r\\n\\r\\n 稳定性\\r\\n\\r\\n稳定性指的是相同的数据所在的位置经过排序后是否发生变化。若是排序后，次序不变，则是稳定的。\\r\\n\\r\\n 内部排序\\r\\n\\r\\n排序记录全部存放在内存中进行排序的过程。\\r\\n\\r\\n 外部排序\\r\\n\\r\\n待排序记录的数量很大，以至于内存不能容纳全部记录，在排序过程中尚需对外存进行访问的排序过程。\\r\\n\\r\\n\\r\\n\\r\\n 选择排序-不稳定\\r\\n\\r\\n每次选择剩余待排序元素中的最小值，放到已排序元素的末尾。\\r\\n\\r\\n原理：每次排序选出最小的元素，替换到对应顺序末尾的位置。\\r\\n思路：第一次排序选出最小的元素，和待排序数组第一位的元素进行交换。\\r\\n\\r\\n```json\\r\\n/**\\r\\n     * 选择排序的思路：\"},{\"url\":\"/other/algorithm/时间复杂度.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"时间复杂度\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"O(1)\\r\\n\\r\\n- 数组下表查询\\r\\n\\r\\n O(n)\\r\\n\\r\\n- 链表元素查询，最坏情况是要查n次。\\r\\n\\r\\n O(logn)\\r\\n\\r\\n- 平衡二叉树\\r\\n- 数组二分法查找指定元素\\r\\n\\r\\n开根号\\r\\n\\r\\n- 比如16长度的数组，想要找到指定元素最多需要4次、\\r\\n  \\r\\n    16→8→4→2→1\\r\\n    \\r\\n- 红黑树（平衡二叉树、完全二叉树）\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n O(log n) \\r\\n\\r\\n复杂度解释：\\r\\n\\r\\n- 在一个理想平衡的二叉搜索树中，每次查找操作从根节点开始，通过比较目标值与当前节点的值来决定是向左还是向右子树进行下一步查找。\\r\\n- 每次比较后，查找范围大致减半，这类似于\"},{\"url\":\"/other/algorithm/查找.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"查找\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"静态查找表\\r\\n\\r\\n 顺序查找\\r\\n\\r\\n线性表查询，查找效率（n+1)/2\\r\\n\\r\\n\\r\\n\\r\\n 折半查找\\r\\n\\r\\n\\r\\n\\r\\n二分查找，仅适用于有序的线性表。\\r\\n\\r\\n折半查找比较次数最多为 [log2n]+1 次。n=2^x，比如8个元素最多需要3次，对应 8=2^3。\\r\\n\\r\\n所以时间复杂度为 O(log2n) 。\\r\\n\\r\\n 分块查找\\r\\n\\r\\n特点是块内无序，但是块间有序。\\r\\n\\r\\n- 先在索引表确定目标所在块。\\r\\n- 在块内顺序查找。\\r\\n\\r\\n\\r\\n\\r\\n比如索引表或者索引文件。\\r\\n\\r\\n 哈希表\\r\\n\\r\\n\\r\\n\\r\\n按照哈希存储元素到哈希表里。\\r\\n\\r\\n 哈希冲突解决方式\\r\\n\\r\\n按照值的哈希值存储会出现哈希冲突的问题，可以通\"},{\"url\":\"/other/datastructure/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"数据结构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 常用数据结构\\r\\n- 二叉树\"},{\"url\":\"/other/datastructure/二叉树.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"二叉树\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"推荐一个练习数据结构的网站\\r\\n\\r\\nData Structure Visualization\\r\\n\\r\\n 二叉树的遍历（重要）\\r\\n\\r\\n以图示二叉树为例。\\r\\n\\r\\n\\r\\n\\r\\n 中序遍历\\r\\n\\r\\n简化为每个树，都是左中右即可。\\r\\n\\r\\n中序遍历（LDR）是二叉树遍历的一种，也叫做中根遍历、中序周游。在二叉树中，中序遍历首先遍历左子树，然后访问根结点，最后遍历右子树。\\r\\n\\r\\n*左子树 → 根节点 → 右子树*\\r\\n\\r\\n图示二叉树中序遍历结果为：`3、5、6、10、14、15、17、20`；\\r\\n\\r\\n参考代码：Java实现中序遍历\\r\\n\\r\\n 前序遍历\\r\\n\\r\\n前序遍历（VLR）， 1] 是[二叉树遍历的一种，也叫做先根遍历\"},{\"url\":\"/other/datastructure/常用数据结构.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"常用数据结构\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"存储结构\\r\\n\\r\\n\\r\\n\\r\\n 复杂度\\r\\n\\r\\n时间复杂度\\r\\n\\r\\n空间复杂度\\r\\n\\r\\n 线性表\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 串\\r\\n\\r\\n比如字符串。\\r\\n\\r\\n\\r\\n\\r\\n 数组\\r\\n\\r\\n\\r\\n\\r\\n 矩阵\\r\\n\\r\\n\\r\\n\\r\\n求矩阵元素下标，直接代入即可。\\r\\n\\r\\n\\r\\n\\r\\n代入 A(0,0) 和 A(0,1)，分别对应 M(1) 和 M(2)。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 广义表\\r\\n\\r\\n\\r\\n\\r\\n例1：长度为3，深度为2\\r\\n\\r\\n例2: 先取表尾，再取表头，再取表头。\\r\\n\\r\\nhead (head ( tail(LS1) ) )\\r\\n\\r\\n 广义表的基本运算\\r\\n\\r\\n1. 取表头\\r\\n2. 取表尾\\r\\n\\r\\n 二叉树\\r\\n\\r\\n\\r\\n\\r\\n- 满二叉树\"},{\"url\":\"/other/design/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"设计模式\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"设计模式的目的\\r\\n\\r\\n* 代码重用性（提取重复代码）\\r\\n* 可读性（代码规范，便于阅读）\\r\\n* 可扩展性（方便增加新功能）\\r\\n* 可靠性（增加新功能，对以前的功能没有影响）\\r\\n* 使程序呈现高内聚、低耦合的特性\\r\\n\\r\\n 设计模式的七大基本原则\\r\\n\\r\\ndesign-principle\\r\\n\\r\\n* 单一职责原则\\r\\n\\r\\n* 接口隔离原则\\r\\n\\r\\n* 依赖倒置原则\\r\\n\\r\\n* 里氏替换原则\\r\\n\\r\\n* 开闭原则\\r\\n\\r\\n* 迪米特法则\\r\\n\\r\\n* 合成复用法则\\r\\n\\r\\n 设计模式三大类型\\r\\n\\r\\n 1. 创建型模式\\r\\n\\r\\ndesign-create\\r\\n\\r\\n* 单例模式\\r\\n\\r\\n    * 序列化和反序列化\\r\\n\\r\\n* 工\"},{\"url\":\"/other/design/七大基本原则.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"七大基本原则\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-principle\\r\\n\\r\\n 单一职责原则\\r\\n\\r\\n1. 一种类只能具有一种职责，降低类的复杂度。\\r\\n2. 提高类的可读性，可维护性。\\r\\n3. 降低变更引起的风险。\\r\\n4. 在类中的方法比较少的时候，可以在方法级别保持单一职责原则。其他情况下，都要保持类的类单一职责原则。\\r\\n\\r\\n 接口隔离原则\\r\\n\\r\\n1. 客户端不应该依赖它不需要的接口。\\r\\n2. 一个类对另一个类的依赖应该建立在最小的接口上。\\r\\n\\r\\n 依赖倒置原则\\r\\n\\r\\n1. 依赖倒置原则的中心思想是面向接口编程。\\r\\n2. 抽象不应该依赖细节，细节应该依赖抽象。抽象是接口或者抽象类，细节即为实现类。\\r\\n3. 对于细节的多变性，抽象的\"},{\"url\":\"/other/design/创建型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"创建型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-create\\r\\n\\r\\n 单例模式\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n 饿汉式\\r\\n\\r\\n特点：类创建时创建对象，节省时间，占用内存，`以空间换时间`。\\r\\n\\r\\n1. 静态变量实现\\r\\n    \\r\\n    类加载时创建对象，节省时间，占用内存，`以空间换时间`。`推荐使用`，但是比较浪费空间。\\r\\n    \\r\\n    ```java\\r\\n    \\t\\t/**\\r\\n         * 类加载时创建对象，节省时间，占用内存，以空间换时间\\r\\n         */\\r\\n        private final static SingletonHungryOne INSTANCE = new Singleton\"},{\"url\":\"/other/design/结构型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"结构型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-structural\\r\\n\\r\\n 代理模式\\r\\n\\r\\n代理模式是属于结构型的设计模式,指客户端的请求到达真正的对象之前，做一些额外的操作。\\r\\n\\r\\n 静态代理模式\\r\\n\\r\\n\\r\\n以 AspectJ 为代表。指代理类在编译期生成的，与动态代理相比，效率会很高，但是会生成大量代理类。\\r\\n\\r\\n 动态代理模式\\r\\n\\r\\n以 SpringAOP 为代表为代表，代理类是动态生成的。虽然会效率会低一点，但是大大简化了代码和开发量。\\r\\n\\r\\n- JDK 动态代理\\r\\n- CGlib 动态代理\\r\\n\\r\\n 桥接模式\\r\\n\\r\\n抽象类：定义一个抽象类，作为系统的一部分。\\r\\n\\r\\n实现类：定义一个或多个实现类，与抽象类通过聚合（而非\"},{\"url\":\"/other/design/行为型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"行为型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"design-behavioral\\r\\n\\r\\n 责任链模式\\r\\n\\r\\n责任链模式——某个请求需要多个对象进行处理，从而避免请求的发送者和接收之间的耦合关系。将这些对象连成一条链子，并沿着这条链子传递该请求，直到有对象处理它为止。主要涉及两个角色：\\r\\n\\r\\n\\r\\n- 抽象处理者角色（Handler）：定义出一个处理请求的接口。这个接口通常由接口或抽象类来实现。\\r\\n- 具体处理者角色（ConcreteHandler）：具体处理者接受到请求后，可以选择将该请求处理掉，或者将请求传给下一个处理者。因此，每个具体处理者需要保存下一个处理者的引用，以便把请求传递下去。\\r\\n\\r\\n 优缺点比较\\r\\n\\r\\n优点\\r\\n\\r\\n- 降低耦\"},{\"url\":\"/other/network/HTTP1x和HTTP2x.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP1x和HTTP2.x\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HTTP1.x\\r\\n\\r\\n 数据格式\\r\\n\\r\\nHTTP1.x基于文本传输。\\r\\n\\r\\n- 请求行\\r\\n- 请求头\\r\\n- 请求体\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 缺点\\r\\n\\r\\n1. 占用字节：在HTTP请求中，包含很多空格和换行符。\\r\\n2. 头部不能压缩：在HTTP1.x中，请求头不能压缩。所以存在请求头比较大的问题，出现大头儿子。\\r\\n   \\r\\n    \\r\\n    &gt; \\r\\n3. 传输效率低：同一个链接（`Keep-Alive`的情况）同时只能处理一个请求，收到响应才会开始发送下一个请求。\\r\\n    - 如果不设置 `Keep-Alive`，则每一次HTTP请求都会新建一个TCP链接。\\r\\n    \\r\\n    &g\"},{\"url\":\"/other/network/HTTP和HTTPS.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP和HTTPS\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"HTTP 和 HTTPS 的区别\\r\\n\\r\\n- 传输问题。\\r\\n    - HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。\\r\\n    - HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。\\r\\n- 建立连接过程。\\r\\n    - HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。\\r\\n    - HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。\\r\\n- 两者的默认端口不一样。\\r\\n    - HTTP 默认端口号是 80。\\r\\n\"},{\"url\":\"/other/network/HTTP常见字段.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"HTTP常见字段\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"```json\\r\\nPOST /apmServer-sl/sys-user/login HTTP/1.1\\r\\nAccept: application/json, text/plain, */*\\r\\nAccept-Encoding: gzip, deflate\\r\\nAccept-Language: zh-CN,zh;q=0.9\\r\\nAuthorization: clusterid34\\r\\nConnection: keep-alive\\r\\nContent-Length: 101\\r\\nContent-Type: application/json\\r\\nCookie: apm.name=admin\\r\\nHost: 10.1\"},{\"url\":\"/other/network/Linux如何收发网络包.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Linux如何收发网络包\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"2.3 Linux 系统是如何收发网络包的？\\r\\n\\r\\n 网络协议栈\\r\\n\\r\\n\\r\\n\\r\\n1. 应用程序需要通过系统调用，来和 Socket 进程数据交互。\\r\\n2. Socket 层是介于应用层和传输层之间的抽象层。\\r\\n3. 最下面的一层，则是网卡驱动程序和硬件网卡设备。\\r\\n\\r\\n Linux 接收和发送网络包的流程\"},{\"url\":\"/other/network/OSI七层网络模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"OSI七层网络模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"- 应用层，负责给应用程序提供统一的接口；\\r\\n- 表示层，负责把数据转换成兼容另一个系统能识别的格式；\\r\\n- 会话层，负责建立、管理和终止表示层实体之间的通信会话；\\r\\n- 传输层，负责端到端的数据传输；\\r\\n- 网络层，负责数据的路由、转发、分片；\\r\\n- 数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址；\\r\\n- 物理层，负责在物理网络中传输数据帧；\"},{\"url\":\"/other/network/RTT和SRTT.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"RTT和SRTT\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"RTT\\r\\n\\r\\nRTT 指的是客户端发出数据 → 客户端收到服务端发送的确认数据的时间。\\r\\n\\r\\nRTT 称为往返时延。\\r\\n\\r\\n SRTT\\r\\n\\r\\nSRTT（Smoothed Round Trip Time）是一种用于衡量网络延迟的指标，通常用于评估网络连接的质量和性能。SRTT表示在一系列网络往返（Round Trip）中的平滑往返时间。\\r\\n\\r\\nSRTT是通过在每次往返时间（RTT）的基础上应用加权平均算法来计算得出的。加权平均算法会给最近的RTT值更高的权重，以反映出网络延迟的实时变化。\\r\\n\\r\\nSRTT的值越小，表示网络延迟越低，网络连接的质量越好。较低的SRTT值通常意味着网络响应更快，数据传\"},{\"url\":\"/other/network/Socket.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Socket\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Socket 位于应用层和传输层之前的抽象层，是一组调用接口，TCP/IP网络的API函数。\\r\\n\\r\\n实际上是对 TCP/IP协议的封装，只是为了更方便使用 TCP/IP 协议。\\r\\n\\r\\n\\r\\n这个就像操作系统会提供标准的编程接口，比如win32编程接口一样。\\r\\nTCP/IP也要提供可供程序员做网络开发所用的接口，这就是Socket编程接口。\\r\\n&gt; \\r\\n\\r\\n Socket 通信流程\\r\\n\\r\\n\\r\\n\\r\\nSocket按照四元组来标识不同客户端与服务端之间的连接。\\r\\n\\r\\n四元组「源 IP、源端口、目的 IP、目的端口」\\r\\n\\r\\n- `accept()`\\r\\n  \\r\\n    服务端绑定端口之后，进入 `acc\"},{\"url\":\"/other/network/TCPIP四层网络模型.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP/IP四层网络模型\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"为什么要有网络模型\\r\\n\\r\\n进程通信的方式\\r\\n\\r\\n- 本机\\r\\n    - 消息队列\\r\\n    - 共享内存\\r\\n    - 管道（程序用来交换数据的地方）\\r\\n- 不同主机\\r\\n    - 网络通信\\r\\n\\r\\n需要网络通信的设备是多种多样的，所以要兼容，就要设定网络通信之间的网络协议。\\r\\n\\r\\n 应用层\\r\\n\\r\\n应用层定义了应用进程之间通信和交互的规则，应用层交互数据单元为报文。\\r\\n\\r\\n不关心数据如何传输，将报文传给传输层做传输。\\r\\n\\r\\n在这一层有很多熟悉的协议，比如 HTTP、HTTPS、DNS等。\\r\\n\\r\\n【计算机网络】TCP / IP 四层协议_tcp/ip协议包含哪几层_L Jiawen的博客-CSDN\"},{\"url\":\"/other/network/TCP分析工具.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP分析工具\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Wireshark · Go Deep\\r\\n\\r\\n\\r\\n\\r\\n 三次握手\\r\\n\\r\\n\\r\\n\\r\\n 第1次握手\\r\\n\\r\\n\\r\\n\\r\\nsyn设置为1，表明这是一个 SYN包\\r\\n\\r\\n\\r\\n\\r\\nseq = 1390201126\\r\\n\\r\\n\\r\\n\\r\\n 第2次握手\\r\\n\\r\\nsyn=1 同时 ACK=1，表明这是一个 SYN/ACK包\\r\\n\\r\\n\\r\\n\\r\\n服务端返回的 ACK = 客户端第一次发送的 seq+1 = 1390201126+1\\r\\n\\r\\n同时服务端向客户端返回了自己的 seq（如果第三次握手客户端返回的ack=seq+1，代表客户端收到了自己发的seq）\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n 第3次握手\\r\\n\\r\\n可以看到第 3 次握手的\"},{\"url\":\"/other/network/TCP协议.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP协议\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"TCP 协议灵魂 12 问，巩固你的网路底层基础！-腾讯云开发者社区-腾讯云\\r\\n\\r\\n\\r\\n\\r\\n TCP和UDP的区别\\r\\n\\r\\n- 面向连接\\r\\n    - TCP 需要客户端与服务端之间通过三次握手建联，之后才可以发送数据。\\r\\n    - UDP直接向服务端发数据包。\\r\\n- 可靠性\\r\\n    - 有状态\\r\\n        - TCP发数据包时，保证数据包按顺序到达。\\r\\n    - 可控制\\r\\n        - 当TCP协议丢包时，可以控制重发和自己的发送速度，保证数据包完整和有序。\\r\\n    - UDP 是无状态并且不可控的。\\r\\n- 基于字节流\\r\\n    - TCP将数据包通过字节流发送。\\r\\n   \"},{\"url\":\"/other/network/TCP粘包拆包.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"TCP粘包拆包\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"发生粘包的原因\\r\\n\\r\\n- 要发送的数据小于 TCP 发送缓冲区的大小，TCP 将多次写入缓冲区的数据一次发送出去，将会发生粘包；\\r\\n- 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包；\\r\\n- 要发送的数据大于 TCP 发送缓冲区剩余空间大小，将会发生拆包；\\r\\n- 待发送数据大于 MSS（最大报文长度），TCP 在传输前将进行拆包。即 TCP 报文长度 - TCP 头部长度 \\r\\n\\r\\n 解决粘包拆包问题\\r\\n\\r\\n- 定长消息：发送端将每个数据包封装为固定长度\\r\\n- 特殊分隔符：在数据尾部增加特殊字符进行分割\\r\\n- 消息头：将数据分为两部分，一部分是头部，一部分是内容体；其中头部结构大小\"},{\"url\":\"/other/network/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"计算机网络\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"基础\\r\\n\\r\\n- TCP/IP四层网络模型\\r\\n- OSI七层网络模型\\r\\n- 网址访问页面中间发生了哪些过程\\r\\n- Linux如何收发网络包\\r\\n- 网络包的封装原理\\r\\n- Socket\\r\\n\\r\\n TCP\\r\\n\\r\\n- TCP协议\\r\\n- TCP分析工具\\r\\n\\r\\n\\r\\n- RTT和SRTT\\r\\n- 流量控制-滑动窗口\\r\\n\\r\\n- 拥塞控制\\r\\n- 重传机制\\r\\n- TCP粘包拆包\\r\\n\\r\\n\\r\\n UDP\\r\\n\\r\\nUDP不需要连接，可以单播和广播。\\r\\n\\r\\n HTTP\\r\\n- HTTP常见字段\\r\\n- HTTP和HTTPS\\r\\n- HTTP1x和HTTP2x\\r\\n\\r\\n 参考链接\\r\\n\\r\\n图解网络介绍\"},{\"url\":\"/other/network/拥塞控制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"拥塞控制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"流量控制是避免数据填满发送方的缓冲区。\\r\\n\\r\\n而拥塞控制是避免发送方的数据填满整个网络。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n在⽹络出现拥堵时，如果继续发送⼤量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是⼀重传就会导致⽹络的负担更重，于是会导致更⼤的延迟以及更多的丢包，这个情况就会进⼊恶性循环被不断地放⼤….\\r\\n\\r\\n所以，TCP 不能忽略整个网络中发⽣的事，它被设计成⼀个⽆私的协议，当⽹络发送拥塞时，TCP 会⾃我牺牲，降低发送的数据流。\\r\\n\\r\\n 拥塞窗口\\r\\n\\r\\n拥塞窗⼝ cwnd是发送⽅维护的⼀个的状态变量，它会根据⽹络的拥塞程度动态变化的。\\r\\n\\r\\n发送窗⼝ swnd 和接\"},{\"url\":\"/other/network/流量控制-滑动窗口.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"流量控制-滑动窗口\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在TCP中，滑动窗口用来流量控制。确保发送方不会过快的发送数据导致接收方无法处理数据。\\r\\n\\r\\nTCP拥塞控制是为了解决发送方以过高的速率发送导致网络中出现阻塞，其核心思想就是发生重传时控制发送方滑动窗口（通过控制拥塞窗口cwnd）的大小，从而控制其发送速率。\\r\\n\\r\\n 滑动窗口\\r\\n\\r\\nTCP窗口包括发送窗口和接收窗口，用来限制不同端所能容纳数据的上限，达到控制发送数据的速率。\\r\\n\\r\\n\\r\\n\\r\\nTCP报文里面的窗口大小，作用是告诉对方本端的接受缓冲区还能容纳多少字节的数据。\\r\\n\\r\\n\\r\\n\\r\\n在通信过程中，接收方每次收到数据包，在发送确认报文的时候，还需要告诉发送方自己的缓冲区剩余大小。缓冲区剩余大小，\"},{\"url\":\"/other/network/网址访问页面中间发生了哪些过程.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"网址访问页面中间发生了哪些过程\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"2.2 键入网址到网页显示，期间发生了什么？\\r\\n\\r\\n URL解析\\r\\n\\r\\n URL组成信息\\r\\n\\r\\nURL实际上就是访问 Web服务器里面的文件资源。\\r\\n\\r\\n\\r\\n\\r\\n 组装HTTP报文\\r\\n\\r\\n根据 URL 解析得到的内容，进行报文组装。\\r\\n\\r\\n\\r\\n&gt; \\r\\n\\r\\n\\r\\n\\r\\n DNS域名解析\\r\\n\\r\\n解析URL时，如果web服务器是域名，需要走DNS服务器进行域名解析，得到真实访问的IP地址。\\r\\n\\r\\n 域名组成\\r\\n\\r\\n`www.server.com.` 类似树状结构，越右等级越高。\\r\\n\\r\\n域名组成都代表了DNS服务器，里面保存了域名和IP的对应关系。\\r\\n\\r\\n域名服务器就像是一个树状结构。\\r\\n\\r\\n- 根\"},{\"url\":\"/other/network/网络包的封装原理.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"网络包的封装原理\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"在 TCP/IP 四层网络模型中，网络包每层的包装如下：\\r\\n\\r\\n- 传输层，给应用数据前面增加了 TCP 头；\\r\\n- 网络层，给 TCP 数据包前面增加了 IP 头；\\r\\n- 网络接口层，给 IP 数据包前后分别增加了帧头和帧尾；\\r\\n\\r\\n每层增加的头部和尾部，都有每层独特的作用，按照各自的协议填充。\\r\\n\\r\\n在物理链路上并不能传输任意大小的数据包，在以太网中，规定了最大传输单元（MTU）为 1500 字节，规定了单次传输的最大 IP 包的大小。\\r\\n\\r\\n当网络包超过 MTU 时，就会在网络层分片，确保分片后的包不会超过 MTU 大小。\\r\\n\\r\\n- 如果 MTU 越小，网络包分片数越多，那么网络吞吐能力\"},{\"url\":\"/other/network/重传机制.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"重传机制\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"超时重传\\r\\n\\r\\n原理是在发送某一个数据以后就开启一个计时器，在一定时间内如果没有得到发送的数据报的 ACK 报文，那么就重新发送数据，直到发送成功为止。\\r\\n\\r\\n RTT\\r\\n\\r\\nRTT（Round-Trip Time，往返时间）。数据包一次的往返时间。\\r\\n\\r\\n\\r\\n\\r\\nSRTT：平均的RTT\\r\\n\\r\\n 缺点\\r\\n\\r\\n- 当一个报文丢失时，会等待一定的超时周期，才重传分组，增加了端到端的时延。\\r\\n- 当一个报文丢失时，在其等待超时的过程中，可能会出现这种情况：其后的报文段已经被接收端接收但却迟迟得不到确认，发送端会认为也丢失了，从而引起不必要的重传，既浪费资源也浪费时间。\\r\\n- 并且，对于 TCP，如果\"},{\"url\":\"/other/observability/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可观测性常见维度\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"可观测性指的是对于系统内部运行状态的全面洞察和理解能力。\\r\\n\\r\\n可观测性项⽬旨在提供⼯具和解决⽅案，帮助开发⼈员和运维团队更好地监视、调试和理解其应⽤程序的行为。\\r\\n\\r\\n 维度\\r\\n\\r\\n- 日志采集 （log）\\r\\n- 指标采集 （Metric）\\r\\n- 链路追踪（Trace）\\r\\n- 告警管理（AlertManager）\\r\\n- 可视化（Visualization）\\r\\n\\r\\n整个可观测项目，维度除了常见的 log、metric、trace之外。还包括告警和可视化。\\r\\n\\r\\n 指标\\r\\n\\r\\n指标又可以分为：\\r\\n\\r\\n- 基础设施\\r\\n\\r\\n  服务器、数据库、MQ的指标。\\r\\n\\r\\n- 应用维度\\r\\n\\r\\n  应用包含模块\"},{\"url\":\"/other/observability/log/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"日志收集全链路\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"ELFK\\r\\n\\r\\nELFK 指的是 elasticsearch+logstash+filebeat+kibana\\r\\n\\r\\n 日志管理\\r\\n\\r\\n日志收集→格式化分析→检索和可视化→日志告警\\r\\n\\r\\n\\r\\n\\r\\n 日志架构\\r\\n\\r\\n 小规模环境\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n 大规模生产环境\\r\\n\\r\\nELFK + Kafka\\r\\n\\r\\n Logstash\\r\\n\\r\\n从多个来源采集数据，转换数据，然后将数据放到不同的数据库中。\\r\\n\\r\\nda 就很像 logstash 的功能设计。\\r\\n\\r\\n 架构\\r\\n\\r\\n\\r\\n\\r\\nLogstash 接入数据源数据，经过内部 Pipeline，将数据可以写到不同的存储（ES、Kafka）里面。\\r\\n\\r\\nLog\"},{\"url\":\"/other/observability/opentelemetry/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Opentelemetry\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"docs-cn/OT.md at main · open-telemetry/docs-cn\\r\\n\\r\\n OpenTracing&OpenCensus\\r\\n\\r\\n- OpenTracing 制定了一套平台无关、厂商无关的协议标准，使得开发人员能够方便的添加或更换底层 APM 的实现。\\r\\n- OpenCensus支持Metrics、分布式跟踪。\\r\\n\\r\\n OpenTelemetry\\r\\n\\r\\nOpenTelemetry 的核心工作目前主要集中在 3 个部分：\\r\\n\\r\\n1. 规范的制定和协议的统一，规范包含数据传输、API的规范。协议的统一包含：HTTP W3C的标准支持及GRPC 等框架的协议标准。\\r\\n2. 多\"},{\"url\":\"/other/observability/opentelemetry/可观测性.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"可观测性\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"可观测性指的是对于系统内部运行状态的全面洞察和理解能力。\\r\\n\\r\\n可观测性项⽬旨在提供⼯具和解决⽅案，帮助开发⼈员和运维团队更好地监视、调试和理解其应⽤程序的行为。\\r\\n\\r\\n 维度\\r\\n\\r\\n- 日志采集 （log）\\r\\n- 指标采集 （Metric）\\r\\n- 链路追踪（Trace）\\r\\n- 告警管理（AlertManager）\\r\\n- 可视化（Visualization）\\r\\n\\r\\n整个可观测项目，维度除了常见的 log、metric、trace之外。还包括告警和可视化。\\r\\n\\r\\n 指标\\r\\n\\r\\n指标又可以分为：\\r\\n\\r\\n- 基础设施\\r\\n\\r\\n  服务器、数据库、MQ的指标。\\r\\n\\r\\n- 应用维度\\r\\n\\r\\n  应用包含模块\"},{\"url\":\"/other/observability/skywalking/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"Skywalking\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Skywalking\\r\\n\\r\\n- 组件安装\\r\\n- 源码学习\"},{\"url\":\"/other/observability/skywalking/源码学习.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"源码学习\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"Category: SkyWalking | 芋道源码 —— 纯源码解析博客\\r\\n\\r\\nSkyWalking8.7源码解析\\r\\n\\r\\n 告警组件\\r\\n\\r\\n 初始化Kafka消费者\\r\\n\\r\\n```java\\r\\n@Slf4j\\r\\npublic class KafkaFetcherProvider extends ModuleProvider {\\r\\n    private KafkaFetcherHandlerRegister handlerRegister;\\r\\n    private KafkaFetcherConfig config;\\r\\n\\r\\n    @Override\\r\\n    public String na\"},{\"url\":\"/other/observability/skywalking/组件安装.html\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"组件安装\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"OAP\\r\\n\\r\\n- 配置文件\\r\\n  \\r\\n    ```java\\r\\n    apache-skywalking-apm-bin/config/application.yml\\r\\n    ```\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n- 启动脚本\\r\\n  \\r\\n    ```java\\r\\n    sh bin/oapService.sh\\r\\n    ```\\r\\n    \\r\\n\\r\\n UI\\r\\n\\r\\n- 配置\\r\\n  \\r\\n    ```java\\r\\n    apache-skywalking-apm-bin/webapp/webapp.yml\\r\\n    ```\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n- 启动脚本\\r\\n  \\r\\n    ```java\\r\\n\"},{\"url\":\"/personal/\",\"frontmatter\":{},\"author\":{\"name\":\"Albert Yang\",\"link\":\"https://github.com/AlbertYang0801/blog\"},\"title\":\"personal\",\"date\":\"2025-08-14 16:38:51\",\"capture\":\"&lt;div align=\\\"center\\\"\\r\\n  &lt;img src=\\\"https://capsule-render.vercel.app/api?type=waving&color=gradient&height=300&section=header&text=Albert%20Yang&fontSize=90&animation=fadeIn&fontAlignY=38&desc=热爱编程%20|%20追求卓越%20|%20创新思维&descAlignY=55&descAlign=62\\\" /&gt;\\r\\n&lt;/div&gt;\\r\\n&lt;p align=\\\"center\\\" style=\"}]}},\"groupPosts\":{\"categories\":{},\"tags\":{}},\"groupCards\":{\"categories\":[],\"tags\":[]}}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}"));