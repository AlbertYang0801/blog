import{_ as a,c as o,o as r,aM as t}from"./chunks/framework.Du1sph90.js";const m=JSON.parse('{"title":"高水位HW和LEO","description":"","frontmatter":{},"headers":[],"relativePath":"middleware/kafka/高水位HW和LEO.md","filePath":"middleware/kafka/高水位HW和LEO.md","lastUpdated":1752827238000}'),l={name:"middleware/kafka/高水位HW和LEO.md"};function s(p,e,d,n,i,_){return r(),o("div",null,e[0]||(e[0]=[t('<h1 id="高水位hw和leo" tabindex="-1">高水位HW和LEO <a class="header-anchor" href="#高水位hw和leo" aria-label="Permalink to &quot;高水位HW和LEO&quot;">​</a></h1><p><strong>LEO（log_end_offset) 指的是当前分区日志末端的 offset。</strong></p><p>而 HW 指的是整个 LSR 集合副本中，LEO 最小的。保障 Consumer 只能消费到 HW 的位置。</p><p>首先Leader 和 Followers 都有自己的 HW和 LEO，当有新消息写入 Leader 时，Consumer 并不能立即消费。</p><p>Followers 会 pull leader 最新的消息，同步完之后，发送 ACK 给 Leader。然后 Leader会增加 HW。增加之后，新产生的消息才能被 Consumer 消费掉。</p><p><strong>这样的目的是为了保证当 Leader 挂掉之后，重新选举的 Follower 有完整的消息。保证消息不会丢失</strong>。</p><blockquote><p>Kafka 的副本机制，既保证了吞吐率，也保证了数据的一致性。而在 Leader 挂掉的情况下，未及时同步的数据会根据 acks 的配置情况而来，可能存在丢掉未及时同步数据的情况。（acks=0 或acks=1）</p></blockquote><h2 id="数据一致性原理" tabindex="-1">数据一致性原理 <a class="header-anchor" href="#数据一致性原理" aria-label="Permalink to &quot;数据一致性原理&quot;">​</a></h2><p><img src="https://s2.loli.net/2025/06/26/kpqZoBWYaMFy2fQ.png" alt="image.png" loading="lazy"></p><p>引入了 HW高水位机制，能够保证数据在 Leader 和 Follower 副本之间的数据一致性。</p><p>高水位会导致消息必须在所有 LSR集合内副本中复制完成之后，才允许被消费。延长了消息被消费的时间。</p><p>该时间可以通过<code>replica.lag.time.max.ms</code>参数控制，指定了消息在副本之间被允许的最大延迟时间。</p>',12)]))}const f=a(l,[["render",s]]);export{m as __pageData,f as default};
