import{_ as e,c as o,o as r,aN as t}from"./chunks/framework.A-MC8nKA.js";const f=JSON.parse('{"title":"kafka保证消息不丢失","description":"","frontmatter":{},"headers":[],"relativePath":"middleware/kafka/kafka保证消息不丢失.md","filePath":"middleware/kafka/kafka保证消息不丢失.md","lastUpdated":1752827238000}'),l={name:"middleware/kafka/kafka保证消息不丢失.md"};function p(i,a,c,d,n,s){return r(),o("div",null,a[0]||(a[0]=[t('<h1 id="kafka保证消息不丢失" tabindex="-1">kafka保证消息不丢失 <a class="header-anchor" href="#kafka保证消息不丢失" aria-label="Permalink to &quot;kafka保证消息不丢失&quot;">​</a></h1><p><strong>Kafka 只对“已提交”的消息（committed message）做有限度的持久化保证。</strong></p><h2 id="生产者端消息丢失" tabindex="-1">生产者端消息丢失 <a class="header-anchor" href="#生产者端消息丢失" aria-label="Permalink to &quot;生产者端消息丢失&quot;">​</a></h2><p>生产者发送消息的时候，如果没有发到 kafka 导致消息丢失（网络抖动），其实这并不是 kafka 的原因。</p><p><strong>kafka 能保证已经提交到 borker 的数据，不会丢失。</strong></p><p>默认生产者发数据，采用 <code>send(msg)</code>发数据，这样发数据之后生产者并不知道是否发送成功。</p><p>最好使用 <strong><code>producer.send(msg, callback)</code></strong> 发数据，这样通过<code>callback</code>能够清楚的知道消息是否发送成功。</p><h2 id="消费者端消息丢失" tabindex="-1">消费者端消息丢失 <a class="header-anchor" href="#消费者端消息丢失" aria-label="Permalink to &quot;消费者端消息丢失&quot;">​</a></h2><p>Consumer 端丢失数据主要体现在要消费的数据丢了。</p><p><img src="https://s2.loli.net/2025/06/26/3EXpLcS9itFhHPY.png" alt="image.png" loading="lazy"></p><p>Consumer 有个 offset 的概念，记录了消费 topic 数据的位置。</p><p>消费者消费消息丢失数据解决有两种情况：</p><ol><li><p>先消费数据，再更新 offset。</p><p>这样会导致重复消费，比如消费数据完成了，但是更新 offset 失败了。下次消费的时候还从未更新的 offset 开始消费，导致数据重复消费。</p></li><li><p>在多线程异步消费消息的情况。</p><p>在多线程情况下，假如有线程消费数据处理失败，而 offset 已经更新，便会导致消息丢失。</p><p>造成这样的原因是因为消息配置了<code>自动提交</code>，取消自动提交改为<code>手动提交</code>即可。</p></li></ol><p><strong>消费者端解决消息丢失很容易，但是同时会带来消息重复消费的问题。</strong></p><h2 id="参数配置" tabindex="-1">参数配置 <a class="header-anchor" href="#参数配置" aria-label="Permalink to &quot;参数配置&quot;">​</a></h2><h3 id="生产者参数" tabindex="-1">生产者参数 <a class="header-anchor" href="#生产者参数" aria-label="Permalink to &quot;生产者参数&quot;">​</a></h3><ul><li><p><code>acks = all</code></p><p>设置为 all，表示所有leader和在LSR副本中的副本收到消息才算<code>已提交</code>。</p></li><li><p><code>retries</code></p><p>这里设置的是生产者生产消息的重试次数，当设置 &gt; 0时，发送消息如果发生网络波动，生产者可以重试消息发送，避免消息丢失。</p></li></ul><h3 id="broker端参数" tabindex="-1">Broker端参数 <a class="header-anchor" href="#broker端参数" aria-label="Permalink to &quot;Broker端参数&quot;">​</a></h3><ul><li><p><code>unclean.leader.election.enable = false</code></p><p>LSR副本集合以外的副本是否有资格竞选分区的 Leader，<strong>一般设置为 false，防止数据丢失</strong>。</p><blockquote><p>如果某个 broker 落后原先的 leader 数据太多（LSR副本集合以外的副本），竞选为leader 之后会导致集群的数据丢失一部分。因为生产者发数据不保证LSR集合以外的副本收到数据。</p></blockquote></li><li><p><code>replication.factor &gt;= 3</code></p><p>副本数量，将数据多保存几份，防止数据丢失。</p></li><li><p><code>min.insync.replicas &gt; 1</code></p><p>控制写入的消息最少写入几个副本算完成，但是也不建议设置为和副本数一致。这样假如有一个副本挂掉就会导致数据写入不成功。</p><p><strong>推荐设置成 replication.factor = min.insync.replicas + 1。</strong></p></li></ul><h3 id="消费者参数" tabindex="-1">消费者参数 <a class="header-anchor" href="#消费者参数" aria-label="Permalink to &quot;消费者参数&quot;">​</a></h3><ul><li><p><code>enable.auto.commit</code></p><p>消息自动提交，最好不要设置为 true，这样可能导致消息丢失。</p><p>最好设置为 false，然后消费数据后手动提交。</p></li></ul>',21)]))}const h=e(l,[["render",p]]);export{f as __pageData,h as default};
