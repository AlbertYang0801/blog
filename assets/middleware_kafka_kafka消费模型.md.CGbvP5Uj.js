import{_ as t,c as e,o as p,aN as l}from"./chunks/framework.A-MC8nKA.js";const m=JSON.parse('{"title":"kafka消费模型","description":"","frontmatter":{},"headers":[],"relativePath":"middleware/kafka/kafka消费模型.md","filePath":"middleware/kafka/kafka消费模型.md","lastUpdated":1752827238000}'),o={name:"middleware/kafka/kafka消费模型.md"};function r(n,a,i,k,s,c){return p(),e("div",null,a[0]||(a[0]=[l('<h1 id="kafka消费模型" tabindex="-1">kafka消费模型 <a class="header-anchor" href="#kafka消费模型" aria-label="Permalink to &quot;kafka消费模型&quot;">​</a></h1><p>kafka消费模型分为两种。</p><ol><li><p>消费组消费</p><p>消费组里面的单个消费者消费一个分区的数据。</p><blockquote><p>如果消费者数量大于分区数量，则多余的消费者不消费分区的数据。所以若采用这种消费模型，应 保证消费者数量和分区数量一致。</p></blockquote><p><img src="https://s2.loli.net/2025/06/26/ga5sFodDmb3ikf9.png" alt="20220308113526.png" loading="lazy"></p></li><li><p>消费者-worker进程消费。</p></li></ol><p><img src="https://s2.loli.net/2025/06/26/9paiUIGQxw54Yqo.png" alt="20220307152737.png" loading="lazy"></p><blockquote><p>第一种消费模型，每个分区对应一个 consumer。</p></blockquote><p>第二种消费模型，只消费数据不处理，处理的工作单独交给 worker线程池，这样可以避免很多 consumer产生的问题。不要把很重的处理逻辑放到消费者中。</p><blockquote><p>难以保证 offset 的语义正确性，可能导致重复消费。</p></blockquote><p><img src="https://s2.loli.net/2025/06/26/mQFtJ7b3dEprOLz.png" alt="image.png" loading="lazy"></p><hr><p>da的kafka消费者数量只有 1 个，单线程去消费数据，使用 while 循环，不断地去 poll 数据（单次最多500条）。</p><blockquote><p>若要提高消费者数量，可以多开几个线程来执行 while 循环。</p></blockquote><p><img src="https://s2.loli.net/2025/06/26/bunjlqgUVAhX2RN.png" alt="20220307152311.png" loading="lazy"></p><p>单线程消费的情况下，为了提高数据处理速度，使用了10个worker线程来处理数据，poll 到数据后，直接提交数据到worker线程池进行数据处理。</p><p><img src="https://s2.loli.net/2025/06/26/XifcoAsSEMmOuJp.png" alt="20220307153101.png" loading="lazy"></p><hr><p><a href="https://www.cnblogs.com/huxi2b/p/6124937.html" target="_blank" rel="noreferrer">https://www.cnblogs.com/huxi2b/p/6124937.html</a></p><p><a href="https://www.cnblogs.com/huxi2b/p/6124937.html" target="_blank" rel="noreferrer">【原创】Kafka Consumer多线程实例 - huxihx - 博客园</a></p>',17)]))}const d=t(o,[["render",r]]);export{m as __pageData,d as default};
