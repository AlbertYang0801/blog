import{_ as s,c as i,o as e,aM as n}from"./chunks/framework.Du1sph90.js";const g=JSON.parse('{"title":"redis的持久化","description":"","frontmatter":{},"headers":[],"relativePath":"database/redis/redis的持久化.md","filePath":"database/redis/redis的持久化.md","lastUpdated":1752827238000}'),t={name:"database/redis/redis的持久化.md"};function l(r,a,p,o,h,d){return e(),i("div",null,a[0]||(a[0]=[n(`<h1 id="redis的持久化" tabindex="-1">redis的持久化 <a class="header-anchor" href="#redis的持久化" aria-label="Permalink to &quot;redis的持久化&quot;">​</a></h1><p>redis 有 <strong>RDB</strong> 和 <strong>AOF</strong> 两种持久化方式。</p><h2 id="rdb" tabindex="-1">RDB <a class="header-anchor" href="#rdb" aria-label="Permalink to &quot;RDB&quot;">​</a></h2><p>RDB 是 <em>Redis DataBase</em> 的简称，指的是在指定时间间隔内将内存中的数据集快照写入磁盘文件，也就是 Snapshot 快照，RDB 是<strong>默认开启</strong>的。</p><h3 id="rdb的原理" tabindex="-1">RDB的原理 <a class="header-anchor" href="#rdb的原理" aria-label="Permalink to &quot;RDB的原理&quot;">​</a></h3><p>Redis 会单独创建 （fork）一个子进程来进行持久化操作，将内存中某一时刻的数据持久化到磁盘文件。这个子进程会先将数据写入到一个临时文件中，等待持久化进程结束后，再用这个临时文件替换掉磁盘文件。</p><p><img src="https://s2.loli.net/2025/06/18/DizMFRYleJAsIEa.png" alt="" loading="lazy"></p><p>在整个过程中，<strong>主进程是不进行任何 IO 操作的</strong>，这样保证了主进程存取的高性能。</p><p>RDB 的持久化过程每次都是<strong>全量存储</strong>，但是 RDB 可能由于系统宕机等问题导致<strong>最后一次持久化的数据丢失</strong>。</p><h3 id="rdb的同步策略" tabindex="-1">RDB的同步策略 <a class="header-anchor" href="#rdb的同步策略" aria-label="Permalink to &quot;RDB的同步策略&quot;">​</a></h3><p>RDB 的配置文件存在 redis.conf 中。</p><div class="language-java vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">java</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">#900秒（15分钟）后，如果至少有一个key更新</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">save </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">900</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">#300秒（5分钟）后，如果至少更改了10个key</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">save </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">300</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">#60秒后，如果至少10000个key发生更改</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">save </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">60</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 10000</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>redis.conf 中配置内容如下：</p><p><img src="https://s2.loli.net/2025/06/18/qIKrwXRtVjZhayS.png" alt="" loading="lazy"></p><h3 id="rdb如何恢复数据" tabindex="-1">RDB如何恢复数据 <a class="header-anchor" href="#rdb如何恢复数据" aria-label="Permalink to &quot;RDB如何恢复数据&quot;">​</a></h3><p>RDB持久化的磁盘文件为 <strong>dump.rdb</strong>，redis 在启动的时候会加载该文件中的数据到内存中。</p><p><img src="https://s2.loli.net/2025/06/18/Ol192dQMnyRzvUN.png" alt="" loading="lazy"></p><h3 id="rdb的优缺点" tabindex="-1">RDB的优缺点 <a class="header-anchor" href="#rdb的优缺点" aria-label="Permalink to &quot;RDB的优缺点&quot;">​</a></h3><p><strong>RDB的优点</strong></p><ol><li>适合大规模的数据恢复。</li><li>对数据完整性和一致性要求不高。</li><li>通过 fork 子进程同步，不影响主进程。</li></ol><p><strong>RDB的缺点</strong></p><ol><li><p>存在<strong>丢失最后一次数据的风险</strong>。</p><p><em>若在最后一次数据持久化之前发生宕机清空，就会导致最后一次数据丢失。</em></p></li><li><p>在持久化过程中，fork 子进程<strong>全量存储</strong>内存中的数据，导致内存中的数据被全量复制了一份，占用内存空间。</p></li></ol><h2 id="aof" tabindex="-1">AOF <a class="header-anchor" href="#aof" aria-label="Permalink to &quot;AOF&quot;">​</a></h2><p>AOF 是 <em>Append Only File</em> 的简称，指的是<strong>以日志的形式来记录每个写操作，将 Redis 执行过的所有写指令记录下来，读操作不记录</strong>。</p><h3 id="aof的原理" tabindex="-1">AOF的原理 <a class="header-anchor" href="#aof的原理" aria-label="Permalink to &quot;AOF的原理&quot;">​</a></h3><p>AOF 的机制只允许<strong>追加文件</strong>但不可以改写文件，</p><p>redis 启动的时候会加载该日志文件，根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复。</p><p><img src="https://s2.loli.net/2025/06/18/ZC9WMA8nzhXGmDt.png" alt="" loading="lazy"></p><h3 id="aof的开启" tabindex="-1">AOF的开启 <a class="header-anchor" href="#aof的开启" aria-label="Permalink to &quot;AOF的开启&quot;">​</a></h3><p>AOF 保存的日志文件是 <strong>appendonly.aof</strong> 文件。</p><p>在 redis 中默认是不开启 AOF 的，可以在 <strong>redis.conf</strong> 修改配置 <code>appendpnly no</code> 为 <code>appendonly yes</code> 即可开启 AOF。</p><p><img src="https://s2.loli.net/2025/06/18/n7pZyNfr6mlwJ3s.png" alt="" loading="lazy"></p><h3 id="aof的同步策略" tabindex="-1">AOF的同步策略 <a class="header-anchor" href="#aof的同步策略" aria-label="Permalink to &quot;AOF的同步策略&quot;">​</a></h3><p>AOF包含三种同步策略。</p><ol><li><p>每次修改同步-<code>appendfsync always</code></p><p>每次发生数据变更便记录到磁盘中，由于持久化频率高，所以性能较差。但是数据完整性比较好。</p></li><li><p>每秒同步-<code>appendfsync everysec</code></p><p>异步每秒记录数据，若发生宕机。可能丢失一秒内的数据。</p></li><li><p>不同步-<code>appendfsync no</code></p><p>从不同步。</p></li></ol><p><img src="https://s2.loli.net/2025/06/18/RKXg8awD6UVb1Gm.png" alt="" loading="lazy"></p><h3 id="aof如何恢复数据" tabindex="-1">AOF如何恢复数据 <a class="header-anchor" href="#aof如何恢复数据" aria-label="Permalink to &quot;AOF如何恢复数据&quot;">​</a></h3><p>AOF 的日志文件 <strong>appendonly.aof</strong> 默认存在 redis 的根目录下，也可以使用 <code>config get dir</code> 命令查看目录。</p><p><img src="https://s2.loli.net/2025/06/18/3KtEnwCXIqib2pN.png" alt="" loading="lazy"></p><p>正常情况开启了 AOF 之后，redis 会加载日志文件，并从前向后执行日志文件中的写指令来恢复数据。</p><p>当异常情况 AOF 文件被写坏时，可以使用 <code>redis-check-aof --fix</code> 命令进行修复，然后重启就可以重新加载数据。</p><h3 id="aof的重写原理" tabindex="-1">AOF的重写原理 <a class="header-anchor" href="#aof的重写原理" aria-label="Permalink to &quot;AOF的重写原理&quot;">​</a></h3><h3 id="为什么需要重写" tabindex="-1">为什么需要重写？ <a class="header-anchor" href="#为什么需要重写" aria-label="Permalink to &quot;为什么需要重写？&quot;">​</a></h3><p>由于AOF采用的是日志追加方式，文件会越来越大，为避免文件过大，新增了重写机制。当 AOF 文件超过指定阀值的时候，AOF 就会启动内容压缩，只保留可以恢复数据的最小指令集。</p><p><em>由于 AOF 每个写指令都追加到日志文件中，可能出现 AOF 文件出现多个相同 key 的写指令（内存中保存的是最后一个写指令的值），所以可以根据内存中的数据对 AOF 日志文件进行压缩。</em></p><h3 id="重写原理" tabindex="-1">重写原理 <a class="header-anchor" href="#重写原理" aria-label="Permalink to &quot;重写原理&quot;">​</a></h3><p>当 AOF 文件超过指定阀值的时候，会 fork 出新进程来重写日志文件（重写过程类似 RDB，先写临时文件再替换）。遍历内存中的所有数据，针对每个数据生成写指令，存入 AOF 文件中。<strong>重写的过程读取的是内存中的数据</strong>，而不是旧的 AOF 文件，类似于 RDB 的存储方式。</p><h3 id="触发机制" tabindex="-1">触发机制 <a class="header-anchor" href="#触发机制" aria-label="Permalink to &quot;触发机制&quot;">​</a></h3><p>redis 会记录上次重写时的 AOF 日志文件大小，默认配置是<strong>当 AOF 日志文件大小是上次重写后大小的一倍并且文件大小大于 64 MB 时触发</strong>。</p><div class="language-java vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">java</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">#重写时候的百分比，默认是100</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">%</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">auto</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">aof</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">rewrite</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">percentage </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">100</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">#日志文件最小大小</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">auto</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">aof</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">rewrite</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">min</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">size 64mb</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>该配置在 redis.conf 中如下所示：</p><p><img src="https://s2.loli.net/2025/06/18/5qr69E3tcWUsZLw.png" alt="" loading="lazy"></p><h3 id="aof的优缺点" tabindex="-1">AOF的优缺点 <a class="header-anchor" href="#aof的优缺点" aria-label="Permalink to &quot;AOF的优缺点&quot;">​</a></h3><p><strong>AOF的优点</strong></p><ol><li>AOF 的数据完整性和实时性比较好。</li><li>AOF 存在重写压缩机制，保证日志文件不至于过大。</li></ol><p><strong>AOF的缺点</strong></p><ol><li>根据 AOF 的同步策略，<strong>可能会丢失最后一条数据或最后一秒的数据</strong>。</li><li>相同大小的数据，AOF 文件要远大于 RDB 文件，恢复速度也小于 RDB 文件。</li><li>AOF 运行效率低于 RDB，每秒同步一次效率较好。</li></ol><h2 id="rdb和aof的对比" tabindex="-1">RDB和AOF的对比 <a class="header-anchor" href="#rdb和aof的对比" aria-label="Permalink to &quot;RDB和AOF的对比&quot;">​</a></h2><p>RDB 持久化方式能够在<strong>指定时间间隔内对数据进行快照存储</strong>。</p><p>AOF 持久化方式<strong>记录每次写指令</strong>，当服务器重启时按照顺序执行这些写指令来恢复数据。其中 AOF 还存在<strong>重写压缩</strong>机制，保证 AOF 文件不至于过大。</p><h3 id="同时开启时的生效规则" tabindex="-1">同时开启时的生效规则 <a class="header-anchor" href="#同时开启时的生效规则" aria-label="Permalink to &quot;同时开启时的生效规则&quot;">​</a></h3><p>当同时开启 RDB（默认开启） 和 AOF（手动开启） 时，redis 会<strong>优先载入 AOF 文件来恢复数据</strong>，也就是以 AOF 文件数据为准。</p><p>因为 AOF 的日志文件数据保存比较完整，而 RDB 的数据并不实时，所以同时开启时会以 AOF 文件为准。</p><h3 id="如何选择持久化方式" tabindex="-1">如何选择持久化方式 <a class="header-anchor" href="#如何选择持久化方式" aria-label="Permalink to &quot;如何选择持久化方式&quot;">​</a></h3><blockquote><p>因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留 <code>save 900 1</code> 这条规则。</p></blockquote><p>如果 Enalbe AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了。代价一是带来了持续的IO，二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。</p><p>如果不 Enable AOF ，仅靠Master-Slave Replication 实现高可用性也可以。能省掉一大笔IO也减少了rewrite时带来的系统波动。代价是如果Master/Slave同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个Master/Slave中的RDB文件，载入较新的那个。新浪微博就选用了这种架构</p><ul><li>如果 redis 只做缓存，则可以不用任何持久化方式。</li><li>若作为后备数据库使用，最好使用 RDB，因为 AOF 不断变化不容易备份。</li><li>最好同时开启 AOF 和 RDB，其中 AOF 保证数据完整，RDB 作为后备使用。</li></ul>`,68)]))}const c=s(t,[["render",l]]);export{g as __pageData,c as default};
